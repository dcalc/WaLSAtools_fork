{"config": {"indexing": "full", "lang": ["en"], "min_search_length": 3, "prebuild_index": false, "separator": "[\\s\\-]+"}, "docs": [{"location": "", "text": "", "title": "Home"}, {"location": "acknowledgements/", "text": "Acknowledgements \u00b6 We sincerely acknowledge all individuals who have contributed to the development of WaLSAtools , as well as third parties whose codes have been utilized within the package. WaLSAtools is the outcome of collaborative scientific discussions within the WaLSA team , supported by the Research Council of Norway (project no. 262622), The Royal Society (award no. Hooke18b/SCTM), and the International Space Science Institute (ISSI Team 502). While every effort has been made to ensure the accuracy and completeness of the acknowledgements, errors may occur. If you notice any omissions or inaccuracies, please help us improve this document by opening an issue or pull request on GitHub . Related Work and Support \u00b6 WaLSAtools development is inspired by and connected to the introductory review article: \"Wave analysis tools\" \u2013 Jafarzadeh et al. (2025), Nature Reviews Methods Primers For a full list of contributors to WaLSAtools, see our Contributors page. For citation details and co-authorship of the foundational review article, see our Citation page. Python Library Dependencies \u00b6 WaLSAtools relies on several Python libraries to deliver its functionality. These libraries are widely used in the scientific computing community and facilitate efficient data processing, visualization, and user interaction. The following Python libraries are used as core dependencies: numpy astropy ipython ipywidgets matplotlib numba pyFFTW PyEMD PyCWT scipy setuptools scikit-image tqdm We are grateful to the developers of these libraries for their contributions to open-source software, which greatly enhance the capabilities of WaLSAtools . Please refer to the respective library documentation for licensing details and additional information. IDL Libraries \u00b6 WaLSAtools incorporates several third-party components from publicly available IDL libraries. Most are bundled within the package, requiring no separate installation. Only standard IDL routines (built-in or from the native IDL library of version 8.5 and above) are not included. IDL is a registered trademark of NV5 Geospatial Solutions, Inc. Solarsoft Coyote Library (Prof. David Fanning) RRIDL (Prof. Rob J. Rutten) \u2014 (1942-2022) \u2014 in memoriam Daithi Library (Dr. D\u00e1ith\u00ed A. Stone) HeLIx+ (Dr. Andreas Korpi-Lagg)", "title": "Acknowledgements"}, {"location": "acknowledgements/#acknowledgements", "text": "We sincerely acknowledge all individuals who have contributed to the development of WaLSAtools , as well as third parties whose codes have been utilized within the package. WaLSAtools is the outcome of collaborative scientific discussions within the WaLSA team , supported by the Research Council of Norway (project no. 262622), The Royal Society (award no. Hooke18b/SCTM), and the International Space Science Institute (ISSI Team 502). While every effort has been made to ensure the accuracy and completeness of the acknowledgements, errors may occur. If you notice any omissions or inaccuracies, please help us improve this document by opening an issue or pull request on GitHub .", "title": "Acknowledgements"}, {"location": "acknowledgements/#related-work-and-support", "text": "WaLSAtools development is inspired by and connected to the introductory review article: \"Wave analysis tools\" \u2013 Jafarzadeh et al. (2025), Nature Reviews Methods Primers For a full list of contributors to WaLSAtools, see our Contributors page. For citation details and co-authorship of the foundational review article, see our Citation page.", "title": "Related Work and Support"}, {"location": "acknowledgements/#python-library-dependencies", "text": "WaLSAtools relies on several Python libraries to deliver its functionality. These libraries are widely used in the scientific computing community and facilitate efficient data processing, visualization, and user interaction. The following Python libraries are used as core dependencies: numpy astropy ipython ipywidgets matplotlib numba pyFFTW PyEMD PyCWT scipy setuptools scikit-image tqdm We are grateful to the developers of these libraries for their contributions to open-source software, which greatly enhance the capabilities of WaLSAtools . Please refer to the respective library documentation for licensing details and additional information.", "title": "Python Library Dependencies"}, {"location": "acknowledgements/#idl-libraries", "text": "WaLSAtools incorporates several third-party components from publicly available IDL libraries. Most are bundled within the package, requiring no separate installation. Only standard IDL routines (built-in or from the native IDL library of version 8.5 and above) are not included. IDL is a registered trademark of NV5 Geospatial Solutions, Inc. Solarsoft Coyote Library (Prof. David Fanning) RRIDL (Prof. Rob J. Rutten) \u2014 (1942-2022) \u2014 in memoriam Daithi Library (Dr. D\u00e1ith\u00ed A. Stone) HeLIx+ (Dr. Andreas Korpi-Lagg)", "title": "IDL Libraries"}, {"location": "changelog/", "text": "Changelog \u00b6 WaLSAtools \u00b6 1.0.0 _ January 05, 2025 _ \u00b6 Initial Release This is the first official release of WaLSAtools, a comprehensive open-source library for wave analysis. This release includes: Core Analysis Modules: Fast Fourier Transform (FFT) Lomb-Scargle Periodogram Wavelet Transform Hilbert-Huang Transform (HHT) Welch's Method k-\u03c9 Analysis Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis Interactive Interface: User-friendly interface for easy access to analysis tools and parameters. Worked Examples: Reproducible examples demonstrating the application of WaLSAtools to synthetic datasets (presented in a Nature Reviews Methods Primers article) Documentation: Comprehensive documentation covering installation, usage, and analysis methods. Multi-Language Support: Available in Python and IDL. We are excited to share WaLSAtools with the community and look forward to your feedback and contributions.", "title": "Changelog"}, {"location": "changelog/#changelog", "text": "", "title": "Changelog"}, {"location": "changelog/#walsatools", "text": "", "title": "WaLSAtools"}, {"location": "changelog/#100-_-january-05-2025-_", "text": "Initial Release This is the first official release of WaLSAtools, a comprehensive open-source library for wave analysis. This release includes: Core Analysis Modules: Fast Fourier Transform (FFT) Lomb-Scargle Periodogram Wavelet Transform Hilbert-Huang Transform (HHT) Welch's Method k-\u03c9 Analysis Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis Interactive Interface: User-friendly interface for easy access to analysis tools and parameters. Worked Examples: Reproducible examples demonstrating the application of WaLSAtools to synthetic datasets (presented in a Nature Reviews Methods Primers article) Documentation: Comprehensive documentation covering installation, usage, and analysis methods. Multi-Language Support: Available in Python and IDL. We are excited to share WaLSAtools with the community and look forward to your feedback and contributions.", "title": "1.0.0 _ January 05, 2025 _"}, {"location": "citation/", "text": "How to Cite WaLSAtools \u00b6 If you use WaLSAtools in your work, please cite it as described below in your publications or presentations. Main Article and Software Package \u00b6 Wave analysis tools: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 Free read-only access: https://WaLSA.tools/nrmp Supplementary Information: https://WaLSA.tools/nrmp-si @ARTICLE { 2025NRvMP...5...21J, author = {{ Jafarzadeh } , Shahin and { Jess } , David B. and { Stangalini } , Marco and { Grant } , Samuel D.~T. and { Higham } , Jonathan E. and { Pessah } , Martin E. and { Keys } , Peter H. and { Belov } , Sergey and { Calchetti } , Daniele and { Duckenfield } , Timothy J. and { Fedun } , Viktor and { Fleck } , Bernhard and { Gafeira } , Ricardo and { Jefferies } , Stuart M. and { Khomenko } , Elena and { Morton } , Richard J. and { Norton } , Aimee A. and { Rajaguru } , S.~P. and { Schiavo } , Luiz A.~C.~A. and { Sharma } , Rahul and { Silva } , Suzana S.~A. and { Solanki } , Sami K. and { Steiner } , Oskar and { Verth } , Gary and { Vigeesh } , Gangadharan and { Yadav } , Nitin } , title = \" { Wave analysis tools } \", journal = { Nature Reviews Methods Primers } , keywords = { Waves, Oscillations, Methods } , year = 2025, month = apr, volume = { 5 } , eid = { 21 } , pages = { 21 } , doi = { 10.1038/s43586-025-00392-0 } , adsurl = { https://ui.adsabs.harvard.edu/abs/2025NRvMP...5...21J } , adsnote = { Provided by the SAO/NASA Astrophysics Data System } } Jafarzadeh, S., Jess, D. B., Stangalini, M., et al. 2025, WaLSAtools, WaLSA Team (GitHub) / Zenodo, doi: 10.5281/zenodo.14978610 Other Relevant Scientific Articles \u00b6 Waves in the Lower Solar Atmosphere: The Dawn of Next-Generation Solar Telescopes : Jess, D. B., Jafarzadeh, S., Keys, P. H., Stangalini, M., Verth, G., Grant, S. D. T. 2023, Living Reviews in Solar Physics, 20, 1 ( ADS ) @ARTICLE { 2023LRSP...20....1J, author = {{ Jess } , David B. and { Jafarzadeh } , Shahin and { Keys } , Peter H. and { Stangalini } , Marco and { Verth } , Gary and { Grant } , Samuel D.~T. } , title = \" { Waves in the lower solar atmosphere: the dawn of next-generation solar telescopes } \", journal = { Living Reviews in Solar Physics } , keywords = { Shock waves, Sun: chromosphere, Sun: oscillations, Sun: photosphere, Telescopes, Astrophysics - Solar and Stellar Astrophysics } , year = 2023, month = dec, volume = { 20 } , number = { 1 } , eid = { 1 } , pages = { 1 } , doi = { 10.1007/s41116-022-00035-6 } , archivePrefix = { arXiv } , eprint = { 2212.09788 } , primaryClass = { astro-ph.SR } , adsurl = { https://ui.adsabs.harvard.edu/abs/2023LRSP...20....1J } , adsnote = { Provided by the SAO/NASA Astrophysics Data System } } Articles for particular functions \u00b6 If you use any specific analysis techniques provided by WaLSAtools, please also cite the original publications where these codes or approaches were first introduced. k-\u03c9 Analysis and Fourier Filtering : Jess et al. 2017, The Astrophysical Journal, 842, 59 ( ADS ) @ARTICLE { 2017ApJ...842...59J, author = {{ Jess } , David B. and { Van Doorsselaere } , Tom and { Verth } , Gary and { Fedun } , Viktor and { Krishna Prasad } , S. and { Erd { \\' e } lyi } , Robert and { Keys } , Peter H. and { Grant } , Samuel D.~T. and { Uitenbroek } , Han and { Christian } , Damian J. } , title = \" { An Inside Look at Sunspot Oscillations with Higher Azimuthal Wavenumbers } \", journal = { \\apj } , keywords = { Sun: chromosphere, Sun: magnetic fields, Sun: oscillations, Sun: photosphere, sunspots, Astrophysics - Solar and Stellar Astrophysics } , year = 2017, month = jun, volume = { 842 } , number = { 1 } , eid = { 59 } , pages = { 59 } , doi = { 10.3847/1538-4357/aa73d6 } , archivePrefix = { arXiv } , eprint = { 1705.06282 } , primaryClass = { astro-ph.SR } , adsurl = { https://ui.adsabs.harvard.edu/abs/2017ApJ...842...59J } , adsnote = { Provided by the SAO/NASA Astrophysics Data System } }", "title": "Citation"}, {"location": "citation/#how-to-cite-walsatools", "text": "If you use WaLSAtools in your work, please cite it as described below in your publications or presentations.", "title": "How to Cite WaLSAtools"}, {"location": "citation/#main-article-and-software-package", "text": "Wave analysis tools: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 Free read-only access: https://WaLSA.tools/nrmp Supplementary Information: https://WaLSA.tools/nrmp-si @ARTICLE { 2025NRvMP...5...21J, author = {{ Jafarzadeh } , Shahin and { Jess } , David B. and { Stangalini } , Marco and { Grant } , Samuel D.~T. and { Higham } , Jonathan E. and { Pessah } , Martin E. and { Keys } , Peter H. and { Belov } , Sergey and { Calchetti } , Daniele and { Duckenfield } , Timothy J. and { Fedun } , Viktor and { Fleck } , Bernhard and { Gafeira } , Ricardo and { Jefferies } , Stuart M. and { Khomenko } , Elena and { Morton } , Richard J. and { Norton } , Aimee A. and { Rajaguru } , S.~P. and { Schiavo } , Luiz A.~C.~A. and { Sharma } , Rahul and { Silva } , Suzana S.~A. and { Solanki } , Sami K. and { Steiner } , Oskar and { Verth } , Gary and { Vigeesh } , Gangadharan and { Yadav } , Nitin } , title = \" { Wave analysis tools } \", journal = { Nature Reviews Methods Primers } , keywords = { Waves, Oscillations, Methods } , year = 2025, month = apr, volume = { 5 } , eid = { 21 } , pages = { 21 } , doi = { 10.1038/s43586-025-00392-0 } , adsurl = { https://ui.adsabs.harvard.edu/abs/2025NRvMP...5...21J } , adsnote = { Provided by the SAO/NASA Astrophysics Data System } } Jafarzadeh, S., Jess, D. B., Stangalini, M., et al. 2025, WaLSAtools, WaLSA Team (GitHub) / Zenodo, doi: 10.5281/zenodo.14978610", "title": "Main Article and Software Package"}, {"location": "citation/#other-relevant-scientific-articles", "text": "Waves in the Lower Solar Atmosphere: The Dawn of Next-Generation Solar Telescopes : Jess, D. B., Jafarzadeh, S., Keys, P. H., Stangalini, M., Verth, G., Grant, S. D. T. 2023, Living Reviews in Solar Physics, 20, 1 ( ADS ) @ARTICLE { 2023LRSP...20....1J, author = {{ Jess } , David B. and { Jafarzadeh } , Shahin and { Keys } , Peter H. and { Stangalini } , Marco and { Verth } , Gary and { Grant } , Samuel D.~T. } , title = \" { Waves in the lower solar atmosphere: the dawn of next-generation solar telescopes } \", journal = { Living Reviews in Solar Physics } , keywords = { Shock waves, Sun: chromosphere, Sun: oscillations, Sun: photosphere, Telescopes, Astrophysics - Solar and Stellar Astrophysics } , year = 2023, month = dec, volume = { 20 } , number = { 1 } , eid = { 1 } , pages = { 1 } , doi = { 10.1007/s41116-022-00035-6 } , archivePrefix = { arXiv } , eprint = { 2212.09788 } , primaryClass = { astro-ph.SR } , adsurl = { https://ui.adsabs.harvard.edu/abs/2023LRSP...20....1J } , adsnote = { Provided by the SAO/NASA Astrophysics Data System } }", "title": "Other Relevant Scientific Articles"}, {"location": "citation/#articles-for-particular-functions", "text": "If you use any specific analysis techniques provided by WaLSAtools, please also cite the original publications where these codes or approaches were first introduced. k-\u03c9 Analysis and Fourier Filtering : Jess et al. 2017, The Astrophysical Journal, 842, 59 ( ADS ) @ARTICLE { 2017ApJ...842...59J, author = {{ Jess } , David B. and { Van Doorsselaere } , Tom and { Verth } , Gary and { Fedun } , Viktor and { Krishna Prasad } , S. and { Erd { \\' e } lyi } , Robert and { Keys } , Peter H. and { Grant } , Samuel D.~T. and { Uitenbroek } , Han and { Christian } , Damian J. } , title = \" { An Inside Look at Sunspot Oscillations with Higher Azimuthal Wavenumbers } \", journal = { \\apj } , keywords = { Sun: chromosphere, Sun: magnetic fields, Sun: oscillations, Sun: photosphere, sunspots, Astrophysics - Solar and Stellar Astrophysics } , year = 2017, month = jun, volume = { 842 } , number = { 1 } , eid = { 59 } , pages = { 59 } , doi = { 10.3847/1538-4357/aa73d6 } , archivePrefix = { arXiv } , eprint = { 1705.06282 } , primaryClass = { astro-ph.SR } , adsurl = { https://ui.adsabs.harvard.edu/abs/2017ApJ...842...59J } , adsnote = { Provided by the SAO/NASA Astrophysics Data System } }", "title": "Articles for particular functions"}, {"location": "contribution/", "text": "Contribution \u00b6 WaLSAtools is an open-access and open-source library designed for researchers across diverse fields interested in analyzing oscillatory phenomena. Initially developed and maintained by the WaLSA team , the project is driven by a commitment to openness, transparency, and reproducibility in research. By sharing this evolving codebase on GitHub , we aim to foster collaboration, enabling contributions from a broad community to refine and extend its functionality. We welcome feedback, suggestions, and contributions that help improve WaLSAtools and expand its applications. The WaLSAtools package provided here marks the beginning of an exciting journey. We envision that the broader community will contribute to advancing these tools and methodologies. The core of WaLSAtools is built upon Python, a widely-used programming language in science and engineering, ensuring accessibility and ease of use for a broad audience. To further enhance accessibility, we are actively developing counterparts in other popular languages. Currently, WaLSAtools is also available (partially) in IDL, with plans to expand to additional languages, such as MATLAB, in the future. Contributions of all kinds are welcome and highly appreciated! GitHub \u00b6 WaLSAtools is managed using Git as a distributed version control system and is hosted on GitHub . To contribute, you will need a GitHub account . Contributions can take various forms, such as forking the repository to submit changes via a pull request , reporting issues , or engaging in discussions directly on GitHub. If you are new to GitHub, we recommend exploring these guides and resources . Bug Reports \u00b6 Bugs are tracked through the GitHub issue tracker . Before submitting a new bug report , please consult the Introduction and Troubleshooting sections under Getting Started . Additionally, search the existing issues database to see if your question or concern has already been addressed. When reporting a bug, please include the following details: WaLSAtools version Version of Python or IDL Operating System and version Any error messages or terminal/Jupyter-notebook output A clear and detailed description of the issue Examples for reproducing the error (including plain text code or steps). Providing detailed and accurate information increases the likelihood of a prompt and effective resolution. If you are unsure whether something is a bug, consider posting your question in our GitHub discussions first. Feature Requests \u00b6 We encourage users to suggest new features, analysis methods, or additional functionality. You can share your ideas in the Wish List section of our GitHub discussions . Before submitting a feature request, please verify that it is not already Under Development . Reviewing Codes and Methods \u00b6 The quality and reliability of the WaLSAtools codes and methods are our top priorities. We invite you to participate in code reviews, examine pull requests , and provide suggestions for improvement. Discussions about solutions or potential enhancements to the methods are also welcome. For general questions or comments, please use the GitHub discussions . Answering Questions \u00b6 We encourage researchers across diverse fields to actively support one another by responding to questions posted in the issue tracker or GitHub discussions . Sharing your expertise and experiences can be invaluable to others facing similar challenges or looking for advice on specific tasks. Pull Requests \u00b6 Pull requests are a key way to contribute to WaLSAtools . Whether fixing bugs or adding new features, we value your input. For details on setting up a development environment and understanding the contribution process, please refer to the Development page. Documentation Improvements \u00b6 We strive to provide not only reliable and user-friendly tools but also comprehensive documentation and examples. If you identify areas where the documentation can be enhanced, your contributions are highly appreciated. Guidance on editing documentation is available on the Development page.", "title": "Contribution"}, {"location": "contribution/#contribution", "text": "WaLSAtools is an open-access and open-source library designed for researchers across diverse fields interested in analyzing oscillatory phenomena. Initially developed and maintained by the WaLSA team , the project is driven by a commitment to openness, transparency, and reproducibility in research. By sharing this evolving codebase on GitHub , we aim to foster collaboration, enabling contributions from a broad community to refine and extend its functionality. We welcome feedback, suggestions, and contributions that help improve WaLSAtools and expand its applications. The WaLSAtools package provided here marks the beginning of an exciting journey. We envision that the broader community will contribute to advancing these tools and methodologies. The core of WaLSAtools is built upon Python, a widely-used programming language in science and engineering, ensuring accessibility and ease of use for a broad audience. To further enhance accessibility, we are actively developing counterparts in other popular languages. Currently, WaLSAtools is also available (partially) in IDL, with plans to expand to additional languages, such as MATLAB, in the future. Contributions of all kinds are welcome and highly appreciated!", "title": "Contribution"}, {"location": "contribution/#github", "text": "WaLSAtools is managed using Git as a distributed version control system and is hosted on GitHub . To contribute, you will need a GitHub account . Contributions can take various forms, such as forking the repository to submit changes via a pull request , reporting issues , or engaging in discussions directly on GitHub. If you are new to GitHub, we recommend exploring these guides and resources .", "title": "GitHub"}, {"location": "contribution/#bug-reports", "text": "Bugs are tracked through the GitHub issue tracker . Before submitting a new bug report , please consult the Introduction and Troubleshooting sections under Getting Started . Additionally, search the existing issues database to see if your question or concern has already been addressed. When reporting a bug, please include the following details: WaLSAtools version Version of Python or IDL Operating System and version Any error messages or terminal/Jupyter-notebook output A clear and detailed description of the issue Examples for reproducing the error (including plain text code or steps). Providing detailed and accurate information increases the likelihood of a prompt and effective resolution. If you are unsure whether something is a bug, consider posting your question in our GitHub discussions first.", "title": "Bug Reports"}, {"location": "contribution/#feature-requests", "text": "We encourage users to suggest new features, analysis methods, or additional functionality. You can share your ideas in the Wish List section of our GitHub discussions . Before submitting a feature request, please verify that it is not already Under Development .", "title": "Feature Requests"}, {"location": "contribution/#reviewing-codes-and-methods", "text": "The quality and reliability of the WaLSAtools codes and methods are our top priorities. We invite you to participate in code reviews, examine pull requests , and provide suggestions for improvement. Discussions about solutions or potential enhancements to the methods are also welcome. For general questions or comments, please use the GitHub discussions .", "title": "Reviewing Codes and Methods"}, {"location": "contribution/#answering-questions", "text": "We encourage researchers across diverse fields to actively support one another by responding to questions posted in the issue tracker or GitHub discussions . Sharing your expertise and experiences can be invaluable to others facing similar challenges or looking for advice on specific tasks.", "title": "Answering Questions"}, {"location": "contribution/#pull-requests", "text": "Pull requests are a key way to contribute to WaLSAtools . Whether fixing bugs or adding new features, we value your input. For details on setting up a development environment and understanding the contribution process, please refer to the Development page.", "title": "Pull Requests"}, {"location": "contribution/#documentation-improvements", "text": "We strive to provide not only reliable and user-friendly tools but also comprehensive documentation and examples. If you identify areas where the documentation can be enhanced, your contributions are highly appreciated. Guidance on editing documentation is available on the Development page.", "title": "Documentation Improvements"}, {"location": "development/", "text": "Development \u00b6 Package Layout \u00b6 The package contains files for building, testing, and continuous integration at its root, but it is broadly organized as shown below. Only the main components are included in this overview. WaLSAtools/ \u251c\u2500\u2500 codes/ \u2502 \u251c\u2500\u2500 python/ # Python implementation of WaLSAtools \u2502 \u2502 \u251c\u2500\u2500 WaLSAtools/ # Core library \u2502 \u2502 \u251c\u2500\u2500 setup.py # Setup script for Python \u2502 \u2502 \u2514\u2500\u2500 README.md # Python-specific README \u2502 \u251c\u2500\u2500 idl/ # IDL implementation of WaLSAtools \u2502 \u2502 \u251c\u2500\u2500 WaLSAtools/ # Core library \u2502 \u2502 \u251c\u2500\u2500 setup.pro # Setup script for IDL \u2502 \u2502 \u2514\u2500\u2500 README.md # IDL-specific README \u251c\u2500\u2500 docs/ # Documentation for WaLSAtools \u251c\u2500\u2500 examples/ # Worked examples directory \u2502 \u251c\u2500\u2500 python/ # Python-specific examples \u2502 \u2502 \u2514\u2500\u2500 Worked_examples__NRMP/ \u2502 \u251c\u2500\u2500 idl/ # IDL-specific examples \u2502 \u2502 \u2514\u2500\u2500 Worked_examples__NRMP/ \u251c\u2500\u2500 LICENSE # License information \u251c\u2500\u2500 NOTICE # Copyright Notice \u2514\u2500\u2500 README.md # Main repository README Directory Structure Directory Description codes Contains the main source codes, their associated analysis modules and dependencies for analysis tools in both Python and IDL. Subdirectories house any third-party components required for the package. docs Contains the source files for documentation. Contributions to Markdown ( .md ) files under the root directory or python and idl subdirectories are welcome via pull requests. Other subdirectories manage the website's visual style and should not be edited. Images and PDF files should be stored in their respective subfolders. examples Includes sample datasets and example scripts demonstrating how to use WaLSAtools . Key Files File Description mkdocs.yml Configuration file for generating the documentation website using MkDocs. WaLSAtools.py The main Python script, serving as the core of WaLSAtools. This provides the essential framework for Python users. walsatools.pro The main IDL script, providing the necessary framework for WaLSAtools in IDL. It is the primary entry point when using WaLSAtools in IDL. Editing Documents \u00b6 All documentation is written in Markdown, with some additional syntax and extensions. It is converted to HTML using Python Markdown and deployed via gh-pages . For those new to Markdown, you can learn about its syntax and structure here . Recommended Tools: \u00b6 Markdown Editing : Using Visual Studio Code is highly recommended for working with Markdown files and coding in Python, IDL, or other languages. To ensure an optimal experience, install all necessary extensions for Markdown and the relevant programming languages. Contribution Process : Edit Markdown files directly within the docs directory and submit your changes via pull requests. Always preview changes locally before pushing updates.", "title": "Development"}, {"location": "development/#development", "text": "", "title": "Development"}, {"location": "development/#package-layout", "text": "The package contains files for building, testing, and continuous integration at its root, but it is broadly organized as shown below. Only the main components are included in this overview. WaLSAtools/ \u251c\u2500\u2500 codes/ \u2502 \u251c\u2500\u2500 python/ # Python implementation of WaLSAtools \u2502 \u2502 \u251c\u2500\u2500 WaLSAtools/ # Core library \u2502 \u2502 \u251c\u2500\u2500 setup.py # Setup script for Python \u2502 \u2502 \u2514\u2500\u2500 README.md # Python-specific README \u2502 \u251c\u2500\u2500 idl/ # IDL implementation of WaLSAtools \u2502 \u2502 \u251c\u2500\u2500 WaLSAtools/ # Core library \u2502 \u2502 \u251c\u2500\u2500 setup.pro # Setup script for IDL \u2502 \u2502 \u2514\u2500\u2500 README.md # IDL-specific README \u251c\u2500\u2500 docs/ # Documentation for WaLSAtools \u251c\u2500\u2500 examples/ # Worked examples directory \u2502 \u251c\u2500\u2500 python/ # Python-specific examples \u2502 \u2502 \u2514\u2500\u2500 Worked_examples__NRMP/ \u2502 \u251c\u2500\u2500 idl/ # IDL-specific examples \u2502 \u2502 \u2514\u2500\u2500 Worked_examples__NRMP/ \u251c\u2500\u2500 LICENSE # License information \u251c\u2500\u2500 NOTICE # Copyright Notice \u2514\u2500\u2500 README.md # Main repository README Directory Structure Directory Description codes Contains the main source codes, their associated analysis modules and dependencies for analysis tools in both Python and IDL. Subdirectories house any third-party components required for the package. docs Contains the source files for documentation. Contributions to Markdown ( .md ) files under the root directory or python and idl subdirectories are welcome via pull requests. Other subdirectories manage the website's visual style and should not be edited. Images and PDF files should be stored in their respective subfolders. examples Includes sample datasets and example scripts demonstrating how to use WaLSAtools . Key Files File Description mkdocs.yml Configuration file for generating the documentation website using MkDocs. WaLSAtools.py The main Python script, serving as the core of WaLSAtools. This provides the essential framework for Python users. walsatools.pro The main IDL script, providing the necessary framework for WaLSAtools in IDL. It is the primary entry point when using WaLSAtools in IDL.", "title": "Package Layout"}, {"location": "development/#editing-documents", "text": "All documentation is written in Markdown, with some additional syntax and extensions. It is converted to HTML using Python Markdown and deployed via gh-pages . For those new to Markdown, you can learn about its syntax and structure here .", "title": "Editing Documents"}, {"location": "development/#recommended-tools", "text": "Markdown Editing : Using Visual Studio Code is highly recommended for working with Markdown files and coding in Python, IDL, or other languages. To ensure an optimal experience, install all necessary extensions for Markdown and the relevant programming languages. Contribution Process : Edit Markdown files directly within the docs directory and submit your changes via pull requests. Always preview changes locally before pushing updates.", "title": "Recommended Tools:"}, {"location": "introduction/", "text": "Introduction \u00b6 Overview \u00b6 WaLSAtools is an open-source library for analysing a wide variety of wave phenomena in time series data \u2013 including 1D signals, images, and multi-dimensional datasets. It provides tools to extract meaningful insights from complex datasets and is applicable across diverse fields, including astrophysics, engineering, life, physical and environmental sciences, and biomedical studies, among others. The library is continuously expanding with new features and functionalities, ensuring it remains a valuable resource for wave analysis. The core of WaLSAtools is built upon Python . This ensures accessibility and ease of use for a broad audience. We are actively developing versions in other popular languages to further enhance accessibility, enabling researchers from various backgrounds to leverage the power of WaLSAtools for their wave analysis needs. Currently, WaLSAtools is partially implemented in IDL , with plans to expand its functionality and extend to other programming languages in the future. WaLSAtools provides a suite of both fundamental and advanced tools, but it remains the user's responsibility to choose the method that best fits the nature of their dataset and the scientific questions being addressed. Selecting the appropriate analysis method is essential for ensuring reliable and scientifically valid results. The use of unsuitable or overly simplified techniques \u2013 without consideration of the data's properties or the research goals \u2013 can lead to incomplete or incorrect conclusions, and potentially to misinterpretation. This principle is central to our accompanying Primer , which emphasises the importance of methodological awareness in wave analysis across all disciplines. Developed by the WaLSA Team , WaLSAtools was initially inspired by the intricate wave dynamics observed in the Sun's atmosphere. However, its applications extend far beyond solar physics, offering a versatile toolkit for anyone working with oscillatory signals. WaLSAtools promotes reproducibility and transparency in wave analysis. Its robust implementations of validated techniques ensure consistent and trustworthy results, empowering researchers to delve deeper into the complexities of their data. Through its interactive interface, WaLSAtools guides users through the analysis process, providing the necessary information and tools to perform various types of wave analysis with ease. This repository is associated with a primer article titled Wave analysis tools in Nature Reviews Methods Primers (NRMP; Free access to view-only Primer and its Supplementary Information ), showcasing its capabilities through detailed analyses of synthetic datasets. The Analysis Tools/Examples/Worked examples - NRMP contain reproducible codes for generating all figures presented in the NRMP article, serving as a practical guide for applying WaLSAtools to real-world analyses. To switch between Python and IDL documentation, click the current programming language name at the top of the page. Key Features \u00b6 Wide Range of Wave Analysis Techniques: From foundational methods like FFT and wavelet analysis to advanced techniques such as EMD, k-\u03c9, and POD analysis. Cross-Disciplinary Applicability: Suitable for signal processing, oscillation studies, and multi-dimensional analysis in various fields. Interactive Interfaces: Simplified workflows through interactive menus for both Python and IDL . Open Science Principles: Promotes reproducibility and transparency in data analysis. Contributions are welcome to improve the codes, methods, or documentation. Analysis Methods \u00b6 WaLSAtools offers a variety of spectral analysis techniques, each tailored to specific types of data and research questions. These methods are broadly categorised into: Single Time Series Analysis: Includes methods for analysing individual time series, such as: 1D Signals: Fast Fourier Transform (FFT), Lomb-Scargle, Wavelet Transform, Welch, Hilbert-Huang Transform (HHT) and Empirical Mode Decomposition (EMD) 3D Cubes: k-\u03c9 Analysis, Dominant Frequency, Mean Power Spectrum, and Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis: Includes methods for analysing correlations between two time series, resulting in cross-spectrum, coherence, and phase relationships. All time series are pre-processed to mitigate unwanted effects, such as long-term trends and edge effects, prior to spectral analysis. This includes detrending and apodization. Detailed Descriptions of Analysis Methods \u00b6 The choice of the most appropriate wave analysis technique depends not only on the nature of the data but also on the specific research goals and the desired insights. WaLSAtools offers a variety of methods, each with its own strengths and limitations, allowing researchers to tailor their analysis to their specific needs. This section provides detailed descriptions of the individual methods available in WaLSAtools , empowering users to make informed decisions about the most suitable techniques for their research. Single time series analysis: 1D signal \u00b6 One Dimensional (1D) Signal WaLSAtools provides a variety of methods for analysing 1D signals (time series). Each method uses a different approach to decompose the signal into its constituent frequencies, making them suitable for various scenarios. Selecting the appropriate technique depends on the specific characteristics of the data and the research goals. FFT Lomb-Scargle Wavelet EMD/HHT Welch The Fast Fourier Transform (FFT; Cooley and Tukey 1965 ) is an efficient algorithm that computes the discrete Fourier transform (DFT; Fourier 1824 ) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. The FFT is widely used in many fields due to its computational efficiency. This makes it significantly faster than directly computing the DFT, especially for large datasets. The FFT algorithm estimates the frequency spectrum by decomposing the signal into a set of sinusoidal oscillations at distinct frequencies, each with its own amplitude and phase. Advantages: Computationally efficient, especially for large datasets. Provides a clear and easily interpretable frequency spectrum. Well-suited for analysing stationary signals with evenly spaced samples. Limitations: Assumes the signal is stationary (frequency content does not change over time). Requires evenly spaced data points. Can be sensitive to edge effects in finite signals. FFT is often the prime choice of method for spectral analysis, unless the science case and/or data properties require the use of other techniques. The Lomb\u2013Scargle periodogram is a method of estimating a frequency spectrum, based on a least-squares fit of sinusoids to data samples, irrespective of whether the sampling is regularly or irregularly spaced in time. Advantages: Can handle irregularly sampled data without the need for interpolation. Provides accurate frequency estimates even with missing data points. Limitations: Can be computationally expensive for very large datasets. May not be as efficient as FFT for evenly spaced data. Lomb\u2013Scargle should be the method of choice when the data points are unequally spaced in time (e.g., when there are gaps or missing data points). Note: While interpolation can sometimes be used to fill gaps in data and enable the use of other methods like FFT, selecting an appropriate interpolation method and mitigating potential artifacts can be challenging. A wavelet transform is a time-frequency representation of a signal. It allows a signal to be decomposed into its constituent wavelets, which are localised in both time and frequency. The Wavelet Transform is a powerful tool for analysing time series data that exhibit non-stationary behaviors, meaning their frequency content changes over time. Unlike the Fourier Transform, which provides a global frequency spectrum, the Wavelet Transform allows for localised analysis in both time and frequency, revealing how different frequencies contribute to the signal at different times. Key Concepts: Mother Wavelet: The Wavelet Transform uses a function called a \"mother wavelet\" to analyse the signal. Different mother wavelets have different shapes and properties, making them suitable for different types of signals and analysis goals. The choice of mother wavelet is crucial for optimal results. Scales: The Wavelet Transform analyses the signal at different scales, which correspond to different frequency ranges. This multi-resolution analysis allows for the detection of both short-lived, high-frequency features and long-lasting, low-frequency trends. Cone of Influence (COI): The COI is a region in the time-frequency plane where edge effects can influence the results of the Wavelet Transform. It is important to be aware of the COI when interpreting the results. WaLSAtools provides a versatile implementation of the Wavelet Transform, allowing users to choose from various mother wavelets and customize the analysis parameters. In addition to the standard 2D time-frequency spectrum, it offers two types of 1D spectra: Global Wavelet Spectrum (GWS): Obtained by averaging the wavelet power over time. Refined Global Wavelet Spectrum (RGWS): A novel approach that excludes the COI and regions below a given confidence level from the time-integral of wavelet power, providing a more robust representation of the significant frequency components. Advantages: Suitable for analysing non-stationary signals. Provides both time and frequency localisation. Offers a multi-resolution view of the signal. Limitations: The choice of mother wavelet can influence the results. Frequency resolution is limited, especially at higher frequencies. Edge effects can influence the analysis near the boundaries of the time series. Wavelet transform is particularly suitable for studying transient oscillations, weak signals, or quasi-periodic signatures. Empirical Mode Decomposition (EMD) is a data-driven technique for analysing nonlinear and non-stationary signals. It decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. The Hilbert-Huang Transform (HHT) combines EMD with the Hilbert Transform to calculate the instantaneous frequency and amplitude of each IMF. This provides a detailed view of how the signal's frequency content evolves over time. WaLSAtools Implementation: WaLSAtools provides implementations of both EMD and HHT, allowing users to: Decompose signals into IMFs using EMD. Calculate instantaneous frequencies and amplitudes using HHT. Visualise the results with time-frequency plots and marginal spectra. Advantages: Suitable for analysing nonlinear and non-stationary signals. Adaptively extracts IMFs based on the signal's local characteristics. Provides time-varying frequency and amplitude information. Limitations: Can be sensitive to noise and parameter choices. Mode mixing can occur, where a single IMF contains components from different oscillatory modes. Requires careful selection of stopping criteria and spline fitting parameters. Key Considerations: Ensemble EMD (EEMD): WaLSAtools also includes EEMD, an ensemble-based approach that reduces the impact of noise and improves mode separation. Significance Testing: It is essential to assess the statistical significance of the extracted IMFs to distinguish genuine oscillations from noise-induced artifacts. Parameter Selection: Carefully choose the EMD and HHT parameters based on the specific characteristics of the data and the research goals. EMD and HHT are valuable tools for analysing complex signals that exhibit non-stationary and nonlinear behaviors, providing insights into the time-varying dynamics of oscillatory phenomena. Welch's method is a technique for estimating the power spectral density (PSD) of a signal. It is particularly useful when dealing with noisy data or signals that have time-varying frequency content. How it works: The signal is divided into overlapping segments. Each segment is windowed (e.g., using a Hann or Hamming window) to reduce spectral leakage. The periodogram (a basic estimate of the PSD) is computed for each segment. The periodograms are averaged to obtain a smoother and more robust estimate of the PSD. Advantages: Reduces noise in the PSD estimate. Can handle signals with time-varying frequency content. Provides a more robust estimate of the PSD compared to a single periodogram. Limitations: Reduces frequency resolution due to the use of shorter segments. The choice of window function and segment length can affect the results. Welch's method is a valuable tool for analysing signals where noise reduction is a priority or when the frequency content of the signal changes over time. Info Power Spectral Density (PSD): The analysis methods compute wave amplitudes at different frequencies, resulting in a frequency spectrum. The Power Spectral Density (PSD) can further be calculated, which represents the power (amplitude squared) per unit frequency. This normalisation allows for meaningful comparisons between different signals, regardless of their frequency resolution. Additionally, WaLSAtools outputs single-sided PSDs, where the power at negative frequencies is folded into the positive frequencies, divided by two since the folding effectively doubles the PSD values. Confidence Levels: WaLSAtools can estimate the statistical significance of the computed power using a randomisation test. This helps distinguish between genuine signals and those arising from noise or spurious effects. For example, a 95% confidence level indicates that the detected power is significant with a 5% probability of being due to random fluctuations. Single time series analysis: 3D Datacube \u00b6 Three Dimensional (3D) Datacube Analysing the distribution of oscillation power over a spatial extent is often crucial to identify wave modes and understand their behaviour. WaLSAtools offers several methods for analysing 3D datacubes (time series of 2D images), each providing unique insights into the spatio-temporal characteristics of waves. k-\u03c9 Mean Power Dominant Frequency POD k-\u03c9 analysis is a powerful technique for investigating wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both spatial (wavenumber, k) and temporal (frequency, \u03c9) domains. The resulting k-\u03c9 diagram reveals the relationship between spatial and temporal scales of oscillations, providing insights into wave dispersion relations and identifying different wave modes. WaLSAtools provides a comprehensive k-\u03c9 analysis tool that allows for: Generating k-\u03c9 diagrams from 3D datacubes. Filtering of the data in k-space and/or \u03c9-space. Reconstructing filtered datacubes to isolate specific wave modes or features. Fourier filtering is a key component of k-\u03c9 analysis, enabling the isolation of wave signatures with specific wavenumber and frequency characteristics. This is particularly useful for identifying weak wave modes that might be masked by stronger signals or background trends. Advantages: Reveals wave dispersion relations. Enables isolation of specific wave modes through filtering. Provides insights into the spatio-temporal characteristics of waves. Limitations: Assumes the wave field is statistically homogeneous and stationary. Can be sensitive to edge effects and noise. For a detailed description of the Fourier filtering technique, refer to the step-by-step guide of the original (QUEEFF) code integrated into WaLSAtools . The mean power spectrum provides a global view of the oscillatory behaviour within a region of interest. It is calculated by averaging the power spectra of individual pixels across the spatial domain. WaLSAtools allows for calculating the mean power spectrum using various 1D analysis methods (FFT, Lomb-Scargle, Wavelet, HHT, Welch, etc.). Advantages: Highlights the dominant (mean) oscillatory modes in a region. Provides a baseline for filtering out global contributions. Can be used to compare oscillatory behaviour across different regions or datasets. Limitations: May not capture localised or subtle variations in oscillatory behaviour. The dominant frequency is the frequency with the highest power in a spectrum. WaLSAtools can calculate the dominant frequency for each pixel in a 3D datacube, generating a map that visualises the spatial distribution of dominant frequencies. Advantages: Provides a visual representation of the dominant oscillatory modes in a region. Can reveal spatial patterns and correlations with other physical properties. Limitations: Can be biased in signals with multiple strong spectral peaks. May not capture the full complexity of oscillatory behaviour. Proper Orthogonal Decomposition (POD) is a powerful data-driven technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. WaLSAtools provides a POD analysis tool that: Calculates the POD modes and their corresponding eigenvalues. Reconstructs the original data using a reduced number of modes. Visualises the spatial patterns and temporal evolution of the dominant modes. Advantages: Effectively reduces the dimensionality of complex datasets. Identifies coherent spatial patterns and their temporal behaviour. Can be used for feature extraction and pattern recognition. Limitations: Assumes the data is statistically stationary. May not capture highly localised or transient phenomena. Cross-correlation Analysis \u00b6 Cross-Correlation Analysis Investigating the relationships between two time series is essential for understanding the interplay of different phenomena across various scientific disciplines. WaLSAtools provides a comprehensive suite of tools for cross-correlation analysis, enabling researchers to: Uncover shared frequencies and correlated power between two signals. Quantify the strength of the relationship between two time series at different frequencies. Determine the relative timing (phase or time lag) between oscillations. These tools are valuable for uncovering hidden connections, tracking wave propagation, and exploring the underlying drivers of oscillatory behaviour in diverse fields. Cross-Spectrum Coherence Phase Difference The cross-spectrum, also known as the cross-power spectrum, is a complex-valued function that describes the correlation between two time series in the frequency domain. It is calculated by multiplying the frequency representation of one signal by the complex conjugate of the frequency representation of the other one. The magnitude of the cross-spectrum, often called the co-spectrum, represents the shared power between the two signals at each frequency. High values in the co-spectrum indicate strong correlations between the oscillations at those frequencies. Applications: Identifying common frequencies and shared power between two signals. Detecting potential connections or shared influences affecting the signals. Limitations: May not reveal correlations if the individual power spectra lack prominent peaks. Can be sensitive to noise and potential biases in the data. Coherence is a normalised measure of the linear correlation between two time series at each frequency. It ranges from 0 (no correlation) to 1 (perfect correlation). High coherence values indicate that the oscillations in the two time series are strongly related at that frequency, even if their individual power spectra do not exhibit strong peaks. Applications: Uncovering hidden relationships between signals. Tracing wave propagation across different locations or systems. Investigating connections between oscillations in different physical parameters or measurements. Limitations: Only measures linear relationships between signals. Can be sensitive to noise and potential biases in the data. Phase difference, or phase lag, measures the relative timing of oscillations in two time series. It is calculated from the phase angle of the complex cross-spectrum and indicates whether the oscillations are in phase, or if one signal leads or lags the other. Applications: Determining the direction and speed of wave propagation. Exploring potential cause-and-effect connections between phenomena. Investigating the degree of synchronization between oscillating systems. Limitations: Can be challenging to interpret in complex systems with multiple interacting oscillations. Sensitive to noise and potential biases in the data. Note The co-spectrum, coherence, and phase lag are one-dimensional for 1D power spectra (FFT, Lomb-Scargle, HHT, GWS, RGWS, Welch) and two-dimensional for the 2D Wavelet spectrum. Info Check out the documentation on the Analysis Tools to learn how to run WaLSAtools and more about all inputs, parameters, and outputs. Under Development \u00b6 WaLSAtools is constantly evolving with new features and improvements. Here are some of the ongoing developments: Expanding Language Support: Further development in IDL (for full consistency between the Python and IDL versions), with potential expansion to MATLAB and other programming languages. Enhancing Existing Methods: Improving the Dominant Frequency method to handle cases with multiple strong power peaks and provide uncertainty estimations. Adding New Methods: Implementing new analysis techniques, such as Adaptive Local Iterative Filtering (ALIF) and Synchrosqueezing Transform (SST). We welcome contributions from the community to help us expand and improve WaLSAtools . If you are interested in contributing, please see the Contribution Guidelines .", "title": "Introduction"}, {"location": "introduction/#introduction", "text": "", "title": "Introduction"}, {"location": "introduction/#overview", "text": "WaLSAtools is an open-source library for analysing a wide variety of wave phenomena in time series data \u2013 including 1D signals, images, and multi-dimensional datasets. It provides tools to extract meaningful insights from complex datasets and is applicable across diverse fields, including astrophysics, engineering, life, physical and environmental sciences, and biomedical studies, among others. The library is continuously expanding with new features and functionalities, ensuring it remains a valuable resource for wave analysis. The core of WaLSAtools is built upon Python . This ensures accessibility and ease of use for a broad audience. We are actively developing versions in other popular languages to further enhance accessibility, enabling researchers from various backgrounds to leverage the power of WaLSAtools for their wave analysis needs. Currently, WaLSAtools is partially implemented in IDL , with plans to expand its functionality and extend to other programming languages in the future. WaLSAtools provides a suite of both fundamental and advanced tools, but it remains the user's responsibility to choose the method that best fits the nature of their dataset and the scientific questions being addressed. Selecting the appropriate analysis method is essential for ensuring reliable and scientifically valid results. The use of unsuitable or overly simplified techniques \u2013 without consideration of the data's properties or the research goals \u2013 can lead to incomplete or incorrect conclusions, and potentially to misinterpretation. This principle is central to our accompanying Primer , which emphasises the importance of methodological awareness in wave analysis across all disciplines. Developed by the WaLSA Team , WaLSAtools was initially inspired by the intricate wave dynamics observed in the Sun's atmosphere. However, its applications extend far beyond solar physics, offering a versatile toolkit for anyone working with oscillatory signals. WaLSAtools promotes reproducibility and transparency in wave analysis. Its robust implementations of validated techniques ensure consistent and trustworthy results, empowering researchers to delve deeper into the complexities of their data. Through its interactive interface, WaLSAtools guides users through the analysis process, providing the necessary information and tools to perform various types of wave analysis with ease. This repository is associated with a primer article titled Wave analysis tools in Nature Reviews Methods Primers (NRMP; Free access to view-only Primer and its Supplementary Information ), showcasing its capabilities through detailed analyses of synthetic datasets. The Analysis Tools/Examples/Worked examples - NRMP contain reproducible codes for generating all figures presented in the NRMP article, serving as a practical guide for applying WaLSAtools to real-world analyses. To switch between Python and IDL documentation, click the current programming language name at the top of the page.", "title": "Overview"}, {"location": "introduction/#key-features", "text": "Wide Range of Wave Analysis Techniques: From foundational methods like FFT and wavelet analysis to advanced techniques such as EMD, k-\u03c9, and POD analysis. Cross-Disciplinary Applicability: Suitable for signal processing, oscillation studies, and multi-dimensional analysis in various fields. Interactive Interfaces: Simplified workflows through interactive menus for both Python and IDL . Open Science Principles: Promotes reproducibility and transparency in data analysis. Contributions are welcome to improve the codes, methods, or documentation.", "title": "Key Features"}, {"location": "introduction/#analysis-methods", "text": "WaLSAtools offers a variety of spectral analysis techniques, each tailored to specific types of data and research questions. These methods are broadly categorised into: Single Time Series Analysis: Includes methods for analysing individual time series, such as: 1D Signals: Fast Fourier Transform (FFT), Lomb-Scargle, Wavelet Transform, Welch, Hilbert-Huang Transform (HHT) and Empirical Mode Decomposition (EMD) 3D Cubes: k-\u03c9 Analysis, Dominant Frequency, Mean Power Spectrum, and Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis: Includes methods for analysing correlations between two time series, resulting in cross-spectrum, coherence, and phase relationships. All time series are pre-processed to mitigate unwanted effects, such as long-term trends and edge effects, prior to spectral analysis. This includes detrending and apodization.", "title": "Analysis Methods"}, {"location": "introduction/#detailed-descriptions-of-analysis-methods", "text": "The choice of the most appropriate wave analysis technique depends not only on the nature of the data but also on the specific research goals and the desired insights. WaLSAtools offers a variety of methods, each with its own strengths and limitations, allowing researchers to tailor their analysis to their specific needs. This section provides detailed descriptions of the individual methods available in WaLSAtools , empowering users to make informed decisions about the most suitable techniques for their research.", "title": "Detailed Descriptions of Analysis Methods"}, {"location": "introduction/#single-time-series-analysis-1d-signal", "text": "One Dimensional (1D) Signal WaLSAtools provides a variety of methods for analysing 1D signals (time series). Each method uses a different approach to decompose the signal into its constituent frequencies, making them suitable for various scenarios. Selecting the appropriate technique depends on the specific characteristics of the data and the research goals. FFT Lomb-Scargle Wavelet EMD/HHT Welch The Fast Fourier Transform (FFT; Cooley and Tukey 1965 ) is an efficient algorithm that computes the discrete Fourier transform (DFT; Fourier 1824 ) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. The FFT is widely used in many fields due to its computational efficiency. This makes it significantly faster than directly computing the DFT, especially for large datasets. The FFT algorithm estimates the frequency spectrum by decomposing the signal into a set of sinusoidal oscillations at distinct frequencies, each with its own amplitude and phase. Advantages: Computationally efficient, especially for large datasets. Provides a clear and easily interpretable frequency spectrum. Well-suited for analysing stationary signals with evenly spaced samples. Limitations: Assumes the signal is stationary (frequency content does not change over time). Requires evenly spaced data points. Can be sensitive to edge effects in finite signals. FFT is often the prime choice of method for spectral analysis, unless the science case and/or data properties require the use of other techniques. The Lomb\u2013Scargle periodogram is a method of estimating a frequency spectrum, based on a least-squares fit of sinusoids to data samples, irrespective of whether the sampling is regularly or irregularly spaced in time. Advantages: Can handle irregularly sampled data without the need for interpolation. Provides accurate frequency estimates even with missing data points. Limitations: Can be computationally expensive for very large datasets. May not be as efficient as FFT for evenly spaced data. Lomb\u2013Scargle should be the method of choice when the data points are unequally spaced in time (e.g., when there are gaps or missing data points). Note: While interpolation can sometimes be used to fill gaps in data and enable the use of other methods like FFT, selecting an appropriate interpolation method and mitigating potential artifacts can be challenging. A wavelet transform is a time-frequency representation of a signal. It allows a signal to be decomposed into its constituent wavelets, which are localised in both time and frequency. The Wavelet Transform is a powerful tool for analysing time series data that exhibit non-stationary behaviors, meaning their frequency content changes over time. Unlike the Fourier Transform, which provides a global frequency spectrum, the Wavelet Transform allows for localised analysis in both time and frequency, revealing how different frequencies contribute to the signal at different times. Key Concepts: Mother Wavelet: The Wavelet Transform uses a function called a \"mother wavelet\" to analyse the signal. Different mother wavelets have different shapes and properties, making them suitable for different types of signals and analysis goals. The choice of mother wavelet is crucial for optimal results. Scales: The Wavelet Transform analyses the signal at different scales, which correspond to different frequency ranges. This multi-resolution analysis allows for the detection of both short-lived, high-frequency features and long-lasting, low-frequency trends. Cone of Influence (COI): The COI is a region in the time-frequency plane where edge effects can influence the results of the Wavelet Transform. It is important to be aware of the COI when interpreting the results. WaLSAtools provides a versatile implementation of the Wavelet Transform, allowing users to choose from various mother wavelets and customize the analysis parameters. In addition to the standard 2D time-frequency spectrum, it offers two types of 1D spectra: Global Wavelet Spectrum (GWS): Obtained by averaging the wavelet power over time. Refined Global Wavelet Spectrum (RGWS): A novel approach that excludes the COI and regions below a given confidence level from the time-integral of wavelet power, providing a more robust representation of the significant frequency components. Advantages: Suitable for analysing non-stationary signals. Provides both time and frequency localisation. Offers a multi-resolution view of the signal. Limitations: The choice of mother wavelet can influence the results. Frequency resolution is limited, especially at higher frequencies. Edge effects can influence the analysis near the boundaries of the time series. Wavelet transform is particularly suitable for studying transient oscillations, weak signals, or quasi-periodic signatures. Empirical Mode Decomposition (EMD) is a data-driven technique for analysing nonlinear and non-stationary signals. It decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. The Hilbert-Huang Transform (HHT) combines EMD with the Hilbert Transform to calculate the instantaneous frequency and amplitude of each IMF. This provides a detailed view of how the signal's frequency content evolves over time. WaLSAtools Implementation: WaLSAtools provides implementations of both EMD and HHT, allowing users to: Decompose signals into IMFs using EMD. Calculate instantaneous frequencies and amplitudes using HHT. Visualise the results with time-frequency plots and marginal spectra. Advantages: Suitable for analysing nonlinear and non-stationary signals. Adaptively extracts IMFs based on the signal's local characteristics. Provides time-varying frequency and amplitude information. Limitations: Can be sensitive to noise and parameter choices. Mode mixing can occur, where a single IMF contains components from different oscillatory modes. Requires careful selection of stopping criteria and spline fitting parameters. Key Considerations: Ensemble EMD (EEMD): WaLSAtools also includes EEMD, an ensemble-based approach that reduces the impact of noise and improves mode separation. Significance Testing: It is essential to assess the statistical significance of the extracted IMFs to distinguish genuine oscillations from noise-induced artifacts. Parameter Selection: Carefully choose the EMD and HHT parameters based on the specific characteristics of the data and the research goals. EMD and HHT are valuable tools for analysing complex signals that exhibit non-stationary and nonlinear behaviors, providing insights into the time-varying dynamics of oscillatory phenomena. Welch's method is a technique for estimating the power spectral density (PSD) of a signal. It is particularly useful when dealing with noisy data or signals that have time-varying frequency content. How it works: The signal is divided into overlapping segments. Each segment is windowed (e.g., using a Hann or Hamming window) to reduce spectral leakage. The periodogram (a basic estimate of the PSD) is computed for each segment. The periodograms are averaged to obtain a smoother and more robust estimate of the PSD. Advantages: Reduces noise in the PSD estimate. Can handle signals with time-varying frequency content. Provides a more robust estimate of the PSD compared to a single periodogram. Limitations: Reduces frequency resolution due to the use of shorter segments. The choice of window function and segment length can affect the results. Welch's method is a valuable tool for analysing signals where noise reduction is a priority or when the frequency content of the signal changes over time. Info Power Spectral Density (PSD): The analysis methods compute wave amplitudes at different frequencies, resulting in a frequency spectrum. The Power Spectral Density (PSD) can further be calculated, which represents the power (amplitude squared) per unit frequency. This normalisation allows for meaningful comparisons between different signals, regardless of their frequency resolution. Additionally, WaLSAtools outputs single-sided PSDs, where the power at negative frequencies is folded into the positive frequencies, divided by two since the folding effectively doubles the PSD values. Confidence Levels: WaLSAtools can estimate the statistical significance of the computed power using a randomisation test. This helps distinguish between genuine signals and those arising from noise or spurious effects. For example, a 95% confidence level indicates that the detected power is significant with a 5% probability of being due to random fluctuations.", "title": "Single time series analysis: 1D signal"}, {"location": "introduction/#single-time-series-analysis-3d-datacube", "text": "Three Dimensional (3D) Datacube Analysing the distribution of oscillation power over a spatial extent is often crucial to identify wave modes and understand their behaviour. WaLSAtools offers several methods for analysing 3D datacubes (time series of 2D images), each providing unique insights into the spatio-temporal characteristics of waves. k-\u03c9 Mean Power Dominant Frequency POD k-\u03c9 analysis is a powerful technique for investigating wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both spatial (wavenumber, k) and temporal (frequency, \u03c9) domains. The resulting k-\u03c9 diagram reveals the relationship between spatial and temporal scales of oscillations, providing insights into wave dispersion relations and identifying different wave modes. WaLSAtools provides a comprehensive k-\u03c9 analysis tool that allows for: Generating k-\u03c9 diagrams from 3D datacubes. Filtering of the data in k-space and/or \u03c9-space. Reconstructing filtered datacubes to isolate specific wave modes or features. Fourier filtering is a key component of k-\u03c9 analysis, enabling the isolation of wave signatures with specific wavenumber and frequency characteristics. This is particularly useful for identifying weak wave modes that might be masked by stronger signals or background trends. Advantages: Reveals wave dispersion relations. Enables isolation of specific wave modes through filtering. Provides insights into the spatio-temporal characteristics of waves. Limitations: Assumes the wave field is statistically homogeneous and stationary. Can be sensitive to edge effects and noise. For a detailed description of the Fourier filtering technique, refer to the step-by-step guide of the original (QUEEFF) code integrated into WaLSAtools . The mean power spectrum provides a global view of the oscillatory behaviour within a region of interest. It is calculated by averaging the power spectra of individual pixels across the spatial domain. WaLSAtools allows for calculating the mean power spectrum using various 1D analysis methods (FFT, Lomb-Scargle, Wavelet, HHT, Welch, etc.). Advantages: Highlights the dominant (mean) oscillatory modes in a region. Provides a baseline for filtering out global contributions. Can be used to compare oscillatory behaviour across different regions or datasets. Limitations: May not capture localised or subtle variations in oscillatory behaviour. The dominant frequency is the frequency with the highest power in a spectrum. WaLSAtools can calculate the dominant frequency for each pixel in a 3D datacube, generating a map that visualises the spatial distribution of dominant frequencies. Advantages: Provides a visual representation of the dominant oscillatory modes in a region. Can reveal spatial patterns and correlations with other physical properties. Limitations: Can be biased in signals with multiple strong spectral peaks. May not capture the full complexity of oscillatory behaviour. Proper Orthogonal Decomposition (POD) is a powerful data-driven technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. WaLSAtools provides a POD analysis tool that: Calculates the POD modes and their corresponding eigenvalues. Reconstructs the original data using a reduced number of modes. Visualises the spatial patterns and temporal evolution of the dominant modes. Advantages: Effectively reduces the dimensionality of complex datasets. Identifies coherent spatial patterns and their temporal behaviour. Can be used for feature extraction and pattern recognition. Limitations: Assumes the data is statistically stationary. May not capture highly localised or transient phenomena.", "title": "Single time series analysis: 3D Datacube"}, {"location": "introduction/#cross-correlation-analysis", "text": "Cross-Correlation Analysis Investigating the relationships between two time series is essential for understanding the interplay of different phenomena across various scientific disciplines. WaLSAtools provides a comprehensive suite of tools for cross-correlation analysis, enabling researchers to: Uncover shared frequencies and correlated power between two signals. Quantify the strength of the relationship between two time series at different frequencies. Determine the relative timing (phase or time lag) between oscillations. These tools are valuable for uncovering hidden connections, tracking wave propagation, and exploring the underlying drivers of oscillatory behaviour in diverse fields. Cross-Spectrum Coherence Phase Difference The cross-spectrum, also known as the cross-power spectrum, is a complex-valued function that describes the correlation between two time series in the frequency domain. It is calculated by multiplying the frequency representation of one signal by the complex conjugate of the frequency representation of the other one. The magnitude of the cross-spectrum, often called the co-spectrum, represents the shared power between the two signals at each frequency. High values in the co-spectrum indicate strong correlations between the oscillations at those frequencies. Applications: Identifying common frequencies and shared power between two signals. Detecting potential connections or shared influences affecting the signals. Limitations: May not reveal correlations if the individual power spectra lack prominent peaks. Can be sensitive to noise and potential biases in the data. Coherence is a normalised measure of the linear correlation between two time series at each frequency. It ranges from 0 (no correlation) to 1 (perfect correlation). High coherence values indicate that the oscillations in the two time series are strongly related at that frequency, even if their individual power spectra do not exhibit strong peaks. Applications: Uncovering hidden relationships between signals. Tracing wave propagation across different locations or systems. Investigating connections between oscillations in different physical parameters or measurements. Limitations: Only measures linear relationships between signals. Can be sensitive to noise and potential biases in the data. Phase difference, or phase lag, measures the relative timing of oscillations in two time series. It is calculated from the phase angle of the complex cross-spectrum and indicates whether the oscillations are in phase, or if one signal leads or lags the other. Applications: Determining the direction and speed of wave propagation. Exploring potential cause-and-effect connections between phenomena. Investigating the degree of synchronization between oscillating systems. Limitations: Can be challenging to interpret in complex systems with multiple interacting oscillations. Sensitive to noise and potential biases in the data. Note The co-spectrum, coherence, and phase lag are one-dimensional for 1D power spectra (FFT, Lomb-Scargle, HHT, GWS, RGWS, Welch) and two-dimensional for the 2D Wavelet spectrum. Info Check out the documentation on the Analysis Tools to learn how to run WaLSAtools and more about all inputs, parameters, and outputs.", "title": "Cross-correlation Analysis"}, {"location": "introduction/#under-development", "text": "WaLSAtools is constantly evolving with new features and improvements. Here are some of the ongoing developments: Expanding Language Support: Further development in IDL (for full consistency between the Python and IDL versions), with potential expansion to MATLAB and other programming languages. Enhancing Existing Methods: Improving the Dominant Frequency method to handle cases with multiple strong power peaks and provide uncertainty estimations. Adding New Methods: Implementing new analysis techniques, such as Adaptive Local Iterative Filtering (ALIF) and Synchrosqueezing Transform (SST). We welcome contributions from the community to help us expand and improve WaLSAtools . If you are interested in contributing, please see the Contribution Guidelines .", "title": "Under Development"}, {"location": "license/", "text": "License and Credits \u00b6 WaLSAtools \u00b6 The WaLSAtools package is distributed under the Apache License Version 2.0 , except where otherwise noted. This license ensures that the software is free to use, modify, and distribute, while maintaining proper attribution to the original authors. Apache License Version 2.0 \u00b6 Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) The Work includes a \"NOTICE\" text file as part of its distribution, so any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. (e) Include a citation or acknowledgment to the original research work associated with WaLSAtools in derivative works or publications using this software. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice. The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Note : If you use WaLSAtools for research, please consider citing: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 \ud83d\udccd Contact For questions, permissions, or inquiries about this license, please contact: WaLSA Team Email: WaLSAtools@WaLSA.team or Shahin.Jafarzadeh@WaLSA.team GitHub: WaLSAteam/WaLSAtools WaLSA_QUB_QUEEFF \u00b6 The walsa_qub_queeff.pro code is a variant of the QUEEFF code originally developed by Prof. David B. Jess and Dr. Samuel D. T. Grant (and modified by Dr. Shahin Jafarzadeh). If you use this code, please cite the original publication: Jess et al. (2017). ApJ, 842, 59. https://ui.adsabs.harvard.edu/abs/2017ApJ...842...59J The original code and manual can be accessed here . epstool-3.08 \u00b6 The epstool utility is used in WaLSAtools for manipulating EPS files, such as fixing bounding boxes. It is distributed under the GNU General Public License : GNU GENERAL PUBLIC LICENSE Copyright (C) 1989, 1991 Free Software Foundation, Inc. 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA. Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. GPL Ghostscript \u00b6 WaLSAtools uses Ghostscript for generating PDF files in both CMYK and RGB color formats. This functionality ensures high-quality outputs for professional use. Version: GPL Ghostscript 10.04.0 (2024-09-18) License: GNU AGPLv3 Documentation \u00b6 This documentation is generated using MkDocs , which builds a static HTML site from Markdown files. The site is hosted on GitHub and deployed to GitHub Pages via our custom domain WaLSA.tools . Copyright \u00a9 2014-present, Tom Christie. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. The site design is based on the Material for MkDocs : Copyright (c) 2016-2021 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "title": "License and Credits"}, {"location": "license/#license-and-credits", "text": "", "title": "License and Credits"}, {"location": "license/#walsatools", "text": "The WaLSAtools package is distributed under the Apache License Version 2.0 , except where otherwise noted. This license ensures that the software is free to use, modify, and distribute, while maintaining proper attribution to the original authors.", "title": "WaLSAtools"}, {"location": "license/#apache-license-version-20", "text": "Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) The Work includes a \"NOTICE\" text file as part of its distribution, so any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. (e) Include a citation or acknowledgment to the original research work associated with WaLSAtools in derivative works or publications using this software. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice. The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Note : If you use WaLSAtools for research, please consider citing: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 \ud83d\udccd Contact For questions, permissions, or inquiries about this license, please contact: WaLSA Team Email: WaLSAtools@WaLSA.team or Shahin.Jafarzadeh@WaLSA.team GitHub: WaLSAteam/WaLSAtools", "title": "Apache License Version 2.0"}, {"location": "license/#walsa_qub_queeff", "text": "The walsa_qub_queeff.pro code is a variant of the QUEEFF code originally developed by Prof. David B. Jess and Dr. Samuel D. T. Grant (and modified by Dr. Shahin Jafarzadeh). If you use this code, please cite the original publication: Jess et al. (2017). ApJ, 842, 59. https://ui.adsabs.harvard.edu/abs/2017ApJ...842...59J The original code and manual can be accessed here .", "title": "WaLSA_QUB_QUEEFF"}, {"location": "license/#epstool-308", "text": "The epstool utility is used in WaLSAtools for manipulating EPS files, such as fixing bounding boxes. It is distributed under the GNU General Public License : GNU GENERAL PUBLIC LICENSE Copyright (C) 1989, 1991 Free Software Foundation, Inc. 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA. Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.", "title": "epstool-3.08"}, {"location": "license/#gpl-ghostscript", "text": "WaLSAtools uses Ghostscript for generating PDF files in both CMYK and RGB color formats. This functionality ensures high-quality outputs for professional use. Version: GPL Ghostscript 10.04.0 (2024-09-18) License: GNU AGPLv3", "title": "GPL Ghostscript"}, {"location": "license/#documentation", "text": "This documentation is generated using MkDocs , which builds a static HTML site from Markdown files. The site is hosted on GitHub and deployed to GitHub Pages via our custom domain WaLSA.tools . Copyright \u00a9 2014-present, Tom Christie. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. The site design is based on the Material for MkDocs : Copyright (c) 2016-2021 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.", "title": "Documentation"}, {"location": "idl/B-omega-example/", "text": "B-\u03c9 Diagram \u00b6 Below is an example for plotting a B-\u03c9 diagram using WaLSAtools for a times series of images from observations with SDO/AIA 170 nm (sampling heights approximately corresponding to temperature minimum of the solar atmosphere) as well as a magnetogram from SDO/HMI, corresponding to the middle of the AIA observations. B-\u03c9 diagram for a small region of interest in the sample datacube To learn how WaLSAtools is employed to compute and plot the B-\u03c9 diagram in this example, please go through its source code accessible at the bottom of this page. The example IDL procedure can also be found under the examples/idl/ directory of the package. The sample datacubes are located in the sample_data folder under the examples directory. To run the example code, simply type the following command (while in the examples/idl/ directory, which can be placed anywhere in your machine, also outside your IDL PATH ) and press Enter IDL> .r example_bomega Below are some examples of the information begin printed in terminal. For simplicity, % Compiled module: messages and repeated information are not shown below. % Compiled module: WALSATOOLS. __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------------------- WaLSAtools v1.0 Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------------------- The input datacube is of size: [91, 41, 610] Temporally, the important values are: 2-element duration (Nyquist period) = 24.0000 seconds Time series duration = 7320 seconds Nyquist frequency = 41.6667 mHz == detrend next row... 91/ 91 .... % finished (through bins, from larger B): 100. mode = 0: log(power) COMPLETED! The output figure of this example is illustrated in panel ( a ), where the averaged (temporal) power spectra within each magnetic-field bin (with 50 G width) are plotted along the y axis. Thus the background colour represents the power spectral density (plotted in a base 10 logarithmic scale). The two horizontal dashed lines mark the periods (or frequencies) of three and five minutes oscillations. Panels ( c ) and ( d ), respectively, illustrate the longitudinal magnetic-field map from SDO/HMI and one image of the SDO/AIA 170 nm time series (corresponding to the middle of the observations) for the region of interest analysed here. Please note that, in this example, the power is considerably smaller in the larger magnetic-field regions compared to the areas with lower magnetic fields, though it still can be significant in some frequencies. One reason is that the amplitudes of fluctuations are likely very small inside the umbra at these observations (which can depend on many factors, including the spatial resolution and the height ranges sampled by these observations). One way to identify power enhancements in individual bins is to use the /normalizedbins keyword, which normalises each power spectrum (in each bin) to it maximum value. See here to learn about all keywords available to this analysis tool. As a guide, see this scientific article where this approach could help revealing signatures of resonant MHD oscillations in a pore umbra. Source code 1", "title": "B-&#969; Diagram"}, {"location": "idl/B-omega-example/#b-diagram", "text": "Below is an example for plotting a B-\u03c9 diagram using WaLSAtools for a times series of images from observations with SDO/AIA 170 nm (sampling heights approximately corresponding to temperature minimum of the solar atmosphere) as well as a magnetogram from SDO/HMI, corresponding to the middle of the AIA observations. B-\u03c9 diagram for a small region of interest in the sample datacube To learn how WaLSAtools is employed to compute and plot the B-\u03c9 diagram in this example, please go through its source code accessible at the bottom of this page. The example IDL procedure can also be found under the examples/idl/ directory of the package. The sample datacubes are located in the sample_data folder under the examples directory. To run the example code, simply type the following command (while in the examples/idl/ directory, which can be placed anywhere in your machine, also outside your IDL PATH ) and press Enter IDL> .r example_bomega Below are some examples of the information begin printed in terminal. For simplicity, % Compiled module: messages and repeated information are not shown below. % Compiled module: WALSATOOLS. __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------------------- WaLSAtools v1.0 Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------------------- The input datacube is of size: [91, 41, 610] Temporally, the important values are: 2-element duration (Nyquist period) = 24.0000 seconds Time series duration = 7320 seconds Nyquist frequency = 41.6667 mHz == detrend next row... 91/ 91 .... % finished (through bins, from larger B): 100. mode = 0: log(power) COMPLETED! The output figure of this example is illustrated in panel ( a ), where the averaged (temporal) power spectra within each magnetic-field bin (with 50 G width) are plotted along the y axis. Thus the background colour represents the power spectral density (plotted in a base 10 logarithmic scale). The two horizontal dashed lines mark the periods (or frequencies) of three and five minutes oscillations. Panels ( c ) and ( d ), respectively, illustrate the longitudinal magnetic-field map from SDO/HMI and one image of the SDO/AIA 170 nm time series (corresponding to the middle of the observations) for the region of interest analysed here. Please note that, in this example, the power is considerably smaller in the larger magnetic-field regions compared to the areas with lower magnetic fields, though it still can be significant in some frequencies. One reason is that the amplitudes of fluctuations are likely very small inside the umbra at these observations (which can depend on many factors, including the spatial resolution and the height ranges sampled by these observations). One way to identify power enhancements in individual bins is to use the /normalizedbins keyword, which normalises each power spectrum (in each bin) to it maximum value. See here to learn about all keywords available to this analysis tool. As a guide, see this scientific article where this approach could help revealing signatures of resonant MHD oscillations in a pore umbra. Source code 1", "title": "B-&#969; Diagram"}, {"location": "idl/WaLSAtools/", "text": "WaLSAtools \u00b6 WaLSAtools is designed for ease of use and accessibility. Its interactive interface guides you through the analysis process, providing clear instructions and helpful information at each step. This section demonstrates how to use WaLSAtools and highlights its key features. Before diving into the interactive demonstration, we recommend familiarizing yourself with the various analysis methods available in WaLSAtools. You can find detailed descriptions of these methods in the Introduction section. Additionally, this page provides several Worked Examples of different analysis techniques applied to synthetic datasets (see the left menu). To learn more about its capabilities and how to apply it to your research, we encourage you to explore the WaLSAtools documentation, the associated Nature Reviews Methods Primers article ( full-text access to a view-only version and its Supplementary Information ), and the provided examples. If you use WaLSAtools in your work, please remember to cite it appropriately (see Citation ). The \"Under the Hood\" section provides details on the individual routines used for wave analysis within the WaLSAtools package, for those interested in exploring the underlying code. However, we strongly encourage all users to perform their analyses by running WaLSAtools directly, as this ensures the correct execution of the analysis workflow and provides a more user-friendly experience. Interactive Demonstration WaLSAtools provides an interactive interface that simplifies wave analysis. To launch the interface, simply run the WaLSAtools command in IDL: IDL> WaLSAtools The interface will guide you through the following steps: Select a category of analysis: Choose from single time series analysis or cross-correlation analysis. Choose the data type: Specify the type of data you are working with (e.g., 1D signal, 3D datacube). Pick a specific analysis method: Select the method most suitable for your data and research question. The interface will then provide information on the selected method, including its calling sequence, input parameters, and expected outputs. Here's an example of the execution of WaLSAtools in IDL (in terminal) % Compiled module: WALSATOOLS. __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------------------- WaLSAtools v1.0 Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------------------- Performing various wave analysis techniques on (a) Single time series (1D signal or [x,y,t] cube) Methods: (1) 1D analysis with: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) (2) 3D analysis: k-\u03c9 (with optional Fourier filtering) or B-\u03c9 diagrams (b) Two time series (cross correlations between two signals) With: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) ---------------------------------------------------------------------------- -- Category -- (enter the option a or b): a b ------------------------------------------------ --- Single time-series analysis: (1) 1D, (2) 3D ------------------------------------------------ -- Method (enter the option 1 or 2): 1 2 ---------------------------------------------------------------------- --- 1D analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT ---------------------------------------------------------------------- --- Type of analysis (enter the option 1-4): 1 2 3 4 --------------------------- ---- 1D analysis with FFT: --------------------------- + CALLING SEQUENCE: walsatools, /fft, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with FFT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ------------------------------- ---- 1D analysis with Wavelet: ------------------------------- + CALLING SEQUENCE: walsatools, /wavelet, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude mother: wavelet function (also depends on param). default: Morlet other available functions: Paul and DOG are available param: optional mother wavelet parameter (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat) dj: spacing between discrete scales. default: 0.025 global: returns global wavelet spectrum (integrated over frequency domain) oglobal: global wavelet spectrum excluding regions influenced by CoI cglobal: global wavelet spectrum excluding regions influenced by (1) CoI and (2) insignificant power colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166 nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) coi: cone-of-influence cube (when global, oglobal, or cglobal are not set) dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) note: only for global (traditional, oglobal, or cglobal) wavelet ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with Wavelet -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ------------------------------------ ---- 1D analysis with Lomb-Scargle: ------------------------------------ + CALLING SEQUENCE: walsatools, /lomb, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with Lomb-Scargle -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- --------------------------- ---- 1D analysis with HHT: --------------------------- + CALLING SEQUENCE: walsatools, /hht, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude stdlimit: standard deviation to be achieved before accepting an IMF (default: 0.2) nfilter: Hanning window width for two dimensional spectrum smoothing (default: 3) (an odd integer equal to or larger than 3; 0: to avoid the windowing) emd: if set, intrinsic mode functions (IMFs) and their associated frequencies (i.e., instantaneous frequencies) can be outputted nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) imf: intrinsic mode functions (IMFs) from EMD analysis, if emd is set instantfreq: instantaneous frequencies of each component time series, if emd is set dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with HHT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ----------------------------------- --- 3D analysis: (1) k-\u03c9, (2) B-\u03c9 ----------------------------------- --- Type of analysis (enter the option 1 or 2): 1 2 ----------------------- ---- 3D analysis: k-\u03c9 ----------------------- + CALLING SEQUENCE: walsatools, /komega, signal=signal, time=time, arcsecpx=arcsecpx, power=p, frequencies=f, wavenumber=k + INPUTS: signal: [x,y,t] datacube [!] note: at present the input datacube needs to have identical x and y dimensions. if not supplied like this the datacube will be cropped accordingly. cadence: delta time between successive frames (in seconds) time: observing times in seconds (1D array). It is ignored if cadence is provided arcsecpx: pixel size (spatial sampling) in arcsec; a float number + OPTIONAL KEYWORDS: filtering: if set, filtering is proceeded f1: lower frequency to filter - given in mHz f2: upper frequency to filter - given in mHz k1: lower wavenumber to filter - given in mHz k2: upper wavenumber to filter - given in arcsec^-1 spatial_torus: if equal to zero, the annulus used for spatial filtering will not have a Gaussian-shaped profile temporal_torus: if equal to zero, the temporal filter will not have a Gaussian-shaped profile no_spatial: if set, no spatial filtering is performed no_temporal: if set, no temporal filtering is performed silent: if set, the k-\u03c9 diagram is not plotted clt: colour table number (IDL ctload) koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2) threemin: if set, a horizontal line marks the three-minute periodicity fivemin: if set, a horizontal line marks the five-minute periodicity xlog: if set, x-axis (wavenumber) is plotted in logarithmic scale ylog: if set, y-axis (frequency) is plotted in logarithmic scale xrange: x-axis (wavenumber) range yrange: y-axis (frequency) range nox2: if set, 2nd x-axis (spatial size, in arcsec) is not plotted (spatial size (i.e., wavelength) = (2*!pi)/wavenumber) noy2: if set, 2nd y-axis (period, in sec) is not plotted (p = 1000/frequency) smooth: if set, power is smoothed mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made + OUTPUTS: power: 2D array of power in log10 scale (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) wavenumber: 1D array of wavenumber (in arcsec^-1) filtered_cube: 3D array of filtered datacube (if filtering is set) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following articles if you use WaLSAtools: k-\u03c9 analysis -- Jess et al. 2021, LRSP, in preparation -- Jess et al. 2017, ApJ, 842, 59 (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ----------------------- ---- 3D analysis: B-\u03c9 ----------------------- + CALLING SEQUENCE: walsatools, /bomega, signal=signal, time=time, bmap=bmap, power=p, frequencies=f, barray=b + INPUTS: signal: [x,y,t] datacube time: observing times in seconds (1D array) bmap: a map of magnetic fields (in G), same [x,y] size as in datacube + OPTIONAL KEYWORDS: binsize: size of magnetic-field bins, over which power spectra are averaged (default: 50 G) silent: if set, the B-\u03c9 diagram is not plotted clt: colour table number (IDL ctload) koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2) threemin: if set, a horizontal line marks the three-minute periodicity fivemin: if set, a horizontal line marks the five-minute periodicity xlog: if set, x-axis (wavenumber) is plotted in logarithmic scale ylog: if set, y-axis (frequency) is plotted in logarithmic scale xrange: x-axis (wavenumber) range yrange: y-axis (frequency) range noy2: if set, 2nd y-axis (period, in sec) is not plotted (p = 1000/frequency) smooth: if set, power is smoothed normalizedbins if set, power at each bin is normalised to its maximum value (this facilitates visibility of relatively small power) xtickinterval x-asis (i.e., magnetic fields) tick intervals in G (default: 400 G) mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made + OUTPUTS: power: 2D array of power (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (y-axis) in mHz barray: 1D array of magnetic fields (x-axis) in G ----------------------------------------------------------------------------------------- * CITATION: Please cite the following articles if you use WaLSAtools: B-\u03c9 analysis -- Jess et al. 2021, LRSP, in preparation -- Stangalini et al. 2021, A&A, in press (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------- --- Two time-series analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT ----------------------------------------------------------------------------------- --- Type of analysis (enter the option 1-4): 1 2 3 4 ------------------------------------ ---- cross-power analysis with FFT: ------------------------------------ + CALLING SEQUENCE: walsatools, /fft, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1) Each of these segments is considered an independent realisation of the underlying process. The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency. siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated + OUTPUTS: cospectrum: absolute values of the cross power (1D array) coherence: coherence (1D array) phase_angle: phase angles in degrees (1D array) frequency: 1D array of frequencies (in mHz) signif_cross: significance levels for the cospectrum (1D array) signif_coh: significance levels for the coherence (1D array) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with FFT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ---------------------------------------- ---- cross-power analysis with Wavelet: ---------------------------------------- + CALLING SEQUENCE: walsatools, /wavelet, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated mother: wavelet function (also depends on param). default: Morlet other available functions: Paul and DOG are available param: optional mother wavelet parameter (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat) dj: spacing between discrete scales. default: 0.025 colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166 plot: if set, wavelet power spectra of the two time series as well as their wavelet cospectrum (cross-spectrum) and coherence, along with the significance levels as contours, are plotted The phase angles between the two time series are also depicted by default Arrows pointing right mark zero phase (meaning in-phase oscillations), arrows pointing straight up indicate data2 lags behind data1 by 90 degrees noarrow: if set, the phase angles are not overplotted as arrows arrowdensity: number of arrows (illustrating phase angles) in x and y directions (default: [30,18]) arrowsize: size of the arrows (default: 1) arrowheadsize: size of the arrows head (default: 1) pownormal: if set, the power is normalised to its maximum value log: if set, the power spectra and the cospectrum are plotted in log10 scale removespace: if set, the time-period areas affected by the CoI over the entire time range are not plotted clt: colour table number (idl ctload) koclt: custom colour tables (currently available: 1 and 2) + OUTPUTS: cospectrum: absolute values of the cross power (2D array for wavelet spectrum; 1D for global, oglobal, or cglobal spectrum) coherence: wavelet coherence (same size as cospectrum) phase_angle: phase angles in degrees (same size as cospectrum) frequency: 1D array of frequencies (in mHz) signif_cross: significance map for the cospectrum (same size as cospectrum) scale: the scale vector of scale indices, given by the overlap of scale1 and scale2 cospectrum/signif_coh indicates regions above the siglevel signif_coh: significance map for the coherence (same size as cospectrum) coherence/signif_coh indicates regions above the siglevel coi: the vector of the cone-of-influence coh_global: global coherence averaged over all times phase_global: global phase averaged over all times cross_global: global cross wavelet averaged over all times coh_oglobal: global coherence averaged over all times excluding areas affected by CoI phase_oglobal: global phase averaged over all times excluding areas affected by CoI cross_oglobal: global cross wavelet averaged over all times excluding areas affected by CoI ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with Wavelet -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- --------------------------------------------- ---- cross-power analysis with Lomb-Scargle: --------------------------------------------- + CALLING SEQUENCE: walsatools, /lomb, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1) Each of these segments is considered an independent realisation of the underlying process. The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency. siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated + OUTPUTS: cospectrum: absolute values of the cross power (1D array) coherence: coherence (1D array) phase_angle: phase angles in degrees (1D array) frequency: 1D array of frequencies (in mHz) signif_cross: significance levels for the cospectrum (1D array) signif_coh: significance levels for the coherence (1D array) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with Lomb-Scargle -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ------------------------------------- ---- cross-powerD analysis with HHT: ------------------------------------- + CALLING SEQUENCE: walsatools, /hht, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1) Each of these segments is considered an independent realisation of the underlying process. The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency. stdlimit: standard deviation to be achieved before accepting an IMF (recommended value between 0.2 and 0.3; perhaps even smaller); default: 0.2 nfilter: Hanning window width for two dimensional smoothing of the Hilbert spectrum. default: 3 (an odd integer, preferably equal to or larger than 3; equal to 0 to avoid the windowing) siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated + OUTPUTS: cospectrum: absolute values of the cross power (1D array) coherence: coherence (1D array) phase_angle: phase angles in degrees (1D array) frequency: 1D array of frequencies (in mHz) signif_cross: significance levels for the cospectrum (1D array) signif_coh: significance levels for the coherence (1D array) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with HHT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- If the data, time, or cadence, and the type of analysis are not provided, the code enters a guidance mode, providing detailed instructions and prompting you for the necessary information. Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSAtools ; ; PURPOSE : ; Performing various wave analysis techniques on ; ( a ) Single time series ( 1 D signal or [ x , y , t ] cube ) ; Methods : ; ( 1 ) 1 D analysis with : FFT ( Fast Fourier Transform ), Wavelet , Lomb - Scargle , ; HHT ( Hilbert - Huang Transform ), or Welch ; ( 2 ) 3 D analysis : k - \u03c9 ( with optional Fourier filtering ) or B - \u03c9 diagrams ; ; ( b ) Two time series ( cross correlations between two signals ) ; With : FFT ( Fast Fourier Transform ), , ; Lomb - Scargle , HHT ( Hilbert - Huang Transform , or Welch ; ; CALLING SEQUENCE : ; IDL > WaLSAtools ; Type WaLSAtools in IDL for further information ( and all keywords ) ; ; Documentation and info : www . WaLSA . tools ; GitHub repository : www . github . com / WaLSAteam / WaLSAtools ; \u00a9 WaLSA Team ( www . WaLSA . team ) ; Please see www . WaLSA . tools / license & www . WaLSA . tools / citation if you use WaLSAtools ; - pro walsatools , $ ; ( 1 ) 1 D analysis with : FFT , Wavelet , Long - Scargle , EMD , or HHT : signal = signal , time = time , $ ; main inputs power = power , frequencies = frequencies , significance = significance , coi = coi , averagedpower = averagedpower , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , welch = welch , wavelet = wavelet , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , psd = psd , $ siglevel = siglevel , nperm = nperm , nosignificance = nosignificance , $ ; significance - level parameters mother = mother , param = param , dj = dj , global = global , oglobal = oglobal , rgws = rgws , colornoise = colornoise , $ ; Wavelet parameters / options stdlimit = stdlimit , nfilter = nfilter , emd = emd , imf = imf , instantfreq = instantfreq , $ ; HHT parameters / options window_size = window_size , overlap = overlap , wfft_size = wfft_size , $ ; Welch parameters mode = mode , $ ; power calibration dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ ; dominant frequency ; + keywords / options for ; ( 2 ) 2 D analysis : k - omega diagram : arcsecpx = arcsecpx , cadence = cadence , $ ; additional main input wavenumber = wavenumber , filtered_cube = filtered_cube , $ ; main ( additional ) outputs filtering = filtering , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , spatial_torus = spatial_torus , temporal_torus = temporal_torus , $ ; filtering options no_spatial_filt = no_spatial_filt , no_temporal_filt = no_temporal_filt , $ clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , $ ; plotting keywords epsfilename = epsfilename , noy2 = noy2 , nox2 = nox2 , smooth = smooth , savefits = savefits , filename = filename , $ ; ( 2 ) 2 D analysis : B - omega diagram : bmap = Bmap , binsize = binsize , barray = Barray , silent = silent , bomega = bomega , komega = komega , help = help , $ normalizedbins = normalizedbins , xtickinterval = xtickinterval , version = version , plot = plot , log = log , removespace = removespace , $ data1 = data1 , data2 = data2 , phase_angle = phase_angle , coherence = coherence , cospectrum = cospectrum , amplitude = amplitude , $ ; cross spectra analysis signif_coh = signif_coh , signif_cross = signif_cross , coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ pownormal = pownormal , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , noarrow = noarrow , $ n_segments = n_segments , d1_power = d1_power , d2_power = d2_power , period = period compile_opt idl2 ; ----------------------------------------------------------------------------------------------------------------------------------- print , ' ' print , ' __ __ _ _____ ' print , ' \\ \\ / / | | / ____| /\\ ' print , ' \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ ' print , ' \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ ' print , ' \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ ' print , ' \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_ \\' print , ' ' print , ' ' print , ' \u00a9 WaLSA Team (www.WaLSA.team)' print , ' -----------------------------------------------------------------------------------' print , ' WaLSAtools v1.0.0' print , ' Documentation: www.WaLSA.tools' print , ' GitHub repository: www.github.com/WaLSAteam/WaLSAtools' print , ' -----------------------------------------------------------------------------------' if keyword_set ( cadence ) or keyword_set ( time ) then temporalinfo = 1 else temporalinfo = 0 if keyword_set ( signal ) and temporalinfo then begin if keyword_set ( fft ) or keyword_set ( wavelet ) or keyword_set ( lombscargle ) or keyword_set ( welch ) or $ keyword_set ( hht ) or keyword_set ( komega ) or keyword_set ( bomega ) $ then help = 0 else help = 1 endif else help = 1 if keyword_set ( signal ) eq 0 then begin if keyword_set ( data1 ) and keyword_set ( data2 ) and temporalinfo then begin if keyword_set ( fft ) or keyword_set ( wavelet ) or keyword_set ( lombscargle ) or keyword_set ( welch ) $ or keyword_set ( hht ) then help = 0 else help = 1 endif else help = 1 endif if help then begin print , ' Performing various wave analysis techniques on ' print , ' (a) Single time series (1D signal or [x,y,t] cube)' print , ' Methods: ' print , ' (1) 1D analysis with: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle,' print , ' HHT (Hilbert-Huang Transform), or Welch' print , ' (2) 3D analysis: k-\u03c9 (with optional Fourier filtering) or B-\u03c9 diagrams' print print , ' (b) Two time series (cross correlations between two signals)' print , ' With: FFT (Fast Fourier Transform), Wavelet,' print , ' Lomb-Scargle, HHT (Hilbert-Huang Transform) or Welch' print , ' ----------------------------------------------------------------------------' if keyword_set ( version ) then begin print return endif category = ' ' read , category , prompt = ' -- Category -- (enter the option a or b): ' if category eq 'a' or category eq 'b' then goto , categories else begin ask : read , category , prompt = ' -- Please enter a or b (i.e., one of the categories (a) or (b) listed above): ' if category eq 'a' or category eq 'b' then goto , categories else goto , ask endelse categories : print if category eq 'a' then begin print , ' ------------------------------------------------' print , ' --- Single time-series analysis: (1) 1D, (2) 3D' print , ' ------------------------------------------------' type = ' ' read , type , prompt = ' -- Method (enter the option 1 or 2): ' while type lt 1 or type gt 2 do begin read , type , prompt = ' -- Please enter 1 or 2 (i.e., one of the methods listed above): ' if type eq 1 or type eq 2 then break endwhile print if type eq 1 then begin print , ' ---------------------------------------------------------------------------------' print , ' --- 1D analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT, (5) Welch' print , ' ---------------------------------------------------------------------------------' m1type = ' ' read , m1type , prompt = ' --- Type of analysis (enter the option 1-4): ' while m1type lt 1 or m1type gt 4 do begin read , m1type , prompt = ' --- Please enter a number between 1 and 4: ' if m1type eq 1 or m1type eq 2 or m1type eq 3 or m1type eq 4 then break endwhile print if m1type eq 1 then begin print , ' ---------------------------' print , ' ---- 1D analysis with FFT:' print , ' ---------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /fft, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 2 then begin print , ' -------------------------------' print , ' ---- 1D analysis with Wavelet:' print , ' -------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /wavelet, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 3 then begin print , ' ------------------------------------' print , ' ---- 1D analysis with Lomb-Scargle:' print , ' ------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /lomb, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 4 then begin print , ' ---------------------------' print , ' ---- 1D analysis with HHT:' print , ' ---------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /hht, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 5 then begin print , ' ----------------------------' print , ' ---- 1D analysis with Welch:' print , ' ----------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /welch, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif print print , ' + INPUTS:' print , ' signal: 1D time series, or [x,y,t] datacube' print , ' time: observing times in seconds (1D array)' print print , ' + OPTIONAL KEYWORDS:' ; ---- padding , detrending , and apodization parameters ---- print , ' padding: oversampling factor: zero padding (default: 1)' print , ' apod: extent of apodization edges (of a Tukey window); default 0.1' print , ' nodetrendapod: if set, neither detrending nor apodization is performed!' print , ' pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2' print , ' polyfit: the degree of polynomial fit to the data to detrend it' print , ' if set, instead of linear fit this polynomial fit is performed' print , ' meantemporal: if set, only a very simple temporal detrending is performed by' print , ' subtracting the mean signal from the signal' print , ' i.e., the fitting procedure (linear or higher polynomial degrees) is omitted' print , ' meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending)' print , ' recon: optional keyword that will Fourier reconstruct the input timeseries' print , ' note: this does not preserve the amplitudes and is only useful when attempting' print , ' to examine frequencies that are far away from the -untrustworthy- low frequencies' print , ' resample if recon is set, then by setting resample, amplitudes are scaled to approximate actual values.' ; ---- significance - level parameters ---- print , ' siglevel: significance level (default: 0.05 = 5 % s ignificance = 95 % c onfidence)' print , ' nperm: number of random permutations for the significance test (default: 1000)' print , ' nosignificance: if set, no significance level is calculated' ; ---- power calibration ---- print , ' mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude' if m1type eq 2 then begin print , ' mother: wavelet function (also depends on param). default: Morlet' print , ' other available functions: Paul and DOG are available' print , ' param: optional mother wavelet parameter' print , ' (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat)' print , ' dj: spacing between discrete scales. default: 0.025' print , ' global: returns global wavelet spectrum (time-averaged wavelet power)' print , ' oglobal: global wavelet spectrum excluding regions affected by CoI' print , ' rgws: time-integral of wavelet power excluding regions influenced by cone-of-influence' print , ' and only for those above the significance level' print , ' i.e., power-weighted frequency distribution (with significant power & unaffected by CoI)' print , ' Note: this is likely the most correct spectrum!' print , ' colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166' endif if m1type eq 4 then begin print , ' stdlimit: standard deviation to be achieved before accepting an IMF (default: 0.2)' print , ' nfilter: Hanning window width for two dimensional spectrum smoothing (default: 3)' print , ' (an odd integer equal to or larger than 3; 0: to avoid the windowing)' print , ' emd: if set, intrinsic mode functions (IMFs) and their associated frequencies' print , ' (i.e., instantaneous frequencies) can be outputted' endif if m1type eq 5 then begin ; ---- Welch parameters / options ---- print , ' window_size: size of Hann window. This code currently uses a Hann window (e.g., 256)' print , ' overlap: commonly, the overlap is set to half the window size.' print , ' wfft_size: generally, a window_size*2 is used for the FFT size to optimize the FFT performance.' endif ; ---- dominant frequency ---- print , ' nodominantfreq: if set, dominant frequency and dominant power are not calculated' print , ' (to, e.g., save computational time for large datasets)' print print , ' + OUTPUTS:' print , ' power: 1D (or 3D; same dimension as input data) array of power' print , ' 2D (or 4D) array for wavelet spectrum' print , ' (in DN^2/mHz, i.e., normalised to frequency resolution)' print , ' frequencies: 1D array of frequencies (in mHz)' print , ' period: 1D array of periods (in seconds)' print , ' significance: significance array (same size and units as power)' if m1type eq 4 then begin print , ' imf: intrinsic mode functions (IMFs) from EMD analysis, if emd is set' print , ' instantfreq: instantaneous frequencies of each component time series, if emd is set' endif if m1type eq 2 then begin print , ' coi: cone-of-influence cube (when global, oglobal, or rgws are not set)' endif print , ' dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz)' print , ' same spatial size as input data (i.e., 1D or 2D)' print , ' if there are multiple peaks with the same power, the lowest dominant frequency is returned!' print , ' dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency' print , ' same spatial size as input data (i.e., 1D or 2D)' print , ' rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range' print , ' averagedpower: spatially averaged power spectrum (of multiple 1D power spectra)' print , ' amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube)' if m1type eq 2 then begin print , ' note: only for global (traditional, oglobal, or rgws) wavelet' endif print , ' -----------------------------------------------------------------------------------------' if m1type eq 1 then m1typecite = 'WaLSAtools: 1D analysis with FFT' if m1type eq 2 then m1typecite = 'WaLSAtools: 1D analysis with Wavelet' if m1type eq 3 then m1typecite = 'WaLSAtools: 1D analysis with Lomb-Scargle' if m1type eq 4 then m1typecite = 'WaLSAtools: 1D analysis with HHT' if m1type eq 5 then m1typecite = 'WaLSAtools: 1D analysis with Welch' print , ' * CITATION:' print , ' Please cite the following article if you use ' + m1typecite print , ' -- Jess et al. 2023, Living Reviews in Solar Physics, 20, 1' print , ' (see www.WaLSA.tools/citation)' print , ' -----------------------------------------------------------------------------------------' print endif if type eq 2 then begin print , ' -----------------------------------' print , ' --- 3D analysis: (1) k-\u03c9, (2) B-\u03c9' print , ' -----------------------------------' m2type = ' ' read , m2type , prompt = ' --- Type of analysis (enter the option 1 or 2): ' while m2type lt 1 or m2type gt 2 do begin read , m2type , prompt = ' --- Please enter 1 or 2: ' if m2type eq 1 or m2type eq 2 then break endwhile print if m2type eq 1 then begin print , ' -----------------------' print , ' ---- 3D analysis: k-\u03c9' print , ' -----------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /komega, signal=signal, time=time, arcsecpx=arcsecpx, power=p, frequencies=f, wavenumber=k' print print , ' + INPUTS:' print , ' signal: [x,y,t] datacube' print , ' [!] note: at present the input datacube needs to have identical x and y dimensions.' print , ' if not supplied like this the datacube will be cropped accordingly.' print , ' cadence: delta time between successive frames (in seconds)' print , ' time: observing times in seconds (1D array). It is ignored if cadence is provided' print , ' arcsecpx: pixel size (spatial sampling) in arcsec; a float number' print print , ' + OPTIONAL KEYWORDS:' ; ---- filtering options ---- print , ' filtering: if set, filtering is proceeded' print , ' f1: lower frequency to filter - given in mHz' print , ' f2: upper frequency to filter - given in mHz' print , ' k1: lower wavenumber to filter - given in mHz' print , ' k2: upper wavenumber to filter - given in arcsec^-1' print , ' spatial_torus: if equal to zero, the annulus used for spatial filtering will not have a Gaussian-shaped profile' print , ' temporal_torus: if equal to zero, the temporal filter will not have a Gaussian-shaped profile' print , ' no_spatial: if set, no spatial filtering is performed' print , ' no_temporal: if set, no temporal filtering is performed' ; ---- plotting parameters ---- print , ' silent: if set, the k-\u03c9 diagram is not plotted' print , ' clt: colour table number (IDL ctload)' print , ' koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2)' print , ' threemin: if set, a horizontal line marks the three-minute periodicity' print , ' fivemin: if set, a horizontal line marks the five-minute periodicity' print , ' xlog: if set, x-axis (wavenumber) is plotted in logarithmic scale' print , ' ylog: if set, y-axis (frequency) is plotted in logarithmic scale' print , ' xrange: x-axis (wavenumber) range' print , ' yrange: y-axis (frequency) range' print , ' nox2: if set, 2nd x-axis (spatial size, in arcsec) is not plotted' print , ' (spatial size (i.e., wavelength) = (2*!pi)/wavenumber)' print , ' noy2: if set, 2nd y-axis (period, in sec) is not plotted' print , ' (p = 1000/frequency)' print , ' smooth: if set, power is smoothed' ; ---- power calibration ---- print , ' mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude' ; ---- output options ---- print , ' epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made' print print , ' + OUTPUTS:' print , ' power: 2D array of power in log10 scale' print , ' (in DN^2/mHz, i.e., normalised to frequency resolution)' print , ' frequencies: 1D array of frequencies (in mHz)' print , ' wavenumber: 1D array of wavenumber (in arcsec^-1)' print , ' filtered_cube: 3D array of filtered datacube (if filtering is set)' endif if m2type eq 2 then begin print , ' -----------------------' print , ' ---- 3D analysis: B-\u03c9' print , ' -----------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /bomega, signal=signal, time=time, bmap=bmap, power=p, frequencies=f, barray=b' print print , ' + INPUTS:' print , ' signal: [x,y,t] datacube' print , ' time: observing times in seconds (1D array)' print , ' bmap: a map of magnetic fields (in G), same [x,y] size as in datacube' print print , ' + OPTIONAL KEYWORDS:' print , ' binsize: size of magnetic-field bins, over which power spectra are averaged' print , ' (default: 50 G)' print , ' silent: if set, the B-\u03c9 diagram is not plotted' print , ' clt: colour table number (IDL ctload)' print , ' koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2)' print , ' threemin: if set, a horizontal line marks the three-minute periodicity' print , ' fivemin: if set, a horizontal line marks the five-minute periodicity' print , ' xlog: if set, x-axis (magnetic field) is plotted in logarithmic scale' print , ' ylog: if set, y-axis (frequency) is plotted in logarithmic scale' print , ' xrange: x-axis (wavenumber) range' print , ' yrange: y-axis (frequency) range' print , ' noy2: if set, 2nd y-axis (period, in sec) is not plotted' print , ' (p = 1000/frequency)' print , ' smooth: if set, power is smoothed' print , ' normalizedbins if set, power at each bin is normalised to its maximum value' print , ' (this facilitates visibility of relatively small power)' print , ' xtickinterval x-asis (i.e., magnetic fields) tick intervals in G (default: 400 G)' ; ---- power calibration ---- print , ' mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude' ; ---- output options ---- print , ' epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made' print print , ' + OUTPUTS:' print , ' power: 2D array of power' print , ' (in DN^2/mHz, i.e., normalised to frequency resolution)' print , ' frequencies: 1D array of frequencies (y-axis) in mHz' print , ' barray: 1D array of magnetic fields (x-axis) in G' endif print , ' -----------------------------------------------------------------------------------------' if m2type eq 1 then m2typecite = 'WaLSAtools: k-\u03c9 analysis' if m2type eq 2 then m2typecite = 'WaLSAtools: B-\u03c9 analysis' print , ' * CITATION:' print , ' Please cite the following articles if you use ' + m2typecite print , ' -- Jess et al. 2023, Living Reviews in Solar Physics, 20, 1' if m2type eq 1 then $ print , ' -- Jess et al. 2017, ApJ, 842, 59' if m2type eq 2 then $ print , ' -- Stangalini et al. 2021, A&A, in press' print , ' (see www.WaLSA.tools/citation)' print , ' -----------------------------------------------------------------------------------------' print endif endif if category eq 'b' then begin print , ' ----------------------------------------------------------------------------------------------' print , ' --- Two time-series analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT, (5) Welch' print , ' ----------------------------------------------------------------------------------------------' c1type = ' ' read , c1type , prompt = ' --- Type of analysis (enter the option 1-4): ' while c1type lt 1 or c1type gt 4 do begin read , c1type , prompt = ' --- Please enter a number between 1 and 4: ' if c1type eq 1 or c1type eq 2 or c1type eq 3 or c1type eq 4 then break endwhile print if c1type eq 1 then begin print , ' ------------------------------------' print , ' ---- cross-power analysis with FFT:' print , ' ------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /fft, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 2 then begin print , ' ----------------------------------------' print , ' ---- cross-power analysis with Wavelet:' print , ' ----------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /wavelet, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 3 then begin print , ' ---------------------------------------------' print , ' ---- cross-power analysis with Lomb-Scargle:' print , ' ---------------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /lomb, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 4 then begin print , ' -------------------------------------' print , ' ---- cross-power analysis with HHT:' print , ' -------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /hht, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 5 then begin print , ' ---------------------------------------------' print , ' ---- cross-power analysis with Welch:' print , ' ---------------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /welch, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif print print , ' + INPUTS:' print , ' data1: first (1D) time series' print , ' data2: second (1D) time series, co-aligned with data1' print , ' time: observing times in seconds (1D array)' print print , ' + OPTIONAL KEYWORDS:' ; ---- padding , detrending , and apodization parameters ---- print , ' padding: oversampling factor: zero padding (default: 1)' print , ' apod: extent of apodization edges (of a Tukey window); default 0.1' print , ' nodetrendapod: if set, neither detrending nor apodization is performed!' print , ' pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2' print , ' polyfit: the degree of polynomial fit to the data to detrend it' print , ' if set, instead of linear fit this polynomial fit is performed' print , ' meantemporal: if set, only a very simple temporal detrending is performed by' print , ' subtracting the mean signal from the signal' print , ' i.e., the fitting procedure (linear or higher polynomial degrees) is omitted' print , ' meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending)' if c1type ne 2 then begin print , ' recon: optional keyword that will Fourier reconstruct the input timeseries' print , ' note: this does not preserve the amplitudes and is only useful when attempting' print , ' to examine frequencies that are far away from the -untrustworthy- low frequencies' print , ' resample if recon is set, then by setting resample, amplitudes are scaled to approximate actual values.' print , ' n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1)' print , ' Each of these segments is considered an independent realisation of the underlying process.' print , ' The cross spectrum for each segement are averaged together to provide phase and coherence ' print , ' estimates at each frequency.' endif if c1type eq 4 then begin ; ---- HHT parameters / options ---- print , ' stdlimit: standard deviation to be achieved before accepting an IMF' print , ' (recommended value between 0.2 and 0.3; perhaps even smaller); default: 0.2' print , ' nfilter: Hanning window width for two dimensional smoothing of the Hilbert spectrum. default: 3 ' print , ' (an odd integer, preferably equal to or larger than 3; equal to 0 to avoid the windowing)' endif if c1type eq 5 then begin ; ---- Welch parameters / options ---- print , ' window_size: size of Hann window. This code currently uses a Hann window (e.g., 256)' print , ' overlap: commonly, the overlap is set to half the window size.' print , ' wfft_size: generally, a window_size*2 is used for the FFT size to optimize the FFT performance.' endif ; ---- significance - level parameters ---- print , ' siglevel: significance level (default: 0.05 = 5 % s ignificance = 95 % c onfidence)' print , ' nperm: number of random permutations for the significance test (default: 50)' print , ' note: the default value is set for quick tests. Choose a large number' print , ' (e.g., 2000 or larger) for a better statistical result' print , ' nosignificance: if set, no significance level is calculated' if c1type eq 2 then begin ; ---- wavelet parameters / options ---- print , ' mother: wavelet function (also depends on param). default: Morlet' print , ' other available functions: Paul and DOG are available' print , ' param: optional mother wavelet parameter' print , ' (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat)' print , ' dj: spacing between discrete scales. default: 0.025' print , ' colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166' endif if c1type eq 2 then begin ; ---- plotting ---- print , ' plot: if set, wavelet power spectra of the two time series as well as' print , ' their wavelet cospectrum (cross-spectrum) and coherence, along with the' print , ' significance levels as contours, are plotted' print , ' The phase angles between the two time series are also depicted by default' print , ' Arrows pointing right mark zero phase (meaning in-phase oscillations),' print , ' arrows pointing straight up indicate data2 lags behind data1 by 90 degrees' print , ' noarrow: if set, the phase angles are not overplotted as arrows' print , ' arrowdensity: number of arrows (illustrating phase angles) in x and y directions (default: [30,18])' print , ' arrowsize: size of the arrows (default: 1)' print , ' arrowheadsize: size of the arrows head (default: 1)' print , ' pownormal: if set, the power is normalised to its maximum value' print , ' log: if set, the power spectra and the cospectrum are plotted in log10 scale' print , ' removespace: if set, the time-period areas affected by the CoI over the entire time range are not plotted' print , ' clt: colour table number (idl ctload)' print , ' koclt: custom colour tables (currently available: 1 and 2)' endif print print , ' + OUTPUTS:' if c1type eq 2 then begin print , ' cospectrum: absolute values of the cross power' print , ' (2D array for wavelet spectrum; 1D for global, oglobal, or rgws spectrum)' print , ' coherence: wavelet coherence (same size as cospectrum)' print , ' phase_angle: phase angles in degrees (same size as cospectrum)' print , ' frequency: 1D array of frequencies (in mHz)' print , ' signif_cross: significance map for the cospectrum (same size as cospectrum)' print , ' scale: the scale vector of scale indices, given by the overlap of scale1 and scale2' print , ' cospectrum/signif_coh indicates regions above the siglevel' print , ' signif_coh: significance map for the coherence (same size as cospectrum)' print , ' coherence/signif_coh indicates regions above the siglevel' print , ' coi: the vector of the cone-of-influence' print , ' coh_global: global coherence averaged over all times' print , ' phase_global: global phase averaged over all times' print , ' cross_global: global cross wavelet averaged over all times' print , ' coh_oglobal: global coherence averaged over all times excluding areas affected by CoI' print , ' phase_oglobal: global phase averaged over all times excluding areas affected by CoI' print , ' cross_oglobal: global cross wavelet averaged over all times excluding areas affected by CoI' endif if c1type ne 2 then begin print , ' cospectrum: absolute values of the cross power (1D array)' print , ' coherence: coherence (1D array)' print , ' phase_angle: phase angles in degrees (1D array)' print , ' frequency: 1D array of frequencies (in mHz)' print , ' signif_cross: significance levels for the cospectrum (1D array)' print , ' signif_coh: significance levels for the coherence (1D array)' endif print , ' -----------------------------------------------------------------------------------------' if c1type eq 1 then c1typecite = 'WaLSAtools: cross-correlation analysis with FFT' if c1type eq 2 then c1typecite = 'WaLSAtools: cross-correlation analysis with Wavelet' if c1type eq 3 then c1typecite = 'WaLSAtools: cross-correlation analysis with Lomb-Scargle' if c1type eq 4 then c1typecite = 'WaLSAtools: cross-correlation analysis with HHT' if c1type eq 5 then c1typecite = 'WaLSAtools: cross-correlation analysis with Welch' print , ' * CITATION:' print , ' Please cite the following article if you use ' + c1typecite print , ' -- Jess et al. 2023, Living Reviews in Solar Physics, 20, 1' print , ' (see www.WaLSA.tools/citation)' print , ' -----------------------------------------------------------------------------------------' print endif return endif else print ; ----------------------------------------------------------------------- if keyword_set ( signal ) then begin ii = where ( ~ finite ( signal ), / null , cnull ) if cnull gt 0 then signal [ ii ] = median ( signal ) if min ( signal ) ge max ( signal ) then begin print , ' [!] The signal does not have any (temporal) variation.' print return endif ; ----------------------------------------------------------------------- if keyword_set ( fft ) or keyword_set ( wavelet ) or keyword_set ( lombscargle ) or keyword_set ( hht ) or keyword_set ( welch ) then $ power = walsa_speclizer ( signal , time , $ ; main inputs frequencies = frequencies , significance = significance , imf = imf , instantfreq = instantfreq , averagedpower = averagedpower , period = period , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , wavelet = wavelet , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , psd = psd , $ siglevel = siglevel , nperm = nperm , nosignificance = nosignificance , $ ; significance - level parameters mother = mother , param = param , dj = dj , global = global , coi = coi , oglobal = oglobal , rgws = rgws , colornoise = colornoise , $ ; Wavelet parameters / options stdlimit = stdlimit , nfilter = nfilter , emd = emd , $ ; HHT parameters / options window_size = window_size , overlap = overlap , wfft_size = wfft_size , $ ; Welch parameters mode = mode , silent = silent , $ ; power calibration dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , amplitude = amplitude ) ; dominant frequency ; ----------------------------------------------------------------------- if keyword_set ( komega ) then $ walsa_qub_queeff , signal , arcsecpx , cadence = cadence , time = time , $ power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube , $ ; main ( additional ) outputs filtering = filtering , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , spatial_torus = spatial_torus , temporal_torus = temporal_torus , $ ; filtering options no_spatial_filt = no_spatial_filt , no_temporal_filt = no_temporal_filt , $ clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , $ ; plotting keywords epsfilename = epsfilename , noy2 = noy2 , nox2 = nox2 , smooth = smooth , silent = silent , mode = mode ; ----------------------------------------------------------------------- if keyword_set ( bomega ) then $ walsa_bomega , signal , Bmap , cadence = cadence , time = time , binsize = binsize , power = power , frequencies = frequencies , barray = Barray , $ silent = silent , clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , $ ; plotting keywords xrange = xrange , yrange = yrange , epsfilename = epsfilename , noy2 = noy2 , smooth = smooth , normalizedbins = normalizedbins , $ xtickinterval = xtickinterval , mode = mode endif ; ----------------------------------------------------------------------- if keyword_set ( data1 ) and keyword_set ( data2 ) then begin ii = where ( ~ finite ( data1 ), / null , cnull ) if cnull gt 0 then data1 [ ii ] = median ( data1 ) ii = where ( ~ finite ( data2 ), / null , cnull ) if cnull gt 0 then data2 [ ii ] = median ( data2 ) if keyword_set ( fft ) or keyword_set ( lombscargle ) or keyword_set ( hht ) or keyword_set ( welch ) then $ walsa_cross_spectrum , data1 = data1 , data2 = data2 , time = time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , cospectrum = cospectrum , $ fft = fft , lombscargle = lombscargle , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , $ stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options nosignificance = nosignificance , signif_coh = signif_coh , signif_cross = signif_cross , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power if keyword_set ( wavelet ) then $ walsa_wavelet_cross_spectrum , data1 , data2 , time , $ ; main inputs mother = mother , param = param , dj = dj , colornoise = colornoise , $ coherence = coherence , phase_angle = phase_angle , $ scale = scale , coi = coi , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ cospectrum = cospectrum , period = period , $ frequency = frequency , signif_coh = signif_coh , signif_cross = signif_cross , $ padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal , $ nosignificance = nosignificance , pownormal = pownormal , siglevel = siglevel , $ plot = plot , clt = clt , log = log , nperm = nperm , removespace = removespace , koclt = koclt , $ arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , noarrow = noarrow return endif ; ---------------------------------------------------------------------- end", "title": "WaLSAtools"}, {"location": "idl/WaLSAtools/#walsatools", "text": "WaLSAtools is designed for ease of use and accessibility. Its interactive interface guides you through the analysis process, providing clear instructions and helpful information at each step. This section demonstrates how to use WaLSAtools and highlights its key features. Before diving into the interactive demonstration, we recommend familiarizing yourself with the various analysis methods available in WaLSAtools. You can find detailed descriptions of these methods in the Introduction section. Additionally, this page provides several Worked Examples of different analysis techniques applied to synthetic datasets (see the left menu). To learn more about its capabilities and how to apply it to your research, we encourage you to explore the WaLSAtools documentation, the associated Nature Reviews Methods Primers article ( full-text access to a view-only version and its Supplementary Information ), and the provided examples. If you use WaLSAtools in your work, please remember to cite it appropriately (see Citation ). The \"Under the Hood\" section provides details on the individual routines used for wave analysis within the WaLSAtools package, for those interested in exploring the underlying code. However, we strongly encourage all users to perform their analyses by running WaLSAtools directly, as this ensures the correct execution of the analysis workflow and provides a more user-friendly experience. Interactive Demonstration WaLSAtools provides an interactive interface that simplifies wave analysis. To launch the interface, simply run the WaLSAtools command in IDL: IDL> WaLSAtools The interface will guide you through the following steps: Select a category of analysis: Choose from single time series analysis or cross-correlation analysis. Choose the data type: Specify the type of data you are working with (e.g., 1D signal, 3D datacube). Pick a specific analysis method: Select the method most suitable for your data and research question. The interface will then provide information on the selected method, including its calling sequence, input parameters, and expected outputs. Here's an example of the execution of WaLSAtools in IDL (in terminal) % Compiled module: WALSATOOLS. __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------------------- WaLSAtools v1.0 Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------------------- Performing various wave analysis techniques on (a) Single time series (1D signal or [x,y,t] cube) Methods: (1) 1D analysis with: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) (2) 3D analysis: k-\u03c9 (with optional Fourier filtering) or B-\u03c9 diagrams (b) Two time series (cross correlations between two signals) With: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) ---------------------------------------------------------------------------- -- Category -- (enter the option a or b): a b ------------------------------------------------ --- Single time-series analysis: (1) 1D, (2) 3D ------------------------------------------------ -- Method (enter the option 1 or 2): 1 2 ---------------------------------------------------------------------- --- 1D analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT ---------------------------------------------------------------------- --- Type of analysis (enter the option 1-4): 1 2 3 4 --------------------------- ---- 1D analysis with FFT: --------------------------- + CALLING SEQUENCE: walsatools, /fft, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with FFT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ------------------------------- ---- 1D analysis with Wavelet: ------------------------------- + CALLING SEQUENCE: walsatools, /wavelet, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude mother: wavelet function (also depends on param). default: Morlet other available functions: Paul and DOG are available param: optional mother wavelet parameter (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat) dj: spacing between discrete scales. default: 0.025 global: returns global wavelet spectrum (integrated over frequency domain) oglobal: global wavelet spectrum excluding regions influenced by CoI cglobal: global wavelet spectrum excluding regions influenced by (1) CoI and (2) insignificant power colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166 nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) coi: cone-of-influence cube (when global, oglobal, or cglobal are not set) dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) note: only for global (traditional, oglobal, or cglobal) wavelet ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with Wavelet -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ------------------------------------ ---- 1D analysis with Lomb-Scargle: ------------------------------------ + CALLING SEQUENCE: walsatools, /lomb, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with Lomb-Scargle -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- --------------------------- ---- 1D analysis with HHT: --------------------------- + CALLING SEQUENCE: walsatools, /hht, signal=signal, time=time, power=p, frequencies=f, significance=signif + INPUTS: signal: 1D time series, or [x,y,t] datacube time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 1000) nosignificance: if set, no significance level is calculated mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude stdlimit: standard deviation to be achieved before accepting an IMF (default: 0.2) nfilter: Hanning window width for two dimensional spectrum smoothing (default: 3) (an odd integer equal to or larger than 3; 0: to avoid the windowing) emd: if set, intrinsic mode functions (IMFs) and their associated frequencies (i.e., instantaneous frequencies) can be outputted nodominantfreq: if set, dominant frequency and dominant power are not calculated (to, e.g., save computational time for large datasets) + OUTPUTS: power: 1D (or 3D; same dimension as input data) array of power 2D (or 4D) array for wavelet spectrum (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) significance: significance array (same size and units as power) imf: intrinsic mode functions (IMFs) from EMD analysis, if emd is set instantfreq: instantaneous frequencies of each component time series, if emd is set dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz) same spatial size as input data (i.e., 1D or 2D) if there are multiple peaks with the same power, the lowest dominant frequency is returned! dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency same spatial size as input data (i.e., 1D or 2D) rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range averagedpower: spatially averaged power spectrum (of multiple 1D power spectra) amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: 1D analysis with HHT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ----------------------------------- --- 3D analysis: (1) k-\u03c9, (2) B-\u03c9 ----------------------------------- --- Type of analysis (enter the option 1 or 2): 1 2 ----------------------- ---- 3D analysis: k-\u03c9 ----------------------- + CALLING SEQUENCE: walsatools, /komega, signal=signal, time=time, arcsecpx=arcsecpx, power=p, frequencies=f, wavenumber=k + INPUTS: signal: [x,y,t] datacube [!] note: at present the input datacube needs to have identical x and y dimensions. if not supplied like this the datacube will be cropped accordingly. cadence: delta time between successive frames (in seconds) time: observing times in seconds (1D array). It is ignored if cadence is provided arcsecpx: pixel size (spatial sampling) in arcsec; a float number + OPTIONAL KEYWORDS: filtering: if set, filtering is proceeded f1: lower frequency to filter - given in mHz f2: upper frequency to filter - given in mHz k1: lower wavenumber to filter - given in mHz k2: upper wavenumber to filter - given in arcsec^-1 spatial_torus: if equal to zero, the annulus used for spatial filtering will not have a Gaussian-shaped profile temporal_torus: if equal to zero, the temporal filter will not have a Gaussian-shaped profile no_spatial: if set, no spatial filtering is performed no_temporal: if set, no temporal filtering is performed silent: if set, the k-\u03c9 diagram is not plotted clt: colour table number (IDL ctload) koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2) threemin: if set, a horizontal line marks the three-minute periodicity fivemin: if set, a horizontal line marks the five-minute periodicity xlog: if set, x-axis (wavenumber) is plotted in logarithmic scale ylog: if set, y-axis (frequency) is plotted in logarithmic scale xrange: x-axis (wavenumber) range yrange: y-axis (frequency) range nox2: if set, 2nd x-axis (spatial size, in arcsec) is not plotted (spatial size (i.e., wavelength) = (2*!pi)/wavenumber) noy2: if set, 2nd y-axis (period, in sec) is not plotted (p = 1000/frequency) smooth: if set, power is smoothed mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made + OUTPUTS: power: 2D array of power in log10 scale (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (in mHz) wavenumber: 1D array of wavenumber (in arcsec^-1) filtered_cube: 3D array of filtered datacube (if filtering is set) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following articles if you use WaLSAtools: k-\u03c9 analysis -- Jess et al. 2021, LRSP, in preparation -- Jess et al. 2017, ApJ, 842, 59 (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ----------------------- ---- 3D analysis: B-\u03c9 ----------------------- + CALLING SEQUENCE: walsatools, /bomega, signal=signal, time=time, bmap=bmap, power=p, frequencies=f, barray=b + INPUTS: signal: [x,y,t] datacube time: observing times in seconds (1D array) bmap: a map of magnetic fields (in G), same [x,y] size as in datacube + OPTIONAL KEYWORDS: binsize: size of magnetic-field bins, over which power spectra are averaged (default: 50 G) silent: if set, the B-\u03c9 diagram is not plotted clt: colour table number (IDL ctload) koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2) threemin: if set, a horizontal line marks the three-minute periodicity fivemin: if set, a horizontal line marks the five-minute periodicity xlog: if set, x-axis (wavenumber) is plotted in logarithmic scale ylog: if set, y-axis (frequency) is plotted in logarithmic scale xrange: x-axis (wavenumber) range yrange: y-axis (frequency) range noy2: if set, 2nd y-axis (period, in sec) is not plotted (p = 1000/frequency) smooth: if set, power is smoothed normalizedbins if set, power at each bin is normalised to its maximum value (this facilitates visibility of relatively small power) xtickinterval x-asis (i.e., magnetic fields) tick intervals in G (default: 400 G) mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made + OUTPUTS: power: 2D array of power (in DN^2/mHz, i.e., normalised to frequency resolution) frequencies: 1D array of frequencies (y-axis) in mHz barray: 1D array of magnetic fields (x-axis) in G ----------------------------------------------------------------------------------------- * CITATION: Please cite the following articles if you use WaLSAtools: B-\u03c9 analysis -- Jess et al. 2021, LRSP, in preparation -- Stangalini et al. 2021, A&A, in press (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------- --- Two time-series analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT ----------------------------------------------------------------------------------- --- Type of analysis (enter the option 1-4): 1 2 3 4 ------------------------------------ ---- cross-power analysis with FFT: ------------------------------------ + CALLING SEQUENCE: walsatools, /fft, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1) Each of these segments is considered an independent realisation of the underlying process. The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency. siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated + OUTPUTS: cospectrum: absolute values of the cross power (1D array) coherence: coherence (1D array) phase_angle: phase angles in degrees (1D array) frequency: 1D array of frequencies (in mHz) signif_cross: significance levels for the cospectrum (1D array) signif_coh: significance levels for the coherence (1D array) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with FFT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ---------------------------------------- ---- cross-power analysis with Wavelet: ---------------------------------------- + CALLING SEQUENCE: walsatools, /wavelet, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated mother: wavelet function (also depends on param). default: Morlet other available functions: Paul and DOG are available param: optional mother wavelet parameter (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat) dj: spacing between discrete scales. default: 0.025 colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166 plot: if set, wavelet power spectra of the two time series as well as their wavelet cospectrum (cross-spectrum) and coherence, along with the significance levels as contours, are plotted The phase angles between the two time series are also depicted by default Arrows pointing right mark zero phase (meaning in-phase oscillations), arrows pointing straight up indicate data2 lags behind data1 by 90 degrees noarrow: if set, the phase angles are not overplotted as arrows arrowdensity: number of arrows (illustrating phase angles) in x and y directions (default: [30,18]) arrowsize: size of the arrows (default: 1) arrowheadsize: size of the arrows head (default: 1) pownormal: if set, the power is normalised to its maximum value log: if set, the power spectra and the cospectrum are plotted in log10 scale removespace: if set, the time-period areas affected by the CoI over the entire time range are not plotted clt: colour table number (idl ctload) koclt: custom colour tables (currently available: 1 and 2) + OUTPUTS: cospectrum: absolute values of the cross power (2D array for wavelet spectrum; 1D for global, oglobal, or cglobal spectrum) coherence: wavelet coherence (same size as cospectrum) phase_angle: phase angles in degrees (same size as cospectrum) frequency: 1D array of frequencies (in mHz) signif_cross: significance map for the cospectrum (same size as cospectrum) scale: the scale vector of scale indices, given by the overlap of scale1 and scale2 cospectrum/signif_coh indicates regions above the siglevel signif_coh: significance map for the coherence (same size as cospectrum) coherence/signif_coh indicates regions above the siglevel coi: the vector of the cone-of-influence coh_global: global coherence averaged over all times phase_global: global phase averaged over all times cross_global: global cross wavelet averaged over all times coh_oglobal: global coherence averaged over all times excluding areas affected by CoI phase_oglobal: global phase averaged over all times excluding areas affected by CoI cross_oglobal: global cross wavelet averaged over all times excluding areas affected by CoI ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with Wavelet -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- --------------------------------------------- ---- cross-power analysis with Lomb-Scargle: --------------------------------------------- + CALLING SEQUENCE: walsatools, /lomb, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1) Each of these segments is considered an independent realisation of the underlying process. The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency. siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated + OUTPUTS: cospectrum: absolute values of the cross power (1D array) coherence: coherence (1D array) phase_angle: phase angles in degrees (1D array) frequency: 1D array of frequencies (in mHz) signif_cross: significance levels for the cospectrum (1D array) signif_coh: significance levels for the coherence (1D array) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with Lomb-Scargle -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- ------------------------------------- ---- cross-powerD analysis with HHT: ------------------------------------- + CALLING SEQUENCE: walsatools, /hht, data1=data1, data2=data2, time=time, $ cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f, significance=signif + INPUTS: data1: first (1D) time series data2: second (1D) time series, co-aligned with data1 time: observing times in seconds (1D array) + OPTIONAL KEYWORDS: padding: oversampling factor: zero padding (default: 1) apod: extent of apodization edges (of a Tukey window); default 0.1 nodetrendapod: if set, neither detrending nor apodization is performed! pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2 polyfit: the degree of polynomial fit to the data to detrend it if set, instead of linear fit this polynomial fit is performed meantemporal: if set, only a very simple temporal detrending is performed by subtracting the mean signal from the signal i.e., the fitting procedure (linear or higher polynomial degrees) is omitted meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending) recon: optional keyword that will Fourier reconstruct the input timeseries note: this does not preserve the amplitudes and is only useful when attempting to examine frequencies that are far away from the -untrustworthy- low frequencies n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1) Each of these segments is considered an independent realisation of the underlying process. The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency. stdlimit: standard deviation to be achieved before accepting an IMF (recommended value between 0.2 and 0.3; perhaps even smaller); default: 0.2 nfilter: Hanning window width for two dimensional smoothing of the Hilbert spectrum. default: 3 (an odd integer, preferably equal to or larger than 3; equal to 0 to avoid the windowing) siglevel: significance level (default: 0.05 = 5% significance = 95% confidence) nperm: number of random permutations for the significance test (default: 50) note: the default value is set for quick tests. Choose a large number (e.g., 2000 or larger) for a better statistical result nosignificance: if set, no significance level is calculated + OUTPUTS: cospectrum: absolute values of the cross power (1D array) coherence: coherence (1D array) phase_angle: phase angles in degrees (1D array) frequency: 1D array of frequencies (in mHz) signif_cross: significance levels for the cospectrum (1D array) signif_coh: significance levels for the coherence (1D array) ----------------------------------------------------------------------------------------- * CITATION: Please cite the following article if you use WaLSAtools: cross-correlation analysis with HHT -- Jess et al. 2021, LRSP, in preparation (see www.WaLSA.tools/citation) ----------------------------------------------------------------------------------------- If the data, time, or cadence, and the type of analysis are not provided, the code enters a guidance mode, providing detailed instructions and prompting you for the necessary information. Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSAtools ; ; PURPOSE : ; Performing various wave analysis techniques on ; ( a ) Single time series ( 1 D signal or [ x , y , t ] cube ) ; Methods : ; ( 1 ) 1 D analysis with : FFT ( Fast Fourier Transform ), Wavelet , Lomb - Scargle , ; HHT ( Hilbert - Huang Transform ), or Welch ; ( 2 ) 3 D analysis : k - \u03c9 ( with optional Fourier filtering ) or B - \u03c9 diagrams ; ; ( b ) Two time series ( cross correlations between two signals ) ; With : FFT ( Fast Fourier Transform ), , ; Lomb - Scargle , HHT ( Hilbert - Huang Transform , or Welch ; ; CALLING SEQUENCE : ; IDL > WaLSAtools ; Type WaLSAtools in IDL for further information ( and all keywords ) ; ; Documentation and info : www . WaLSA . tools ; GitHub repository : www . github . com / WaLSAteam / WaLSAtools ; \u00a9 WaLSA Team ( www . WaLSA . team ) ; Please see www . WaLSA . tools / license & www . WaLSA . tools / citation if you use WaLSAtools ; - pro walsatools , $ ; ( 1 ) 1 D analysis with : FFT , Wavelet , Long - Scargle , EMD , or HHT : signal = signal , time = time , $ ; main inputs power = power , frequencies = frequencies , significance = significance , coi = coi , averagedpower = averagedpower , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , welch = welch , wavelet = wavelet , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , psd = psd , $ siglevel = siglevel , nperm = nperm , nosignificance = nosignificance , $ ; significance - level parameters mother = mother , param = param , dj = dj , global = global , oglobal = oglobal , rgws = rgws , colornoise = colornoise , $ ; Wavelet parameters / options stdlimit = stdlimit , nfilter = nfilter , emd = emd , imf = imf , instantfreq = instantfreq , $ ; HHT parameters / options window_size = window_size , overlap = overlap , wfft_size = wfft_size , $ ; Welch parameters mode = mode , $ ; power calibration dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ ; dominant frequency ; + keywords / options for ; ( 2 ) 2 D analysis : k - omega diagram : arcsecpx = arcsecpx , cadence = cadence , $ ; additional main input wavenumber = wavenumber , filtered_cube = filtered_cube , $ ; main ( additional ) outputs filtering = filtering , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , spatial_torus = spatial_torus , temporal_torus = temporal_torus , $ ; filtering options no_spatial_filt = no_spatial_filt , no_temporal_filt = no_temporal_filt , $ clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , $ ; plotting keywords epsfilename = epsfilename , noy2 = noy2 , nox2 = nox2 , smooth = smooth , savefits = savefits , filename = filename , $ ; ( 2 ) 2 D analysis : B - omega diagram : bmap = Bmap , binsize = binsize , barray = Barray , silent = silent , bomega = bomega , komega = komega , help = help , $ normalizedbins = normalizedbins , xtickinterval = xtickinterval , version = version , plot = plot , log = log , removespace = removespace , $ data1 = data1 , data2 = data2 , phase_angle = phase_angle , coherence = coherence , cospectrum = cospectrum , amplitude = amplitude , $ ; cross spectra analysis signif_coh = signif_coh , signif_cross = signif_cross , coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ pownormal = pownormal , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , noarrow = noarrow , $ n_segments = n_segments , d1_power = d1_power , d2_power = d2_power , period = period compile_opt idl2 ; ----------------------------------------------------------------------------------------------------------------------------------- print , ' ' print , ' __ __ _ _____ ' print , ' \\ \\ / / | | / ____| /\\ ' print , ' \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ ' print , ' \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ ' print , ' \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ ' print , ' \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_ \\' print , ' ' print , ' ' print , ' \u00a9 WaLSA Team (www.WaLSA.team)' print , ' -----------------------------------------------------------------------------------' print , ' WaLSAtools v1.0.0' print , ' Documentation: www.WaLSA.tools' print , ' GitHub repository: www.github.com/WaLSAteam/WaLSAtools' print , ' -----------------------------------------------------------------------------------' if keyword_set ( cadence ) or keyword_set ( time ) then temporalinfo = 1 else temporalinfo = 0 if keyword_set ( signal ) and temporalinfo then begin if keyword_set ( fft ) or keyword_set ( wavelet ) or keyword_set ( lombscargle ) or keyword_set ( welch ) or $ keyword_set ( hht ) or keyword_set ( komega ) or keyword_set ( bomega ) $ then help = 0 else help = 1 endif else help = 1 if keyword_set ( signal ) eq 0 then begin if keyword_set ( data1 ) and keyword_set ( data2 ) and temporalinfo then begin if keyword_set ( fft ) or keyword_set ( wavelet ) or keyword_set ( lombscargle ) or keyword_set ( welch ) $ or keyword_set ( hht ) then help = 0 else help = 1 endif else help = 1 endif if help then begin print , ' Performing various wave analysis techniques on ' print , ' (a) Single time series (1D signal or [x,y,t] cube)' print , ' Methods: ' print , ' (1) 1D analysis with: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle,' print , ' HHT (Hilbert-Huang Transform), or Welch' print , ' (2) 3D analysis: k-\u03c9 (with optional Fourier filtering) or B-\u03c9 diagrams' print print , ' (b) Two time series (cross correlations between two signals)' print , ' With: FFT (Fast Fourier Transform), Wavelet,' print , ' Lomb-Scargle, HHT (Hilbert-Huang Transform) or Welch' print , ' ----------------------------------------------------------------------------' if keyword_set ( version ) then begin print return endif category = ' ' read , category , prompt = ' -- Category -- (enter the option a or b): ' if category eq 'a' or category eq 'b' then goto , categories else begin ask : read , category , prompt = ' -- Please enter a or b (i.e., one of the categories (a) or (b) listed above): ' if category eq 'a' or category eq 'b' then goto , categories else goto , ask endelse categories : print if category eq 'a' then begin print , ' ------------------------------------------------' print , ' --- Single time-series analysis: (1) 1D, (2) 3D' print , ' ------------------------------------------------' type = ' ' read , type , prompt = ' -- Method (enter the option 1 or 2): ' while type lt 1 or type gt 2 do begin read , type , prompt = ' -- Please enter 1 or 2 (i.e., one of the methods listed above): ' if type eq 1 or type eq 2 then break endwhile print if type eq 1 then begin print , ' ---------------------------------------------------------------------------------' print , ' --- 1D analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT, (5) Welch' print , ' ---------------------------------------------------------------------------------' m1type = ' ' read , m1type , prompt = ' --- Type of analysis (enter the option 1-4): ' while m1type lt 1 or m1type gt 4 do begin read , m1type , prompt = ' --- Please enter a number between 1 and 4: ' if m1type eq 1 or m1type eq 2 or m1type eq 3 or m1type eq 4 then break endwhile print if m1type eq 1 then begin print , ' ---------------------------' print , ' ---- 1D analysis with FFT:' print , ' ---------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /fft, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 2 then begin print , ' -------------------------------' print , ' ---- 1D analysis with Wavelet:' print , ' -------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /wavelet, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 3 then begin print , ' ------------------------------------' print , ' ---- 1D analysis with Lomb-Scargle:' print , ' ------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /lomb, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 4 then begin print , ' ---------------------------' print , ' ---- 1D analysis with HHT:' print , ' ---------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /hht, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif if m1type eq 5 then begin print , ' ----------------------------' print , ' ---- 1D analysis with Welch:' print , ' ----------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /welch, signal=signal, time=time, power=p, frequencies=f, significance=signif' endif print print , ' + INPUTS:' print , ' signal: 1D time series, or [x,y,t] datacube' print , ' time: observing times in seconds (1D array)' print print , ' + OPTIONAL KEYWORDS:' ; ---- padding , detrending , and apodization parameters ---- print , ' padding: oversampling factor: zero padding (default: 1)' print , ' apod: extent of apodization edges (of a Tukey window); default 0.1' print , ' nodetrendapod: if set, neither detrending nor apodization is performed!' print , ' pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2' print , ' polyfit: the degree of polynomial fit to the data to detrend it' print , ' if set, instead of linear fit this polynomial fit is performed' print , ' meantemporal: if set, only a very simple temporal detrending is performed by' print , ' subtracting the mean signal from the signal' print , ' i.e., the fitting procedure (linear or higher polynomial degrees) is omitted' print , ' meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending)' print , ' recon: optional keyword that will Fourier reconstruct the input timeseries' print , ' note: this does not preserve the amplitudes and is only useful when attempting' print , ' to examine frequencies that are far away from the -untrustworthy- low frequencies' print , ' resample if recon is set, then by setting resample, amplitudes are scaled to approximate actual values.' ; ---- significance - level parameters ---- print , ' siglevel: significance level (default: 0.05 = 5 % s ignificance = 95 % c onfidence)' print , ' nperm: number of random permutations for the significance test (default: 1000)' print , ' nosignificance: if set, no significance level is calculated' ; ---- power calibration ---- print , ' mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude' if m1type eq 2 then begin print , ' mother: wavelet function (also depends on param). default: Morlet' print , ' other available functions: Paul and DOG are available' print , ' param: optional mother wavelet parameter' print , ' (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat)' print , ' dj: spacing between discrete scales. default: 0.025' print , ' global: returns global wavelet spectrum (time-averaged wavelet power)' print , ' oglobal: global wavelet spectrum excluding regions affected by CoI' print , ' rgws: time-integral of wavelet power excluding regions influenced by cone-of-influence' print , ' and only for those above the significance level' print , ' i.e., power-weighted frequency distribution (with significant power & unaffected by CoI)' print , ' Note: this is likely the most correct spectrum!' print , ' colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166' endif if m1type eq 4 then begin print , ' stdlimit: standard deviation to be achieved before accepting an IMF (default: 0.2)' print , ' nfilter: Hanning window width for two dimensional spectrum smoothing (default: 3)' print , ' (an odd integer equal to or larger than 3; 0: to avoid the windowing)' print , ' emd: if set, intrinsic mode functions (IMFs) and their associated frequencies' print , ' (i.e., instantaneous frequencies) can be outputted' endif if m1type eq 5 then begin ; ---- Welch parameters / options ---- print , ' window_size: size of Hann window. This code currently uses a Hann window (e.g., 256)' print , ' overlap: commonly, the overlap is set to half the window size.' print , ' wfft_size: generally, a window_size*2 is used for the FFT size to optimize the FFT performance.' endif ; ---- dominant frequency ---- print , ' nodominantfreq: if set, dominant frequency and dominant power are not calculated' print , ' (to, e.g., save computational time for large datasets)' print print , ' + OUTPUTS:' print , ' power: 1D (or 3D; same dimension as input data) array of power' print , ' 2D (or 4D) array for wavelet spectrum' print , ' (in DN^2/mHz, i.e., normalised to frequency resolution)' print , ' frequencies: 1D array of frequencies (in mHz)' print , ' period: 1D array of periods (in seconds)' print , ' significance: significance array (same size and units as power)' if m1type eq 4 then begin print , ' imf: intrinsic mode functions (IMFs) from EMD analysis, if emd is set' print , ' instantfreq: instantaneous frequencies of each component time series, if emd is set' endif if m1type eq 2 then begin print , ' coi: cone-of-influence cube (when global, oglobal, or rgws are not set)' endif print , ' dominantfreq: dominant frequency, i.e., frequency corresponding to the maximum power (in mHz)' print , ' same spatial size as input data (i.e., 1D or 2D)' print , ' if there are multiple peaks with the same power, the lowest dominant frequency is returned!' print , ' dominantpower: power (in DN^2/mHz) corresponding to the dominant frequency' print , ' same spatial size as input data (i.e., 1D or 2D)' print , ' rangefreq: frequency range over which the dominant frequency is computed. default: full frequency range' print , ' averagedpower: spatially averaged power spectrum (of multiple 1D power spectra)' print , ' amplitude: 1D array of oscillation amplitude (or a 3D array if the input is a 3D cube)' if m1type eq 2 then begin print , ' note: only for global (traditional, oglobal, or rgws) wavelet' endif print , ' -----------------------------------------------------------------------------------------' if m1type eq 1 then m1typecite = 'WaLSAtools: 1D analysis with FFT' if m1type eq 2 then m1typecite = 'WaLSAtools: 1D analysis with Wavelet' if m1type eq 3 then m1typecite = 'WaLSAtools: 1D analysis with Lomb-Scargle' if m1type eq 4 then m1typecite = 'WaLSAtools: 1D analysis with HHT' if m1type eq 5 then m1typecite = 'WaLSAtools: 1D analysis with Welch' print , ' * CITATION:' print , ' Please cite the following article if you use ' + m1typecite print , ' -- Jess et al. 2023, Living Reviews in Solar Physics, 20, 1' print , ' (see www.WaLSA.tools/citation)' print , ' -----------------------------------------------------------------------------------------' print endif if type eq 2 then begin print , ' -----------------------------------' print , ' --- 3D analysis: (1) k-\u03c9, (2) B-\u03c9' print , ' -----------------------------------' m2type = ' ' read , m2type , prompt = ' --- Type of analysis (enter the option 1 or 2): ' while m2type lt 1 or m2type gt 2 do begin read , m2type , prompt = ' --- Please enter 1 or 2: ' if m2type eq 1 or m2type eq 2 then break endwhile print if m2type eq 1 then begin print , ' -----------------------' print , ' ---- 3D analysis: k-\u03c9' print , ' -----------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /komega, signal=signal, time=time, arcsecpx=arcsecpx, power=p, frequencies=f, wavenumber=k' print print , ' + INPUTS:' print , ' signal: [x,y,t] datacube' print , ' [!] note: at present the input datacube needs to have identical x and y dimensions.' print , ' if not supplied like this the datacube will be cropped accordingly.' print , ' cadence: delta time between successive frames (in seconds)' print , ' time: observing times in seconds (1D array). It is ignored if cadence is provided' print , ' arcsecpx: pixel size (spatial sampling) in arcsec; a float number' print print , ' + OPTIONAL KEYWORDS:' ; ---- filtering options ---- print , ' filtering: if set, filtering is proceeded' print , ' f1: lower frequency to filter - given in mHz' print , ' f2: upper frequency to filter - given in mHz' print , ' k1: lower wavenumber to filter - given in mHz' print , ' k2: upper wavenumber to filter - given in arcsec^-1' print , ' spatial_torus: if equal to zero, the annulus used for spatial filtering will not have a Gaussian-shaped profile' print , ' temporal_torus: if equal to zero, the temporal filter will not have a Gaussian-shaped profile' print , ' no_spatial: if set, no spatial filtering is performed' print , ' no_temporal: if set, no temporal filtering is performed' ; ---- plotting parameters ---- print , ' silent: if set, the k-\u03c9 diagram is not plotted' print , ' clt: colour table number (IDL ctload)' print , ' koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2)' print , ' threemin: if set, a horizontal line marks the three-minute periodicity' print , ' fivemin: if set, a horizontal line marks the five-minute periodicity' print , ' xlog: if set, x-axis (wavenumber) is plotted in logarithmic scale' print , ' ylog: if set, y-axis (frequency) is plotted in logarithmic scale' print , ' xrange: x-axis (wavenumber) range' print , ' yrange: y-axis (frequency) range' print , ' nox2: if set, 2nd x-axis (spatial size, in arcsec) is not plotted' print , ' (spatial size (i.e., wavelength) = (2*!pi)/wavenumber)' print , ' noy2: if set, 2nd y-axis (period, in sec) is not plotted' print , ' (p = 1000/frequency)' print , ' smooth: if set, power is smoothed' ; ---- power calibration ---- print , ' mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude' ; ---- output options ---- print , ' epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made' print print , ' + OUTPUTS:' print , ' power: 2D array of power in log10 scale' print , ' (in DN^2/mHz, i.e., normalised to frequency resolution)' print , ' frequencies: 1D array of frequencies (in mHz)' print , ' wavenumber: 1D array of wavenumber (in arcsec^-1)' print , ' filtered_cube: 3D array of filtered datacube (if filtering is set)' endif if m2type eq 2 then begin print , ' -----------------------' print , ' ---- 3D analysis: B-\u03c9' print , ' -----------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /bomega, signal=signal, time=time, bmap=bmap, power=p, frequencies=f, barray=b' print print , ' + INPUTS:' print , ' signal: [x,y,t] datacube' print , ' time: observing times in seconds (1D array)' print , ' bmap: a map of magnetic fields (in G), same [x,y] size as in datacube' print print , ' + OPTIONAL KEYWORDS:' print , ' binsize: size of magnetic-field bins, over which power spectra are averaged' print , ' (default: 50 G)' print , ' silent: if set, the B-\u03c9 diagram is not plotted' print , ' clt: colour table number (IDL ctload)' print , ' koclt: custom colour tables for k-\u03c9 diagram (currently available: 1 and 2)' print , ' threemin: if set, a horizontal line marks the three-minute periodicity' print , ' fivemin: if set, a horizontal line marks the five-minute periodicity' print , ' xlog: if set, x-axis (magnetic field) is plotted in logarithmic scale' print , ' ylog: if set, y-axis (frequency) is plotted in logarithmic scale' print , ' xrange: x-axis (wavenumber) range' print , ' yrange: y-axis (frequency) range' print , ' noy2: if set, 2nd y-axis (period, in sec) is not plotted' print , ' (p = 1000/frequency)' print , ' smooth: if set, power is smoothed' print , ' normalizedbins if set, power at each bin is normalised to its maximum value' print , ' (this facilitates visibility of relatively small power)' print , ' xtickinterval x-asis (i.e., magnetic fields) tick intervals in G (default: 400 G)' ; ---- power calibration ---- print , ' mode: 0 = log(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude' ; ---- output options ---- print , ' epsfilename: if provided (as a string), an eps file of the k-\u03c9 diagram is made' print print , ' + OUTPUTS:' print , ' power: 2D array of power' print , ' (in DN^2/mHz, i.e., normalised to frequency resolution)' print , ' frequencies: 1D array of frequencies (y-axis) in mHz' print , ' barray: 1D array of magnetic fields (x-axis) in G' endif print , ' -----------------------------------------------------------------------------------------' if m2type eq 1 then m2typecite = 'WaLSAtools: k-\u03c9 analysis' if m2type eq 2 then m2typecite = 'WaLSAtools: B-\u03c9 analysis' print , ' * CITATION:' print , ' Please cite the following articles if you use ' + m2typecite print , ' -- Jess et al. 2023, Living Reviews in Solar Physics, 20, 1' if m2type eq 1 then $ print , ' -- Jess et al. 2017, ApJ, 842, 59' if m2type eq 2 then $ print , ' -- Stangalini et al. 2021, A&A, in press' print , ' (see www.WaLSA.tools/citation)' print , ' -----------------------------------------------------------------------------------------' print endif endif if category eq 'b' then begin print , ' ----------------------------------------------------------------------------------------------' print , ' --- Two time-series analysis with: (1) FFT, (2) Wavelet, (3) Lomb-Scargle, (4) HHT, (5) Welch' print , ' ----------------------------------------------------------------------------------------------' c1type = ' ' read , c1type , prompt = ' --- Type of analysis (enter the option 1-4): ' while c1type lt 1 or c1type gt 4 do begin read , c1type , prompt = ' --- Please enter a number between 1 and 4: ' if c1type eq 1 or c1type eq 2 or c1type eq 3 or c1type eq 4 then break endwhile print if c1type eq 1 then begin print , ' ------------------------------------' print , ' ---- cross-power analysis with FFT:' print , ' ------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /fft, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 2 then begin print , ' ----------------------------------------' print , ' ---- cross-power analysis with Wavelet:' print , ' ----------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /wavelet, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 3 then begin print , ' ---------------------------------------------' print , ' ---- cross-power analysis with Lomb-Scargle:' print , ' ---------------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /lomb, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 4 then begin print , ' -------------------------------------' print , ' ---- cross-power analysis with HHT:' print , ' -------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /hht, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif if c1type eq 5 then begin print , ' ---------------------------------------------' print , ' ---- cross-power analysis with Welch:' print , ' ---------------------------------------------' print , ' + CALLING SEQUENCE:' print , ' walsatools, /welch, data1=data1, data2=data2, time=time, $' print , ' cospectrum=cospec, phase_angle=ph, coherence=coh, frequencies=f' endif print print , ' + INPUTS:' print , ' data1: first (1D) time series' print , ' data2: second (1D) time series, co-aligned with data1' print , ' time: observing times in seconds (1D array)' print print , ' + OPTIONAL KEYWORDS:' ; ---- padding , detrending , and apodization parameters ---- print , ' padding: oversampling factor: zero padding (default: 1)' print , ' apod: extent of apodization edges (of a Tukey window); default 0.1' print , ' nodetrendapod: if set, neither detrending nor apodization is performed!' print , ' pxdetrend: subtract linear trend with time per pixel. options: 1=simple, 2=advanced; default: 2' print , ' polyfit: the degree of polynomial fit to the data to detrend it' print , ' if set, instead of linear fit this polynomial fit is performed' print , ' meantemporal: if set, only a very simple temporal detrending is performed by' print , ' subtracting the mean signal from the signal' print , ' i.e., the fitting procedure (linear or higher polynomial degrees) is omitted' print , ' meandetrend: if set, subtract linear trend with time for the image means (i.e., spatial detrending)' if c1type ne 2 then begin print , ' recon: optional keyword that will Fourier reconstruct the input timeseries' print , ' note: this does not preserve the amplitudes and is only useful when attempting' print , ' to examine frequencies that are far away from the -untrustworthy- low frequencies' print , ' resample if recon is set, then by setting resample, amplitudes are scaled to approximate actual values.' print , ' n_segments: number of euqal segments (to which both datasets are broken prior to the analyses; default: 1)' print , ' Each of these segments is considered an independent realisation of the underlying process.' print , ' The cross spectrum for each segement are averaged together to provide phase and coherence ' print , ' estimates at each frequency.' endif if c1type eq 4 then begin ; ---- HHT parameters / options ---- print , ' stdlimit: standard deviation to be achieved before accepting an IMF' print , ' (recommended value between 0.2 and 0.3; perhaps even smaller); default: 0.2' print , ' nfilter: Hanning window width for two dimensional smoothing of the Hilbert spectrum. default: 3 ' print , ' (an odd integer, preferably equal to or larger than 3; equal to 0 to avoid the windowing)' endif if c1type eq 5 then begin ; ---- Welch parameters / options ---- print , ' window_size: size of Hann window. This code currently uses a Hann window (e.g., 256)' print , ' overlap: commonly, the overlap is set to half the window size.' print , ' wfft_size: generally, a window_size*2 is used for the FFT size to optimize the FFT performance.' endif ; ---- significance - level parameters ---- print , ' siglevel: significance level (default: 0.05 = 5 % s ignificance = 95 % c onfidence)' print , ' nperm: number of random permutations for the significance test (default: 50)' print , ' note: the default value is set for quick tests. Choose a large number' print , ' (e.g., 2000 or larger) for a better statistical result' print , ' nosignificance: if set, no significance level is calculated' if c1type eq 2 then begin ; ---- wavelet parameters / options ---- print , ' mother: wavelet function (also depends on param). default: Morlet' print , ' other available functions: Paul and DOG are available' print , ' param: optional mother wavelet parameter' print , ' (default: 6 (for Morlet), 4 (for Paul), 2 (for DOG; i.e., Mexican-hat)' print , ' dj: spacing between discrete scales. default: 0.025' print , ' colornoise: if set, noise background is based on Auch\u00e8re+2017, ApJ, 838, 166' endif if c1type eq 2 then begin ; ---- plotting ---- print , ' plot: if set, wavelet power spectra of the two time series as well as' print , ' their wavelet cospectrum (cross-spectrum) and coherence, along with the' print , ' significance levels as contours, are plotted' print , ' The phase angles between the two time series are also depicted by default' print , ' Arrows pointing right mark zero phase (meaning in-phase oscillations),' print , ' arrows pointing straight up indicate data2 lags behind data1 by 90 degrees' print , ' noarrow: if set, the phase angles are not overplotted as arrows' print , ' arrowdensity: number of arrows (illustrating phase angles) in x and y directions (default: [30,18])' print , ' arrowsize: size of the arrows (default: 1)' print , ' arrowheadsize: size of the arrows head (default: 1)' print , ' pownormal: if set, the power is normalised to its maximum value' print , ' log: if set, the power spectra and the cospectrum are plotted in log10 scale' print , ' removespace: if set, the time-period areas affected by the CoI over the entire time range are not plotted' print , ' clt: colour table number (idl ctload)' print , ' koclt: custom colour tables (currently available: 1 and 2)' endif print print , ' + OUTPUTS:' if c1type eq 2 then begin print , ' cospectrum: absolute values of the cross power' print , ' (2D array for wavelet spectrum; 1D for global, oglobal, or rgws spectrum)' print , ' coherence: wavelet coherence (same size as cospectrum)' print , ' phase_angle: phase angles in degrees (same size as cospectrum)' print , ' frequency: 1D array of frequencies (in mHz)' print , ' signif_cross: significance map for the cospectrum (same size as cospectrum)' print , ' scale: the scale vector of scale indices, given by the overlap of scale1 and scale2' print , ' cospectrum/signif_coh indicates regions above the siglevel' print , ' signif_coh: significance map for the coherence (same size as cospectrum)' print , ' coherence/signif_coh indicates regions above the siglevel' print , ' coi: the vector of the cone-of-influence' print , ' coh_global: global coherence averaged over all times' print , ' phase_global: global phase averaged over all times' print , ' cross_global: global cross wavelet averaged over all times' print , ' coh_oglobal: global coherence averaged over all times excluding areas affected by CoI' print , ' phase_oglobal: global phase averaged over all times excluding areas affected by CoI' print , ' cross_oglobal: global cross wavelet averaged over all times excluding areas affected by CoI' endif if c1type ne 2 then begin print , ' cospectrum: absolute values of the cross power (1D array)' print , ' coherence: coherence (1D array)' print , ' phase_angle: phase angles in degrees (1D array)' print , ' frequency: 1D array of frequencies (in mHz)' print , ' signif_cross: significance levels for the cospectrum (1D array)' print , ' signif_coh: significance levels for the coherence (1D array)' endif print , ' -----------------------------------------------------------------------------------------' if c1type eq 1 then c1typecite = 'WaLSAtools: cross-correlation analysis with FFT' if c1type eq 2 then c1typecite = 'WaLSAtools: cross-correlation analysis with Wavelet' if c1type eq 3 then c1typecite = 'WaLSAtools: cross-correlation analysis with Lomb-Scargle' if c1type eq 4 then c1typecite = 'WaLSAtools: cross-correlation analysis with HHT' if c1type eq 5 then c1typecite = 'WaLSAtools: cross-correlation analysis with Welch' print , ' * CITATION:' print , ' Please cite the following article if you use ' + c1typecite print , ' -- Jess et al. 2023, Living Reviews in Solar Physics, 20, 1' print , ' (see www.WaLSA.tools/citation)' print , ' -----------------------------------------------------------------------------------------' print endif return endif else print ; ----------------------------------------------------------------------- if keyword_set ( signal ) then begin ii = where ( ~ finite ( signal ), / null , cnull ) if cnull gt 0 then signal [ ii ] = median ( signal ) if min ( signal ) ge max ( signal ) then begin print , ' [!] The signal does not have any (temporal) variation.' print return endif ; ----------------------------------------------------------------------- if keyword_set ( fft ) or keyword_set ( wavelet ) or keyword_set ( lombscargle ) or keyword_set ( hht ) or keyword_set ( welch ) then $ power = walsa_speclizer ( signal , time , $ ; main inputs frequencies = frequencies , significance = significance , imf = imf , instantfreq = instantfreq , averagedpower = averagedpower , period = period , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , wavelet = wavelet , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , psd = psd , $ siglevel = siglevel , nperm = nperm , nosignificance = nosignificance , $ ; significance - level parameters mother = mother , param = param , dj = dj , global = global , coi = coi , oglobal = oglobal , rgws = rgws , colornoise = colornoise , $ ; Wavelet parameters / options stdlimit = stdlimit , nfilter = nfilter , emd = emd , $ ; HHT parameters / options window_size = window_size , overlap = overlap , wfft_size = wfft_size , $ ; Welch parameters mode = mode , silent = silent , $ ; power calibration dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , amplitude = amplitude ) ; dominant frequency ; ----------------------------------------------------------------------- if keyword_set ( komega ) then $ walsa_qub_queeff , signal , arcsecpx , cadence = cadence , time = time , $ power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube , $ ; main ( additional ) outputs filtering = filtering , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , spatial_torus = spatial_torus , temporal_torus = temporal_torus , $ ; filtering options no_spatial_filt = no_spatial_filt , no_temporal_filt = no_temporal_filt , $ clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , $ ; plotting keywords epsfilename = epsfilename , noy2 = noy2 , nox2 = nox2 , smooth = smooth , silent = silent , mode = mode ; ----------------------------------------------------------------------- if keyword_set ( bomega ) then $ walsa_bomega , signal , Bmap , cadence = cadence , time = time , binsize = binsize , power = power , frequencies = frequencies , barray = Barray , $ silent = silent , clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , $ ; plotting keywords xrange = xrange , yrange = yrange , epsfilename = epsfilename , noy2 = noy2 , smooth = smooth , normalizedbins = normalizedbins , $ xtickinterval = xtickinterval , mode = mode endif ; ----------------------------------------------------------------------- if keyword_set ( data1 ) and keyword_set ( data2 ) then begin ii = where ( ~ finite ( data1 ), / null , cnull ) if cnull gt 0 then data1 [ ii ] = median ( data1 ) ii = where ( ~ finite ( data2 ), / null , cnull ) if cnull gt 0 then data2 [ ii ] = median ( data2 ) if keyword_set ( fft ) or keyword_set ( lombscargle ) or keyword_set ( hht ) or keyword_set ( welch ) then $ walsa_cross_spectrum , data1 = data1 , data2 = data2 , time = time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , cospectrum = cospectrum , $ fft = fft , lombscargle = lombscargle , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , $ stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options nosignificance = nosignificance , signif_coh = signif_coh , signif_cross = signif_cross , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power if keyword_set ( wavelet ) then $ walsa_wavelet_cross_spectrum , data1 , data2 , time , $ ; main inputs mother = mother , param = param , dj = dj , colornoise = colornoise , $ coherence = coherence , phase_angle = phase_angle , $ scale = scale , coi = coi , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ cospectrum = cospectrum , period = period , $ frequency = frequency , signif_coh = signif_coh , signif_cross = signif_cross , $ padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal , $ nosignificance = nosignificance , pownormal = pownormal , siglevel = siglevel , $ plot = plot , clt = clt , log = log , nperm = nperm , removespace = removespace , koclt = koclt , $ arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , noarrow = noarrow return endif ; ---------------------------------------------------------------------- end", "title": "WaLSAtools"}, {"location": "idl/cross-correlation-example/", "text": "Worked Example - NRMP: Cross-Correlation Analysis \u00b6 This example demonstrates the application of cross-correlation analysis to two nearly identical synthetic 1D signals. The signals share the same base frequencies and amplitudes but have slight phase differences introduced between them. This simulates a scenario where similar wave signals are observed at different locations or with a time delay. By analysing the cross-correlation between these signals, we can identify common frequencies, quantify the strength of their relationship, and determine the phase or time lag between their oscillations. This provides valuable insights into the potential connections or shared drivers influencing the signals. Analysis and Figure The figure below presents a comparative analysis of cross-correlation techniques applied to the two synthetic 1D signals. Methods used: Fast Fourier Transform (FFT) Wavelet Transform (with Morlet wavelet) WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 6 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Cross-correlation analysis of two synthetic 1D time series using FFT and wavelet techniques. (a) and (b) display the first and second time series, respectively. \u00a9 compares their FFT power spectra (blue: time series 1, red: time series 2). (d)-(f) present the FFT-derived co-spectrum, coherence spectrum, and phase differences. (g) and (h) show individual wavelet power spectra (Morlet mother wavelet). (i) and (j) depict the wavelet co-spectrum and coherence map. Cross-hatched areas in wavelet panels mark the cone of influence (COI); black contours indicate the 95% confidence level. Power is represented in log-scale in panels (g)-(i) , while colors in panel (j) map coherence levels. Phase differences in (i) and (j) are visualized as arrows (right: in-phase, up: 90-degree lead for time series 1). Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 ; pro FIG6__cross_correlation data_dir = 'Synthetic_Data/' data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) restore , 'save_files/frequencies_1D_signal.save' ; cross - correlations : FFT analysis WaLSAtools , / fft , data1 = data2 , data2 = data1 , time = time , nperm = 100 , cospectrum = cospectrum , phase_angle = phase_angle , $ coherence = coherence , frequencies = frequencies , / nosignificance , d1_power = power1 , d2_power = power2 , n_segments = 2 ; ----------------------- plotting colset device , decomposed = 0 walsa_eps , size = [ 20 , 23 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 1.8 ! x . thick = 3.2 ! y . thick = 3.2 thick = 2.0 ! P . Multi = [ 0 , 3 , 4 ] ! x . ticklen =- 0.080 ! y . ticklen =- 0.042 df = frequencies [ 1 ] - frequencies [ 0 ] ; frequency resolution / the lowest detectable frequency xr = [ 0 , 36 ] tr = [ min ( time ), max ( time )] ; pos = cgLayout ([ 3 , 2 ], OXMargin = [ 10 , 4 ], OYMargin = [ 7 , 5 ], XGap = 12 , YGap = 10 ) pos = fltarr ( 4 , 6 ) pos [ * , 0 ] = [ 0.08 , 0.8583331 , 0.32111109 , 0.9583331 ] pos [ * , 1 ] = [ 0.41111109 , 0.8583331 , 0.64888890 , 0.9583331 ] pos [ * , 2 ] = [ 0.75888886 , 0.8583331 , 0.99 , 0.9583331 ] pos [ * , 3 ] = [ 0.08 , 0.670000 , 0.32111109 , 0.770000 ] pos [ * , 4 ] = [ 0.41111109 , 0.670000 , 0.64888890 , 0.770000 ] pos [ * , 5 ] = [ 0.75888886 , 0.670000 , 0.99 , 0.770000 ] ; -------------------------------- ; Plot the detrended & apodized light curve 1 signal1 = walsa_detrend_apod ( data1 ) cgplot , time , signal1 * 10. , charsize = charsize , pos = pos [ * , 0 ], thick = thick , $ xtitle = 'Time (s)' , ytitle = 'DN (arb. unit)' , xs = 1 , yr = [ min ( reform ( signal1 * 10. )), max ( reform ( signal1 * 10. ))], color = cgColor ( 'DodgerBlue' ), YTICKINTERVAL = 40 xyouts , tr [ 0 ] + (( tr [ 1 ] - tr [ 0 ]) / 2. ), max ( reform ( signal1 * 10. )) + 10. , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(a) 1st Time Series' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot the detrended & apodized light curve 2 signal2 = walsa_detrend_apod ( data2 ) cgplot , time , signal2 * 10. , charsize = charsize , pos = pos [ * , 1 ], thick = thick , $ xtitle = 'Time (s)' , ytitle = 'DN (arb. unit)' , xs = 1 , yr = [ min ( reform ( signal1 * 10. )), max ( reform ( signal1 * 10. ))], color = cgColor ( 'Red' ), YTICKINTERVAL = 40 xyouts , tr [ 0 ] + (( tr [ 1 ] - tr [ 0 ]) / 2. ), max ( reform ( signal1 * 10. )) + 10. , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(b) 2nd Time Series' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot FFT power spectra of the two time series cgplot , frequencies / 1000. , 100. * power1 / max ( power1 ), charsize = charsize , pos = pos [ * , 2 ], thick = 3 , $ xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , xs = 1 , ys = 1 , xr = xr , yr = [ 0 , 40 ], color = cgColor ( 'DodgerBlue' ), yminor = 5 oplot , frequencies / 1000. , 100. * power2 / max ( power2 ), color = cgColor ( 'Red' ), thick = 2 , lines = 2 xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 100 * 0.438 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(c) Power spectra' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot co - spectrum cgplot , frequencies / 1000. , 100. * cospectrum / max ( cospectrum ), yr = [ 0 , 40 ], xr = xr , charsize = charsize , pos = pos [ * , 3 ], thick = thick , $ xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , color = cgColor ( 'DarkGreen' ), yminor = 5 sjvline , sf , color = cgColor ( 'Orange' ) oplot , frequencies / 1000. , 100. * cospectrum / max ( cospectrum ), thick = thick , color = cgColor ( 'DarkGreen' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 100 * 0.438 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(d) Co-spectrum' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot coherence levels as a function of frequency cgplot , frequencies / 1000. , coherence , yr = [ 0 , 1.1 ], xr = xr , charsize = charsize , pos = pos [ * , 4 ], thick = thick , $ xtitle = 'Frequency (Hz)' , ytitle = 'Coherence' , color = cgColor ( 'DarkGreen' ), YTICKNAME = [ '0.0' , ' ' , '0.4' , ' ' , '0.8' , ' ' ] sjvline , sf , color = cgColor ( 'Orange' ) oplot , frequencies / 1000. , coherence , thick = thick , color = cgColor ( 'DarkGreen' ) sjhline , 0.80 , lines = 0 , thick = 3 , color = cgColor ( 'DarkRed' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 1.2 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(e) Coherence' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot phase lags as a function of frequency cgplot , frequencies / 1000. , phase_angle , yr = [ - 200 , 200 ], xr = xr , charsize = charsize , pos = pos [ * , 5 ], thick = thick , $ xtitle = 'Frequency (Hz)' , ytitle = 'Phase (deg)' , color = cgColor ( 'DarkGreen' ), yminor = 5 sjvline , sf , color = cgColor ( 'Orange' ) oplot , frequencies / 1000. , phase_angle , thick = thick , color = cgColor ( 'DarkGreen' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 240 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(f) Phase Difference' , color = cgColor ( 'Black' ) ; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ pos1 = [ 0.08 , 0.35 , 0.42 , 0.55 ] pos2 = [ 0.61 , 0.35 , 0.95 , 0.55 ] pos3 = [ 0.08 , 0.05 , 0.42 , 0.25 ] pos4 = [ 0.61 , 0.05 , 0.95 , 0.25 ] data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; Wavelet power spectrum : time series 1 WaLSAtools , / wavelet , signal = data1 , time = time , power = power , period = period , significance = significance , coi = coi walsa_plot_wavelet_spectrum_panel , power , period , time , coi , significance , / log , / removespace , pos = pos1 , ztitle = '(g) Log!d10!n(Power)!C' ; ----------------------- data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; Wavelet power spectrum : time series 2 WaLSAtools , / wavelet , signal = data2 , time = time , power = power , period = period , significance = significance , coi = coi WaLSA_plot_wavelet_spectrum_panel , power , period , time , coi , significance , / log , / removespace , pos = pos2 , ztitle = '(h) Log!d10!n(Power)!C' ; ----------------------- data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; cross - correlations : Wavelet analysis : co - spectrum WaLSAtools , / wavelet , data1 = data2 , data2 = data1 , time = time , nperm = 50 , signif_cross = signif_cross , $ cospectrum = cospectrum , phase_angle = phase_angle , period = period , coi = coi save , cospectrum , period , time , coi , phase_angle , signif_cross , file = 'save_files/wavelet_co-spectrum.save' restore , 'save_files/wavelet_co-spectrum.save' walsa_plot_wavelet_cross_spectrum_panel , cospectrum , period , time , coi , clt = clt , phase_angle = phase_angle , / log , $ / crossspectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , / removespace , significancelevel = signif_cross , pos = pos3 , ref_pos = [ 0.025 , 0.22 ], ztitle = '(i) Log!d10!n(Cross Power)!C' ; ----------------------- data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; cross - correlations : Wavelet analysis : coherence WaLSAtools , / wavelet , data1 = data2 , data2 = data1 , time = time , nperm = 1000 , signif_coh = signif_coh , $ phase_angle = phase_angle , coherence = coherence , period = period , coi = coi save , coherence , period , time , coi , phase_angle , signif_coh , file = 'save_files/wavelet_coherence.save' restore , 'save_files/wavelet_coherence.save' walsa_plot_wavelet_cross_spectrum_panel , coherence , period , time , coi , clt = clt , phase_angle = phase_angle , $ / coherencespectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , / removespace , log = 0 , significancelevel = signif_coh , pos = pos4 , ref_pos = [ 0.55 , 0.22 ], ztitle = '(j) Coherence!C' ; ----------------------- walsa_endeps , filename = 'Figures/Fig6_cross-correlations_FFT_Wavelet' stop end", "title": "Cross Correlations"}, {"location": "idl/cross-correlation-example/#worked-example-nrmp-cross-correlation-analysis", "text": "This example demonstrates the application of cross-correlation analysis to two nearly identical synthetic 1D signals. The signals share the same base frequencies and amplitudes but have slight phase differences introduced between them. This simulates a scenario where similar wave signals are observed at different locations or with a time delay. By analysing the cross-correlation between these signals, we can identify common frequencies, quantify the strength of their relationship, and determine the phase or time lag between their oscillations. This provides valuable insights into the potential connections or shared drivers influencing the signals. Analysis and Figure The figure below presents a comparative analysis of cross-correlation techniques applied to the two synthetic 1D signals. Methods used: Fast Fourier Transform (FFT) Wavelet Transform (with Morlet wavelet) WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 6 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Cross-correlation analysis of two synthetic 1D time series using FFT and wavelet techniques. (a) and (b) display the first and second time series, respectively. \u00a9 compares their FFT power spectra (blue: time series 1, red: time series 2). (d)-(f) present the FFT-derived co-spectrum, coherence spectrum, and phase differences. (g) and (h) show individual wavelet power spectra (Morlet mother wavelet). (i) and (j) depict the wavelet co-spectrum and coherence map. Cross-hatched areas in wavelet panels mark the cone of influence (COI); black contours indicate the 95% confidence level. Power is represented in log-scale in panels (g)-(i) , while colors in panel (j) map coherence levels. Phase differences in (i) and (j) are visualized as arrows (right: in-phase, up: 90-degree lead for time series 1). Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 ; pro FIG6__cross_correlation data_dir = 'Synthetic_Data/' data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) restore , 'save_files/frequencies_1D_signal.save' ; cross - correlations : FFT analysis WaLSAtools , / fft , data1 = data2 , data2 = data1 , time = time , nperm = 100 , cospectrum = cospectrum , phase_angle = phase_angle , $ coherence = coherence , frequencies = frequencies , / nosignificance , d1_power = power1 , d2_power = power2 , n_segments = 2 ; ----------------------- plotting colset device , decomposed = 0 walsa_eps , size = [ 20 , 23 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 1.8 ! x . thick = 3.2 ! y . thick = 3.2 thick = 2.0 ! P . Multi = [ 0 , 3 , 4 ] ! x . ticklen =- 0.080 ! y . ticklen =- 0.042 df = frequencies [ 1 ] - frequencies [ 0 ] ; frequency resolution / the lowest detectable frequency xr = [ 0 , 36 ] tr = [ min ( time ), max ( time )] ; pos = cgLayout ([ 3 , 2 ], OXMargin = [ 10 , 4 ], OYMargin = [ 7 , 5 ], XGap = 12 , YGap = 10 ) pos = fltarr ( 4 , 6 ) pos [ * , 0 ] = [ 0.08 , 0.8583331 , 0.32111109 , 0.9583331 ] pos [ * , 1 ] = [ 0.41111109 , 0.8583331 , 0.64888890 , 0.9583331 ] pos [ * , 2 ] = [ 0.75888886 , 0.8583331 , 0.99 , 0.9583331 ] pos [ * , 3 ] = [ 0.08 , 0.670000 , 0.32111109 , 0.770000 ] pos [ * , 4 ] = [ 0.41111109 , 0.670000 , 0.64888890 , 0.770000 ] pos [ * , 5 ] = [ 0.75888886 , 0.670000 , 0.99 , 0.770000 ] ; -------------------------------- ; Plot the detrended & apodized light curve 1 signal1 = walsa_detrend_apod ( data1 ) cgplot , time , signal1 * 10. , charsize = charsize , pos = pos [ * , 0 ], thick = thick , $ xtitle = 'Time (s)' , ytitle = 'DN (arb. unit)' , xs = 1 , yr = [ min ( reform ( signal1 * 10. )), max ( reform ( signal1 * 10. ))], color = cgColor ( 'DodgerBlue' ), YTICKINTERVAL = 40 xyouts , tr [ 0 ] + (( tr [ 1 ] - tr [ 0 ]) / 2. ), max ( reform ( signal1 * 10. )) + 10. , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(a) 1st Time Series' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot the detrended & apodized light curve 2 signal2 = walsa_detrend_apod ( data2 ) cgplot , time , signal2 * 10. , charsize = charsize , pos = pos [ * , 1 ], thick = thick , $ xtitle = 'Time (s)' , ytitle = 'DN (arb. unit)' , xs = 1 , yr = [ min ( reform ( signal1 * 10. )), max ( reform ( signal1 * 10. ))], color = cgColor ( 'Red' ), YTICKINTERVAL = 40 xyouts , tr [ 0 ] + (( tr [ 1 ] - tr [ 0 ]) / 2. ), max ( reform ( signal1 * 10. )) + 10. , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(b) 2nd Time Series' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot FFT power spectra of the two time series cgplot , frequencies / 1000. , 100. * power1 / max ( power1 ), charsize = charsize , pos = pos [ * , 2 ], thick = 3 , $ xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , xs = 1 , ys = 1 , xr = xr , yr = [ 0 , 40 ], color = cgColor ( 'DodgerBlue' ), yminor = 5 oplot , frequencies / 1000. , 100. * power2 / max ( power2 ), color = cgColor ( 'Red' ), thick = 2 , lines = 2 xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 100 * 0.438 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(c) Power spectra' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot co - spectrum cgplot , frequencies / 1000. , 100. * cospectrum / max ( cospectrum ), yr = [ 0 , 40 ], xr = xr , charsize = charsize , pos = pos [ * , 3 ], thick = thick , $ xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , color = cgColor ( 'DarkGreen' ), yminor = 5 sjvline , sf , color = cgColor ( 'Orange' ) oplot , frequencies / 1000. , 100. * cospectrum / max ( cospectrum ), thick = thick , color = cgColor ( 'DarkGreen' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 100 * 0.438 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(d) Co-spectrum' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot coherence levels as a function of frequency cgplot , frequencies / 1000. , coherence , yr = [ 0 , 1.1 ], xr = xr , charsize = charsize , pos = pos [ * , 4 ], thick = thick , $ xtitle = 'Frequency (Hz)' , ytitle = 'Coherence' , color = cgColor ( 'DarkGreen' ), YTICKNAME = [ '0.0' , ' ' , '0.4' , ' ' , '0.8' , ' ' ] sjvline , sf , color = cgColor ( 'Orange' ) oplot , frequencies / 1000. , coherence , thick = thick , color = cgColor ( 'DarkGreen' ) sjhline , 0.80 , lines = 0 , thick = 3 , color = cgColor ( 'DarkRed' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 1.2 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(e) Coherence' , color = cgColor ( 'Black' ) ; -------------------------------- ; Plot phase lags as a function of frequency cgplot , frequencies / 1000. , phase_angle , yr = [ - 200 , 200 ], xr = xr , charsize = charsize , pos = pos [ * , 5 ], thick = thick , $ xtitle = 'Frequency (Hz)' , ytitle = 'Phase (deg)' , color = cgColor ( 'DarkGreen' ), yminor = 5 sjvline , sf , color = cgColor ( 'Orange' ) oplot , frequencies / 1000. , phase_angle , thick = thick , color = cgColor ( 'DarkGreen' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 240 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , '(f) Phase Difference' , color = cgColor ( 'Black' ) ; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ pos1 = [ 0.08 , 0.35 , 0.42 , 0.55 ] pos2 = [ 0.61 , 0.35 , 0.95 , 0.55 ] pos3 = [ 0.08 , 0.05 , 0.42 , 0.25 ] pos4 = [ 0.61 , 0.05 , 0.95 , 0.25 ] data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; Wavelet power spectrum : time series 1 WaLSAtools , / wavelet , signal = data1 , time = time , power = power , period = period , significance = significance , coi = coi walsa_plot_wavelet_spectrum_panel , power , period , time , coi , significance , / log , / removespace , pos = pos1 , ztitle = '(g) Log!d10!n(Power)!C' ; ----------------------- data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; Wavelet power spectrum : time series 2 WaLSAtools , / wavelet , signal = data2 , time = time , power = power , period = period , significance = significance , coi = coi WaLSA_plot_wavelet_spectrum_panel , power , period , time , coi , significance , / log , / removespace , pos = pos2 , ztitle = '(h) Log!d10!n(Power)!C' ; ----------------------- data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; cross - correlations : Wavelet analysis : co - spectrum WaLSAtools , / wavelet , data1 = data2 , data2 = data1 , time = time , nperm = 50 , signif_cross = signif_cross , $ cospectrum = cospectrum , phase_angle = phase_angle , period = period , coi = coi save , cospectrum , period , time , coi , phase_angle , signif_cross , file = 'save_files/wavelet_co-spectrum.save' restore , 'save_files/wavelet_co-spectrum.save' walsa_plot_wavelet_cross_spectrum_panel , cospectrum , period , time , coi , clt = clt , phase_angle = phase_angle , / log , $ / crossspectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , / removespace , significancelevel = signif_cross , pos = pos3 , ref_pos = [ 0.025 , 0.22 ], ztitle = '(i) Log!d10!n(Cross Power)!C' ; ----------------------- data1 = readfits ( data_dir + 'NRMP_signal_1D.fits' ) data2 = readfits ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) ; cross - correlations : Wavelet analysis : coherence WaLSAtools , / wavelet , data1 = data2 , data2 = data1 , time = time , nperm = 1000 , signif_coh = signif_coh , $ phase_angle = phase_angle , coherence = coherence , period = period , coi = coi save , coherence , period , time , coi , phase_angle , signif_coh , file = 'save_files/wavelet_coherence.save' restore , 'save_files/wavelet_coherence.save' walsa_plot_wavelet_cross_spectrum_panel , coherence , period , time , coi , clt = clt , phase_angle = phase_angle , $ / coherencespectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , / removespace , log = 0 , significancelevel = signif_coh , pos = pos4 , ref_pos = [ 0.55 , 0.22 ], ztitle = '(j) Coherence!C' ; ----------------------- walsa_endeps , filename = 'Figures/Fig6_cross-correlations_FFT_Wavelet' stop end", "title": "Worked Example - NRMP: Cross-Correlation Analysis"}, {"location": "idl/dominant-frequency-example/", "text": "Worked Example - NRMP: Dominant Frequency \u00b6 This example demonstrates the application of dominant frequency analysis to a synthetic spatio-temporal dataset. The dataset comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing the dominant frequencies at each spatial location, we can gain insights into the spatial distribution of oscillatory behaviour and identify potential wave modes. Analysis and Figure The figure below shows the dominant frequency maps calculated using different spectral analysis methods. The maps reveal the spatial distribution of the most prominent oscillation frequencies in the dataset. Methods used: Fast Fourier Transform (FFT) Refined Global Wavelet Spectrum (RGWS) with Morlet wavelet Refined Global Wavelet Spectrum (RGWS) with Paul wavelet WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Dominant frequency maps and mean power spectra. Top row: Dominant frequency maps derived using FFT (left), Morlet-based RGWS (middle), and Paul-based RGWS (right). Bottom panel: Normalized mean power spectra for FFT (blue), Morlet-based RGWS (red), and Paul-based RGWS (black). Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 ; pro FIG4__dominant_frequency__mean_spectra data_dir = 'Synthetic_Data/' data = readfits ( data_dir + 'NRMP_signal_3D.fits' , / silent ) cadence = 0.5 ; sec arcsecpx = 1 ; arcsec nx = n_elements ( data [ * , 0 , 0 ]) ny = n_elements ( data [ 0 , * , 0 ]) nt = n_elements ( data [ 0 , 0 , * ]) time = findgen ( nt ) * cadence ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ colset device , decomposed = 0 ; x and y ranges of the image in arcsec xrg = [ ABS ( 0 ), ABS ( nx - 1 )] * arcsecpx yrg = [ ABS ( 0 ), ABS ( ny - 1 )] * arcsecpx df = 1000. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ; calculate mean power sepctrum and dominant - frequency map : FFT analysis ; ----------------------- plotting walsa_eps , size = [ 30 , 22 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 3.0 barthick = 300 distbar = 300 ! x . thick = 5.0 ! y . thick = 5.0 line_thick = 4. ! P . Multi = [ 0 , 3 , 2 ] pos = cgLayout ([ 3 , 2 ], OXMargin = [ 0 , 0 ], OYMargin = [ 0 , 0 ], XGap = 14 , YGap = 0 ) ; To avoid - 0 in Dominant Frequency plots ! xy_lables = [ '0' , '20' , '40' , '60' , '80' , '100' , '120' ] ; ppos = pos [ * , 0 ] ; xyouts , ppos [ 0 ] + (( ppos [ 2 ] - ppos [ 0 ]) / 2. ), ppos [ 3 ] + (( 1 - ppos [ 3 ]) / 2. ), ALIGNMENT = 0.5 , CHARSIZE = charsize , / normal , 'Mean Power Spectrum (FFT)' , color = cgColor ( 'Black' ) ; WaLSAtools , / fft , signal = data , time = time , averagedpower = averagedpower , frequencies = frequencies , dominantfreq = dominantfreq , $ ; / nosignificance , power = power , rangefreq = rangefreq ; ; save , frequencies , dominantfreq , averagedpower , power , file = 'save_files/dominant_frequencies_FFT.save' restore , 'save_files/dominant_frequencies_FFT.save' walsa_powercolor , 1 walsa_image_plot , dominantfreq , xrange = abs ( xrg ), yrange = yrg , nobar = 0 , zrange = round ( minmax ( dominantfreq , / nan )), $ contour = 0 , / nocolor , ztitle = 'FFT!C!CDominant Frequency (mHz)!C' , xtitle = '(pixel)' , ytitle = '(pixel)' , $ exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , zlen =- 0.45 , distbar = barthick , xticklen =- 0.04 , yticklen =- 0.035 , $ barthick = barthick , charsize = charsize , position = pos [ * , 0 ], resample = 2 , BARZTICKINTERVAL = 100 , XTICKNAME = xy_lables , YTICKNAME = xy_lables cgplot , frequencies , 100 * averagedpower / max ( averagedpower ), yr = [ 0 , 115 ], charsize = charsize , xticklen =- 0.045 , yticklen =- 0.012 , position = [ 0. , 0. , 1.0 , 0.345 ], $ xtitle = 'Frequency (mHz)' , ytitle = 'Normalised Power' , thick = 6 , Color = cgColor ( 'DodgerBlue' ), xr = [ 20 , 640 ], XTICKINTERVAL = 50 , XTICKNAME = [ ' ' , '100' , ' ' , '200' , ' ' , '300' , ' ' , '400' , ' ' , '500' , ' ' , '600' ] xyouts , 310. , 126. , ALIGNMENT = 0.5 , CHARSIZE = 0.55 * charsize , / data , 'Mean Power Spectra' , color = cgColor ( 'Black' ) ; ----------------------------------------------------------------------------- ; calculate mean power sepctrum and dominant - frequency map : Wavelet analysis - RGWS Wavelet ; WaLSAtools , / wavelet , / rgws , signal = data , time = time , averagedpower = averagedpower , frequencies = frequencies , dominantfreq = dominantfreq , $ ; / nosignificance , power = power , rangefreq = rangefreq , mother = 'Morlet' ; ; save , frequencies , dominantfreq , averagedpower , power , file = 'save_files/dominant_frequencies_RGWS_morlet.save' restore , 'save_files/dominant_frequencies_RGWS_morlet.save' oplot , frequencies , 100 * averagedpower / max ( averagedpower ), thick = 6 , Color = cgColor ( 'Red' );, / ylog restore , 'save_files/dominant_frequencies_RGWS_paul.save' oplot , frequencies , 100 * averagedpower / max ( averagedpower ), thick = 6 , Color = cgColor ( 'Black' );, / ylog ; legends loc = [ 600 , 98 ] & VSpace = 19 & ls = [ 0 , 0 , 0 ] & colors = [ 'DodgerBlue' , 'Red' , 'Black' ] & names = [ 'FFT' , 'RGWS (Morlet)' , 'RGWS (Paul)' ] for fac = 0 L , 2 do begin cgPlots , [ loc [ 0 ], loc [ 0 ] + 25 ], [ loc [ 1 ] - fac * VSpace , loc [ 1 ] - fac * VSpace ], linestyle = ls [ fac ], color = cgColor ( colors [ fac ]), thick = 6 , / data xyouts , loc [ 0 ] - 5 , loc [ 1 ] - fac * VSpace - 3.0 , names [ fac ], ALIGNMENT = 1 , CHARSIZE = charsize / 2.0 , / data , color = cgColor ( 'Black' ) endfor restore , 'save_files/dominant_frequencies_RGWS_morlet.save' ; ppos = pos [ * , 0 ] ; xyouts , ppos [ 0 ] + (( ppos [ 2 ] - ppos [ 0 ]) / 2. ), ppos [ 3 ] + (( 1 - ppos [ 3 ]) / 2. ), ALIGNMENT = 0.5 , CHARSIZE = charsize , / normal , 'Mean Power Spectrum (Sensible Wavelet)' , color = cgColor ( 'Black' ) walsa_powercolor , 1 walsa_image_plot , dominantfreq , xrange = xrg , yrange = yrg , nobar = 0 , zrange = round ( minmax ( dominantfreq , / nan )), $ contour = 0 , / nocolor , ztitle = 'RGWS - Morlet!C!CDominant Frequency (mHz)!C' , xtitle = '(pixel)' , ytitle = '(pixel)' , $ exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , zlen =- 0.45 , distbar = barthick , xticklen =- 0.04 , yticklen =- 0.035 , $ barthick = barthick , charsize = charsize , position = pos [ * , 1 ], resample = 2 , BARZTICKINTERVAL = 100 , XTICKNAME = xy_lables , YTICKNAME = xy_lables ; ----------------------------------------------------------------------------- ; calculate mean power sepctrum and dominant - frequency map : Wavelet analysis - RGWS Wavelet ; WaLSAtools , / wavelet , / rgws , signal = data , time = time , averagedpower = averagedpower , frequencies = frequencies , dominantfreq = dominantfreq , $ ; / nosignificance , power = power , rangefreq = rangefreq , mother = 'Paul' ; ; save , frequencies , dominantfreq , averagedpower , power , file = 'save_files/dominant_frequencies_RGWS_paul.save' restore , 'save_files/dominant_frequencies_RGWS_paul.save' ; ppos = pos [ * , 0 ] ; xyouts , ppos [ 0 ] + (( ppos [ 2 ] - ppos [ 0 ]) / 2. ), ppos [ 3 ] + (( 1 - ppos [ 3 ]) / 2. ), ALIGNMENT = 0.5 , CHARSIZE = charsize , / normal , 'Mean Power Spectrum (Sensible Wavelet)' , color = cgColor ( 'Black' ) walsa_powercolor , 1 walsa_image_plot , dominantfreq , xrange = xrg , yrange = yrg , nobar = 0 , zrange = round ( minmax ( dominantfreq , / nan )), $ contour = 0 , / nocolor , ztitle = 'RGWS - Paul!C!CDominant Frequency (mHz)!C' , xtitle = '(pixel)' , ytitle = '(pixel)' , $ exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , zlen =- 0.45 , distbar = barthick , xticklen =- 0.04 , yticklen =- 0.035 , $ barthick = barthick , charsize = charsize , position = pos [ * , 2 ], resample = 2 , BARZTICKINTERVAL = 100 , XTICKNAME = xy_lables , YTICKNAME = xy_lables ; ----------------------------------------------------------------------------- walsa_endeps , filename = 'Figures/Fig4_dominant_frequency_mean_power_spectra' ; ----------------------------------------------------------------------------- ! P . Multi = 0 Cleanplot , / Silent stop end", "title": "Dominant Frequency"}, {"location": "idl/dominant-frequency-example/#worked-example-nrmp-dominant-frequency", "text": "This example demonstrates the application of dominant frequency analysis to a synthetic spatio-temporal dataset. The dataset comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing the dominant frequencies at each spatial location, we can gain insights into the spatial distribution of oscillatory behaviour and identify potential wave modes. Analysis and Figure The figure below shows the dominant frequency maps calculated using different spectral analysis methods. The maps reveal the spatial distribution of the most prominent oscillation frequencies in the dataset. Methods used: Fast Fourier Transform (FFT) Refined Global Wavelet Spectrum (RGWS) with Morlet wavelet Refined Global Wavelet Spectrum (RGWS) with Paul wavelet WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Dominant frequency maps and mean power spectra. Top row: Dominant frequency maps derived using FFT (left), Morlet-based RGWS (middle), and Paul-based RGWS (right). Bottom panel: Normalized mean power spectra for FFT (blue), Morlet-based RGWS (red), and Paul-based RGWS (black). Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 ; pro FIG4__dominant_frequency__mean_spectra data_dir = 'Synthetic_Data/' data = readfits ( data_dir + 'NRMP_signal_3D.fits' , / silent ) cadence = 0.5 ; sec arcsecpx = 1 ; arcsec nx = n_elements ( data [ * , 0 , 0 ]) ny = n_elements ( data [ 0 , * , 0 ]) nt = n_elements ( data [ 0 , 0 , * ]) time = findgen ( nt ) * cadence ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ colset device , decomposed = 0 ; x and y ranges of the image in arcsec xrg = [ ABS ( 0 ), ABS ( nx - 1 )] * arcsecpx yrg = [ ABS ( 0 ), ABS ( ny - 1 )] * arcsecpx df = 1000. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ; calculate mean power sepctrum and dominant - frequency map : FFT analysis ; ----------------------- plotting walsa_eps , size = [ 30 , 22 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 3.0 barthick = 300 distbar = 300 ! x . thick = 5.0 ! y . thick = 5.0 line_thick = 4. ! P . Multi = [ 0 , 3 , 2 ] pos = cgLayout ([ 3 , 2 ], OXMargin = [ 0 , 0 ], OYMargin = [ 0 , 0 ], XGap = 14 , YGap = 0 ) ; To avoid - 0 in Dominant Frequency plots ! xy_lables = [ '0' , '20' , '40' , '60' , '80' , '100' , '120' ] ; ppos = pos [ * , 0 ] ; xyouts , ppos [ 0 ] + (( ppos [ 2 ] - ppos [ 0 ]) / 2. ), ppos [ 3 ] + (( 1 - ppos [ 3 ]) / 2. ), ALIGNMENT = 0.5 , CHARSIZE = charsize , / normal , 'Mean Power Spectrum (FFT)' , color = cgColor ( 'Black' ) ; WaLSAtools , / fft , signal = data , time = time , averagedpower = averagedpower , frequencies = frequencies , dominantfreq = dominantfreq , $ ; / nosignificance , power = power , rangefreq = rangefreq ; ; save , frequencies , dominantfreq , averagedpower , power , file = 'save_files/dominant_frequencies_FFT.save' restore , 'save_files/dominant_frequencies_FFT.save' walsa_powercolor , 1 walsa_image_plot , dominantfreq , xrange = abs ( xrg ), yrange = yrg , nobar = 0 , zrange = round ( minmax ( dominantfreq , / nan )), $ contour = 0 , / nocolor , ztitle = 'FFT!C!CDominant Frequency (mHz)!C' , xtitle = '(pixel)' , ytitle = '(pixel)' , $ exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , zlen =- 0.45 , distbar = barthick , xticklen =- 0.04 , yticklen =- 0.035 , $ barthick = barthick , charsize = charsize , position = pos [ * , 0 ], resample = 2 , BARZTICKINTERVAL = 100 , XTICKNAME = xy_lables , YTICKNAME = xy_lables cgplot , frequencies , 100 * averagedpower / max ( averagedpower ), yr = [ 0 , 115 ], charsize = charsize , xticklen =- 0.045 , yticklen =- 0.012 , position = [ 0. , 0. , 1.0 , 0.345 ], $ xtitle = 'Frequency (mHz)' , ytitle = 'Normalised Power' , thick = 6 , Color = cgColor ( 'DodgerBlue' ), xr = [ 20 , 640 ], XTICKINTERVAL = 50 , XTICKNAME = [ ' ' , '100' , ' ' , '200' , ' ' , '300' , ' ' , '400' , ' ' , '500' , ' ' , '600' ] xyouts , 310. , 126. , ALIGNMENT = 0.5 , CHARSIZE = 0.55 * charsize , / data , 'Mean Power Spectra' , color = cgColor ( 'Black' ) ; ----------------------------------------------------------------------------- ; calculate mean power sepctrum and dominant - frequency map : Wavelet analysis - RGWS Wavelet ; WaLSAtools , / wavelet , / rgws , signal = data , time = time , averagedpower = averagedpower , frequencies = frequencies , dominantfreq = dominantfreq , $ ; / nosignificance , power = power , rangefreq = rangefreq , mother = 'Morlet' ; ; save , frequencies , dominantfreq , averagedpower , power , file = 'save_files/dominant_frequencies_RGWS_morlet.save' restore , 'save_files/dominant_frequencies_RGWS_morlet.save' oplot , frequencies , 100 * averagedpower / max ( averagedpower ), thick = 6 , Color = cgColor ( 'Red' );, / ylog restore , 'save_files/dominant_frequencies_RGWS_paul.save' oplot , frequencies , 100 * averagedpower / max ( averagedpower ), thick = 6 , Color = cgColor ( 'Black' );, / ylog ; legends loc = [ 600 , 98 ] & VSpace = 19 & ls = [ 0 , 0 , 0 ] & colors = [ 'DodgerBlue' , 'Red' , 'Black' ] & names = [ 'FFT' , 'RGWS (Morlet)' , 'RGWS (Paul)' ] for fac = 0 L , 2 do begin cgPlots , [ loc [ 0 ], loc [ 0 ] + 25 ], [ loc [ 1 ] - fac * VSpace , loc [ 1 ] - fac * VSpace ], linestyle = ls [ fac ], color = cgColor ( colors [ fac ]), thick = 6 , / data xyouts , loc [ 0 ] - 5 , loc [ 1 ] - fac * VSpace - 3.0 , names [ fac ], ALIGNMENT = 1 , CHARSIZE = charsize / 2.0 , / data , color = cgColor ( 'Black' ) endfor restore , 'save_files/dominant_frequencies_RGWS_morlet.save' ; ppos = pos [ * , 0 ] ; xyouts , ppos [ 0 ] + (( ppos [ 2 ] - ppos [ 0 ]) / 2. ), ppos [ 3 ] + (( 1 - ppos [ 3 ]) / 2. ), ALIGNMENT = 0.5 , CHARSIZE = charsize , / normal , 'Mean Power Spectrum (Sensible Wavelet)' , color = cgColor ( 'Black' ) walsa_powercolor , 1 walsa_image_plot , dominantfreq , xrange = xrg , yrange = yrg , nobar = 0 , zrange = round ( minmax ( dominantfreq , / nan )), $ contour = 0 , / nocolor , ztitle = 'RGWS - Morlet!C!CDominant Frequency (mHz)!C' , xtitle = '(pixel)' , ytitle = '(pixel)' , $ exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , zlen =- 0.45 , distbar = barthick , xticklen =- 0.04 , yticklen =- 0.035 , $ barthick = barthick , charsize = charsize , position = pos [ * , 1 ], resample = 2 , BARZTICKINTERVAL = 100 , XTICKNAME = xy_lables , YTICKNAME = xy_lables ; ----------------------------------------------------------------------------- ; calculate mean power sepctrum and dominant - frequency map : Wavelet analysis - RGWS Wavelet ; WaLSAtools , / wavelet , / rgws , signal = data , time = time , averagedpower = averagedpower , frequencies = frequencies , dominantfreq = dominantfreq , $ ; / nosignificance , power = power , rangefreq = rangefreq , mother = 'Paul' ; ; save , frequencies , dominantfreq , averagedpower , power , file = 'save_files/dominant_frequencies_RGWS_paul.save' restore , 'save_files/dominant_frequencies_RGWS_paul.save' ; ppos = pos [ * , 0 ] ; xyouts , ppos [ 0 ] + (( ppos [ 2 ] - ppos [ 0 ]) / 2. ), ppos [ 3 ] + (( 1 - ppos [ 3 ]) / 2. ), ALIGNMENT = 0.5 , CHARSIZE = charsize , / normal , 'Mean Power Spectrum (Sensible Wavelet)' , color = cgColor ( 'Black' ) walsa_powercolor , 1 walsa_image_plot , dominantfreq , xrange = xrg , yrange = yrg , nobar = 0 , zrange = round ( minmax ( dominantfreq , / nan )), $ contour = 0 , / nocolor , ztitle = 'RGWS - Paul!C!CDominant Frequency (mHz)!C' , xtitle = '(pixel)' , ytitle = '(pixel)' , $ exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , zlen =- 0.45 , distbar = barthick , xticklen =- 0.04 , yticklen =- 0.035 , $ barthick = barthick , charsize = charsize , position = pos [ * , 2 ], resample = 2 , BARZTICKINTERVAL = 100 , XTICKNAME = xy_lables , YTICKNAME = xy_lables ; ----------------------------------------------------------------------------- walsa_endeps , filename = 'Figures/Fig4_dominant_frequency_mean_power_spectra' ; ----------------------------------------------------------------------------- ! P . Multi = 0 Cleanplot , / Silent stop end", "title": "Worked Example - NRMP: Dominant Frequency"}, {"location": "idl/eemd-example/", "text": "Worked Example - NRMP: Ensemble Empirical Mode Decomposition (EEMD) \u00b6 The IDL version of this example is currently under development .....", "title": "EEMD"}, {"location": "idl/eemd-example/#worked-example-nrmp-ensemble-empirical-mode-decomposition-eemd", "text": "The IDL version of this example is currently under development .....", "title": "Worked Example - NRMP: Ensemble Empirical Mode Decomposition (EEMD)"}, {"location": "idl/emd-example/", "text": "Worked Example - NRMP: Empirical Mode Decomposition (EMD) \u00b6 The IDL version of this example is currently under development .....", "title": "EMD"}, {"location": "idl/emd-example/#worked-example-nrmp-empirical-mode-decomposition-emd", "text": "The IDL version of this example is currently under development .....", "title": "Worked Example - NRMP: Empirical Mode Decomposition (EMD)"}, {"location": "idl/installation/", "text": "Installation - IDL version \u00b6 The IDL version of the WaLSAtools package requires the Interactive Data Language ( IDL ) . The package has primarily been tested with IDL version 8.5 and later, but should work with earlier versions as well. The package includes all third-party dependencies, so no other libraries are required. Installation with Git \u00b6 The preferred method for installing WaLSAtools is through Git. This allows you to easily update to the latest version and track changes. Clone the WaLSAtools repository from GitHub: git clone https://github.com/WaLSAteam/WaLSAtools Add the WaLSAtools directory to your IDL path by navigating to the idl directory, starting IDL and running: .run setup.pro See Setting your IDL PATH for further instructions. To update an existing installation to the latest version, navigate to the WaLSAtools directory in your terminal and run: git pull Installation via Direct Download \u00b6 Alternatively, you can download the WaLSAtools package as a zip file . After downloading, extract the contents of the zip file to a location of your choice and add that location to your IDL path (by simply navigating to the idl directory, starting IDL and running .run setup.pro ). Hints \u00b6 IDL PATH Add WaLSAtools to your IDL PATH . Verifying the Installation To verify that WaLSAtools is installed correctly, start IDL and run the following command (preferably, anywhere outside the WaLSAtools directory): IDL> WaLSAtools, /version This should print the WaLSAtools version and a brief overview of its functionalities: % Compiled module: WALSATOOLS. __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------------------- WaLSAtools v1.0 Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------------------- Performing various wave analysis techniques on (a) Single time series (1D signal or [x,y,t] cube) Methods: (1) 1D analysis with: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) (2) 3D analysis: k-\u03c9 (with optional Fourier filtering) or B-\u03c9 diagrams (b) Two time series (cross correlations between two signals) With: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) ---------------------------------------------------------------------------- Troubleshooting If you encounter any problems during the installation process, please refer to the Troubleshooting section for common issues and solutions.", "title": "Installation"}, {"location": "idl/installation/#installation-idl-version", "text": "The IDL version of the WaLSAtools package requires the Interactive Data Language ( IDL ) . The package has primarily been tested with IDL version 8.5 and later, but should work with earlier versions as well. The package includes all third-party dependencies, so no other libraries are required.", "title": "Installation - IDL version"}, {"location": "idl/installation/#installation-with-git", "text": "The preferred method for installing WaLSAtools is through Git. This allows you to easily update to the latest version and track changes. Clone the WaLSAtools repository from GitHub: git clone https://github.com/WaLSAteam/WaLSAtools Add the WaLSAtools directory to your IDL path by navigating to the idl directory, starting IDL and running: .run setup.pro See Setting your IDL PATH for further instructions. To update an existing installation to the latest version, navigate to the WaLSAtools directory in your terminal and run: git pull", "title": "Installation with Git"}, {"location": "idl/installation/#installation-via-direct-download", "text": "Alternatively, you can download the WaLSAtools package as a zip file . After downloading, extract the contents of the zip file to a location of your choice and add that location to your IDL path (by simply navigating to the idl directory, starting IDL and running .run setup.pro ).", "title": "Installation via Direct Download"}, {"location": "idl/installation/#hints", "text": "IDL PATH Add WaLSAtools to your IDL PATH . Verifying the Installation To verify that WaLSAtools is installed correctly, start IDL and run the following command (preferably, anywhere outside the WaLSAtools directory): IDL> WaLSAtools, /version This should print the WaLSAtools version and a brief overview of its functionalities: % Compiled module: WALSATOOLS. __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------------------- WaLSAtools v1.0 Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------------------- Performing various wave analysis techniques on (a) Single time series (1D signal or [x,y,t] cube) Methods: (1) 1D analysis with: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) (2) 3D analysis: k-\u03c9 (with optional Fourier filtering) or B-\u03c9 diagrams (b) Two time series (cross correlations between two signals) With: FFT (Fast Fourier Transform), Wavelet, Lomb-Scargle, or HHT (Hilbert-Huang Transform) ---------------------------------------------------------------------------- Troubleshooting If you encounter any problems during the installation process, please refer to the Troubleshooting section for common issues and solutions.", "title": "Hints"}, {"location": "idl/introduction/", "text": "Introduction \u00b6 Overview \u00b6 WaLSAtools is an open-source library for analysing a wide variety of wave phenomena in time series data \u2013 including 1D signals, images, and multi-dimensional datasets. It provides tools to extract meaningful insights from complex datasets and is applicable across diverse fields, including astrophysics, engineering, life, physical and environmental sciences, and biomedical studies, among others. The library is continuously expanding with new features and functionalities, ensuring it remains a valuable resource for wave analysis. The core of WaLSAtools is built upon Python . This ensures accessibility and ease of use for a broad audience. We are actively developing versions in other popular languages to further enhance accessibility, enabling researchers from various backgrounds to leverage the power of WaLSAtools for their wave analysis needs. Currently, WaLSAtools is partially implemented in IDL , with plans to expand its functionality and extend to other programming languages in the future. WaLSAtools provides a suite of both fundamental and advanced tools, but it remains the user's responsibility to choose the method that best fits the nature of their dataset and the scientific questions being addressed. Selecting the appropriate analysis method is essential for ensuring reliable and scientifically valid results. The use of unsuitable or overly simplified techniques \u2013 without consideration of the data's properties or the research goals \u2013 can lead to incomplete or incorrect conclusions, and potentially to misinterpretation. This principle is central to our accompanying Primer , which emphasises the importance of methodological awareness in wave analysis across all disciplines. Developed by the WaLSA Team , WaLSAtools was initially inspired by the intricate wave dynamics observed in the Sun's atmosphere. However, its applications extend far beyond solar physics, offering a versatile toolkit for anyone working with oscillatory signals. WaLSAtools promotes reproducibility and transparency in wave analysis. Its robust implementations of validated techniques ensure consistent and trustworthy results, empowering researchers to delve deeper into the complexities of their data. Through its interactive interface, WaLSAtools guides users through the analysis process, providing the necessary information and tools to perform various types of wave analysis with ease. This repository is associated with a primer article titled Wave analysis tools in Nature Reviews Methods Primers (NRMP; Free access to view-only Primer and its Supplementary Information ), showcasing its capabilities through detailed analyses of synthetic datasets. The Analysis Tools/Examples/Worked examples - NRMP contain reproducible codes for generating all figures presented in the NRMP article, serving as a practical guide for applying WaLSAtools to real-world analyses. To switch between Python and IDL documentation, click the current programming language name at the top of the page. Key Features \u00b6 Wide Range of Wave Analysis Techniques: From foundational methods like FFT and wavelet analysis to advanced techniques such as EMD, k-\u03c9, and POD analysis. Cross-Disciplinary Applicability: Suitable for signal processing, oscillation studies, and multi-dimensional analysis in various fields. Interactive Interfaces: Simplified workflows through interactive menus for both Python and IDL . Open Science Principles: Promotes reproducibility and transparency in data analysis. Contributions are welcome to improve the codes, methods, or documentation. Analysis Methods \u00b6 WaLSAtools offers a variety of spectral analysis techniques, each tailored to specific types of data and research questions. These methods are broadly categorised into: Single Time Series Analysis: Includes methods for analysing individual time series, such as: 1D Signals: Fast Fourier Transform (FFT), Lomb-Scargle, Wavelet Transform, Welch, Hilbert-Huang Transform (HHT) and Empirical Mode Decomposition (EMD) 3D Cubes: k-\u03c9 Analysis, Dominant Frequency, Mean Power Spectrum, and Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis: Includes methods for analysing correlations between two time series, resulting in cross-spectrum, coherence, and phase relationships. All time series are pre-processed to mitigate unwanted effects, such as long-term trends and edge effects, prior to spectral analysis. This includes detrending and apodization. Detailed Descriptions of Analysis Methods \u00b6 The choice of the most appropriate wave analysis technique depends not only on the nature of the data but also on the specific research goals and the desired insights. WaLSAtools offers a variety of methods, each with its own strengths and limitations, allowing researchers to tailor their analysis to their specific needs. This section provides detailed descriptions of the individual methods available in WaLSAtools , empowering users to make informed decisions about the most suitable techniques for their research. Single time series analysis: 1D signal \u00b6 One Dimensional (1D) Signal WaLSAtools provides a variety of methods for analysing 1D signals (time series). Each method uses a different approach to decompose the signal into its constituent frequencies, making them suitable for various scenarios. Selecting the appropriate technique depends on the specific characteristics of the data and the research goals. FFT Lomb-Scargle Wavelet EMD/HHT Welch The Fast Fourier Transform (FFT; Cooley and Tukey 1965 ) is an efficient algorithm that computes the discrete Fourier transform (DFT; Fourier 1824 ) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. The FFT is widely used in many fields due to its computational efficiency. This makes it significantly faster than directly computing the DFT, especially for large datasets. The FFT algorithm estimates the frequency spectrum by decomposing the signal into a set of sinusoidal oscillations at distinct frequencies, each with its own amplitude and phase. Advantages: Computationally efficient, especially for large datasets. Provides a clear and easily interpretable frequency spectrum. Well-suited for analysing stationary signals with evenly spaced samples. Limitations: Assumes the signal is stationary (frequency content does not change over time). Requires evenly spaced data points. Can be sensitive to edge effects in finite signals. FFT is often the prime choice of method for spectral analysis, unless the science case and/or data properties require the use of other techniques. The Lomb\u2013Scargle periodogram is a method of estimating a frequency spectrum, based on a least-squares fit of sinusoids to data samples, irrespective of whether the sampling is regularly or irregularly spaced in time. Advantages: Can handle irregularly sampled data without the need for interpolation. Provides accurate frequency estimates even with missing data points. Limitations: Can be computationally expensive for very large datasets. May not be as efficient as FFT for evenly spaced data. Lomb\u2013Scargle should be the method of choice when the data points are unequally spaced in time (e.g., when there are gaps or missing data points). Note: While interpolation can sometimes be used to fill gaps in data and enable the use of other methods like FFT, selecting an appropriate interpolation method and mitigating potential artifacts can be challenging. A wavelet transform is a time-frequency representation of a signal. It allows a signal to be decomposed into its constituent wavelets, which are localised in both time and frequency. The Wavelet Transform is a powerful tool for analysing time series data that exhibit non-stationary behaviors, meaning their frequency content changes over time. Unlike the Fourier Transform, which provides a global frequency spectrum, the Wavelet Transform allows for localised analysis in both time and frequency, revealing how different frequencies contribute to the signal at different times. Key Concepts: Mother Wavelet: The Wavelet Transform uses a function called a \"mother wavelet\" to analyse the signal. Different mother wavelets have different shapes and properties, making them suitable for different types of signals and analysis goals. The choice of mother wavelet is crucial for optimal results. Scales: The Wavelet Transform analyses the signal at different scales, which correspond to different frequency ranges. This multi-resolution analysis allows for the detection of both short-lived, high-frequency features and long-lasting, low-frequency trends. Cone of Influence (COI): The COI is a region in the time-frequency plane where edge effects can influence the results of the Wavelet Transform. It is important to be aware of the COI when interpreting the results. WaLSAtools provides a versatile implementation of the Wavelet Transform, allowing users to choose from various mother wavelets and customize the analysis parameters. In addition to the standard 2D time-frequency spectrum, it offers two types of 1D spectra: Global Wavelet Spectrum (GWS): Obtained by averaging the wavelet power over time. Refined Global Wavelet Spectrum (RGWS): A novel approach that excludes the COI and regions below a given confidence level from the time-integral of wavelet power, providing a more robust representation of the significant frequency components. Advantages: Suitable for analysing non-stationary signals. Provides both time and frequency localisation. Offers a multi-resolution view of the signal. Limitations: The choice of mother wavelet can influence the results. Frequency resolution is limited, especially at higher frequencies. Edge effects can influence the analysis near the boundaries of the time series. Wavelet transform is particularly suitable for studying transient oscillations, weak signals, or quasi-periodic signatures. Empirical Mode Decomposition (EMD) is a data-driven technique for analysing nonlinear and non-stationary signals. It decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. The Hilbert-Huang Transform (HHT) combines EMD with the Hilbert Transform to calculate the instantaneous frequency and amplitude of each IMF. This provides a detailed view of how the signal's frequency content evolves over time. WaLSAtools Implementation: WaLSAtools provides implementations of both EMD and HHT, allowing users to: Decompose signals into IMFs using EMD. Calculate instantaneous frequencies and amplitudes using HHT. Visualise the results with time-frequency plots and marginal spectra. Advantages: Suitable for analysing nonlinear and non-stationary signals. Adaptively extracts IMFs based on the signal's local characteristics. Provides time-varying frequency and amplitude information. Limitations: Can be sensitive to noise and parameter choices. Mode mixing can occur, where a single IMF contains components from different oscillatory modes. Requires careful selection of stopping criteria and spline fitting parameters. Key Considerations: Ensemble EMD (EEMD): WaLSAtools also includes EEMD, an ensemble-based approach that reduces the impact of noise and improves mode separation. Significance Testing: It is essential to assess the statistical significance of the extracted IMFs to distinguish genuine oscillations from noise-induced artifacts. Parameter Selection: Carefully choose the EMD and HHT parameters based on the specific characteristics of the data and the research goals. EMD and HHT are valuable tools for analysing complex signals that exhibit non-stationary and nonlinear behaviors, providing insights into the time-varying dynamics of oscillatory phenomena. Welch's method is a technique for estimating the power spectral density (PSD) of a signal. It is particularly useful when dealing with noisy data or signals that have time-varying frequency content. How it works: The signal is divided into overlapping segments. Each segment is windowed (e.g., using a Hann or Hamming window) to reduce spectral leakage. The periodogram (a basic estimate of the PSD) is computed for each segment. The periodograms are averaged to obtain a smoother and more robust estimate of the PSD. Advantages: Reduces noise in the PSD estimate. Can handle signals with time-varying frequency content. Provides a more robust estimate of the PSD compared to a single periodogram. Limitations: Reduces frequency resolution due to the use of shorter segments. The choice of window function and segment length can affect the results. Welch's method is a valuable tool for analysing signals where noise reduction is a priority or when the frequency content of the signal changes over time. Info Power Spectral Density (PSD): The analysis methods compute wave amplitudes at different frequencies, resulting in a frequency spectrum. The Power Spectral Density (PSD) can further be calculated, which represents the power (amplitude squared) per unit frequency. This normalisation allows for meaningful comparisons between different signals, regardless of their frequency resolution. Additionally, WaLSAtools outputs single-sided PSDs, where the power at negative frequencies is folded into the positive frequencies, divided by two since the folding effectively doubles the PSD values. Confidence Levels: WaLSAtools can estimate the statistical significance of the computed power using a randomisation test. This helps distinguish between genuine signals and those arising from noise or spurious effects. For example, a 95% confidence level indicates that the detected power is significant with a 5% probability of being due to random fluctuations. Single time series analysis: 3D Datacube \u00b6 Three Dimensional (3D) Datacube Analysing the distribution of oscillation power over a spatial extent is often crucial to identify wave modes and understand their behaviour. WaLSAtools offers several methods for analysing 3D datacubes (time series of 2D images), each providing unique insights into the spatio-temporal characteristics of waves. k-\u03c9 Mean Power Dominant Frequency POD k-\u03c9 analysis is a powerful technique for investigating wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both spatial (wavenumber, k) and temporal (frequency, \u03c9) domains. The resulting k-\u03c9 diagram reveals the relationship between spatial and temporal scales of oscillations, providing insights into wave dispersion relations and identifying different wave modes. WaLSAtools provides a comprehensive k-\u03c9 analysis tool that allows for: Generating k-\u03c9 diagrams from 3D datacubes. Filtering of the data in k-space and/or \u03c9-space. Reconstructing filtered datacubes to isolate specific wave modes or features. Fourier filtering is a key component of k-\u03c9 analysis, enabling the isolation of wave signatures with specific wavenumber and frequency characteristics. This is particularly useful for identifying weak wave modes that might be masked by stronger signals or background trends. Advantages: Reveals wave dispersion relations. Enables isolation of specific wave modes through filtering. Provides insights into the spatio-temporal characteristics of waves. Limitations: Assumes the wave field is statistically homogeneous and stationary. Can be sensitive to edge effects and noise. For a detailed description of the Fourier filtering technique, refer to the step-by-step guide of the original (QUEEFF) code integrated into WaLSAtools . The mean power spectrum provides a global view of the oscillatory behaviour within a region of interest. It is calculated by averaging the power spectra of individual pixels across the spatial domain. WaLSAtools allows for calculating the mean power spectrum using various 1D analysis methods (FFT, Lomb-Scargle, Wavelet, HHT, Welch, etc.). Advantages: Highlights the dominant (mean) oscillatory modes in a region. Provides a baseline for filtering out global contributions. Can be used to compare oscillatory behaviour across different regions or datasets. Limitations: May not capture localised or subtle variations in oscillatory behaviour. The dominant frequency is the frequency with the highest power in a spectrum. WaLSAtools can calculate the dominant frequency for each pixel in a 3D datacube, generating a map that visualises the spatial distribution of dominant frequencies. Advantages: Provides a visual representation of the dominant oscillatory modes in a region. Can reveal spatial patterns and correlations with other physical properties. Limitations: Can be biased in signals with multiple strong spectral peaks. May not capture the full complexity of oscillatory behaviour. Proper Orthogonal Decomposition (POD) is a powerful data-driven technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. WaLSAtools provides a POD analysis tool that: Calculates the POD modes and their corresponding eigenvalues. Reconstructs the original data using a reduced number of modes. Visualises the spatial patterns and temporal evolution of the dominant modes. Advantages: Effectively reduces the dimensionality of complex datasets. Identifies coherent spatial patterns and their temporal behaviour. Can be used for feature extraction and pattern recognition. Limitations: Assumes the data is statistically stationary. May not capture highly localised or transient phenomena. Cross-correlation Analysis \u00b6 Cross-Correlation Analysis Investigating the relationships between two time series is essential for understanding the interplay of different phenomena across various scientific disciplines. WaLSAtools provides a comprehensive suite of tools for cross-correlation analysis, enabling researchers to: Uncover shared frequencies and correlated power between two signals. Quantify the strength of the relationship between two time series at different frequencies. Determine the relative timing (phase or time lag) between oscillations. These tools are valuable for uncovering hidden connections, tracking wave propagation, and exploring the underlying drivers of oscillatory behaviour in diverse fields. Cross-Spectrum Coherence Phase Difference The cross-spectrum, also known as the cross-power spectrum, is a complex-valued function that describes the correlation between two time series in the frequency domain. It is calculated by multiplying the frequency representation of one signal by the complex conjugate of the frequency representation of the other one. The magnitude of the cross-spectrum, often called the co-spectrum, represents the shared power between the two signals at each frequency. High values in the co-spectrum indicate strong correlations between the oscillations at those frequencies. Applications: Identifying common frequencies and shared power between two signals. Detecting potential connections or shared influences affecting the signals. Limitations: May not reveal correlations if the individual power spectra lack prominent peaks. Can be sensitive to noise and potential biases in the data. Coherence is a normalised measure of the linear correlation between two time series at each frequency. It ranges from 0 (no correlation) to 1 (perfect correlation). High coherence values indicate that the oscillations in the two time series are strongly related at that frequency, even if their individual power spectra do not exhibit strong peaks. Applications: Uncovering hidden relationships between signals. Tracing wave propagation across different locations or systems. Investigating connections between oscillations in different physical parameters or measurements. Limitations: Only measures linear relationships between signals. Can be sensitive to noise and potential biases in the data. Phase difference, or phase lag, measures the relative timing of oscillations in two time series. It is calculated from the phase angle of the complex cross-spectrum and indicates whether the oscillations are in phase, or if one signal leads or lags the other. Applications: Determining the direction and speed of wave propagation. Exploring potential cause-and-effect connections between phenomena. Investigating the degree of synchronization between oscillating systems. Limitations: Can be challenging to interpret in complex systems with multiple interacting oscillations. Sensitive to noise and potential biases in the data. Note The co-spectrum, coherence, and phase lag are one-dimensional for 1D power spectra (FFT, Lomb-Scargle, HHT, GWS, RGWS, Welch) and two-dimensional for the 2D Wavelet spectrum. Info Check out the documentation on the Analysis Tools to learn how to run WaLSAtools and more about all inputs, parameters, and outputs. Under Development \u00b6 WaLSAtools is constantly evolving with new features and improvements. Here are some of the ongoing developments: Expanding Language Support: Further development in IDL (for full consistency between the Python and IDL versions), with potential expansion to MATLAB and other programming languages. Enhancing Existing Methods: Improving the Dominant Frequency method to handle cases with multiple strong power peaks and provide uncertainty estimations. Adding New Methods: Implementing new analysis techniques, such as Adaptive Local Iterative Filtering (ALIF) and Synchrosqueezing Transform (SST). We welcome contributions from the community to help us expand and improve WaLSAtools . If you are interested in contributing, please see the Contribution Guidelines .", "title": "Introduction"}, {"location": "idl/introduction/#introduction", "text": "", "title": "Introduction"}, {"location": "idl/introduction/#overview", "text": "WaLSAtools is an open-source library for analysing a wide variety of wave phenomena in time series data \u2013 including 1D signals, images, and multi-dimensional datasets. It provides tools to extract meaningful insights from complex datasets and is applicable across diverse fields, including astrophysics, engineering, life, physical and environmental sciences, and biomedical studies, among others. The library is continuously expanding with new features and functionalities, ensuring it remains a valuable resource for wave analysis. The core of WaLSAtools is built upon Python . This ensures accessibility and ease of use for a broad audience. We are actively developing versions in other popular languages to further enhance accessibility, enabling researchers from various backgrounds to leverage the power of WaLSAtools for their wave analysis needs. Currently, WaLSAtools is partially implemented in IDL , with plans to expand its functionality and extend to other programming languages in the future. WaLSAtools provides a suite of both fundamental and advanced tools, but it remains the user's responsibility to choose the method that best fits the nature of their dataset and the scientific questions being addressed. Selecting the appropriate analysis method is essential for ensuring reliable and scientifically valid results. The use of unsuitable or overly simplified techniques \u2013 without consideration of the data's properties or the research goals \u2013 can lead to incomplete or incorrect conclusions, and potentially to misinterpretation. This principle is central to our accompanying Primer , which emphasises the importance of methodological awareness in wave analysis across all disciplines. Developed by the WaLSA Team , WaLSAtools was initially inspired by the intricate wave dynamics observed in the Sun's atmosphere. However, its applications extend far beyond solar physics, offering a versatile toolkit for anyone working with oscillatory signals. WaLSAtools promotes reproducibility and transparency in wave analysis. Its robust implementations of validated techniques ensure consistent and trustworthy results, empowering researchers to delve deeper into the complexities of their data. Through its interactive interface, WaLSAtools guides users through the analysis process, providing the necessary information and tools to perform various types of wave analysis with ease. This repository is associated with a primer article titled Wave analysis tools in Nature Reviews Methods Primers (NRMP; Free access to view-only Primer and its Supplementary Information ), showcasing its capabilities through detailed analyses of synthetic datasets. The Analysis Tools/Examples/Worked examples - NRMP contain reproducible codes for generating all figures presented in the NRMP article, serving as a practical guide for applying WaLSAtools to real-world analyses. To switch between Python and IDL documentation, click the current programming language name at the top of the page.", "title": "Overview"}, {"location": "idl/introduction/#key-features", "text": "Wide Range of Wave Analysis Techniques: From foundational methods like FFT and wavelet analysis to advanced techniques such as EMD, k-\u03c9, and POD analysis. Cross-Disciplinary Applicability: Suitable for signal processing, oscillation studies, and multi-dimensional analysis in various fields. Interactive Interfaces: Simplified workflows through interactive menus for both Python and IDL . Open Science Principles: Promotes reproducibility and transparency in data analysis. Contributions are welcome to improve the codes, methods, or documentation.", "title": "Key Features"}, {"location": "idl/introduction/#analysis-methods", "text": "WaLSAtools offers a variety of spectral analysis techniques, each tailored to specific types of data and research questions. These methods are broadly categorised into: Single Time Series Analysis: Includes methods for analysing individual time series, such as: 1D Signals: Fast Fourier Transform (FFT), Lomb-Scargle, Wavelet Transform, Welch, Hilbert-Huang Transform (HHT) and Empirical Mode Decomposition (EMD) 3D Cubes: k-\u03c9 Analysis, Dominant Frequency, Mean Power Spectrum, and Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis: Includes methods for analysing correlations between two time series, resulting in cross-spectrum, coherence, and phase relationships. All time series are pre-processed to mitigate unwanted effects, such as long-term trends and edge effects, prior to spectral analysis. This includes detrending and apodization.", "title": "Analysis Methods"}, {"location": "idl/introduction/#detailed-descriptions-of-analysis-methods", "text": "The choice of the most appropriate wave analysis technique depends not only on the nature of the data but also on the specific research goals and the desired insights. WaLSAtools offers a variety of methods, each with its own strengths and limitations, allowing researchers to tailor their analysis to their specific needs. This section provides detailed descriptions of the individual methods available in WaLSAtools , empowering users to make informed decisions about the most suitable techniques for their research.", "title": "Detailed Descriptions of Analysis Methods"}, {"location": "idl/introduction/#single-time-series-analysis-1d-signal", "text": "One Dimensional (1D) Signal WaLSAtools provides a variety of methods for analysing 1D signals (time series). Each method uses a different approach to decompose the signal into its constituent frequencies, making them suitable for various scenarios. Selecting the appropriate technique depends on the specific characteristics of the data and the research goals. FFT Lomb-Scargle Wavelet EMD/HHT Welch The Fast Fourier Transform (FFT; Cooley and Tukey 1965 ) is an efficient algorithm that computes the discrete Fourier transform (DFT; Fourier 1824 ) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. The FFT is widely used in many fields due to its computational efficiency. This makes it significantly faster than directly computing the DFT, especially for large datasets. The FFT algorithm estimates the frequency spectrum by decomposing the signal into a set of sinusoidal oscillations at distinct frequencies, each with its own amplitude and phase. Advantages: Computationally efficient, especially for large datasets. Provides a clear and easily interpretable frequency spectrum. Well-suited for analysing stationary signals with evenly spaced samples. Limitations: Assumes the signal is stationary (frequency content does not change over time). Requires evenly spaced data points. Can be sensitive to edge effects in finite signals. FFT is often the prime choice of method for spectral analysis, unless the science case and/or data properties require the use of other techniques. The Lomb\u2013Scargle periodogram is a method of estimating a frequency spectrum, based on a least-squares fit of sinusoids to data samples, irrespective of whether the sampling is regularly or irregularly spaced in time. Advantages: Can handle irregularly sampled data without the need for interpolation. Provides accurate frequency estimates even with missing data points. Limitations: Can be computationally expensive for very large datasets. May not be as efficient as FFT for evenly spaced data. Lomb\u2013Scargle should be the method of choice when the data points are unequally spaced in time (e.g., when there are gaps or missing data points). Note: While interpolation can sometimes be used to fill gaps in data and enable the use of other methods like FFT, selecting an appropriate interpolation method and mitigating potential artifacts can be challenging. A wavelet transform is a time-frequency representation of a signal. It allows a signal to be decomposed into its constituent wavelets, which are localised in both time and frequency. The Wavelet Transform is a powerful tool for analysing time series data that exhibit non-stationary behaviors, meaning their frequency content changes over time. Unlike the Fourier Transform, which provides a global frequency spectrum, the Wavelet Transform allows for localised analysis in both time and frequency, revealing how different frequencies contribute to the signal at different times. Key Concepts: Mother Wavelet: The Wavelet Transform uses a function called a \"mother wavelet\" to analyse the signal. Different mother wavelets have different shapes and properties, making them suitable for different types of signals and analysis goals. The choice of mother wavelet is crucial for optimal results. Scales: The Wavelet Transform analyses the signal at different scales, which correspond to different frequency ranges. This multi-resolution analysis allows for the detection of both short-lived, high-frequency features and long-lasting, low-frequency trends. Cone of Influence (COI): The COI is a region in the time-frequency plane where edge effects can influence the results of the Wavelet Transform. It is important to be aware of the COI when interpreting the results. WaLSAtools provides a versatile implementation of the Wavelet Transform, allowing users to choose from various mother wavelets and customize the analysis parameters. In addition to the standard 2D time-frequency spectrum, it offers two types of 1D spectra: Global Wavelet Spectrum (GWS): Obtained by averaging the wavelet power over time. Refined Global Wavelet Spectrum (RGWS): A novel approach that excludes the COI and regions below a given confidence level from the time-integral of wavelet power, providing a more robust representation of the significant frequency components. Advantages: Suitable for analysing non-stationary signals. Provides both time and frequency localisation. Offers a multi-resolution view of the signal. Limitations: The choice of mother wavelet can influence the results. Frequency resolution is limited, especially at higher frequencies. Edge effects can influence the analysis near the boundaries of the time series. Wavelet transform is particularly suitable for studying transient oscillations, weak signals, or quasi-periodic signatures. Empirical Mode Decomposition (EMD) is a data-driven technique for analysing nonlinear and non-stationary signals. It decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. The Hilbert-Huang Transform (HHT) combines EMD with the Hilbert Transform to calculate the instantaneous frequency and amplitude of each IMF. This provides a detailed view of how the signal's frequency content evolves over time. WaLSAtools Implementation: WaLSAtools provides implementations of both EMD and HHT, allowing users to: Decompose signals into IMFs using EMD. Calculate instantaneous frequencies and amplitudes using HHT. Visualise the results with time-frequency plots and marginal spectra. Advantages: Suitable for analysing nonlinear and non-stationary signals. Adaptively extracts IMFs based on the signal's local characteristics. Provides time-varying frequency and amplitude information. Limitations: Can be sensitive to noise and parameter choices. Mode mixing can occur, where a single IMF contains components from different oscillatory modes. Requires careful selection of stopping criteria and spline fitting parameters. Key Considerations: Ensemble EMD (EEMD): WaLSAtools also includes EEMD, an ensemble-based approach that reduces the impact of noise and improves mode separation. Significance Testing: It is essential to assess the statistical significance of the extracted IMFs to distinguish genuine oscillations from noise-induced artifacts. Parameter Selection: Carefully choose the EMD and HHT parameters based on the specific characteristics of the data and the research goals. EMD and HHT are valuable tools for analysing complex signals that exhibit non-stationary and nonlinear behaviors, providing insights into the time-varying dynamics of oscillatory phenomena. Welch's method is a technique for estimating the power spectral density (PSD) of a signal. It is particularly useful when dealing with noisy data or signals that have time-varying frequency content. How it works: The signal is divided into overlapping segments. Each segment is windowed (e.g., using a Hann or Hamming window) to reduce spectral leakage. The periodogram (a basic estimate of the PSD) is computed for each segment. The periodograms are averaged to obtain a smoother and more robust estimate of the PSD. Advantages: Reduces noise in the PSD estimate. Can handle signals with time-varying frequency content. Provides a more robust estimate of the PSD compared to a single periodogram. Limitations: Reduces frequency resolution due to the use of shorter segments. The choice of window function and segment length can affect the results. Welch's method is a valuable tool for analysing signals where noise reduction is a priority or when the frequency content of the signal changes over time. Info Power Spectral Density (PSD): The analysis methods compute wave amplitudes at different frequencies, resulting in a frequency spectrum. The Power Spectral Density (PSD) can further be calculated, which represents the power (amplitude squared) per unit frequency. This normalisation allows for meaningful comparisons between different signals, regardless of their frequency resolution. Additionally, WaLSAtools outputs single-sided PSDs, where the power at negative frequencies is folded into the positive frequencies, divided by two since the folding effectively doubles the PSD values. Confidence Levels: WaLSAtools can estimate the statistical significance of the computed power using a randomisation test. This helps distinguish between genuine signals and those arising from noise or spurious effects. For example, a 95% confidence level indicates that the detected power is significant with a 5% probability of being due to random fluctuations.", "title": "Single time series analysis: 1D signal"}, {"location": "idl/introduction/#single-time-series-analysis-3d-datacube", "text": "Three Dimensional (3D) Datacube Analysing the distribution of oscillation power over a spatial extent is often crucial to identify wave modes and understand their behaviour. WaLSAtools offers several methods for analysing 3D datacubes (time series of 2D images), each providing unique insights into the spatio-temporal characteristics of waves. k-\u03c9 Mean Power Dominant Frequency POD k-\u03c9 analysis is a powerful technique for investigating wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both spatial (wavenumber, k) and temporal (frequency, \u03c9) domains. The resulting k-\u03c9 diagram reveals the relationship between spatial and temporal scales of oscillations, providing insights into wave dispersion relations and identifying different wave modes. WaLSAtools provides a comprehensive k-\u03c9 analysis tool that allows for: Generating k-\u03c9 diagrams from 3D datacubes. Filtering of the data in k-space and/or \u03c9-space. Reconstructing filtered datacubes to isolate specific wave modes or features. Fourier filtering is a key component of k-\u03c9 analysis, enabling the isolation of wave signatures with specific wavenumber and frequency characteristics. This is particularly useful for identifying weak wave modes that might be masked by stronger signals or background trends. Advantages: Reveals wave dispersion relations. Enables isolation of specific wave modes through filtering. Provides insights into the spatio-temporal characteristics of waves. Limitations: Assumes the wave field is statistically homogeneous and stationary. Can be sensitive to edge effects and noise. For a detailed description of the Fourier filtering technique, refer to the step-by-step guide of the original (QUEEFF) code integrated into WaLSAtools . The mean power spectrum provides a global view of the oscillatory behaviour within a region of interest. It is calculated by averaging the power spectra of individual pixels across the spatial domain. WaLSAtools allows for calculating the mean power spectrum using various 1D analysis methods (FFT, Lomb-Scargle, Wavelet, HHT, Welch, etc.). Advantages: Highlights the dominant (mean) oscillatory modes in a region. Provides a baseline for filtering out global contributions. Can be used to compare oscillatory behaviour across different regions or datasets. Limitations: May not capture localised or subtle variations in oscillatory behaviour. The dominant frequency is the frequency with the highest power in a spectrum. WaLSAtools can calculate the dominant frequency for each pixel in a 3D datacube, generating a map that visualises the spatial distribution of dominant frequencies. Advantages: Provides a visual representation of the dominant oscillatory modes in a region. Can reveal spatial patterns and correlations with other physical properties. Limitations: Can be biased in signals with multiple strong spectral peaks. May not capture the full complexity of oscillatory behaviour. Proper Orthogonal Decomposition (POD) is a powerful data-driven technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. WaLSAtools provides a POD analysis tool that: Calculates the POD modes and their corresponding eigenvalues. Reconstructs the original data using a reduced number of modes. Visualises the spatial patterns and temporal evolution of the dominant modes. Advantages: Effectively reduces the dimensionality of complex datasets. Identifies coherent spatial patterns and their temporal behaviour. Can be used for feature extraction and pattern recognition. Limitations: Assumes the data is statistically stationary. May not capture highly localised or transient phenomena.", "title": "Single time series analysis: 3D Datacube"}, {"location": "idl/introduction/#cross-correlation-analysis", "text": "Cross-Correlation Analysis Investigating the relationships between two time series is essential for understanding the interplay of different phenomena across various scientific disciplines. WaLSAtools provides a comprehensive suite of tools for cross-correlation analysis, enabling researchers to: Uncover shared frequencies and correlated power between two signals. Quantify the strength of the relationship between two time series at different frequencies. Determine the relative timing (phase or time lag) between oscillations. These tools are valuable for uncovering hidden connections, tracking wave propagation, and exploring the underlying drivers of oscillatory behaviour in diverse fields. Cross-Spectrum Coherence Phase Difference The cross-spectrum, also known as the cross-power spectrum, is a complex-valued function that describes the correlation between two time series in the frequency domain. It is calculated by multiplying the frequency representation of one signal by the complex conjugate of the frequency representation of the other one. The magnitude of the cross-spectrum, often called the co-spectrum, represents the shared power between the two signals at each frequency. High values in the co-spectrum indicate strong correlations between the oscillations at those frequencies. Applications: Identifying common frequencies and shared power between two signals. Detecting potential connections or shared influences affecting the signals. Limitations: May not reveal correlations if the individual power spectra lack prominent peaks. Can be sensitive to noise and potential biases in the data. Coherence is a normalised measure of the linear correlation between two time series at each frequency. It ranges from 0 (no correlation) to 1 (perfect correlation). High coherence values indicate that the oscillations in the two time series are strongly related at that frequency, even if their individual power spectra do not exhibit strong peaks. Applications: Uncovering hidden relationships between signals. Tracing wave propagation across different locations or systems. Investigating connections between oscillations in different physical parameters or measurements. Limitations: Only measures linear relationships between signals. Can be sensitive to noise and potential biases in the data. Phase difference, or phase lag, measures the relative timing of oscillations in two time series. It is calculated from the phase angle of the complex cross-spectrum and indicates whether the oscillations are in phase, or if one signal leads or lags the other. Applications: Determining the direction and speed of wave propagation. Exploring potential cause-and-effect connections between phenomena. Investigating the degree of synchronization between oscillating systems. Limitations: Can be challenging to interpret in complex systems with multiple interacting oscillations. Sensitive to noise and potential biases in the data. Note The co-spectrum, coherence, and phase lag are one-dimensional for 1D power spectra (FFT, Lomb-Scargle, HHT, GWS, RGWS, Welch) and two-dimensional for the 2D Wavelet spectrum. Info Check out the documentation on the Analysis Tools to learn how to run WaLSAtools and more about all inputs, parameters, and outputs.", "title": "Cross-correlation Analysis"}, {"location": "idl/introduction/#under-development", "text": "WaLSAtools is constantly evolving with new features and improvements. Here are some of the ongoing developments: Expanding Language Support: Further development in IDL (for full consistency between the Python and IDL versions), with potential expansion to MATLAB and other programming languages. Enhancing Existing Methods: Improving the Dominant Frequency method to handle cases with multiple strong power peaks and provide uncertainty estimations. Adding New Methods: Implementing new analysis techniques, such as Adaptive Local Iterative Filtering (ALIF) and Synchrosqueezing Transform (SST). We welcome contributions from the community to help us expand and improve WaLSAtools . If you are interested in contributing, please see the Contribution Guidelines .", "title": "Under Development"}, {"location": "idl/k-omega-example/", "text": "Worked Example - NRMP: k-\u03c9 Analysis and Filtering \u00b6 This example demonstrates the application of k-\u03c9 analysis and filtering to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset in the k-\u03c9 domain, we can gain insights into the relationship between spatial and temporal scales of oscillations, identify different wave modes, and isolate specific wave features through filtering. Analysis and Figure The figure below provides a comprehensive illustration of k-\u03c9 analysis and filtering applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis Fourier filtering in the wavenumber and frequency domains WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Supplementary Figure S4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Illustration of k-\u03c9 analysis and filtering applied to a synthetic spatio-temporal dataset. (a) The k-\u03c9 power diagram, with dashed lines outlining the targeted filtering region. (b) A six-frame sequence from the filtered datacube, showcasing the spatial and temporal evolution of the isolated wave features. \u00a9-(e) Step-by-step visualization of the spatial filtering process: \u00a9 The time-averaged spatial power spectrum of the original dataset. (d) The spatial filter mask. (e) The result of applying the mask to the spatial Fourier transform. (f) The spatially-averaged temporal power spectrum, with the temporal filter masks (dashed lines) and the preserved oscillatory power (solid red curves). Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 ; + ; NAME : WaLSA_QUB_QUEEFF ; part of -- WaLSAtools -- ; ; ORIGINAL CODE : QUEEns Fourier Filtering ( QUEEFF ) code ; WRITTEN , ANNOTATED , TESTED AND UPDATED BY : ; ( 1 ) Dr . David B . Jess ; ( 2 ) Dr . Samuel D . T . Grant ; The original code along with its manual can be downloaded at : https : // bit . ly / 37 mx9ic ; ; WaLSA_QUB_QUEEFF : Slightly modified ( i . e . , a few additional keywords added ) by Shahin Jafarzadeh ; ; CHECK DEPENDENCIES ( MAKE SURE ALL REQUIRED PROGRAMMES ARE INSTALLED ): ; NOTE ; @/ Users / dbj / ARC / IDL_programmes / Fourier_filtering / QUEEFF_code / QUEEFF_dependencies . bat ; ; CALLING SEQUENCE : ; EXAMPLES : ; walsa_qub_queeff , datacube , arcsecpx , time = time , power = power , wavenumber = wavenumber , frequencies = frequencies , koclt = 1 ; walsa_qub_queeff , datacube , arcsecpx , cadence , / filtering , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube ; ; + INPUTS : ; datacube input datacube , normally in the form of [ x , y , t ] ; [ note - at present the input datacube needs to have identical x and y dimensions . if not supplied like this the datacube will be cropped accordingly ! ] ; cadence delta time between sucessive frames - given in seconds . if not set , time must be provided ( see optional inputs ) ; arcsecpx spatial sampling of the input datacube - given in arcseconds per pixel ; ; + OPTIONAL INPUTS : ; ( if optional inputs not supplied , the user will need to interact with the displayed k - omega diagram to define these values ) ; time observing times in seconds ( 1 d array ) . it is ignored if cadence is provided ; filtering if set , filterring is proceeded ; f1 optional lower ( temporal ) frequency to filter - given in mhz ; f2 optional upper ( temporal ) frequency to filter - given in mhz ; k1 optional lower ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; k2 optional upper ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; spatial_torus makes the annulus used for spatial filtering have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; temporal_torus makes the temporal filter have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; no_spatial_filt optional keyword that ensures no spatial filtering is performed on the dataset ( i . e . , only temporal filtering ) ; no_temporal_filt optional keyword that ensures no temporal filtering is performed on the dataset ( i . e . , only spatial filtering ) ; silent : if set , the k - \u03c9 diagram is not plotted ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( wavenumber ) is plotted in logarithmic scale ( base 10 ) ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ( base 10 ) ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; nox2 : if set , 2 nd x - axis ( spatial size , in arcsec ) is not plotted ; ( spatial size ( i . e . , wavelength ) = ( 2 * ! pi ) / wavenumber ) ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ; + OUTPUTS : ; power : 2 d array of power ( see mode for the scale ) ; ( in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ) ; frequencies : 1 d array of frequencies ( in mhz ) ; wavenumber : 1 d array of wavenumber ( in arcsec ^- 1 ) ; filtered_cube : 3 d array of filtered datacube ( if filtering is set ) ; ; ; IF YOU USE THIS CODE , THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED : ; Jess et al . 2017 , ApJ , 842 , 59 ( http : // adsabs . harvard . edu / abs / 2017 ApJ .. .842 .. .59 J ) ; - ; pro FIG6__NRMP_walsa_komega_analysis data_dir = 'Synthetic_Data/' data = readfits ( data_dir + 'NRMP_signal_3D.fits' , / silent ) cadence = 0.5 ; sec arcsecpx = 1.0 ; arcsec nt = n_elements ( data [ 0 , 0 , * ]) time = findgen ( nt ) * cadence datacube = data arcsecpx = 1.0 time = time filtering = 1 smooth = 1 xrange = [ 0 , 0.3 ] f1 = 470 f2 = 530 k1 = 0.047 k2 = 0.25 if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) ; DEFINE THE SCREEN RESOLUTION TO ENSURE THE PLOTS DO NOT SPILL OVER THE EDGES OF THE SCREEN dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize xsize_cube = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ysize_cube = N_ELEMENTS ( datacube [ 0 , * , 0 ]) zsize_cube = N_ELEMENTS ( datacube [ 0 , 0 , * ]) ; FORCE THE CUBES TO HAVE THE SAME SPATIAL DIMENSIONS IF xsize_cube gt ysize_cube THEN datacube = TEMPORARY ( datacube [ 0 :( ysize_cube - 1 ), * , * ]) IF xsize_cube gt ysize_cube THEN xsize_cube = ysize_cube IF ysize_cube gt xsize_cube THEN datacube = TEMPORARY ( datacube [ * , 0 :( xsize_cube - 1 ), * ]) IF ysize_cube gt xsize_cube THEN ysize_cube = xsize_cube if n_elements ( spatial_torus ) eq 0 then spatial_torus = 1 if n_elements ( temporal_torus ) eq 0 then temporal_torus = 1 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nox2 ) eq 0 then nox2 = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if not keyword_set ( mode ) then mode = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( filtering ) eq 0 then filtering = 0 else silent = 0 ; CALCULATE THE NYQUIST FREQUENCIES spatial_Nyquist = ( 2. * ! pi ) / ( arcsecpx * 2. ) temporal_Nyquist = 1. / ( cadence * 2. ) print , '' print , 'The input datacube is of size: [' + strtrim ( xsize_cube , 2 ) + ', ' + strtrim ( ysize_cube , 2 ) + ', ' + strtrim ( zsize_cube , 2 ) + ']' print , '' print , 'Spatially, the important values are:' print , ' 2-pixel size = ' + strtrim (( arcsecpx * 2. ), 2 ) + ' pixel' print , ' Field of view size = ' + strtrim (( arcsecpx * xsize_cube ), 2 ) + ' pixel' print , ' Nyquist wavenumber = ' + strtrim ( spatial_Nyquist , 2 ) + ' pixel^-1' IF KEYWORD_SET ( no_spatial_filt ) THEN print , '***NO SPATIAL FILTERING WILL BE PERFORMED***' print , '' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * zsize_cube , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' IF KEYWORD_SET ( no_temporal_filt ) THEN print , '***NO TEMPORAL FILTERING WILL BE PERFORMED***' ; MAKE A k - omega DIAGRAM sp_out = DBLARR ( xsize_cube / 2 , zsize_cube / 2 ) print , '' print , 'Constructing a k-omega diagram of the input datacube..........' print , '' ; MAKE THE k - omega DIAGRAM USING THE PROVEN METHOD OF ROB RUTTEN kopower = walsa_plotkopower_funct ( datacube , sp_out , arcsecpx , cadence , apod = 0.1 , kmax = 1. , fmax = 1. ) ; X SIZE STUFF xsize_kopower = N_ELEMENTS ( kopower [ * , 0 ]) dxsize_kopower = spatial_Nyquist / FLOAT ( xsize_kopower - 1. ) kopower_xscale = ( FINDGEN ( xsize_kopower ) * dxsize_kopower ) ; IN pixel ^- 1 ; Y SIZE STUFF ysize_kopower = N_ELEMENTS ( kopower [ 0 , * ]) dysize_kopower = temporal_Nyquist / FLOAT ( ysize_kopower - 1. ) kopower_yscale = ( FINDGEN ( ysize_kopower ) * dysize_kopower ) * 1000. ; IN mHz Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) kopower_plot = kopower kopower_plot [ * , 1 : * ] = CONVOL ( kopower [ * , 1 : * ], Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) ; normalise to frequency resolution ( in mHz ) freq = kopower_yscale [ 1 : * ] if freq [ 0 ] eq 0 then freq0 = freq [ 1 ] else freq0 = freq [ 0 ] kopower_plot = kopower_plot / freq0 if mode eq 0 then kopower_plot = ALOG10 ( kopower_plot ) if mode eq 2 then kopower_plot = SQRT ( kopower_plot ) LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. p1_x1 = 0.083 p1_x2 = 0.46 p1_y1 = 0.62 p1_y2 = 0.85 ! P . Multi = [ 0 , 3 , 4 ] ! p . background = 255. ! p . color = 0. ; WHEN PLOTTING WE NEED TO IGNORE THE ZERO 'TH ELEMENT (I.E., THE MEAN f=0) SINCE THIS WILL MESS UP THE LOG PLOT! komegamap = ( kopower_plot )[ 1 : * , 1 : * ] > MIN (( kopower_plot )[ 1 : * , 1 : * ], / nan ) < MAX (( kopower_plot )[ 1 : * , 1 : * ], / nan ) EPS = 1 IF silent EQ 0 THEN BEGIN if n_elements ( komega ) eq 0 then komega = 0 else komega = 1 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. IF EPS eq 1 THEN BEGIN walsa_eps , size = [ 23 , 27 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 2.2 ! p . charsize = 2.2 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.037 ! y . ticklen =- 0.025 positioncb = [ 0.56 , 0.69 , 0.572 , 0.93 ] ENDIF ELSE BEGIN IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN WINDOW , 0 , xsize = 1000 , ysize = 1000 , title = 'QUEEFF: k-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN WINDOW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'QUEEFF: k-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF ENDELSE walsa_pg_plotimage_komega , komegamap , kopower_xscale [ 1 : * ], kopower_yscale [ 1 : * ], noy2 = noy2 , nox2 = nox2 , smooth = smooth , $ xtitle = 'Wavenumber (pixel!U-1!N)' , ytitle = 'Frequency (mHz)' , xst = 8 , yst = 8 , xlog = xlog , ylog = ylog , position = [ p1_x1 , p1_y1 + 0.07 , p1_x2 , 0.93 ], $ xrange = xrange , yrange = yrange , threemin = threemin , fivemin = fivemin , eps = eps , xminor = 5 , x2ndaxistitle = 'Spatial size (pixel)!C' , $ y2ndaxistitle = '!CPeriod (s)' tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ position = positioncb , / right , ticknames = tickmarknames , xticklen = 0.00001 , charsize = 2.4 , / vertical ;, yticklen =- 0.6 xyouts , 0.65 , 0.81 , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / normal , 'Log!d10!n(Oscillation Power)' , color = cgColor ( 'Black' ), ORIENTATION = 90. ENDIF power = komegamap wavenumber = kopower_xscale [ 1 : * ] frequencies = kopower_yscale [ 1 : * ] print , ' ' if filtering then print , ' ..... start filtering (in k-\u03c9 space)' else return print , ' ' ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; STEPS USED TO MAKE SURE THE FREQUENCIES ARE CHOSEN ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; NEED f1 AND k1 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , f1 , / data WAIT , 1.0 ; NEED f2 AND k2 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 IF KEYWORD_SET ( no_spatial_filt ) THEN k1 = kopower_xscale [ 1 ] IF KEYWORD_SET ( no_spatial_filt ) THEN k2 = MAX ( kopower_xscale , / nan ) IF KEYWORD_SET ( no_temporal_filt ) THEN f1 = kopower_yscale [ 1 ] IF KEYWORD_SET ( no_temporal_filt ) THEN f2 = MAX ( kopower_yscale , / nan ) IF ( k1 le 0.0 ) THEN k1 = kopower_xscale [ 1 ] IF ( k2 gt MAX ( kopower_xscale , / nan )) THEN k2 = MAX ( kopower_xscale , / nan ) IF ( f1 le 0.0 ) THEN f1 = kopower_yscale [ 1 ] IF ( f2 gt MAX ( kopower_yscale , / nan )) THEN f2 = MAX ( kopower_yscale , / nan ) IF NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN k1 = kopower_xscale [ 1 ] k2 = MAX ( kopower_xscale , / nan ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF print , '' print , 'The preserved wavenumbers are [' + strtrim ( k1 , 2 ) + ', ' + strtrim ( k2 , 2 ) + '] pixel^-1' print , 'The preserved spatial sizes are [' + strtrim (( 2. * ! pi ) / k2 , 2 ) + ', ' + strtrim (( 2. * ! pi ) / k1 , 2 ) + '] pixel' print , '' print , 'The preserved frequencies are [' + strtrim ( f1 , 2 ) + ', ' + strtrim ( f2 , 2 ) + '] mHz' print , 'The preserved periods are [' + strtrim ( FIX ( 1. / ( f2 / 1000. )), 2 ) + ', ' + strtrim ( FIX ( 1. / ( f1 / 1000. )), 2 ) + '] seconds' pwavenumber = [ k1 , k2 ] pspatialsize = [( 2. * ! pi ) / k2 ,( 2. * ! pi ) / k1 ] pfrequency = [ f1 , f2 ] pperiod = [ FIX ( 1. / ( f2 / 1000. )), FIX ( 1. / ( f1 / 1000. ))] print , '' print , 'Making a 3D Fourier transform of the input datacube..........' threedft = FFT ( datacube , - 1 , / double , / center ) ; CALCULATE THE FREQUENCY AXES FOR THE 3 D FFT temp_x = FINDGEN (( xsize_cube - 1 ) / 2 ) + 1 is_N_even = ( xsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ spatial_frequencies_orig = ([ 0.0 , temp_x , xsize_cube / 2 , - xsize_cube / 2 + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) $ ELSE $ spatial_frequencies_orig = ([ 0.0 , temp_x , - ( xsize_cube / 2 + 1 ) + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) temp_x = FINDGEN (( zsize_cube - 1 ) / 2 ) + 1 is_N_even = ( zsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ temporal_frequencies_orig = [ 0.0 , temp_x , zsize_cube / 2 , - zsize_cube / 2 + temp_x ] / ( zsize_cube * cadence ) $ ELSE $ temporal_frequencies_orig = [ 0.0 , temp_x , - ( zsize_cube / 2 + 1 ) + temp_x ] / ( zsize_cube * cadence ) ; NOW COMPENSATE THESE FREQUENCY AXES DUE TO THE FACT THE / center KEYWORD IS USED FOR THE FFT TRANSFORM spatial_positive_frequencies = N_ELEMENTS ( WHERE ( spatial_frequencies_orig ge 0. )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 2 )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 NE 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 1 )) temporal_positive_frequencies = N_ELEMENTS ( WHERE ( temporal_frequencies_orig ge 0. )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 2 )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 NE 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 1 )) ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE NEW FREQUENCY AXES DESCRIBED ABOVE IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), - 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ - 1 , - 1 ]) ENDIF ; CONVERT FREQUENCIES AND WAVENUMBERS OF INTEREST INTO ( FFT ) DATACUBE PIXELS pixel_k1_positive = walsa_closest ( k1 , spatial_frequencies_orig ) pixel_k2_positive = walsa_closest ( k2 , spatial_frequencies_orig ) pixel_f1_positive = walsa_closest ( f1 / 1000. , temporal_frequencies ) pixel_f2_positive = walsa_closest ( f2 / 1000. , temporal_frequencies ) pixel_f1_negative = walsa_closest ( - f1 / 1000. , temporal_frequencies ) pixel_f2_negative = walsa_closest ( - f2 / 1000. , temporal_frequencies ) torus_depth = FIX (( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) * 2. torus_center = FIX ((( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) + pixel_k1_positive [ 0 ]) IF KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN ; CREATE A FILTER RING PRESERVING EQUAL WAVENUMBERS FOR BOTH kx AND ky ; DO THIS AS A TORUS TO PRESERVE AN INTEGRATED GAUSSIAN SHAPE ACROSS THE WIDTH OF THE ANNULUS , THEN INTEGRATE ALONG 'z' spatial_torus = FLTARR ( xsize_cube , ysize_cube , torus_depth ) FOR i = 0 , ( FIX ( torus_depth / 2. )) DO BEGIN spatial_ring = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - i )) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + i + 1 )) spatial_ring [ WHERE ( spatial_ring gt 0. )] = 1. spatial_ring [ WHERE ( spatial_ring ne 1. )] = 0. spatial_torus [ * , * , i ] = spatial_ring spatial_torus [ * , * , torus_depth - i - 1 ] = spatial_ring ENDFOR ; INTEGRATE THROUGH THE TORUS TO FIND THE SPATIAL FILTER spatial_ring_filter = TOTAL ( spatial_torus , 3 , / nan ) / FLOAT ( torus_depth ) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF NOT KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - ( FIX ( torus_depth / 2. )))) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + ( FIX ( torus_depth / 2. )) + 1 )) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 spatial_ring_filter [ WHERE ( spatial_ring_filter NE 1. )] = 0. ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = FLTARR ( xsize_cube , ysize_cube ) spatial_ring_filter [ * ] = 1. ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND KEYWORD_SET ( temporal_torus ) THEN BEGIN ; CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 25 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 3 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 25 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 30 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 4 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 30 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 40 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 5 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 40 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 45 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 6 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 45 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 50 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 7 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 50 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 55 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 8 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 55 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 60 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 9 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 60 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 65 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 10 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 65 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 70 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 11 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 70 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 80 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 12 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 80 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 90 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 13 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 90 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 100 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 14 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 100 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 110 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 15 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 110 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 16 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 17 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = temporal_Gaussian temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = temporal_Gaussian temporal_filter = temporal_filter / MAX ( temporal_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND NOT KEYWORD_SET ( temporal_torus ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = 1.0 temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = 1.0 ENDIF IF KEYWORD_SET ( no_temporal_filt ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 1. ENDIF charsize = 2.2 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ; MAKE SOME FIGURES FOR PLOTTING - MAKES THINGS AESTHETICALLY PLEASING ! torus_map = MAKE_MAP ( spatial_ring_filter , dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft = TOTAL ( threedft , 3 , / nan ) spatial_fft_map = MAKE_MAP ( ALOG10 ( spatial_fft ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = MAKE_MAP ( ALOG10 ( spatial_fft_filtered > 1e-15 ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) temporal_fft = TOTAL ( TOTAL ( threedft , 2 , / nan ), 1 ) ; IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN WINDOW , 1 , xsize = 1500 , ysize = 1000 , title = 'QUEEFF: FFT filter specs' ; IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN WINDOW , 1 , xsize = smallest_screensize , ysize = FIX ( smallest_screensize * 0.8 ), title = 'QUEEFF: FFT filter specs' x1 = 0.07 x2 = 0.286 x3 = 0.42 x4 = 0.635 x5 = 0.765 x6 = 0.98 y1 = 0.19 y2 = 0.32 y3 = 0.40 y4 = 0.58 LOADCT , 5 , / silent plot_map , spatial_fft_map , charsize = charsize , xticklen =- .045 , yticklen =- .045 , xtitle = 'Wavenumber (k!Dx!N; pixel!U-1!N)' , ytitle = 'Wavenumber (k!Dy!N; pixel!U-1!N)' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x1 , y3 , x2 , y4 ], / SQUARE_SCALE , xminor = 3 , yminor = 3 , / NOTITLE PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 3 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 3 , color = 255 LOADCT , 0 , / silent xyouts , 0. , 3.7 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / data , '(c) Spatial FFT' , color = cgColor ( 'Black' ) plot_map , torus_map , charsize = charsize , xticklen =- .045 , yticklen =- .045 , xtitle = 'Wavenumber (k!Dx!N; pixel!U-1!N)' , dmin = 0 , dmax = 1 , position = [ x3 , y3 , x4 , y4 ], / noerase , / SQUARE_SCALE , xminor = 3 , yminor = 3 , ytitle = 'Wavenumber (k!Dy!N; pixel!U-1!N)' , / NOTITLE ;, ytickformat = '(A1)' PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 3 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 3 , color = 255 LOADCT , 5 , / silent xyouts , 0. , 3.7 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / data , '(d) Spatial FFT filter' , color = cgColor ( 'Black' ) plot_map , spatial_fft_filtered_map , charsize = charsize , xticklen =- .045 , yticklen =- .045 , xtitle = 'Wavenumber (k!Dx!N pixel!U-1!N)' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x5 , y3 , x6 , y4 ], / noerase , SQUARE_SCALE , xminor = 3 , yminor = 3 , ytitle = 'Wavenumber (k!Dy!N; pixel!U-1!N)' , / NOTITLE ;, ytickformat = '(A1)' PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 3 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 3 , color = 255 xyouts , 0. , 3.7 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / data , '(e) Filtered spatial FFT' , color = cgColor ( 'Black' ) PLOT , temporal_frequencies * 1000. , ABS ( temporal_fft ), / ylog , xst = 1 , charsize = charsize , xticklen =- .060 , yticklen =- .008 , xtitle = 'Frequency (mHz)' , ytitle = 'Power (arb. units)' , position = [ x1 + 0.01 , y1 , x6 , y2 ], / noerase , xminor = 5 , XTICKINTERVAL = 250 , YTICKNAME = [ ' ' , '10!u-2' , ' ' , '10!u0' , ' ' , '10!u2' ] temporal_fft_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) temporal_fft_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) PLOTS , [ 0 , 0 ], [ temporal_fft_plot_ymin , temporal_fft_plot_ymax ], line = 2 , thick = 4 , color = 0 LOADCT , 39 , / silent OPLOT , temporal_frequencies * 1000. , ( temporal_filter ) > temporal_fft_plot_ymin , line = 2 , color = 55 , thick = 5 OPLOT , temporal_frequencies * 1000. , ( ABS ( temporal_fft * temporal_filter )) > temporal_fft_plot_ymin , line = 0 , color = 254 , thick = 4 LOADCT , 5 , / silent WAIT , 0.5 ; APPLY THE GAUSSIAN FILTERS TO THE DATA TO PREVENT ALIASING FOR i = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , i ] = REFORM ( threedft [ * , * , i ]) * spatial_ring_filter FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO BEGIN threedft [ x , y , * ] = REFORM ( threedft [ x , y , * ]) * temporal_filter ENDFOR ENDFOR ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE / center CALL IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ 1 , 1 ]) ENDIF new_cube = REAL_PART ( FFT ( threedft , 1 , / double , / center )) LOADCT , 0 , / silent filtered_cube = new_cube PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' pos = fltarr ( 4 , 6 ) xl = 0.725 & xr = 0.98 yb = y4 + 0.08 & yt = 0.98 xgap = 0. ygap = 0. rows = (( xr - xl ) / 2. ) - xgap cols = (( yt - yb ) / 3. ) - ( 2. * ygap ) pos [ * , 0 ] = [ xl , yb + cols + ygap + cols + ygap , xl + rows , yt ] pos [ * , 1 ] = [ xl + rows + xgap , yb + cols + ygap + cols + ygap , xr , yt ] pos [ * , 2 ] = [ xl , yb + cols + ygap , xl + rows , yb + cols + ygap + cols ] pos [ * , 3 ] = [ xl + rows + xgap , yb + cols + ygap , xr , yb + cols + ygap + cols ] pos [ * , 4 ] = [ xl , yb , xl + rows , yb + cols ] pos [ * , 5 ] = [ xl + rows + xgap , yb , xr , yb + cols ] loadct , 1 ! x . ticklen =- 0.07 ! y . ticklen =- 0.07 for i = 0 L , 5 do begin im = reform ( filtered_cube [ * , * , i ]) walsa_image_plot , iris_histo_opt ( im ), xrange = xrg , yrange = yrg , nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = pos [ * , i ], xminor = 2 , yminor = 2 cgPlotS , 18 , 111 , PSym = 16 , SymColor = 'Black' , SymSize = 2.7 cgPlotS , 18 , 111 , PSym = 16 , SymColor = 'White' , SymSize = 2.2 cgtext , 18 , 103.5 , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / data , strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor cgPolygon , [ xl - 0.05 , xl - 0.05 , xr + 0.01 , xr + 0.01 , xl - 0.05 ], [ yb - 0.019 , yt , yt , yb - 0.019 , yb - 0.019 ], $ / NORMAL , COLOR = cgColor ( 'DodgerBlue' ), thick = 5 , linestyle = 1 xyouts , p1_x1 - 0.07 , p1_y2 + 0.11 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(a)' , color = cgColor ( 'Black' ) xyouts , xl - 0.025 , yt - 0.022 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(b)' , color = cgColor ( 'Black' ) xyouts , x1 + 0.030 , y2 - 0.022 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(f)' , color = cgColor ( 'Black' ) ! P . Multi = 0 Cleanplot , / Silent print , '' print , 'COMPLETED!' print , '' walsa_endeps , filename = 'Figures/FigS4_k-omega_analysis' stop END", "title": "k-&#969; analysis"}, {"location": "idl/k-omega-example/#worked-example-nrmp-k-analysis-and-filtering", "text": "This example demonstrates the application of k-\u03c9 analysis and filtering to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset in the k-\u03c9 domain, we can gain insights into the relationship between spatial and temporal scales of oscillations, identify different wave modes, and isolate specific wave features through filtering. Analysis and Figure The figure below provides a comprehensive illustration of k-\u03c9 analysis and filtering applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis Fourier filtering in the wavenumber and frequency domains WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Supplementary Figure S4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Illustration of k-\u03c9 analysis and filtering applied to a synthetic spatio-temporal dataset. (a) The k-\u03c9 power diagram, with dashed lines outlining the targeted filtering region. (b) A six-frame sequence from the filtered datacube, showcasing the spatial and temporal evolution of the isolated wave features. \u00a9-(e) Step-by-step visualization of the spatial filtering process: \u00a9 The time-averaged spatial power spectrum of the original dataset. (d) The spatial filter mask. (e) The result of applying the mask to the spatial Fourier transform. (f) The spatially-averaged temporal power spectrum, with the temporal filter masks (dashed lines) and the preserved oscillatory power (solid red curves). Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 ; + ; NAME : WaLSA_QUB_QUEEFF ; part of -- WaLSAtools -- ; ; ORIGINAL CODE : QUEEns Fourier Filtering ( QUEEFF ) code ; WRITTEN , ANNOTATED , TESTED AND UPDATED BY : ; ( 1 ) Dr . David B . Jess ; ( 2 ) Dr . Samuel D . T . Grant ; The original code along with its manual can be downloaded at : https : // bit . ly / 37 mx9ic ; ; WaLSA_QUB_QUEEFF : Slightly modified ( i . e . , a few additional keywords added ) by Shahin Jafarzadeh ; ; CHECK DEPENDENCIES ( MAKE SURE ALL REQUIRED PROGRAMMES ARE INSTALLED ): ; NOTE ; @/ Users / dbj / ARC / IDL_programmes / Fourier_filtering / QUEEFF_code / QUEEFF_dependencies . bat ; ; CALLING SEQUENCE : ; EXAMPLES : ; walsa_qub_queeff , datacube , arcsecpx , time = time , power = power , wavenumber = wavenumber , frequencies = frequencies , koclt = 1 ; walsa_qub_queeff , datacube , arcsecpx , cadence , / filtering , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube ; ; + INPUTS : ; datacube input datacube , normally in the form of [ x , y , t ] ; [ note - at present the input datacube needs to have identical x and y dimensions . if not supplied like this the datacube will be cropped accordingly ! ] ; cadence delta time between sucessive frames - given in seconds . if not set , time must be provided ( see optional inputs ) ; arcsecpx spatial sampling of the input datacube - given in arcseconds per pixel ; ; + OPTIONAL INPUTS : ; ( if optional inputs not supplied , the user will need to interact with the displayed k - omega diagram to define these values ) ; time observing times in seconds ( 1 d array ) . it is ignored if cadence is provided ; filtering if set , filterring is proceeded ; f1 optional lower ( temporal ) frequency to filter - given in mhz ; f2 optional upper ( temporal ) frequency to filter - given in mhz ; k1 optional lower ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; k2 optional upper ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; spatial_torus makes the annulus used for spatial filtering have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; temporal_torus makes the temporal filter have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; no_spatial_filt optional keyword that ensures no spatial filtering is performed on the dataset ( i . e . , only temporal filtering ) ; no_temporal_filt optional keyword that ensures no temporal filtering is performed on the dataset ( i . e . , only spatial filtering ) ; silent : if set , the k - \u03c9 diagram is not plotted ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( wavenumber ) is plotted in logarithmic scale ( base 10 ) ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ( base 10 ) ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; nox2 : if set , 2 nd x - axis ( spatial size , in arcsec ) is not plotted ; ( spatial size ( i . e . , wavelength ) = ( 2 * ! pi ) / wavenumber ) ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ; + OUTPUTS : ; power : 2 d array of power ( see mode for the scale ) ; ( in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ) ; frequencies : 1 d array of frequencies ( in mhz ) ; wavenumber : 1 d array of wavenumber ( in arcsec ^- 1 ) ; filtered_cube : 3 d array of filtered datacube ( if filtering is set ) ; ; ; IF YOU USE THIS CODE , THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED : ; Jess et al . 2017 , ApJ , 842 , 59 ( http : // adsabs . harvard . edu / abs / 2017 ApJ .. .842 .. .59 J ) ; - ; pro FIG6__NRMP_walsa_komega_analysis data_dir = 'Synthetic_Data/' data = readfits ( data_dir + 'NRMP_signal_3D.fits' , / silent ) cadence = 0.5 ; sec arcsecpx = 1.0 ; arcsec nt = n_elements ( data [ 0 , 0 , * ]) time = findgen ( nt ) * cadence datacube = data arcsecpx = 1.0 time = time filtering = 1 smooth = 1 xrange = [ 0 , 0.3 ] f1 = 470 f2 = 530 k1 = 0.047 k2 = 0.25 if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) ; DEFINE THE SCREEN RESOLUTION TO ENSURE THE PLOTS DO NOT SPILL OVER THE EDGES OF THE SCREEN dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize xsize_cube = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ysize_cube = N_ELEMENTS ( datacube [ 0 , * , 0 ]) zsize_cube = N_ELEMENTS ( datacube [ 0 , 0 , * ]) ; FORCE THE CUBES TO HAVE THE SAME SPATIAL DIMENSIONS IF xsize_cube gt ysize_cube THEN datacube = TEMPORARY ( datacube [ 0 :( ysize_cube - 1 ), * , * ]) IF xsize_cube gt ysize_cube THEN xsize_cube = ysize_cube IF ysize_cube gt xsize_cube THEN datacube = TEMPORARY ( datacube [ * , 0 :( xsize_cube - 1 ), * ]) IF ysize_cube gt xsize_cube THEN ysize_cube = xsize_cube if n_elements ( spatial_torus ) eq 0 then spatial_torus = 1 if n_elements ( temporal_torus ) eq 0 then temporal_torus = 1 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nox2 ) eq 0 then nox2 = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if not keyword_set ( mode ) then mode = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( filtering ) eq 0 then filtering = 0 else silent = 0 ; CALCULATE THE NYQUIST FREQUENCIES spatial_Nyquist = ( 2. * ! pi ) / ( arcsecpx * 2. ) temporal_Nyquist = 1. / ( cadence * 2. ) print , '' print , 'The input datacube is of size: [' + strtrim ( xsize_cube , 2 ) + ', ' + strtrim ( ysize_cube , 2 ) + ', ' + strtrim ( zsize_cube , 2 ) + ']' print , '' print , 'Spatially, the important values are:' print , ' 2-pixel size = ' + strtrim (( arcsecpx * 2. ), 2 ) + ' pixel' print , ' Field of view size = ' + strtrim (( arcsecpx * xsize_cube ), 2 ) + ' pixel' print , ' Nyquist wavenumber = ' + strtrim ( spatial_Nyquist , 2 ) + ' pixel^-1' IF KEYWORD_SET ( no_spatial_filt ) THEN print , '***NO SPATIAL FILTERING WILL BE PERFORMED***' print , '' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * zsize_cube , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' IF KEYWORD_SET ( no_temporal_filt ) THEN print , '***NO TEMPORAL FILTERING WILL BE PERFORMED***' ; MAKE A k - omega DIAGRAM sp_out = DBLARR ( xsize_cube / 2 , zsize_cube / 2 ) print , '' print , 'Constructing a k-omega diagram of the input datacube..........' print , '' ; MAKE THE k - omega DIAGRAM USING THE PROVEN METHOD OF ROB RUTTEN kopower = walsa_plotkopower_funct ( datacube , sp_out , arcsecpx , cadence , apod = 0.1 , kmax = 1. , fmax = 1. ) ; X SIZE STUFF xsize_kopower = N_ELEMENTS ( kopower [ * , 0 ]) dxsize_kopower = spatial_Nyquist / FLOAT ( xsize_kopower - 1. ) kopower_xscale = ( FINDGEN ( xsize_kopower ) * dxsize_kopower ) ; IN pixel ^- 1 ; Y SIZE STUFF ysize_kopower = N_ELEMENTS ( kopower [ 0 , * ]) dysize_kopower = temporal_Nyquist / FLOAT ( ysize_kopower - 1. ) kopower_yscale = ( FINDGEN ( ysize_kopower ) * dysize_kopower ) * 1000. ; IN mHz Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) kopower_plot = kopower kopower_plot [ * , 1 : * ] = CONVOL ( kopower [ * , 1 : * ], Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) ; normalise to frequency resolution ( in mHz ) freq = kopower_yscale [ 1 : * ] if freq [ 0 ] eq 0 then freq0 = freq [ 1 ] else freq0 = freq [ 0 ] kopower_plot = kopower_plot / freq0 if mode eq 0 then kopower_plot = ALOG10 ( kopower_plot ) if mode eq 2 then kopower_plot = SQRT ( kopower_plot ) LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. p1_x1 = 0.083 p1_x2 = 0.46 p1_y1 = 0.62 p1_y2 = 0.85 ! P . Multi = [ 0 , 3 , 4 ] ! p . background = 255. ! p . color = 0. ; WHEN PLOTTING WE NEED TO IGNORE THE ZERO 'TH ELEMENT (I.E., THE MEAN f=0) SINCE THIS WILL MESS UP THE LOG PLOT! komegamap = ( kopower_plot )[ 1 : * , 1 : * ] > MIN (( kopower_plot )[ 1 : * , 1 : * ], / nan ) < MAX (( kopower_plot )[ 1 : * , 1 : * ], / nan ) EPS = 1 IF silent EQ 0 THEN BEGIN if n_elements ( komega ) eq 0 then komega = 0 else komega = 1 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. IF EPS eq 1 THEN BEGIN walsa_eps , size = [ 23 , 27 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 2.2 ! p . charsize = 2.2 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.037 ! y . ticklen =- 0.025 positioncb = [ 0.56 , 0.69 , 0.572 , 0.93 ] ENDIF ELSE BEGIN IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN WINDOW , 0 , xsize = 1000 , ysize = 1000 , title = 'QUEEFF: k-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN WINDOW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'QUEEFF: k-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF ENDELSE walsa_pg_plotimage_komega , komegamap , kopower_xscale [ 1 : * ], kopower_yscale [ 1 : * ], noy2 = noy2 , nox2 = nox2 , smooth = smooth , $ xtitle = 'Wavenumber (pixel!U-1!N)' , ytitle = 'Frequency (mHz)' , xst = 8 , yst = 8 , xlog = xlog , ylog = ylog , position = [ p1_x1 , p1_y1 + 0.07 , p1_x2 , 0.93 ], $ xrange = xrange , yrange = yrange , threemin = threemin , fivemin = fivemin , eps = eps , xminor = 5 , x2ndaxistitle = 'Spatial size (pixel)!C' , $ y2ndaxistitle = '!CPeriod (s)' tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ position = positioncb , / right , ticknames = tickmarknames , xticklen = 0.00001 , charsize = 2.4 , / vertical ;, yticklen =- 0.6 xyouts , 0.65 , 0.81 , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / normal , 'Log!d10!n(Oscillation Power)' , color = cgColor ( 'Black' ), ORIENTATION = 90. ENDIF power = komegamap wavenumber = kopower_xscale [ 1 : * ] frequencies = kopower_yscale [ 1 : * ] print , ' ' if filtering then print , ' ..... start filtering (in k-\u03c9 space)' else return print , ' ' ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; STEPS USED TO MAKE SURE THE FREQUENCIES ARE CHOSEN ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; NEED f1 AND k1 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , f1 , / data WAIT , 1.0 ; NEED f2 AND k2 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 IF KEYWORD_SET ( no_spatial_filt ) THEN k1 = kopower_xscale [ 1 ] IF KEYWORD_SET ( no_spatial_filt ) THEN k2 = MAX ( kopower_xscale , / nan ) IF KEYWORD_SET ( no_temporal_filt ) THEN f1 = kopower_yscale [ 1 ] IF KEYWORD_SET ( no_temporal_filt ) THEN f2 = MAX ( kopower_yscale , / nan ) IF ( k1 le 0.0 ) THEN k1 = kopower_xscale [ 1 ] IF ( k2 gt MAX ( kopower_xscale , / nan )) THEN k2 = MAX ( kopower_xscale , / nan ) IF ( f1 le 0.0 ) THEN f1 = kopower_yscale [ 1 ] IF ( f2 gt MAX ( kopower_yscale , / nan )) THEN f2 = MAX ( kopower_yscale , / nan ) IF NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN k1 = kopower_xscale [ 1 ] k2 = MAX ( kopower_xscale , / nan ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF print , '' print , 'The preserved wavenumbers are [' + strtrim ( k1 , 2 ) + ', ' + strtrim ( k2 , 2 ) + '] pixel^-1' print , 'The preserved spatial sizes are [' + strtrim (( 2. * ! pi ) / k2 , 2 ) + ', ' + strtrim (( 2. * ! pi ) / k1 , 2 ) + '] pixel' print , '' print , 'The preserved frequencies are [' + strtrim ( f1 , 2 ) + ', ' + strtrim ( f2 , 2 ) + '] mHz' print , 'The preserved periods are [' + strtrim ( FIX ( 1. / ( f2 / 1000. )), 2 ) + ', ' + strtrim ( FIX ( 1. / ( f1 / 1000. )), 2 ) + '] seconds' pwavenumber = [ k1 , k2 ] pspatialsize = [( 2. * ! pi ) / k2 ,( 2. * ! pi ) / k1 ] pfrequency = [ f1 , f2 ] pperiod = [ FIX ( 1. / ( f2 / 1000. )), FIX ( 1. / ( f1 / 1000. ))] print , '' print , 'Making a 3D Fourier transform of the input datacube..........' threedft = FFT ( datacube , - 1 , / double , / center ) ; CALCULATE THE FREQUENCY AXES FOR THE 3 D FFT temp_x = FINDGEN (( xsize_cube - 1 ) / 2 ) + 1 is_N_even = ( xsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ spatial_frequencies_orig = ([ 0.0 , temp_x , xsize_cube / 2 , - xsize_cube / 2 + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) $ ELSE $ spatial_frequencies_orig = ([ 0.0 , temp_x , - ( xsize_cube / 2 + 1 ) + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) temp_x = FINDGEN (( zsize_cube - 1 ) / 2 ) + 1 is_N_even = ( zsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ temporal_frequencies_orig = [ 0.0 , temp_x , zsize_cube / 2 , - zsize_cube / 2 + temp_x ] / ( zsize_cube * cadence ) $ ELSE $ temporal_frequencies_orig = [ 0.0 , temp_x , - ( zsize_cube / 2 + 1 ) + temp_x ] / ( zsize_cube * cadence ) ; NOW COMPENSATE THESE FREQUENCY AXES DUE TO THE FACT THE / center KEYWORD IS USED FOR THE FFT TRANSFORM spatial_positive_frequencies = N_ELEMENTS ( WHERE ( spatial_frequencies_orig ge 0. )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 2 )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 NE 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 1 )) temporal_positive_frequencies = N_ELEMENTS ( WHERE ( temporal_frequencies_orig ge 0. )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 2 )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 NE 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 1 )) ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE NEW FREQUENCY AXES DESCRIBED ABOVE IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), - 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ - 1 , - 1 ]) ENDIF ; CONVERT FREQUENCIES AND WAVENUMBERS OF INTEREST INTO ( FFT ) DATACUBE PIXELS pixel_k1_positive = walsa_closest ( k1 , spatial_frequencies_orig ) pixel_k2_positive = walsa_closest ( k2 , spatial_frequencies_orig ) pixel_f1_positive = walsa_closest ( f1 / 1000. , temporal_frequencies ) pixel_f2_positive = walsa_closest ( f2 / 1000. , temporal_frequencies ) pixel_f1_negative = walsa_closest ( - f1 / 1000. , temporal_frequencies ) pixel_f2_negative = walsa_closest ( - f2 / 1000. , temporal_frequencies ) torus_depth = FIX (( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) * 2. torus_center = FIX ((( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) + pixel_k1_positive [ 0 ]) IF KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN ; CREATE A FILTER RING PRESERVING EQUAL WAVENUMBERS FOR BOTH kx AND ky ; DO THIS AS A TORUS TO PRESERVE AN INTEGRATED GAUSSIAN SHAPE ACROSS THE WIDTH OF THE ANNULUS , THEN INTEGRATE ALONG 'z' spatial_torus = FLTARR ( xsize_cube , ysize_cube , torus_depth ) FOR i = 0 , ( FIX ( torus_depth / 2. )) DO BEGIN spatial_ring = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - i )) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + i + 1 )) spatial_ring [ WHERE ( spatial_ring gt 0. )] = 1. spatial_ring [ WHERE ( spatial_ring ne 1. )] = 0. spatial_torus [ * , * , i ] = spatial_ring spatial_torus [ * , * , torus_depth - i - 1 ] = spatial_ring ENDFOR ; INTEGRATE THROUGH THE TORUS TO FIND THE SPATIAL FILTER spatial_ring_filter = TOTAL ( spatial_torus , 3 , / nan ) / FLOAT ( torus_depth ) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF NOT KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - ( FIX ( torus_depth / 2. )))) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + ( FIX ( torus_depth / 2. )) + 1 )) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 spatial_ring_filter [ WHERE ( spatial_ring_filter NE 1. )] = 0. ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = FLTARR ( xsize_cube , ysize_cube ) spatial_ring_filter [ * ] = 1. ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND KEYWORD_SET ( temporal_torus ) THEN BEGIN ; CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 25 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 3 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 25 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 30 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 4 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 30 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 40 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 5 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 40 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 45 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 6 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 45 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 50 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 7 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 50 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 55 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 8 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 55 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 60 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 9 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 60 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 65 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 10 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 65 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 70 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 11 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 70 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 80 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 12 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 80 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 90 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 13 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 90 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 100 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 14 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 100 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 110 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 15 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 110 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 16 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 17 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = temporal_Gaussian temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = temporal_Gaussian temporal_filter = temporal_filter / MAX ( temporal_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND NOT KEYWORD_SET ( temporal_torus ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = 1.0 temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = 1.0 ENDIF IF KEYWORD_SET ( no_temporal_filt ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 1. ENDIF charsize = 2.2 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ; MAKE SOME FIGURES FOR PLOTTING - MAKES THINGS AESTHETICALLY PLEASING ! torus_map = MAKE_MAP ( spatial_ring_filter , dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft = TOTAL ( threedft , 3 , / nan ) spatial_fft_map = MAKE_MAP ( ALOG10 ( spatial_fft ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = MAKE_MAP ( ALOG10 ( spatial_fft_filtered > 1e-15 ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) temporal_fft = TOTAL ( TOTAL ( threedft , 2 , / nan ), 1 ) ; IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN WINDOW , 1 , xsize = 1500 , ysize = 1000 , title = 'QUEEFF: FFT filter specs' ; IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN WINDOW , 1 , xsize = smallest_screensize , ysize = FIX ( smallest_screensize * 0.8 ), title = 'QUEEFF: FFT filter specs' x1 = 0.07 x2 = 0.286 x3 = 0.42 x4 = 0.635 x5 = 0.765 x6 = 0.98 y1 = 0.19 y2 = 0.32 y3 = 0.40 y4 = 0.58 LOADCT , 5 , / silent plot_map , spatial_fft_map , charsize = charsize , xticklen =- .045 , yticklen =- .045 , xtitle = 'Wavenumber (k!Dx!N; pixel!U-1!N)' , ytitle = 'Wavenumber (k!Dy!N; pixel!U-1!N)' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x1 , y3 , x2 , y4 ], / SQUARE_SCALE , xminor = 3 , yminor = 3 , / NOTITLE PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 3 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 3 , color = 255 LOADCT , 0 , / silent xyouts , 0. , 3.7 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / data , '(c) Spatial FFT' , color = cgColor ( 'Black' ) plot_map , torus_map , charsize = charsize , xticklen =- .045 , yticklen =- .045 , xtitle = 'Wavenumber (k!Dx!N; pixel!U-1!N)' , dmin = 0 , dmax = 1 , position = [ x3 , y3 , x4 , y4 ], / noerase , / SQUARE_SCALE , xminor = 3 , yminor = 3 , ytitle = 'Wavenumber (k!Dy!N; pixel!U-1!N)' , / NOTITLE ;, ytickformat = '(A1)' PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 3 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 3 , color = 255 LOADCT , 5 , / silent xyouts , 0. , 3.7 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / data , '(d) Spatial FFT filter' , color = cgColor ( 'Black' ) plot_map , spatial_fft_filtered_map , charsize = charsize , xticklen =- .045 , yticklen =- .045 , xtitle = 'Wavenumber (k!Dx!N pixel!U-1!N)' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x5 , y3 , x6 , y4 ], / noerase , SQUARE_SCALE , xminor = 3 , yminor = 3 , ytitle = 'Wavenumber (k!Dy!N; pixel!U-1!N)' , / NOTITLE ;, ytickformat = '(A1)' PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 3 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 3 , color = 255 xyouts , 0. , 3.7 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / data , '(e) Filtered spatial FFT' , color = cgColor ( 'Black' ) PLOT , temporal_frequencies * 1000. , ABS ( temporal_fft ), / ylog , xst = 1 , charsize = charsize , xticklen =- .060 , yticklen =- .008 , xtitle = 'Frequency (mHz)' , ytitle = 'Power (arb. units)' , position = [ x1 + 0.01 , y1 , x6 , y2 ], / noerase , xminor = 5 , XTICKINTERVAL = 250 , YTICKNAME = [ ' ' , '10!u-2' , ' ' , '10!u0' , ' ' , '10!u2' ] temporal_fft_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) temporal_fft_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) PLOTS , [ 0 , 0 ], [ temporal_fft_plot_ymin , temporal_fft_plot_ymax ], line = 2 , thick = 4 , color = 0 LOADCT , 39 , / silent OPLOT , temporal_frequencies * 1000. , ( temporal_filter ) > temporal_fft_plot_ymin , line = 2 , color = 55 , thick = 5 OPLOT , temporal_frequencies * 1000. , ( ABS ( temporal_fft * temporal_filter )) > temporal_fft_plot_ymin , line = 0 , color = 254 , thick = 4 LOADCT , 5 , / silent WAIT , 0.5 ; APPLY THE GAUSSIAN FILTERS TO THE DATA TO PREVENT ALIASING FOR i = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , i ] = REFORM ( threedft [ * , * , i ]) * spatial_ring_filter FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO BEGIN threedft [ x , y , * ] = REFORM ( threedft [ x , y , * ]) * temporal_filter ENDFOR ENDFOR ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE / center CALL IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ 1 , 1 ]) ENDIF new_cube = REAL_PART ( FFT ( threedft , 1 , / double , / center )) LOADCT , 0 , / silent filtered_cube = new_cube PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' pos = fltarr ( 4 , 6 ) xl = 0.725 & xr = 0.98 yb = y4 + 0.08 & yt = 0.98 xgap = 0. ygap = 0. rows = (( xr - xl ) / 2. ) - xgap cols = (( yt - yb ) / 3. ) - ( 2. * ygap ) pos [ * , 0 ] = [ xl , yb + cols + ygap + cols + ygap , xl + rows , yt ] pos [ * , 1 ] = [ xl + rows + xgap , yb + cols + ygap + cols + ygap , xr , yt ] pos [ * , 2 ] = [ xl , yb + cols + ygap , xl + rows , yb + cols + ygap + cols ] pos [ * , 3 ] = [ xl + rows + xgap , yb + cols + ygap , xr , yb + cols + ygap + cols ] pos [ * , 4 ] = [ xl , yb , xl + rows , yb + cols ] pos [ * , 5 ] = [ xl + rows + xgap , yb , xr , yb + cols ] loadct , 1 ! x . ticklen =- 0.07 ! y . ticklen =- 0.07 for i = 0 L , 5 do begin im = reform ( filtered_cube [ * , * , i ]) walsa_image_plot , iris_histo_opt ( im ), xrange = xrg , yrange = yrg , nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = pos [ * , i ], xminor = 2 , yminor = 2 cgPlotS , 18 , 111 , PSym = 16 , SymColor = 'Black' , SymSize = 2.7 cgPlotS , 18 , 111 , PSym = 16 , SymColor = 'White' , SymSize = 2.2 cgtext , 18 , 103.5 , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / data , strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor cgPolygon , [ xl - 0.05 , xl - 0.05 , xr + 0.01 , xr + 0.01 , xl - 0.05 ], [ yb - 0.019 , yt , yt , yb - 0.019 , yb - 0.019 ], $ / NORMAL , COLOR = cgColor ( 'DodgerBlue' ), thick = 5 , linestyle = 1 xyouts , p1_x1 - 0.07 , p1_y2 + 0.11 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(a)' , color = cgColor ( 'Black' ) xyouts , xl - 0.025 , yt - 0.022 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(b)' , color = cgColor ( 'Black' ) xyouts , x1 + 0.030 , y2 - 0.022 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(f)' , color = cgColor ( 'Black' ) ! P . Multi = 0 Cleanplot , / Silent print , '' print , 'COMPLETED!' print , '' walsa_endeps , filename = 'Figures/FigS4_k-omega_analysis' stop END", "title": "Worked Example - NRMP: k-\u03c9 Analysis and Filtering"}, {"location": "idl/k-omega-pod-example/", "text": "Worked Example - NRMP: k-\u03c9 and POD Analysis \u00b6 This example demonstrates the application of k-\u03c9 filtering and Proper Orthogonal Decomposition (POD) to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset with k-\u03c9 and POD, we can identify and isolate specific wave modes, revealing their spatial structures and temporal dynamics. k-\u03c9 Analysis \u00b6 k-\u03c9 analysis is a technique used to study wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both the spatial domain (wavenumber, k) and the temporal domain (frequency, \u03c9). The resulting k-\u03c9 diagram shows how wave power is distributed across different spatial and temporal scales, providing insights into wave dispersion relations and the characteristics of different wave modes. In this example, we apply k-\u03c9 analysis to the synthetic spatio-temporal dataset to identify and isolate a specific wave mode with a frequency of 500 mHz and wavenumbers between 0.05 and 0.25 pixel -1 . We then use Fourier filtering to extract this wave mode from the dataset, revealing its spatial structure and temporal evolution. Proper Orthogonal Decomposition (POD) \u00b6 Proper Orthogonal Decomposition (POD) is a powerful technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. In this example, we apply POD to the synthetic spatio-temporal dataset to identify the dominant spatial modes of oscillation. We then apply frequency filtering to the temporal coefficients of these modes to isolate the 500 mHz wave mode. This allows us to compare the results of k-\u03c9 filtering and POD-based filtering, highlighting their respective strengths and limitations. Analysis and Figure The figure below shows a comparison of k-\u03c9 filtering and POD analysis applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis with Fourier filtering Proper Orthogonal Decomposition (POD) with frequency filtering WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 5 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Comparison of k-\u03c9 filtering and POD analysis. (a) k-\u03c9 power diagram of the synthetic spatio-temporal dataset with a targeted filtering region (dashed lines). (b) First six spatial modes from POD analysis (each 130\u00d7130 pixels 2 ). \u00a9 First six frames of the k-\u03c9 filtered datacube centred at 500 mHz (\u00b130 mHz) and wavenumbers 0.05\u22120.25 pixel -1 . (d) First six frames of the frequency-filtered POD reconstruction at 500 mHz using the first 22 POD modes (99% of total variance). All images and spatial modes are plotted with their own minimum and maximum values to highlight detailed structures within them. Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 ; + ; NAME : WaLSA_QUB_QUEEFF ; part of -- WaLSAtools -- ; ; ORIGINAL CODE : QUEEns Fourier Filtering ( QUEEFF ) code ; WRITTEN , ANNOTATED , TESTED AND UPDATED BY : ; ( 1 ) Dr . David B . Jess ; ( 2 ) Dr . Samuel D . T . Grant ; The original code along with its manual can be downloaded at : https : // bit . ly / 37 mx9ic ; ; WaLSA_QUB_QUEEFF : Slightly modified ( i . e . , a few additional keywords added ) by Shahin Jafarzadeh ; ; CHECK DEPENDENCIES ( MAKE SURE ALL REQUIRED PROGRAMMES ARE INSTALLED ): ; NOTE ; @/ Users / dbj / ARC / IDL_programmes / Fourier_filtering / QUEEFF_code / QUEEFF_dependencies . bat ; ; CALLING SEQUENCE : ; EXAMPLES : ; walsa_qub_queeff , datacube , arcsecpx , time = time , power = power , wavenumber = wavenumber , frequencies = frequencies , koclt = 1 ; walsa_qub_queeff , datacube , arcsecpx , cadence , / filtering , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube ; ; + INPUTS : ; datacube input datacube , normally in the form of [ x , y , t ] ; [ note - at present the input datacube needs to have identical x and y dimensions . if not supplied like this the datacube will be cropped accordingly ! ] ; cadence delta time between sucessive frames - given in seconds . if not set , time must be provided ( see optional inputs ) ; arcsecpx spatial sampling of the input datacube - given in arcseconds per pixel ; ; + OPTIONAL INPUTS : ; ( if optional inputs not supplied , the user will need to interact with the displayed k - omega diagram to define these values ) ; time observing times in seconds ( 1 d array ) . it is ignored if cadence is provided ; filtering if set , filterring is proceeded ; f1 optional lower ( temporal ) frequency to filter - given in mhz ; f2 optional upper ( temporal ) frequency to filter - given in mhz ; k1 optional lower ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; k2 optional upper ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; spatial_torus makes the annulus used for spatial filtering have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; temporal_torus makes the temporal filter have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; no_spatial_filt optional keyword that ensures no spatial filtering is performed on the dataset ( i . e . , only temporal filtering ) ; no_temporal_filt optional keyword that ensures no temporal filtering is performed on the dataset ( i . e . , only spatial filtering ) ; silent : if set , the k - \u03c9 diagram is not plotted ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( wavenumber ) is plotted in logarithmic scale ( base 10 ) ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ( base 10 ) ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; nox2 : if set , 2 nd x - axis ( spatial size , in arcsec ) is not plotted ; ( spatial size ( i . e . , wavelength ) = ( 2 * ! pi ) / wavenumber ) ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ; + OUTPUTS : ; power : 2 d array of power ( see mode for the scale ) ; ( in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ) ; frequencies : 1 d array of frequencies ( in mhz ) ; wavenumber : 1 d array of wavenumber ( in arcsec ^- 1 ) ; filtered_cube : 3 d array of filtered datacube ( if filtering is set ) ; ; ; IF YOU USE THIS CODE , THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED : ; Jess et al . 2017 , ApJ , 842 , 59 ( http : // adsabs . harvard . edu / abs / 2017 ApJ .. .842 .. .59 J ) ; - ; pro FIG5__komega_POD_analyses data_dir = 'Synthetic_Data/' data = readfits ( data_dir + 'NRMP_signal_3D.fits' , / silent ) cadence = 0.5 ; sec arcsecpx = 1.0 ; arcsec nt = n_elements ( data [ 0 , 0 , * ]) time = findgen ( nt ) * cadence datacube = data arcsecpx = 1.0 time = time filtering = 1 smooth = 1 xrange = [ 0 , 0.3 ] f1 = 470 f2 = 530 k1 = 0.047 k2 = 0.25 if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) ; DEFINE THE SCREEN RESOLUTION TO ENSURE THE PLOTS DO NOT SPILL OVER THE EDGES OF THE SCREEN dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize xsize_cube = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ysize_cube = N_ELEMENTS ( datacube [ 0 , * , 0 ]) zsize_cube = N_ELEMENTS ( datacube [ 0 , 0 , * ]) ; FORCE THE CUBES TO HAVE THE SAME SPATIAL DIMENSIONS IF xsize_cube gt ysize_cube THEN datacube = TEMPORARY ( datacube [ 0 :( ysize_cube - 1 ), * , * ]) IF xsize_cube gt ysize_cube THEN xsize_cube = ysize_cube IF ysize_cube gt xsize_cube THEN datacube = TEMPORARY ( datacube [ * , 0 :( xsize_cube - 1 ), * ]) IF ysize_cube gt xsize_cube THEN ysize_cube = xsize_cube if n_elements ( spatial_torus ) eq 0 then spatial_torus = 1 if n_elements ( temporal_torus ) eq 0 then temporal_torus = 1 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nox2 ) eq 0 then nox2 = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if not keyword_set ( mode ) then mode = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( filtering ) eq 0 then filtering = 0 else silent = 0 ; CALCULATE THE NYQUIST FREQUENCIES spatial_Nyquist = ( 2. * ! pi ) / ( arcsecpx * 2. ) temporal_Nyquist = 1. / ( cadence * 2. ) print , '' print , 'The input datacube is of size: [' + strtrim ( xsize_cube , 2 ) + ', ' + strtrim ( ysize_cube , 2 ) + ', ' + strtrim ( zsize_cube , 2 ) + ']' print , '' print , 'Spatially, the important values are:' print , ' 2-pixel size = ' + strtrim (( arcsecpx * 2. ), 2 ) + ' pixel' print , ' Field of view size = ' + strtrim (( arcsecpx * xsize_cube ), 2 ) + ' pixel' print , ' Nyquist wavenumber = ' + strtrim ( spatial_Nyquist , 2 ) + ' pixel^-1' IF KEYWORD_SET ( no_spatial_filt ) THEN print , '***NO SPATIAL FILTERING WILL BE PERFORMED***' print , '' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * zsize_cube , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' IF KEYWORD_SET ( no_temporal_filt ) THEN print , '***NO TEMPORAL FILTERING WILL BE PERFORMED***' ; MAKE A k - omega DIAGRAM sp_out = DBLARR ( xsize_cube / 2 , zsize_cube / 2 ) print , '' print , 'Constructing a k-omega diagram of the input datacube..........' print , '' ; MAKE THE k - omega DIAGRAM USING THE PROVEN METHOD OF ROB RUTTEN kopower = walsa_plotkopower_funct ( datacube , sp_out , arcsecpx , cadence , apod = 0.1 , kmax = 1. , fmax = 1. ) ; X SIZE STUFF xsize_kopower = N_ELEMENTS ( kopower [ * , 0 ]) dxsize_kopower = spatial_Nyquist / FLOAT ( xsize_kopower - 1. ) kopower_xscale = ( FINDGEN ( xsize_kopower ) * dxsize_kopower ) ; IN pixel ^- 1 ; Y SIZE STUFF ysize_kopower = N_ELEMENTS ( kopower [ 0 , * ]) dysize_kopower = temporal_Nyquist / FLOAT ( ysize_kopower - 1. ) kopower_yscale = ( FINDGEN ( ysize_kopower ) * dysize_kopower ) * 1000. ; IN mHz Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) kopower_plot = kopower kopower_plot [ * , 1 : * ] = CONVOL ( kopower [ * , 1 : * ], Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) ; normalise to frequency resolution ( in mHz ) freq = kopower_yscale [ 1 : * ] if freq [ 0 ] eq 0 then freq0 = freq [ 1 ] else freq0 = freq [ 0 ] kopower_plot = kopower_plot / freq0 if mode eq 0 then kopower_plot = ALOG10 ( kopower_plot ) if mode eq 2 then kopower_plot = SQRT ( kopower_plot ) LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. p1_x1 = 0.083 p1_x2 = 0.49 p1_y1 = 0.58 p1_y2 = 0.82 ! P . Multi = [ 0 , 6 , 6 ] ! p . background = 255. ! p . color = 0. ; WHEN PLOTTING WE NEED TO IGNORE THE ZERO 'TH ELEMENT (I.E., THE MEAN f=0) SINCE THIS WILL MESS UP THE LOG PLOT! komegamap = ( kopower_plot )[ 1 : * , 1 : * ] > MIN (( kopower_plot )[ 1 : * , 1 : * ], / nan ) < MAX (( kopower_plot )[ 1 : * , 1 : * ], / nan ) EPS = 1 IF silent EQ 0 THEN BEGIN if n_elements ( komega ) eq 0 then komega = 0 else komega = 1 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. IF EPS eq 1 THEN BEGIN walsa_eps , size = [ 23 , 27 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 2.1 ! p . charsize = 2.1 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.037 ! y . ticklen =- 0.025 ; positioncb = [ 0.56 , 0.69 , 0.572 , 0.93 ] positioncb = [ p1_x1 , p1_y2 + 0.08 , p1_x2 , p1_y2 + 0.094 ] ENDIF ELSE BEGIN IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN WINDOW , 0 , xsize = 1000 , ysize = 1000 , title = 'QUEEFF: k-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN WINDOW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'QUEEFF: k-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF ENDELSE walsa_pg_plotimage_komega , komegamap , kopower_xscale [ 1 : * ], kopower_yscale [ 1 : * ], noy2 = noy2 , nox2 = nox2 , smooth = smooth , $ xtitle = 'Wavenumber (pixel!U-1!N)' , ytitle = 'Frequency (mHz)' , xst = 8 , yst = 8 , xlog = xlog , ylog = ylog , position = [ p1_x1 , p1_y1 , p1_x2 , p1_y2 ], $ xrange = xrange , yrange = yrange , threemin = threemin , fivemin = fivemin , eps = eps , xminor = 5 , x2ndaxistitle = 'Spatial size (pixel)!C' , $ y2ndaxistitle = '!CPeriod (s)' tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) ; cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ ; position = positioncb , / right , ticknames = tickmarknames , xticklen = 0.00001 , charsize = 2.4 , / vertical cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ position = positioncb , / top , ticknames = tickmarknames , yticklen = 0.00001 , charsize = 2.1 xyouts , p1_x1 + ( p1_x2 - p1_x1 ) / 2. , p1_y2 + 0.123 , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / normal , 'Log!d10!n(Oscillation Power)' , color = cgColor ( 'Black' ) xyouts , p1_x1 + ( p1_x2 - p1_x1 ) / 2. , p1_y2 + 0.16 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(a) k-' + cgGreek ( 'omega' ) + ' diagram and filtering' , color = cgColor ( 'Black' ) ENDIF power = komegamap wavenumber = kopower_xscale [ 1 : * ] frequencies = kopower_yscale [ 1 : * ] print , ' ' if filtering then print , ' ..... start filtering (in k-\u03c9 space)' else return print , ' ' ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; STEPS USED TO MAKE SURE THE FREQUENCIES ARE CHOSEN ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; NEED f1 AND k1 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , f1 , / data WAIT , 1.0 ; NEED f2 AND k2 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 IF KEYWORD_SET ( no_spatial_filt ) THEN k1 = kopower_xscale [ 1 ] IF KEYWORD_SET ( no_spatial_filt ) THEN k2 = MAX ( kopower_xscale , / nan ) IF KEYWORD_SET ( no_temporal_filt ) THEN f1 = kopower_yscale [ 1 ] IF KEYWORD_SET ( no_temporal_filt ) THEN f2 = MAX ( kopower_yscale , / nan ) IF ( k1 le 0.0 ) THEN k1 = kopower_xscale [ 1 ] IF ( k2 gt MAX ( kopower_xscale , / nan )) THEN k2 = MAX ( kopower_xscale , / nan ) IF ( f1 le 0.0 ) THEN f1 = kopower_yscale [ 1 ] IF ( f2 gt MAX ( kopower_yscale , / nan )) THEN f2 = MAX ( kopower_yscale , / nan ) IF NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN k1 = kopower_xscale [ 1 ] k2 = MAX ( kopower_xscale , / nan ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF print , '' print , 'The preserved wavenumbers are [' + strtrim ( k1 , 2 ) + ', ' + strtrim ( k2 , 2 ) + '] pixel^-1' print , 'The preserved spatial sizes are [' + strtrim (( 2. * ! pi ) / k2 , 2 ) + ', ' + strtrim (( 2. * ! pi ) / k1 , 2 ) + '] pixel' print , '' print , 'The preserved frequencies are [' + strtrim ( f1 , 2 ) + ', ' + strtrim ( f2 , 2 ) + '] mHz' print , 'The preserved periods are [' + strtrim ( FIX ( 1. / ( f2 / 1000. )), 2 ) + ', ' + strtrim ( FIX ( 1. / ( f1 / 1000. )), 2 ) + '] seconds' pwavenumber = [ k1 , k2 ] pspatialsize = [( 2. * ! pi ) / k2 ,( 2. * ! pi ) / k1 ] pfrequency = [ f1 , f2 ] pperiod = [ FIX ( 1. / ( f2 / 1000. )), FIX ( 1. / ( f1 / 1000. ))] print , '' print , 'Making a 3D Fourier transform of the input datacube..........' threedft = FFT ( datacube , - 1 , / double , / center ) ; CALCULATE THE FREQUENCY AXES FOR THE 3 D FFT temp_x = FINDGEN (( xsize_cube - 1 ) / 2 ) + 1 is_N_even = ( xsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ spatial_frequencies_orig = ([ 0.0 , temp_x , xsize_cube / 2 , - xsize_cube / 2 + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) $ ELSE $ spatial_frequencies_orig = ([ 0.0 , temp_x , - ( xsize_cube / 2 + 1 ) + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) temp_x = FINDGEN (( zsize_cube - 1 ) / 2 ) + 1 is_N_even = ( zsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ temporal_frequencies_orig = [ 0.0 , temp_x , zsize_cube / 2 , - zsize_cube / 2 + temp_x ] / ( zsize_cube * cadence ) $ ELSE $ temporal_frequencies_orig = [ 0.0 , temp_x , - ( zsize_cube / 2 + 1 ) + temp_x ] / ( zsize_cube * cadence ) ; NOW COMPENSATE THESE FREQUENCY AXES DUE TO THE FACT THE / center KEYWORD IS USED FOR THE FFT TRANSFORM spatial_positive_frequencies = N_ELEMENTS ( WHERE ( spatial_frequencies_orig ge 0. )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 2 )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 NE 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 1 )) temporal_positive_frequencies = N_ELEMENTS ( WHERE ( temporal_frequencies_orig ge 0. )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 2 )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 NE 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 1 )) ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE NEW FREQUENCY AXES DESCRIBED ABOVE IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), - 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ - 1 , - 1 ]) ENDIF ; CONVERT FREQUENCIES AND WAVENUMBERS OF INTEREST INTO ( FFT ) DATACUBE PIXELS pixel_k1_positive = walsa_closest ( k1 , spatial_frequencies_orig ) pixel_k2_positive = walsa_closest ( k2 , spatial_frequencies_orig ) pixel_f1_positive = walsa_closest ( f1 / 1000. , temporal_frequencies ) pixel_f2_positive = walsa_closest ( f2 / 1000. , temporal_frequencies ) pixel_f1_negative = walsa_closest ( - f1 / 1000. , temporal_frequencies ) pixel_f2_negative = walsa_closest ( - f2 / 1000. , temporal_frequencies ) torus_depth = FIX (( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) * 2. torus_center = FIX ((( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) + pixel_k1_positive [ 0 ]) IF KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN ; CREATE A FILTER RING PRESERVING EQUAL WAVENUMBERS FOR BOTH kx AND ky ; DO THIS AS A TORUS TO PRESERVE AN INTEGRATED GAUSSIAN SHAPE ACROSS THE WIDTH OF THE ANNULUS , THEN INTEGRATE ALONG 'z' spatial_torus = FLTARR ( xsize_cube , ysize_cube , torus_depth ) FOR i = 0 , ( FIX ( torus_depth / 2. )) DO BEGIN spatial_ring = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - i )) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + i + 1 )) spatial_ring [ WHERE ( spatial_ring gt 0. )] = 1. spatial_ring [ WHERE ( spatial_ring ne 1. )] = 0. spatial_torus [ * , * , i ] = spatial_ring spatial_torus [ * , * , torus_depth - i - 1 ] = spatial_ring ENDFOR ; INTEGRATE THROUGH THE TORUS TO FIND THE SPATIAL FILTER spatial_ring_filter = TOTAL ( spatial_torus , 3 , / nan ) / FLOAT ( torus_depth ) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF NOT KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - ( FIX ( torus_depth / 2. )))) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + ( FIX ( torus_depth / 2. )) + 1 )) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 spatial_ring_filter [ WHERE ( spatial_ring_filter NE 1. )] = 0. ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = FLTARR ( xsize_cube , ysize_cube ) spatial_ring_filter [ * ] = 1. ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND KEYWORD_SET ( temporal_torus ) THEN BEGIN ; CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 25 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 3 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 25 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 30 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 4 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 30 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 40 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 5 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 40 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 45 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 6 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 45 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 50 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 7 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 50 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 55 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 8 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 55 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 60 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 9 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 60 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 65 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 10 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 65 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 70 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 11 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 70 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 80 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 12 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 80 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 90 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 13 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 90 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 100 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 14 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 100 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 110 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 15 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 110 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 16 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 17 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = temporal_Gaussian temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = temporal_Gaussian temporal_filter = temporal_filter / MAX ( temporal_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND NOT KEYWORD_SET ( temporal_torus ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = 1.0 temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = 1.0 ENDIF IF KEYWORD_SET ( no_temporal_filt ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 1. ENDIF charsize = 2.2 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ; MAKE SOME FIGURES FOR PLOTTING - MAKES THINGS AESTHETICALLY PLEASING ! torus_map = MAKE_MAP ( spatial_ring_filter , dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft = TOTAL ( threedft , 3 , / nan ) spatial_fft_map = MAKE_MAP ( ALOG10 ( spatial_fft ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = MAKE_MAP ( ALOG10 ( spatial_fft_filtered > 1e-15 ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) temporal_fft = TOTAL ( TOTAL ( threedft , 2 , / nan ), 1 ) ; IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN WINDOW , 1 , xsize = 1500 , ysize = 1000 , title = 'QUEEFF: FFT filter specs' ; IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN WINDOW , 1 , xsize = smallest_screensize , ysize = FIX ( smallest_screensize * 0.8 ), title = 'QUEEFF: FFT filter specs' x1 = 0.07 x2 = 0.286 x3 = 0.42 x4 = 0.635 x5 = 0.765 x6 = 0.98 y1 = 0.19 y2 = 0.32 y3 = 0.40 y4 = 0.58 ; APPLY THE GAUSSIAN FILTERS TO THE DATA TO PREVENT ALIASING FOR i = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , i ] = REFORM ( threedft [ * , * , i ]) * spatial_ring_filter FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO BEGIN threedft [ x , y , * ] = REFORM ( threedft [ x , y , * ]) * temporal_filter ENDFOR ENDFOR ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE / center CALL IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ 1 , 1 ]) ENDIF new_cube = REAL_PART ( FFT ( threedft , 1 , / double , / center )) LOADCT , 0 , / silent filtered_cube = new_cube PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ k - omega Filtered Images pos = cgLayout ([ 6 , 6 ], OXMargin = [ 0 , 0 ], OYMargin = [ 0 , 0 ], XGap = 2 , YGap = 2 ) loadct , 1 imy1 = 0.30 imy2 = 0.50 ! x . ticklen =- 0.055 ! y . ticklen =- 0.055 for i = 0 L , 5 do begin tmppos = reform ( pos [ * , i ]) position = [ tmppos [ 0 ], imy1 , tmppos [ 2 ], imy2 ] im = reform ( filtered_cube [ * , * , i ]) rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 tvlct , R , G , B walsa_image_plot , im , xrange = [ 0 , 129 ], yrange = [ 0 , 129 ], nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = position , xminor = 2 , yminor = 2 cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'Black' , SymSize = 3.2 , / data cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'White' , SymSize = 2.7 , / data cgtext , 20 , 102. , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / data , strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor xyouts , 0.5 , 0.47 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(c) k-' + cgGreek ( 'omega' ) + ' filtered images' , color = cgColor ( 'Black' ) ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ POD Frequency Filtered Spatial Modes podffsmy1 = 0.10 podffsmy2 = 0.30 for i = 0 L , 5 do begin tmppos = reform ( pos [ * , i ]) position = [ tmppos [ 0 ], podffsmy1 , tmppos [ 2 ], podffsmy2 ] podffsm = readfits ( 'Python_parameters/pod_frequency_filtered_spatial_modes_frame' + strtrim ( long ( i ), 2 ) + '.fits' ) im = reform ( podffsm [ * , * , 8 ]) rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 tvlct , R , G , B walsa_image_plot , im , xrange = [ 0 , 129 ], yrange = [ 0 , 129 ], nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = position , xminor = 2 , yminor = 2 cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'Black' , SymSize = 3.2 , / data cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'White' , SymSize = 2.7 , / data cgtext , 20 , 102. , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / data , strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor xyouts , 0.5 , 0.27 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(d) POD frequency-filtered spatial images' , color = cgColor ( 'Black' ) ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ POD Spatial Modes pos = fltarr ( 4 , 6 ) xl = 0.658 & xr = 0.999 yb = 0.535 & yt = 0.97 xgap = 0. ygap = 0. rows = (( xr - xl ) / 2. ) - xgap cols = (( yt - yb ) / 3. ) - ( 2. * ygap ) pos [ * , 0 ] = [ xl , yb + cols + ygap + cols + ygap , xl + rows , yt ] pos [ * , 1 ] = [ xl + rows + xgap , yb + cols + ygap + cols + ygap , xr , yt ] pos [ * , 2 ] = [ xl , yb + cols + ygap , xl + rows , yb + cols + ygap + cols ] pos [ * , 3 ] = [ xl + rows + xgap , yb + cols + ygap , xr , yb + cols + ygap + cols ] pos [ * , 4 ] = [ xl , yb , xl + rows , yb + cols ] pos [ * , 5 ] = [ xl + rows + xgap , yb , xr , yb + cols ] pod_modes = readfits ( 'Python_parameters/pod_first_6_spatial_modes.fits' ) ! x . ticklen =- 0.058 ! y . ticklen =- 0.058 for i = 0 L , 5 do begin im = reform ( pod_modes [ * , * , i ]) rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 tvlct , R , G , B walsa_image_plot , im , xrange = [ 0 , 129 ], yrange = [ 0 , 129 ], nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = pos [ * , i ], xminor = 2 , yminor = 2 cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'Black' , SymSize = 3.2 , / data cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'White' , SymSize = 2.7 , / data cgtext , 20 , 102. , ALIGNMENT = 0.5 , CHARSIZE = 1.05 , / data , '!5P!X' + strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor xyouts , xl + ( xr - xl ) / 2. , p1_y2 + 0.16 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(b) POD spatial modes' , color = cgColor ( 'Black' ) ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ SPOD Spatial Modes ; Unnecessary to show them here ! The pair SPOD modes are part of the POD frequency - filtered modes ; pos = fltarr ( 4 , 6 ) ; xl = 0.73 & xr = 0.99 ; yb = 0.11 & yt = 0.54 ; xgap = 0. ; ygap = 0. ; ; ! x . ticklen =- 0.055 ; ! y . ticklen =- 0.055 ; ; rows = (( xr - xl ) / 2. ) - xgap ; cols = (( yt - yb ) / 3. ) - ( 2. * ygap ) ; ; pos [ * , 0 ] = [ xl , yb + cols + ygap + cols + ygap , xl + rows , yt ] ; pos [ * , 1 ] = [ xl + rows + xgap , yb + cols + ygap + cols + ygap , xr , yt ] ; pos [ * , 2 ] = [ xl , yb + cols + ygap , xl + rows , yb + cols + ygap + cols ] ; pos [ * , 3 ] = [ xl + rows + xgap , yb + cols + ygap , xr , yb + cols + ygap + cols ] ; pos [ * , 4 ] = [ xl , yb , xl + rows , yb + cols ] ; pos [ * , 5 ] = [ xl + rows + xgap , yb , xr , yb + cols ] ; ; for i = 0 L , 1 do begin ; spod = readfits ( 'Python_parameters/spod_first_20_modes.fits' ) ; ; if i eq 0 then im = reform ( spod [ * , * , 10 ]) ; if i eq 1 then im = reform ( spod [ * , * , 11 ]) ; rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! ; R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 ; tvlct , R , G , B ; walsa_image_plot , im , xrange = xrg , yrange = yrg , nobar = 1 , zrange = minmax ( im ), / nocolor , $ ; contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , noxval = 1 , $ ; noyval = 1 , cblog = cblog , position = pos [ * , i ], xminor = 2 , yminor = 2 ; endfor ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ ; xyouts , x1 + 0.030 , y2 - 0.022 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(f)' , color = cgColor ( 'Black' ) ! P . Multi = 0 Cleanplot , / Silent print , '' print , 'COMPLETED!' print , '' walsa_endeps , filename = 'Figures/k-omega_and_pod_analyses' done stop END", "title": "k-&#969; and POD"}, {"location": "idl/k-omega-pod-example/#worked-example-nrmp-k-and-pod-analysis", "text": "This example demonstrates the application of k-\u03c9 filtering and Proper Orthogonal Decomposition (POD) to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset with k-\u03c9 and POD, we can identify and isolate specific wave modes, revealing their spatial structures and temporal dynamics.", "title": "Worked Example - NRMP: k-\u03c9 and POD Analysis"}, {"location": "idl/k-omega-pod-example/#k-analysis", "text": "k-\u03c9 analysis is a technique used to study wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both the spatial domain (wavenumber, k) and the temporal domain (frequency, \u03c9). The resulting k-\u03c9 diagram shows how wave power is distributed across different spatial and temporal scales, providing insights into wave dispersion relations and the characteristics of different wave modes. In this example, we apply k-\u03c9 analysis to the synthetic spatio-temporal dataset to identify and isolate a specific wave mode with a frequency of 500 mHz and wavenumbers between 0.05 and 0.25 pixel -1 . We then use Fourier filtering to extract this wave mode from the dataset, revealing its spatial structure and temporal evolution.", "title": "k-\u03c9 Analysis"}, {"location": "idl/k-omega-pod-example/#proper-orthogonal-decomposition-pod", "text": "Proper Orthogonal Decomposition (POD) is a powerful technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. In this example, we apply POD to the synthetic spatio-temporal dataset to identify the dominant spatial modes of oscillation. We then apply frequency filtering to the temporal coefficients of these modes to isolate the 500 mHz wave mode. This allows us to compare the results of k-\u03c9 filtering and POD-based filtering, highlighting their respective strengths and limitations. Analysis and Figure The figure below shows a comparison of k-\u03c9 filtering and POD analysis applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis with Fourier filtering Proper Orthogonal Decomposition (POD) with frequency filtering WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 5 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Comparison of k-\u03c9 filtering and POD analysis. (a) k-\u03c9 power diagram of the synthetic spatio-temporal dataset with a targeted filtering region (dashed lines). (b) First six spatial modes from POD analysis (each 130\u00d7130 pixels 2 ). \u00a9 First six frames of the k-\u03c9 filtered datacube centred at 500 mHz (\u00b130 mHz) and wavenumbers 0.05\u22120.25 pixel -1 . (d) First six frames of the frequency-filtered POD reconstruction at 500 mHz using the first 22 POD modes (99% of total variance). All images and spatial modes are plotted with their own minimum and maximum values to highlight detailed structures within them. Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 ; + ; NAME : WaLSA_QUB_QUEEFF ; part of -- WaLSAtools -- ; ; ORIGINAL CODE : QUEEns Fourier Filtering ( QUEEFF ) code ; WRITTEN , ANNOTATED , TESTED AND UPDATED BY : ; ( 1 ) Dr . David B . Jess ; ( 2 ) Dr . Samuel D . T . Grant ; The original code along with its manual can be downloaded at : https : // bit . ly / 37 mx9ic ; ; WaLSA_QUB_QUEEFF : Slightly modified ( i . e . , a few additional keywords added ) by Shahin Jafarzadeh ; ; CHECK DEPENDENCIES ( MAKE SURE ALL REQUIRED PROGRAMMES ARE INSTALLED ): ; NOTE ; @/ Users / dbj / ARC / IDL_programmes / Fourier_filtering / QUEEFF_code / QUEEFF_dependencies . bat ; ; CALLING SEQUENCE : ; EXAMPLES : ; walsa_qub_queeff , datacube , arcsecpx , time = time , power = power , wavenumber = wavenumber , frequencies = frequencies , koclt = 1 ; walsa_qub_queeff , datacube , arcsecpx , cadence , / filtering , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube ; ; + INPUTS : ; datacube input datacube , normally in the form of [ x , y , t ] ; [ note - at present the input datacube needs to have identical x and y dimensions . if not supplied like this the datacube will be cropped accordingly ! ] ; cadence delta time between sucessive frames - given in seconds . if not set , time must be provided ( see optional inputs ) ; arcsecpx spatial sampling of the input datacube - given in arcseconds per pixel ; ; + OPTIONAL INPUTS : ; ( if optional inputs not supplied , the user will need to interact with the displayed k - omega diagram to define these values ) ; time observing times in seconds ( 1 d array ) . it is ignored if cadence is provided ; filtering if set , filterring is proceeded ; f1 optional lower ( temporal ) frequency to filter - given in mhz ; f2 optional upper ( temporal ) frequency to filter - given in mhz ; k1 optional lower ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; k2 optional upper ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; spatial_torus makes the annulus used for spatial filtering have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; temporal_torus makes the temporal filter have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; no_spatial_filt optional keyword that ensures no spatial filtering is performed on the dataset ( i . e . , only temporal filtering ) ; no_temporal_filt optional keyword that ensures no temporal filtering is performed on the dataset ( i . e . , only spatial filtering ) ; silent : if set , the k - \u03c9 diagram is not plotted ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( wavenumber ) is plotted in logarithmic scale ( base 10 ) ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ( base 10 ) ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; nox2 : if set , 2 nd x - axis ( spatial size , in arcsec ) is not plotted ; ( spatial size ( i . e . , wavelength ) = ( 2 * ! pi ) / wavenumber ) ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ; + OUTPUTS : ; power : 2 d array of power ( see mode for the scale ) ; ( in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ) ; frequencies : 1 d array of frequencies ( in mhz ) ; wavenumber : 1 d array of wavenumber ( in arcsec ^- 1 ) ; filtered_cube : 3 d array of filtered datacube ( if filtering is set ) ; ; ; IF YOU USE THIS CODE , THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED : ; Jess et al . 2017 , ApJ , 842 , 59 ( http : // adsabs . harvard . edu / abs / 2017 ApJ .. .842 .. .59 J ) ; - ; pro FIG5__komega_POD_analyses data_dir = 'Synthetic_Data/' data = readfits ( data_dir + 'NRMP_signal_3D.fits' , / silent ) cadence = 0.5 ; sec arcsecpx = 1.0 ; arcsec nt = n_elements ( data [ 0 , 0 , * ]) time = findgen ( nt ) * cadence datacube = data arcsecpx = 1.0 time = time filtering = 1 smooth = 1 xrange = [ 0 , 0.3 ] f1 = 470 f2 = 530 k1 = 0.047 k2 = 0.25 if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) ; DEFINE THE SCREEN RESOLUTION TO ENSURE THE PLOTS DO NOT SPILL OVER THE EDGES OF THE SCREEN dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize xsize_cube = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ysize_cube = N_ELEMENTS ( datacube [ 0 , * , 0 ]) zsize_cube = N_ELEMENTS ( datacube [ 0 , 0 , * ]) ; FORCE THE CUBES TO HAVE THE SAME SPATIAL DIMENSIONS IF xsize_cube gt ysize_cube THEN datacube = TEMPORARY ( datacube [ 0 :( ysize_cube - 1 ), * , * ]) IF xsize_cube gt ysize_cube THEN xsize_cube = ysize_cube IF ysize_cube gt xsize_cube THEN datacube = TEMPORARY ( datacube [ * , 0 :( xsize_cube - 1 ), * ]) IF ysize_cube gt xsize_cube THEN ysize_cube = xsize_cube if n_elements ( spatial_torus ) eq 0 then spatial_torus = 1 if n_elements ( temporal_torus ) eq 0 then temporal_torus = 1 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nox2 ) eq 0 then nox2 = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if not keyword_set ( mode ) then mode = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( filtering ) eq 0 then filtering = 0 else silent = 0 ; CALCULATE THE NYQUIST FREQUENCIES spatial_Nyquist = ( 2. * ! pi ) / ( arcsecpx * 2. ) temporal_Nyquist = 1. / ( cadence * 2. ) print , '' print , 'The input datacube is of size: [' + strtrim ( xsize_cube , 2 ) + ', ' + strtrim ( ysize_cube , 2 ) + ', ' + strtrim ( zsize_cube , 2 ) + ']' print , '' print , 'Spatially, the important values are:' print , ' 2-pixel size = ' + strtrim (( arcsecpx * 2. ), 2 ) + ' pixel' print , ' Field of view size = ' + strtrim (( arcsecpx * xsize_cube ), 2 ) + ' pixel' print , ' Nyquist wavenumber = ' + strtrim ( spatial_Nyquist , 2 ) + ' pixel^-1' IF KEYWORD_SET ( no_spatial_filt ) THEN print , '***NO SPATIAL FILTERING WILL BE PERFORMED***' print , '' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * zsize_cube , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' IF KEYWORD_SET ( no_temporal_filt ) THEN print , '***NO TEMPORAL FILTERING WILL BE PERFORMED***' ; MAKE A k - omega DIAGRAM sp_out = DBLARR ( xsize_cube / 2 , zsize_cube / 2 ) print , '' print , 'Constructing a k-omega diagram of the input datacube..........' print , '' ; MAKE THE k - omega DIAGRAM USING THE PROVEN METHOD OF ROB RUTTEN kopower = walsa_plotkopower_funct ( datacube , sp_out , arcsecpx , cadence , apod = 0.1 , kmax = 1. , fmax = 1. ) ; X SIZE STUFF xsize_kopower = N_ELEMENTS ( kopower [ * , 0 ]) dxsize_kopower = spatial_Nyquist / FLOAT ( xsize_kopower - 1. ) kopower_xscale = ( FINDGEN ( xsize_kopower ) * dxsize_kopower ) ; IN pixel ^- 1 ; Y SIZE STUFF ysize_kopower = N_ELEMENTS ( kopower [ 0 , * ]) dysize_kopower = temporal_Nyquist / FLOAT ( ysize_kopower - 1. ) kopower_yscale = ( FINDGEN ( ysize_kopower ) * dysize_kopower ) * 1000. ; IN mHz Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) kopower_plot = kopower kopower_plot [ * , 1 : * ] = CONVOL ( kopower [ * , 1 : * ], Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) ; normalise to frequency resolution ( in mHz ) freq = kopower_yscale [ 1 : * ] if freq [ 0 ] eq 0 then freq0 = freq [ 1 ] else freq0 = freq [ 0 ] kopower_plot = kopower_plot / freq0 if mode eq 0 then kopower_plot = ALOG10 ( kopower_plot ) if mode eq 2 then kopower_plot = SQRT ( kopower_plot ) LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. p1_x1 = 0.083 p1_x2 = 0.49 p1_y1 = 0.58 p1_y2 = 0.82 ! P . Multi = [ 0 , 6 , 6 ] ! p . background = 255. ! p . color = 0. ; WHEN PLOTTING WE NEED TO IGNORE THE ZERO 'TH ELEMENT (I.E., THE MEAN f=0) SINCE THIS WILL MESS UP THE LOG PLOT! komegamap = ( kopower_plot )[ 1 : * , 1 : * ] > MIN (( kopower_plot )[ 1 : * , 1 : * ], / nan ) < MAX (( kopower_plot )[ 1 : * , 1 : * ], / nan ) EPS = 1 IF silent EQ 0 THEN BEGIN if n_elements ( komega ) eq 0 then komega = 0 else komega = 1 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. IF EPS eq 1 THEN BEGIN walsa_eps , size = [ 23 , 27 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 2.1 ! p . charsize = 2.1 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.037 ! y . ticklen =- 0.025 ; positioncb = [ 0.56 , 0.69 , 0.572 , 0.93 ] positioncb = [ p1_x1 , p1_y2 + 0.08 , p1_x2 , p1_y2 + 0.094 ] ENDIF ELSE BEGIN IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN WINDOW , 0 , xsize = 1000 , ysize = 1000 , title = 'QUEEFF: k-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN WINDOW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'QUEEFF: k-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF ENDELSE walsa_pg_plotimage_komega , komegamap , kopower_xscale [ 1 : * ], kopower_yscale [ 1 : * ], noy2 = noy2 , nox2 = nox2 , smooth = smooth , $ xtitle = 'Wavenumber (pixel!U-1!N)' , ytitle = 'Frequency (mHz)' , xst = 8 , yst = 8 , xlog = xlog , ylog = ylog , position = [ p1_x1 , p1_y1 , p1_x2 , p1_y2 ], $ xrange = xrange , yrange = yrange , threemin = threemin , fivemin = fivemin , eps = eps , xminor = 5 , x2ndaxistitle = 'Spatial size (pixel)!C' , $ y2ndaxistitle = '!CPeriod (s)' tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) ; cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ ; position = positioncb , / right , ticknames = tickmarknames , xticklen = 0.00001 , charsize = 2.4 , / vertical cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ position = positioncb , / top , ticknames = tickmarknames , yticklen = 0.00001 , charsize = 2.1 xyouts , p1_x1 + ( p1_x2 - p1_x1 ) / 2. , p1_y2 + 0.123 , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / normal , 'Log!d10!n(Oscillation Power)' , color = cgColor ( 'Black' ) xyouts , p1_x1 + ( p1_x2 - p1_x1 ) / 2. , p1_y2 + 0.16 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(a) k-' + cgGreek ( 'omega' ) + ' diagram and filtering' , color = cgColor ( 'Black' ) ENDIF power = komegamap wavenumber = kopower_xscale [ 1 : * ] frequencies = kopower_yscale [ 1 : * ] print , ' ' if filtering then print , ' ..... start filtering (in k-\u03c9 space)' else return print , ' ' ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; STEPS USED TO MAKE SURE THE FREQUENCIES ARE CHOSEN ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; NEED f1 AND k1 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , f1 , / data WAIT , 1.0 ; NEED f2 AND k2 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 IF KEYWORD_SET ( no_spatial_filt ) THEN k1 = kopower_xscale [ 1 ] IF KEYWORD_SET ( no_spatial_filt ) THEN k2 = MAX ( kopower_xscale , / nan ) IF KEYWORD_SET ( no_temporal_filt ) THEN f1 = kopower_yscale [ 1 ] IF KEYWORD_SET ( no_temporal_filt ) THEN f2 = MAX ( kopower_yscale , / nan ) IF ( k1 le 0.0 ) THEN k1 = kopower_xscale [ 1 ] IF ( k2 gt MAX ( kopower_xscale , / nan )) THEN k2 = MAX ( kopower_xscale , / nan ) IF ( f1 le 0.0 ) THEN f1 = kopower_yscale [ 1 ] IF ( f2 gt MAX ( kopower_yscale , / nan )) THEN f2 = MAX ( kopower_yscale , / nan ) IF NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN k1 = kopower_xscale [ 1 ] k2 = MAX ( kopower_xscale , / nan ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 8 , color = cgColor ( 'Black' ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 5 , color = cgColor ( 'White' ) ENDIF print , '' print , 'The preserved wavenumbers are [' + strtrim ( k1 , 2 ) + ', ' + strtrim ( k2 , 2 ) + '] pixel^-1' print , 'The preserved spatial sizes are [' + strtrim (( 2. * ! pi ) / k2 , 2 ) + ', ' + strtrim (( 2. * ! pi ) / k1 , 2 ) + '] pixel' print , '' print , 'The preserved frequencies are [' + strtrim ( f1 , 2 ) + ', ' + strtrim ( f2 , 2 ) + '] mHz' print , 'The preserved periods are [' + strtrim ( FIX ( 1. / ( f2 / 1000. )), 2 ) + ', ' + strtrim ( FIX ( 1. / ( f1 / 1000. )), 2 ) + '] seconds' pwavenumber = [ k1 , k2 ] pspatialsize = [( 2. * ! pi ) / k2 ,( 2. * ! pi ) / k1 ] pfrequency = [ f1 , f2 ] pperiod = [ FIX ( 1. / ( f2 / 1000. )), FIX ( 1. / ( f1 / 1000. ))] print , '' print , 'Making a 3D Fourier transform of the input datacube..........' threedft = FFT ( datacube , - 1 , / double , / center ) ; CALCULATE THE FREQUENCY AXES FOR THE 3 D FFT temp_x = FINDGEN (( xsize_cube - 1 ) / 2 ) + 1 is_N_even = ( xsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ spatial_frequencies_orig = ([ 0.0 , temp_x , xsize_cube / 2 , - xsize_cube / 2 + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) $ ELSE $ spatial_frequencies_orig = ([ 0.0 , temp_x , - ( xsize_cube / 2 + 1 ) + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) temp_x = FINDGEN (( zsize_cube - 1 ) / 2 ) + 1 is_N_even = ( zsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ temporal_frequencies_orig = [ 0.0 , temp_x , zsize_cube / 2 , - zsize_cube / 2 + temp_x ] / ( zsize_cube * cadence ) $ ELSE $ temporal_frequencies_orig = [ 0.0 , temp_x , - ( zsize_cube / 2 + 1 ) + temp_x ] / ( zsize_cube * cadence ) ; NOW COMPENSATE THESE FREQUENCY AXES DUE TO THE FACT THE / center KEYWORD IS USED FOR THE FFT TRANSFORM spatial_positive_frequencies = N_ELEMENTS ( WHERE ( spatial_frequencies_orig ge 0. )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 2 )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 NE 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 1 )) temporal_positive_frequencies = N_ELEMENTS ( WHERE ( temporal_frequencies_orig ge 0. )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 2 )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 NE 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 1 )) ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE NEW FREQUENCY AXES DESCRIBED ABOVE IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), - 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ - 1 , - 1 ]) ENDIF ; CONVERT FREQUENCIES AND WAVENUMBERS OF INTEREST INTO ( FFT ) DATACUBE PIXELS pixel_k1_positive = walsa_closest ( k1 , spatial_frequencies_orig ) pixel_k2_positive = walsa_closest ( k2 , spatial_frequencies_orig ) pixel_f1_positive = walsa_closest ( f1 / 1000. , temporal_frequencies ) pixel_f2_positive = walsa_closest ( f2 / 1000. , temporal_frequencies ) pixel_f1_negative = walsa_closest ( - f1 / 1000. , temporal_frequencies ) pixel_f2_negative = walsa_closest ( - f2 / 1000. , temporal_frequencies ) torus_depth = FIX (( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) * 2. torus_center = FIX ((( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) + pixel_k1_positive [ 0 ]) IF KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN ; CREATE A FILTER RING PRESERVING EQUAL WAVENUMBERS FOR BOTH kx AND ky ; DO THIS AS A TORUS TO PRESERVE AN INTEGRATED GAUSSIAN SHAPE ACROSS THE WIDTH OF THE ANNULUS , THEN INTEGRATE ALONG 'z' spatial_torus = FLTARR ( xsize_cube , ysize_cube , torus_depth ) FOR i = 0 , ( FIX ( torus_depth / 2. )) DO BEGIN spatial_ring = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - i )) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + i + 1 )) spatial_ring [ WHERE ( spatial_ring gt 0. )] = 1. spatial_ring [ WHERE ( spatial_ring ne 1. )] = 0. spatial_torus [ * , * , i ] = spatial_ring spatial_torus [ * , * , torus_depth - i - 1 ] = spatial_ring ENDFOR ; INTEGRATE THROUGH THE TORUS TO FIND THE SPATIAL FILTER spatial_ring_filter = TOTAL ( spatial_torus , 3 , / nan ) / FLOAT ( torus_depth ) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF NOT KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - ( FIX ( torus_depth / 2. )))) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + ( FIX ( torus_depth / 2. )) + 1 )) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 spatial_ring_filter [ WHERE ( spatial_ring_filter NE 1. )] = 0. ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = FLTARR ( xsize_cube , ysize_cube ) spatial_ring_filter [ * ] = 1. ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND KEYWORD_SET ( temporal_torus ) THEN BEGIN ; CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 25 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 3 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 25 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 30 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 4 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 30 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 40 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 5 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 40 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 45 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 6 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 45 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 50 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 7 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 50 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 55 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 8 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 55 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 60 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 9 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 60 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 65 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 10 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 65 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 70 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 11 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 70 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 80 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 12 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 80 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 90 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 13 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 90 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 100 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 14 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 100 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 110 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 15 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 110 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 16 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 17 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = temporal_Gaussian temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = temporal_Gaussian temporal_filter = temporal_filter / MAX ( temporal_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND NOT KEYWORD_SET ( temporal_torus ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = 1.0 temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = 1.0 ENDIF IF KEYWORD_SET ( no_temporal_filt ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 1. ENDIF charsize = 2.2 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ; MAKE SOME FIGURES FOR PLOTTING - MAKES THINGS AESTHETICALLY PLEASING ! torus_map = MAKE_MAP ( spatial_ring_filter , dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft = TOTAL ( threedft , 3 , / nan ) spatial_fft_map = MAKE_MAP ( ALOG10 ( spatial_fft ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = MAKE_MAP ( ALOG10 ( spatial_fft_filtered > 1e-15 ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'pixels' ) temporal_fft = TOTAL ( TOTAL ( threedft , 2 , / nan ), 1 ) ; IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN WINDOW , 1 , xsize = 1500 , ysize = 1000 , title = 'QUEEFF: FFT filter specs' ; IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN WINDOW , 1 , xsize = smallest_screensize , ysize = FIX ( smallest_screensize * 0.8 ), title = 'QUEEFF: FFT filter specs' x1 = 0.07 x2 = 0.286 x3 = 0.42 x4 = 0.635 x5 = 0.765 x6 = 0.98 y1 = 0.19 y2 = 0.32 y3 = 0.40 y4 = 0.58 ; APPLY THE GAUSSIAN FILTERS TO THE DATA TO PREVENT ALIASING FOR i = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , i ] = REFORM ( threedft [ * , * , i ]) * spatial_ring_filter FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO BEGIN threedft [ x , y , * ] = REFORM ( threedft [ x , y , * ]) * temporal_filter ENDFOR ENDFOR ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE / center CALL IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ 1 , 1 ]) ENDIF new_cube = REAL_PART ( FFT ( threedft , 1 , / double , / center )) LOADCT , 0 , / silent filtered_cube = new_cube PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ k - omega Filtered Images pos = cgLayout ([ 6 , 6 ], OXMargin = [ 0 , 0 ], OYMargin = [ 0 , 0 ], XGap = 2 , YGap = 2 ) loadct , 1 imy1 = 0.30 imy2 = 0.50 ! x . ticklen =- 0.055 ! y . ticklen =- 0.055 for i = 0 L , 5 do begin tmppos = reform ( pos [ * , i ]) position = [ tmppos [ 0 ], imy1 , tmppos [ 2 ], imy2 ] im = reform ( filtered_cube [ * , * , i ]) rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 tvlct , R , G , B walsa_image_plot , im , xrange = [ 0 , 129 ], yrange = [ 0 , 129 ], nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = position , xminor = 2 , yminor = 2 cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'Black' , SymSize = 3.2 , / data cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'White' , SymSize = 2.7 , / data cgtext , 20 , 102. , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / data , strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor xyouts , 0.5 , 0.47 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(c) k-' + cgGreek ( 'omega' ) + ' filtered images' , color = cgColor ( 'Black' ) ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ POD Frequency Filtered Spatial Modes podffsmy1 = 0.10 podffsmy2 = 0.30 for i = 0 L , 5 do begin tmppos = reform ( pos [ * , i ]) position = [ tmppos [ 0 ], podffsmy1 , tmppos [ 2 ], podffsmy2 ] podffsm = readfits ( 'Python_parameters/pod_frequency_filtered_spatial_modes_frame' + strtrim ( long ( i ), 2 ) + '.fits' ) im = reform ( podffsm [ * , * , 8 ]) rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 tvlct , R , G , B walsa_image_plot , im , xrange = [ 0 , 129 ], yrange = [ 0 , 129 ], nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = position , xminor = 2 , yminor = 2 cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'Black' , SymSize = 3.2 , / data cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'White' , SymSize = 2.7 , / data cgtext , 20 , 102. , ALIGNMENT = 0.5 , CHARSIZE = 1.1 , / data , strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor xyouts , 0.5 , 0.27 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(d) POD frequency-filtered spatial images' , color = cgColor ( 'Black' ) ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ POD Spatial Modes pos = fltarr ( 4 , 6 ) xl = 0.658 & xr = 0.999 yb = 0.535 & yt = 0.97 xgap = 0. ygap = 0. rows = (( xr - xl ) / 2. ) - xgap cols = (( yt - yb ) / 3. ) - ( 2. * ygap ) pos [ * , 0 ] = [ xl , yb + cols + ygap + cols + ygap , xl + rows , yt ] pos [ * , 1 ] = [ xl + rows + xgap , yb + cols + ygap + cols + ygap , xr , yt ] pos [ * , 2 ] = [ xl , yb + cols + ygap , xl + rows , yb + cols + ygap + cols ] pos [ * , 3 ] = [ xl + rows + xgap , yb + cols + ygap , xr , yb + cols + ygap + cols ] pos [ * , 4 ] = [ xl , yb , xl + rows , yb + cols ] pos [ * , 5 ] = [ xl + rows + xgap , yb , xr , yb + cols ] pod_modes = readfits ( 'Python_parameters/pod_first_6_spatial_modes.fits' ) ! x . ticklen =- 0.058 ! y . ticklen =- 0.058 for i = 0 L , 5 do begin im = reform ( pod_modes [ * , * , i ]) rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 tvlct , R , G , B walsa_image_plot , im , xrange = [ 0 , 129 ], yrange = [ 0 , 129 ], nobar = 1 , zrange = minmax ( im ), / nocolor , $ contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , barpos = 1 , noxval = 1 , distbar = 80 , $ noyval = 1 , cblog = cblog , position = pos [ * , i ], xminor = 2 , yminor = 2 cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'Black' , SymSize = 3.2 , / data cgPlotS , 20 , 109 , PSym = 16 , SymColor = 'White' , SymSize = 2.7 , / data cgtext , 20 , 102. , ALIGNMENT = 0.5 , CHARSIZE = 1.05 , / data , '!5P!X' + strtrim ( long ( i + 1. ), 2 ), color = cgColor ( 'Black' ) endfor xyouts , xl + ( xr - xl ) / 2. , p1_y2 + 0.16 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(b) POD spatial modes' , color = cgColor ( 'Black' ) ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ SPOD Spatial Modes ; Unnecessary to show them here ! The pair SPOD modes are part of the POD frequency - filtered modes ; pos = fltarr ( 4 , 6 ) ; xl = 0.73 & xr = 0.99 ; yb = 0.11 & yt = 0.54 ; xgap = 0. ; ygap = 0. ; ; ! x . ticklen =- 0.055 ; ! y . ticklen =- 0.055 ; ; rows = (( xr - xl ) / 2. ) - xgap ; cols = (( yt - yb ) / 3. ) - ( 2. * ygap ) ; ; pos [ * , 0 ] = [ xl , yb + cols + ygap + cols + ygap , xl + rows , yt ] ; pos [ * , 1 ] = [ xl + rows + xgap , yb + cols + ygap + cols + ygap , xr , yt ] ; pos [ * , 2 ] = [ xl , yb + cols + ygap , xl + rows , yb + cols + ygap + cols ] ; pos [ * , 3 ] = [ xl + rows + xgap , yb + cols + ygap , xr , yb + cols + ygap + cols ] ; pos [ * , 4 ] = [ xl , yb , xl + rows , yb + cols ] ; pos [ * , 5 ] = [ xl + rows + xgap , yb , xr , yb + cols ] ; ; for i = 0 L , 1 do begin ; spod = readfits ( 'Python_parameters/spod_first_20_modes.fits' ) ; ; if i eq 0 then im = reform ( spod [ * , * , 10 ]) ; if i eq 1 then im = reform ( spod [ * , * , 11 ]) ; rgb = sjreadtext ( 'Python_parameters/jet_colormap.txt' ) ; the jet colormap of Python ! ; R = reform ( rgb [ 0 , * ]) * 255 & G = reform ( rgb [ 1 , * ]) * 255 & B = reform ( rgb [ 2 , * ]) * 255 ; tvlct , R , G , B ; walsa_image_plot , im , xrange = xrg , yrange = yrg , nobar = 1 , zrange = minmax ( im ), / nocolor , $ ; contour = 0 , exact = 1 , aspect = 1 , cutaspect = 1 , noxval = 1 , $ ; noyval = 1 , cblog = cblog , position = pos [ * , i ], xminor = 2 , yminor = 2 ; endfor ; ++++++++++++++++++++++++++++++++++++++++++++++++++++++ ; xyouts , x1 + 0.030 , y2 - 0.022 , ALIGNMENT = 0.5 , CHARSIZE = 1.3 , / normal , '(f)' , color = cgColor ( 'Black' ) ! P . Multi = 0 Cleanplot , / Silent print , '' print , 'COMPLETED!' print , '' walsa_endeps , filename = 'Figures/k-omega_and_pod_analyses' done stop END", "title": "Proper Orthogonal Decomposition (POD)"}, {"location": "idl/nrmp-synthetic-data/", "text": "Worked Example - NRMP: Synthetic Datasets \u00b6 This page provides detailed information about the synthetic datasets used in the worked examples presented in the Nature Reviews Methods Primers article. These datasets were carefully crafted to evaluate the performance of various wave analysis techniques in a controlled environment. They comprise a 1D time series and a spatio-temporal datacube, each containing a variety of oscillatory signals with known parameters. Synthetic 1D Time Series \u00b6 The synthetic 1D time series is constructed by combining five sinusoidal waves with distinct frequencies (5, 12, 15, 18, and 25 Hz) and amplitudes. To introduce realistic variability, the amplitudes of these waves are modulated with an envelope function. Additional features, such as a short-lived transient oscillation, a weak high-frequency signal, and a quasi-periodic signature, are also incorporated. Non-linearity is introduced through a mathematical transformation, and random noise is added to simulate measurement imperfections. A second, nearly identical time series is also generated with adjusted phases for some of the wave components. This simulates observing the signal at a different location or time, enabling the evaluation of cross-correlation techniques. Synthetic Spatio-Temporal Datacube \u00b6 The synthetic spatio-temporal datacube comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. The datacube contains 50 concentric circular regions, each with ten sinusoidal waves of distinct frequencies, amplitudes, and phases. Additional complexities, such as a transient cubic polynomial signal, simulated transverse motion, a fluting-like instability, a quasi-periodic signal, and noise, are also incorporated. Detailed Parameters \u00b6 The tables below provide detailed parameter specifications for the synthetic datasets. [Image of Supplementary Table S1 from NRMP article] Table Caption: Parameters for the synthetic 1D time series. [Image of Supplementary Table S2 from NRMP article] Table Caption: Parameters for the synthetic spatio-temporal datacube. These synthetic datasets serve as valuable benchmarks for assessing the capabilities and limitations of different wave analysis techniques. By comparing the analysis results against the known ground truth, researchers can gain insights into the appropriate use cases for each method and improve the reliability of their interpretations when analysing real-world data.", "title": "Worked Example - NRMP: Synthetic Datasets"}, {"location": "idl/nrmp-synthetic-data/#worked-example-nrmp-synthetic-datasets", "text": "This page provides detailed information about the synthetic datasets used in the worked examples presented in the Nature Reviews Methods Primers article. These datasets were carefully crafted to evaluate the performance of various wave analysis techniques in a controlled environment. They comprise a 1D time series and a spatio-temporal datacube, each containing a variety of oscillatory signals with known parameters.", "title": "Worked Example - NRMP: Synthetic Datasets"}, {"location": "idl/nrmp-synthetic-data/#synthetic-1d-time-series", "text": "The synthetic 1D time series is constructed by combining five sinusoidal waves with distinct frequencies (5, 12, 15, 18, and 25 Hz) and amplitudes. To introduce realistic variability, the amplitudes of these waves are modulated with an envelope function. Additional features, such as a short-lived transient oscillation, a weak high-frequency signal, and a quasi-periodic signature, are also incorporated. Non-linearity is introduced through a mathematical transformation, and random noise is added to simulate measurement imperfections. A second, nearly identical time series is also generated with adjusted phases for some of the wave components. This simulates observing the signal at a different location or time, enabling the evaluation of cross-correlation techniques.", "title": "Synthetic 1D Time Series"}, {"location": "idl/nrmp-synthetic-data/#synthetic-spatio-temporal-datacube", "text": "The synthetic spatio-temporal datacube comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. The datacube contains 50 concentric circular regions, each with ten sinusoidal waves of distinct frequencies, amplitudes, and phases. Additional complexities, such as a transient cubic polynomial signal, simulated transverse motion, a fluting-like instability, a quasi-periodic signal, and noise, are also incorporated.", "title": "Synthetic Spatio-Temporal Datacube"}, {"location": "idl/nrmp-synthetic-data/#detailed-parameters", "text": "The tables below provide detailed parameter specifications for the synthetic datasets. [Image of Supplementary Table S1 from NRMP article] Table Caption: Parameters for the synthetic 1D time series. [Image of Supplementary Table S2 from NRMP article] Table Caption: Parameters for the synthetic spatio-temporal datacube. These synthetic datasets serve as valuable benchmarks for assessing the capabilities and limitations of different wave analysis techniques. By comparing the analysis results against the known ground truth, researchers can gain insights into the appropriate use cases for each method and improve the reliability of their interpretations when analysing real-world data.", "title": "Detailed Parameters"}, {"location": "idl/pod-eigenvalues-example/", "text": "Worked Example - NRMP: POD Eigenvalues and Explained Variance \u00b6 The IDL version of this example is currently under development .....", "title": "POD eigenvalues"}, {"location": "idl/pod-eigenvalues-example/#worked-example-nrmp-pod-eigenvalues-and-explained-variance", "text": "The IDL version of this example is currently under development .....", "title": "Worked Example - NRMP: POD Eigenvalues and Explained Variance"}, {"location": "idl/pod-example/", "text": "Worked Example - NRMP: Proper Orthogonal Decomposition (POD) Analysis \u00b6 The IDL version of this example is currently under development .....", "title": "POD analysis"}, {"location": "idl/pod-example/#worked-example-nrmp-proper-orthogonal-decomposition-pod-analysis", "text": "The IDL version of this example is currently under development .....", "title": "Worked Example - NRMP: Proper Orthogonal Decomposition (POD) Analysis"}, {"location": "idl/pod-filtering-example/", "text": "Worked Example - NRMP: POD with Frequency Filtering \u00b6 The IDL version of this example is currently under development .....", "title": "POD filtering"}, {"location": "idl/pod-filtering-example/#worked-example-nrmp-pod-with-frequency-filtering", "text": "The IDL version of this example is currently under development .....", "title": "Worked Example - NRMP: POD with Frequency Filtering"}, {"location": "idl/power-spectra-example/", "text": "Worked Example - NRMP: Power Spectra \u00b6 This example demonstrates the application of various spectral analysis techniques to a synthetic 1D signal constructed with predefined frequencies and amplitudes. The signal includes a range of oscillatory components with different characteristics, including: Dominant oscillations: Five dominant frequencies (5, 12, 15, 18, and 25 Hz) with varying amplitudes. Transient oscillation: A short-lived oscillation with a frequency of 2 Hz. Weak oscillation: A low-amplitude oscillation with a frequency of 33 Hz. Quasi-periodic oscillation: An oscillation with a frequency of 10 Hz and a time-varying amplitude. Noise: Random noise added to the signal. By analysing this synthetic signal with different methods, we can evaluate their ability to accurately identify and characterise these diverse oscillatory components. This provides valuable insights into the strengths and limitations of each technique, guiding the selection of appropriate methods for analysing real-world data. For a comprehensive discussion of the analysis and results, please refer to the associated article in Nature Reviews Methods Primers . Analysis and Figure The figure below presents a comparative analysis of various wave analysis methods applied to the synthetic 1D signal. The signal was pre-processed by detrending (to remove any linear trends) and apodized (to reduce edge effects) using a Tukey window. Methods used: Fast Fourier Transform (FFT) Lomb-Scargle Periodogram Welch's Method Wavelet Transform (with Morlet, Paul, and Mexican Hat wavelets) Global Wavelet Spectrum (GWS) Refined Global Wavelet Spectrum (RGWS) Hilbert-Huang Transform (HHT) with Empirical Mode Decomposition (EMD) and Ensemble EMD (EEMD) WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 3 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Performance of diverse analysis methods on a synthetic 1D time series. (a) The detrended and apodized signal. (b) The unevenly sampled signal. (c) The FFT power spectrum. (d) The Lomb-Scargle periodogram. (e) The global wavelet spectrum (GWS) for the Morlet, Mexican Hat, and Paul wavelets. (f) The refined global wavelet spectrum (RGWS) for the Morlet, Mexican Hat, and Paul wavelets. (g) The HHT spectrum using EMD. (h) The FFT power spectra of the individual IMFs extracted by EMD. (i) The HHT spectrum using EEMD. (j) The FFT power spectra of the individual IMFs extracted by EEMD. (k) The Welch power spectrum. (l)-(n) The wavelet power spectra for the Morlet, Mexican Hat, and Paul wavelets, respectively. All powers are normalized to their maximum value and shown in percentages, with panels (c) , (d) , (h) , and (j) zoomed in on a smaller power range for better visibility of smaller peaks. The 95% confidence levels are indicated by dot-dashed curves for 1D power spectra and solid black contours for wavelet spectra. Vertical lines above each 1D spectrum mark the frequency resolution. Green vertical (or horizontal) lines on the frequency axes indicate the predefined frequencies used to construct the synthetic signal. Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 ; pro FIG3__walsatools_power_spectra data_dir = 'Synthetic_Data/' signal = readfits ( data_dir + 'NRMP_signal_1D.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) sf = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] ; input frequencies nt = n_elements ( time ) fundf = 1. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz colset device , decomposed = 0 walsa_eps , size = [ 30 , 28 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 2.3 barthick = 300 distbar = 300 ; Create uneven sampling n_points = n_elements ( reform ( signal )) ; Define gaps to be removed gap1_size = 17 gap2_size = 42 gap3_size = 95 gap4_size = 46 gaps_size = [ gap1_size , gap2_size , gap3_size , gap4_size ] * 0.01 ; Define start indices for each gap ( for example ) gap1_start = 150 gap2_start = 200 gap3_start = 500 gap4_start = 800 gaps_start = [ gap1_start , gap2_start , gap3_start , gap4_start ] * 0.01 ; Remove gaps indices = LINDGEN ( n_points ) ; Initial set of indices indices = indices [ WHERE ( indices LT gap1_start OR indices GE gap1_start + gap1_size )] indices = indices [ WHERE ( indices LT gap2_start OR indices GE gap2_start + gap2_size )] indices = indices [ WHERE ( indices LT gap3_start OR indices GE gap3_start + gap3_size )] indices = indices [ WHERE ( indices LT gap4_start OR indices GE gap4_start + gap4_size )] ; Reduce both time and signal arrays according to final indices t_uneven = time [ indices ] signal_uneven = signal [ indices ] t_uneven = t_uneven ( sort ( t_uneven )) signal_uneven = signal_uneven ( sort ( t_uneven )) ! P . Multi = [ 0 , 3 , 5 ] ! x . thick = 4.0 ! y . thick = 4.0 ; define range of frequency ( in mHz ), for plotting . limit = 0 xr = [ 0 , 36 ] poswave1 = [ 0.74077778 , 0.787 , 0.94666664 , 0.937 ] poswave2 = [ 0.74077778 , 0.524 , 0.94666664 , 0.674 ] poswave3 = [ 0.7407778 , 0.26 , 0.94666664 , 0.41 ] pos = cgLayout ([ 3 , 5 ], OXMargin = [ 10 , 4 ], OYMargin = [ 7 , 5 ], XGap = 10 , YGap = 11 ) ; -------------------------------------------------------------------------------- ; Wavelet power spectrum : Morlet WaLSAtools , / wavelet , signal = signal , time = time , power = ipower , frequencies = frequencies , significance = isig , mother = 'Morlet' , mode = 1 , coi = icoi frequencies = frequencies / 1000. iperiod = 1. / reform ( frequencies ) ; period in sec nt = n_elements ( reform ( ipower [ * , 0 ])) ; number of data points in time nf = n_elements ( reform ( iperiod )) ; number of data points in frequency itime = time isig = REBIN ( TRANSPOSE ( isig ), nt , nf ) maxp = max ( icoi ) ; maxp = 1. / fundf iit = closest_index ( maxp , iperiod ) iperiod = iperiod [ 0 : iit ] isig = reform ( isig [ * , 0 : iit ]) ipower = reform ( ipower [ * , 0 : iit ]) ipower = reverse ( ipower , 2 ) isig = reverse ( isig , 2 ) sigi = ipower / isig ii = where ( ipower lt 0. , cii ) & if cii gt 0 then ipower ( ii ) = 0. & ipower = 100. * ipower / max ( ipower ) xrg = minmax ( itime ) ; yrg = [ 10. , 0.025 ] yrg = [ max ( iperiod ), min ( iperiod )] ; Load color table 20 and enhance it for better visibility LOADCT , 20 , / SILENT TVLCT , r , g , b , / GET r = BYTSCL ( r , MIN = 90 , MAX = 255 ) g = BYTSCL ( g , MIN = 90 , MAX = 255 ) b = BYTSCL ( b , MIN = 90 , MAX = 255 ) TVLCT , r , g , b walsa_image_plot , ipower , xrange = xrg , yrange = yrg , nobar = 0 , zrange = minmax ( ipower , / nan ), / ylog , $ contour = 0 , / nocolor , xtitle = 'Time (s)' , $ exact = 1 , aspect = 0 , cutaspect = 0 , barpos = 1 , zlen =- 0.75 , distbar = barthick , xticklen =- 0.06 , yticklen =- 0.045 , xxlen =- 0.04 , $ barthick = barthick , charsize = charsize , position = poswave1 , ystyle = 5 , cbfac = 0.9 ztitle = '(l) Power (%) | Morlet Wavelet' xyouts , poswave1 [ 0 ] + (( poswave1 [ 2 ] - poswave1 [ 0 ]) / 2. ), poswave1 [ 3 ] + 0.028 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / normal , ztitle , color = cgColor ( 'Black' ) sjhline , 1. / sf , color = cgColor ( 'Green' ) cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize , yticklen =- 0.03 cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize , yticklen =- 0.03 plots , itime , icoi , noclip = 0 , linestyle = 0 , thick = 2 , color = cgColor ( 'Black' ) ncoi = n_elements ( icoi ) & y = fltarr ( ncoi ) & for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION =- 45 cgContour , sigi , / noerase , levels = 1.01 , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = 1 ; -------------------------------------------------------------------------------- ; Wavelet power spectrum : DOG WaLSAtools , / wavelet , signal = signal , time = time , power = ipower , frequencies = frequencies , significance = isig , mother = 'DOG' , mode = 1 , coi = icoi frequencies = frequencies / 1000. iperiod = 1. / reform ( frequencies ) nt = n_elements ( reform ( ipower [ * , 0 ])) & nf = n_elements ( reform ( iperiod )) itime = time isig = REBIN ( TRANSPOSE ( isig ), nt , nf ) maxp = max ( icoi ) ; maxp = 1. / fundf iit = closest_index ( maxp , iperiod ) iperiod = iperiod [ 0 : iit ] isig = reform ( isig [ * , 0 : iit ]) ipower = reform ( ipower [ * , 0 : iit ]) ipower = reverse ( ipower , 2 ) isig = reverse ( isig , 2 ) sigi = ipower / isig ii = where ( ipower lt 0. , cii ) & if cii gt 0 then ipower ( ii ) = 0. & ipower = 100. * ipower / max ( ipower ) xrg = minmax ( itime ) yrg = [ max ( iperiod ), min ( iperiod )] ; Load color table 20 and enhance it for better visibility LOADCT , 20 , / SILENT TVLCT , r , g , b , / GET r = BYTSCL ( r , MIN = 90 , MAX = 255 ) g = BYTSCL ( g , MIN = 90 , MAX = 255 ) b = BYTSCL ( b , MIN = 90 , MAX = 255 ) TVLCT , r , g , b walsa_image_plot , ipower , xrange = xrg , yrange = yrg , nobar = 0 , zrange = minmax ( ipower , / nan ), / ylog , $ contour = 0 , / nocolor , xtitle = 'Time (s)' , $ exact = 1 , aspect = 0 , cutaspect = 0 , barpos = 1 , zlen =- 0.75 , distbar = barthick , xticklen =- 0.06 , yticklen =- 0.045 , xxlen =- 0.04 , $ barthick = barthick , charsize = charsize , position = poswave2 , ystyle = 5 , cbfac = 0.9 ztitle = '(m) Power (%) | Mexican-Hat Wavelet' xyouts , poswave2 [ 0 ] + (( poswave2 [ 2 ] - poswave2 [ 0 ]) / 2. ), poswave2 [ 3 ] + 0.028 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / normal , ztitle , color = cgColor ( 'Black' ) sjhline , 1. / sf , color = cgColor ( 'Green' ) cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize , yticklen =- 0.03 cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize , yticklen =- 0.03 plots , itime , icoi , noclip = 0 , linestyle = 0 , thick = 2 , color = cgColor ( 'Black' ) ncoi = n_elements ( icoi ) & y = fltarr ( ncoi ) & for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION =- 45 cgContour , sigi , / noerase , levels = 1.01 , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = 1 ; -------------------------------------------------------------------------------- ; Wavelet power spectrum : Paul WaLSAtools , / wavelet , signal = signal , time = time , power = ipower , frequencies = frequencies , significance = isig , mother = 'Paul' , mode = 1 , coi = icoi frequencies = frequencies / 1000. iperiod = 1. / reform ( frequencies ) nt = n_elements ( reform ( ipower [ * , 0 ])) & nf = n_elements ( reform ( iperiod )) itime = time isig = REBIN ( TRANSPOSE ( isig ), nt , nf ) maxp = max ( icoi ) ; maxp = 1. / fundf iit = closest_index ( maxp , iperiod ) iperiod = iperiod [ 0 : iit ] isig = reform ( isig [ * , 0 : iit ]) ipower = reform ( ipower [ * , 0 : iit ]) ipower = reverse ( ipower , 2 ) isig = reverse ( isig , 2 ) sigi = ipower / isig ii = where ( ipower lt 0. , cii ) & if cii gt 0 then ipower ( ii ) = 0. & ipower = 100. * ipower / max ( ipower ) xrg = minmax ( itime ) yrg = [ max ( iperiod ), min ( iperiod )] ; Load color table 20 and enhance it for better visibility LOADCT , 20 , / SILENT TVLCT , r , g , b , / GET r = BYTSCL ( r , MIN = 90 , MAX = 255 ) g = BYTSCL ( g , MIN = 90 , MAX = 255 ) b = BYTSCL ( b , MIN = 90 , MAX = 255 ) TVLCT , r , g , b walsa_image_plot , ipower , xrange = xrg , yrange = yrg , nobar = 0 , zrange = minmax ( ipower , / nan ), / ylog , $ contour = 0 , / nocolor , xtitle = 'Time (s)' , $ exact = 1 , aspect = 0 , cutaspect = 0 , barpos = 1 , zlen =- 0.75 , distbar = barthick , xticklen =- 0.06 , yticklen =- 0.045 , xxlen =- 0.04 , $ barthick = barthick , charsize = charsize , position = poswave3 , ystyle = 5 , cbfac = 0.9 ztitle = '(n) Power (%) | Paul Wavelet' xyouts , poswave3 [ 0 ] + (( poswave3 [ 2 ] - poswave3 [ 0 ]) / 2. ), poswave3 [ 3 ] + 0.028 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / normal , ztitle , color = cgColor ( 'Black' ) sjhline , 1. / sf , color = cgColor ( 'Green' ) cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize , yticklen =- 0.03 cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize , yticklen =- 0.03 plots , itime , icoi , noclip = 0 , linestyle = 0 , thick = 2 , color = cgColor ( 'Black' ) ncoi = n_elements ( icoi ) & y = fltarr ( ncoi ) & for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION =- 45 cgContour , sigi , / noerase , levels = 1.01 , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = 1 ; -------------------------------------------------------------------------------- cgColorFill , [ 0.025 , 0.663 , 0.663 , 0.025 ], [ 0 , 0 , 1 , 1 ], / NORMAL , COLOR = 'LightGray' ; COLOR = 'WT2' cgColorFill , [ 0.66 , 1.01 , 1.01 , 0.66 ], [ 0 , 0 , 0.20 , 0.20 ], / NORMAL , COLOR = 'LightGray' ; -------------------------------------------------------------------------------- ; Plot the detrended & apodized light curve acube = ( reform ( walsa_detrend_apod ( signal )) + mean ( signal )) title = '(c) Time series' cgplot , time , acube * 10. , Thick = 2 , Color = cgColor ( 'DodgerBlue' ), xtitle = 'Time (s)' , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 0 ], $ xs = 1 , yr = [ min ( reform ( acube * 10. )), max ( reform ( acube * 10. ))], / NOERASE , ytitle = 'DN (arb. unit)' , YTICKINTERVAL = 40 ; xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube )), ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) note = '(a) Detrended & apodized synthetic signal' xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube * 10. )) + 12.3 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , note , color = cgColor ( 'Black' ) ; xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube * 10. )) + 10.3 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , 'f (Hz)= ' + stitle , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Plot the detrended & apodized light curve + gaps ( missing data points ) acube = ( reform ( walsa_detrend_apod ( signal )) + mean ( signal )) title = '(c) Time series' cgplot , time , acube * 10. , Thick = 2 , Color = cgColor ( 'DodgerBlue' ), xtitle = 'Time (s)' , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 3 ], $ xs = 1 , yr = [ min ( reform ( acube * 10. )), max ( reform ( acube * 10. ))], / NOERASE , ytitle = 'DN (arb. unit)' , YTICKINTERVAL = 40 ; gaps : the unevenly sampled data for igaps = 0 L , 3 do $ cgColorFill , [ gaps_start [ igaps ], gaps_start [ igaps ] + gaps_size [ igaps ], gaps_start [ igaps ] + gaps_size [ igaps ], gaps_start [ igaps ]], $ [ min ( reform ( acube * 10. )), min ( reform ( acube * 10. )), max ( reform ( acube * 10. )) - 2 , max ( reform ( acube * 10. )) - 2 ], Color = 'LightGray' ; xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube )), ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) note = '(b) The synthetic signal with gaps' xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube * 10. )) + 12.3 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , note , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; FFT power spectrum WaLSAtools , / fft , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , nperm = 1000 frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(c) FFT' cgplot , frequencies , pm , yr = [ 0 , 12 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 1 ], / NOERASE , $ YTICKINTERVAL = 5 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' ; sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 2 , Color = cgColor ( 'Red' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 2 sjhline , 10.5 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) loc = [ 32 , 11 ] cgPlots , [ loc [ 0 ], loc [ 0 ] + 4 ], [ loc [ 1 ] - 2. , loc [ 1 ] - 2. ], linestyle = 3 , color = cgColor ( 'Black' ), thick = 2 , / data xyouts , loc [ 0 ] - 0.2 , loc [ 1 ] - 2.5 , '95 % c onfidence level' , ALIGNMENT = 1 , CHARSIZE = charsize / 2.5 , / data , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Global Wavelet Spectrum : Morlet ( k0 = 6 ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / global , nperm = 1000 , mother = 'Morlet' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(e) GWS' cgplot , frequencies , pm , yr = [ 0 , 119 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 6 ], $ / NOERASE , YTICKINTERVAL = 30 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'DarkGreen' ) sjhline , 105 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'DarkGreen' ), linest = 3 , Thick = 2 fffff = frequencies ; Global Wavelet power spectrum : Paul ( m = 4 ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / global , nperm = 1000 , mother = 'Paul' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) oplot , frequencies , pm , Thick = 6 , Color = cgColor ( 'Blue' ), linestyle = 0 oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Blue' ), linest = 3 , Thick = 2 ; Global Wavelet power spectrum : DOG ( the real - valued Mexican hat wavelet ; m = 2 ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / global , nperm = 1000 , mother = 'DOG' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'Red' ), linestyle = 0 ; oplot , frequencies , pm , Thick = 1 , Color = cgColor ( 'black' ), linestyle = 0 oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Red' ), linest = 3 , Thick = 2 ; oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'black' ), linest = 3 , Thick = 1 ; legends loc = [ 32 , 90 ] & VSpace = 19 & ls = [ 0 , 0 , 0 ] & colors = [ 'DarkGreen' , 'Red' , 'Blue' ] & names = [ 'Morlet' , 'Mexican Hat' , 'Paul' ] for fac = 0 L , 2 do begin cgPlots , [ loc [ 0 ], loc [ 0 ] + 2.5 ], [ loc [ 1 ] - fac * VSpace , loc [ 1 ] - fac * VSpace ], linestyle = ls [ fac ], color = cgColor ( colors [ fac ]), thick = 3 , / data xyouts , loc [ 0 ] - 0.4 , loc [ 1 ] - fac * VSpace - 3.0 , names [ fac ], ALIGNMENT = 1 , CHARSIZE = charsize / 2.5 , / data , color = cgColor ( 'Black' ) endfor ; -------------------------------------------------------------------------------- ; Lomb - scargle power spectrum : suitable for unevenly sampled data . WaLSAtools , / lomb , signal = signal_uneven , time = t_uneven , power = pm , frequencies = frequencies , significance = significance , mode = 1 , nperm = 1000 frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(d) Lomb-Scargle' cgplot , frequencies , pm , yr = [ 0 , 12 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 4 ], $ / NOERASE , YTICKINTERVAL = 5 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 2 , Color = cgColor ( 'Red' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 2 sjhline , 10.5 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Refined Global Wavelet Spectrum ( power - weighted frequency distribution with significant power & unaffected by CoI ): Morlet m = 6 WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / rgws , mother = 'Morlet' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(f) RGWS' cgplot , frequencies , pm , yr = [ 0 , 119 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 7 ], $ / NOERASE , YTICKINTERVAL = 30 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'DarkGreen' ) sjhline , 105 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; RGWS : Paul WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / rgws , nperm = 1000 , mother = 'Paul' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) oplot , frequencies , pm , Thick = 5 , Color = cgColor ( 'Blue' ), linestyle = 0 ; RGWS ( power - weighted frequency distribution with significant power & unaffected by CoI ): DOG m = 2 ( Mexican hat ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / rgws , mother = 'DOG' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'Red' ), linestyle = 0 ; -------------------------------------------------------------------------------- ; ; HHT power spectrum ; WaLSAtools , / hht , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , nperm = 50 , stdlimit = 0.05 ; frequencies = frequencies / 1000. ; pm1 = pm ; pm = 100. * pm / max ( pm1 ) ; title = '(e) HHT (EMD + Hilbert)' ; cgplot , frequencies , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ ; xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 6 ], / NOERASE , YTICKINTERVAL = 30 ; ; sjvline , sf , color = cgColor ( 'Green' ) ; sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] ; oplot , frequencies , pm , Thick = 2 , Color = cgColor ( 'Red' ) ; oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 2 ; sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] ; sjhline , 105 , color = cgColor ( 'Black' ) ; xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; HHT - EMD from Python freq_bins = readfits ( 'Python_parameters/EMD_freq_bins.fits' ) power_spectrum = readfits ( 'Python_parameters/EMD_power_spectrum.fits' ) significance_level = readfits ( 'Python_parameters/EMD_significance_level.fits' ) pm = 100. * power_spectrum / max ( power_spectrum ) title = '(g) HHT (EMD + Hilbert)' cgplot , freq_bins , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 9 ], / NOERASE , YTICKINTERVAL = 30 sjvline , sf , color = cgColor ( 'Green' ) oplot , freq_bins , pm , Thick = 4 , Color = cgColor ( 'Red' ) oplot , freq_bins , 100. * significance_level / max ( power_spectrum ), color = cgColor ( 'Black' ), linest = 3 , Thick = 4 sjvline , freq_bins , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] sjhline , 105 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; EMD from Python : FFT of IMFs psd_spectra_fft = readfits ( 'Python_parameters/EMD_psd_spectra_fft.fits' ) confidence_levels_fft = readfits ( 'Python_parameters/EMD_confidence_levels_fft.fits' ) xf = reform ( psd_spectra_fft [ * , 0 , 0 ]) title = '(h) FFT of IMFs (EMD)' cgplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), yr = [ 0 , 12 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 10 ], / NOERASE , YTICKINTERVAL = 5 icolor = [ 'DodgerBlue' , 'Orange Red' , 'DarkGreen' , 'Red' , 'gray' , 'Orchid' , 'Lime Green' , 'Cyan' ] sjvline , sf , color = cgColor ( 'Green' ) oplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( 0 )) oplot , xf , 100. * reform ( confidence_levels_fft [ * , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 for ic = 1 L , 7 do oplot , reform ( psd_spectra_fft [ * , 0 , ic ]), 100. * reform ( psd_spectra_fft [ * , 1 , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( ic )) for ic = 1 L , 7 do oplot , xf , 100. * reform ( confidence_levels_fft [ * , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 sjvline , xf , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] sjhline , 10.5 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; HHT - EEMD from Python freq_bins = readfits ( 'Python_parameters/EEMD_freq_bins.fits' ) power_spectrum = readfits ( 'Python_parameters/EEMD_power_spectrum.fits' ) significance_level = readfits ( 'Python_parameters/EEMD_significance_level.fits' ) pm = 100. * power_spectrum / max ( power_spectrum ) title = '(i) HHT (EEMD + Hilbert)' cgplot , freq_bins , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 12 ], / NOERASE , YTICKINTERVAL = 30 sjvline , sf , color = cgColor ( 'Green' ) oplot , freq_bins , pm , Thick = 4 , Color = cgColor ( 'Red' ) oplot , freq_bins , 100. * significance_level / max ( power_spectrum ), color = cgColor ( 'Black' ), linest = 3 , Thick = 4 sjvline , freq_bins , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] sjhline , 105 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; EEMD from Python : FFT of IMFs psd_spectra_fft = readfits ( 'Python_parameters/EEMD_psd_spectra_fft.fits' ) confidence_levels_fft = readfits ( 'Python_parameters/EEMD_confidence_levels_fft.fits' ) xf = reform ( psd_spectra_fft [ * , 0 , 0 ]) title = '(j) FFT of IMFs (EEMD)' cgplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), yr = [ 0 , 12 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 13 ], / NOERASE , YTICKINTERVAL = 5 icolor = [ 'DodgerBlue' , 'Orange Red' , 'DarkGreen' , 'Red' , 'gray' , 'Orchid' , 'Lime Green' , 'Cyan' ] sjvline , sf , color = cgColor ( 'Green' ) oplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( 0 )) oplot , xf , 100. * reform ( confidence_levels_fft [ * , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 for ic = 1 L , 7 do oplot , reform ( psd_spectra_fft [ * , 0 , ic ]), 100. * reform ( psd_spectra_fft [ * , 1 , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( ic )) for ic = 1 L , 7 do oplot , xf , 100. * reform ( confidence_levels_fft [ * , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 sjvline , xf , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] sjhline , 10.5 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Welch power spectrum WaLSAtools , / welch , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , window_size = 200. , overlap = 20. frequencies = frequencies / 1000. ; mHz to Hz pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(k) Welch' cgplot , frequencies , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 14 ], / NOERASE , YTICKINTERVAL = 30 sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 4 , Color = cgColor ( 'Red' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 sjhline , 105 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- walsa_endeps , filename = 'Figures/Fig3_power_spectra_1D_signal' ! P . Multi = 0 Cleanplot , / Silent done stop end", "title": "Power Spectra"}, {"location": "idl/power-spectra-example/#worked-example-nrmp-power-spectra", "text": "This example demonstrates the application of various spectral analysis techniques to a synthetic 1D signal constructed with predefined frequencies and amplitudes. The signal includes a range of oscillatory components with different characteristics, including: Dominant oscillations: Five dominant frequencies (5, 12, 15, 18, and 25 Hz) with varying amplitudes. Transient oscillation: A short-lived oscillation with a frequency of 2 Hz. Weak oscillation: A low-amplitude oscillation with a frequency of 33 Hz. Quasi-periodic oscillation: An oscillation with a frequency of 10 Hz and a time-varying amplitude. Noise: Random noise added to the signal. By analysing this synthetic signal with different methods, we can evaluate their ability to accurately identify and characterise these diverse oscillatory components. This provides valuable insights into the strengths and limitations of each technique, guiding the selection of appropriate methods for analysing real-world data. For a comprehensive discussion of the analysis and results, please refer to the associated article in Nature Reviews Methods Primers . Analysis and Figure The figure below presents a comparative analysis of various wave analysis methods applied to the synthetic 1D signal. The signal was pre-processed by detrending (to remove any linear trends) and apodized (to reduce edge effects) using a Tukey window. Methods used: Fast Fourier Transform (FFT) Lomb-Scargle Periodogram Welch's Method Wavelet Transform (with Morlet, Paul, and Mexican Hat wavelets) Global Wavelet Spectrum (GWS) Refined Global Wavelet Spectrum (RGWS) Hilbert-Huang Transform (HHT) with Empirical Mode Decomposition (EMD) and Ensemble EMD (EEMD) WaLSAtools version: 1.0 These particular analyses generate the figure below (the IDL version of Figure 3 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Performance of diverse analysis methods on a synthetic 1D time series. (a) The detrended and apodized signal. (b) The unevenly sampled signal. (c) The FFT power spectrum. (d) The Lomb-Scargle periodogram. (e) The global wavelet spectrum (GWS) for the Morlet, Mexican Hat, and Paul wavelets. (f) The refined global wavelet spectrum (RGWS) for the Morlet, Mexican Hat, and Paul wavelets. (g) The HHT spectrum using EMD. (h) The FFT power spectra of the individual IMFs extracted by EMD. (i) The HHT spectrum using EEMD. (j) The FFT power spectra of the individual IMFs extracted by EEMD. (k) The Welch power spectrum. (l)-(n) The wavelet power spectra for the Morlet, Mexican Hat, and Paul wavelets, respectively. All powers are normalized to their maximum value and shown in percentages, with panels (c) , (d) , (h) , and (j) zoomed in on a smaller power range for better visibility of smaller peaks. The 95% confidence levels are indicated by dot-dashed curves for 1D power spectra and solid black contours for wavelet spectra. Vertical lines above each 1D spectrum mark the frequency resolution. Green vertical (or horizontal) lines on the frequency axes indicate the predefined frequencies used to construct the synthetic signal. Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 ; pro FIG3__walsatools_power_spectra data_dir = 'Synthetic_Data/' signal = readfits ( data_dir + 'NRMP_signal_1D.fits' ) time = readfits ( data_dir + 'NRMP_signal_1D.fits' , ext = 1 ) sf = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] ; input frequencies nt = n_elements ( time ) fundf = 1. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz colset device , decomposed = 0 walsa_eps , size = [ 30 , 28 ] ! p . font = 0 device , set_font = 'helvetica' charsize = 2.3 barthick = 300 distbar = 300 ; Create uneven sampling n_points = n_elements ( reform ( signal )) ; Define gaps to be removed gap1_size = 17 gap2_size = 42 gap3_size = 95 gap4_size = 46 gaps_size = [ gap1_size , gap2_size , gap3_size , gap4_size ] * 0.01 ; Define start indices for each gap ( for example ) gap1_start = 150 gap2_start = 200 gap3_start = 500 gap4_start = 800 gaps_start = [ gap1_start , gap2_start , gap3_start , gap4_start ] * 0.01 ; Remove gaps indices = LINDGEN ( n_points ) ; Initial set of indices indices = indices [ WHERE ( indices LT gap1_start OR indices GE gap1_start + gap1_size )] indices = indices [ WHERE ( indices LT gap2_start OR indices GE gap2_start + gap2_size )] indices = indices [ WHERE ( indices LT gap3_start OR indices GE gap3_start + gap3_size )] indices = indices [ WHERE ( indices LT gap4_start OR indices GE gap4_start + gap4_size )] ; Reduce both time and signal arrays according to final indices t_uneven = time [ indices ] signal_uneven = signal [ indices ] t_uneven = t_uneven ( sort ( t_uneven )) signal_uneven = signal_uneven ( sort ( t_uneven )) ! P . Multi = [ 0 , 3 , 5 ] ! x . thick = 4.0 ! y . thick = 4.0 ; define range of frequency ( in mHz ), for plotting . limit = 0 xr = [ 0 , 36 ] poswave1 = [ 0.74077778 , 0.787 , 0.94666664 , 0.937 ] poswave2 = [ 0.74077778 , 0.524 , 0.94666664 , 0.674 ] poswave3 = [ 0.7407778 , 0.26 , 0.94666664 , 0.41 ] pos = cgLayout ([ 3 , 5 ], OXMargin = [ 10 , 4 ], OYMargin = [ 7 , 5 ], XGap = 10 , YGap = 11 ) ; -------------------------------------------------------------------------------- ; Wavelet power spectrum : Morlet WaLSAtools , / wavelet , signal = signal , time = time , power = ipower , frequencies = frequencies , significance = isig , mother = 'Morlet' , mode = 1 , coi = icoi frequencies = frequencies / 1000. iperiod = 1. / reform ( frequencies ) ; period in sec nt = n_elements ( reform ( ipower [ * , 0 ])) ; number of data points in time nf = n_elements ( reform ( iperiod )) ; number of data points in frequency itime = time isig = REBIN ( TRANSPOSE ( isig ), nt , nf ) maxp = max ( icoi ) ; maxp = 1. / fundf iit = closest_index ( maxp , iperiod ) iperiod = iperiod [ 0 : iit ] isig = reform ( isig [ * , 0 : iit ]) ipower = reform ( ipower [ * , 0 : iit ]) ipower = reverse ( ipower , 2 ) isig = reverse ( isig , 2 ) sigi = ipower / isig ii = where ( ipower lt 0. , cii ) & if cii gt 0 then ipower ( ii ) = 0. & ipower = 100. * ipower / max ( ipower ) xrg = minmax ( itime ) ; yrg = [ 10. , 0.025 ] yrg = [ max ( iperiod ), min ( iperiod )] ; Load color table 20 and enhance it for better visibility LOADCT , 20 , / SILENT TVLCT , r , g , b , / GET r = BYTSCL ( r , MIN = 90 , MAX = 255 ) g = BYTSCL ( g , MIN = 90 , MAX = 255 ) b = BYTSCL ( b , MIN = 90 , MAX = 255 ) TVLCT , r , g , b walsa_image_plot , ipower , xrange = xrg , yrange = yrg , nobar = 0 , zrange = minmax ( ipower , / nan ), / ylog , $ contour = 0 , / nocolor , xtitle = 'Time (s)' , $ exact = 1 , aspect = 0 , cutaspect = 0 , barpos = 1 , zlen =- 0.75 , distbar = barthick , xticklen =- 0.06 , yticklen =- 0.045 , xxlen =- 0.04 , $ barthick = barthick , charsize = charsize , position = poswave1 , ystyle = 5 , cbfac = 0.9 ztitle = '(l) Power (%) | Morlet Wavelet' xyouts , poswave1 [ 0 ] + (( poswave1 [ 2 ] - poswave1 [ 0 ]) / 2. ), poswave1 [ 3 ] + 0.028 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / normal , ztitle , color = cgColor ( 'Black' ) sjhline , 1. / sf , color = cgColor ( 'Green' ) cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize , yticklen =- 0.03 cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize , yticklen =- 0.03 plots , itime , icoi , noclip = 0 , linestyle = 0 , thick = 2 , color = cgColor ( 'Black' ) ncoi = n_elements ( icoi ) & y = fltarr ( ncoi ) & for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION =- 45 cgContour , sigi , / noerase , levels = 1.01 , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = 1 ; -------------------------------------------------------------------------------- ; Wavelet power spectrum : DOG WaLSAtools , / wavelet , signal = signal , time = time , power = ipower , frequencies = frequencies , significance = isig , mother = 'DOG' , mode = 1 , coi = icoi frequencies = frequencies / 1000. iperiod = 1. / reform ( frequencies ) nt = n_elements ( reform ( ipower [ * , 0 ])) & nf = n_elements ( reform ( iperiod )) itime = time isig = REBIN ( TRANSPOSE ( isig ), nt , nf ) maxp = max ( icoi ) ; maxp = 1. / fundf iit = closest_index ( maxp , iperiod ) iperiod = iperiod [ 0 : iit ] isig = reform ( isig [ * , 0 : iit ]) ipower = reform ( ipower [ * , 0 : iit ]) ipower = reverse ( ipower , 2 ) isig = reverse ( isig , 2 ) sigi = ipower / isig ii = where ( ipower lt 0. , cii ) & if cii gt 0 then ipower ( ii ) = 0. & ipower = 100. * ipower / max ( ipower ) xrg = minmax ( itime ) yrg = [ max ( iperiod ), min ( iperiod )] ; Load color table 20 and enhance it for better visibility LOADCT , 20 , / SILENT TVLCT , r , g , b , / GET r = BYTSCL ( r , MIN = 90 , MAX = 255 ) g = BYTSCL ( g , MIN = 90 , MAX = 255 ) b = BYTSCL ( b , MIN = 90 , MAX = 255 ) TVLCT , r , g , b walsa_image_plot , ipower , xrange = xrg , yrange = yrg , nobar = 0 , zrange = minmax ( ipower , / nan ), / ylog , $ contour = 0 , / nocolor , xtitle = 'Time (s)' , $ exact = 1 , aspect = 0 , cutaspect = 0 , barpos = 1 , zlen =- 0.75 , distbar = barthick , xticklen =- 0.06 , yticklen =- 0.045 , xxlen =- 0.04 , $ barthick = barthick , charsize = charsize , position = poswave2 , ystyle = 5 , cbfac = 0.9 ztitle = '(m) Power (%) | Mexican-Hat Wavelet' xyouts , poswave2 [ 0 ] + (( poswave2 [ 2 ] - poswave2 [ 0 ]) / 2. ), poswave2 [ 3 ] + 0.028 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / normal , ztitle , color = cgColor ( 'Black' ) sjhline , 1. / sf , color = cgColor ( 'Green' ) cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize , yticklen =- 0.03 cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize , yticklen =- 0.03 plots , itime , icoi , noclip = 0 , linestyle = 0 , thick = 2 , color = cgColor ( 'Black' ) ncoi = n_elements ( icoi ) & y = fltarr ( ncoi ) & for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION =- 45 cgContour , sigi , / noerase , levels = 1.01 , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = 1 ; -------------------------------------------------------------------------------- ; Wavelet power spectrum : Paul WaLSAtools , / wavelet , signal = signal , time = time , power = ipower , frequencies = frequencies , significance = isig , mother = 'Paul' , mode = 1 , coi = icoi frequencies = frequencies / 1000. iperiod = 1. / reform ( frequencies ) nt = n_elements ( reform ( ipower [ * , 0 ])) & nf = n_elements ( reform ( iperiod )) itime = time isig = REBIN ( TRANSPOSE ( isig ), nt , nf ) maxp = max ( icoi ) ; maxp = 1. / fundf iit = closest_index ( maxp , iperiod ) iperiod = iperiod [ 0 : iit ] isig = reform ( isig [ * , 0 : iit ]) ipower = reform ( ipower [ * , 0 : iit ]) ipower = reverse ( ipower , 2 ) isig = reverse ( isig , 2 ) sigi = ipower / isig ii = where ( ipower lt 0. , cii ) & if cii gt 0 then ipower ( ii ) = 0. & ipower = 100. * ipower / max ( ipower ) xrg = minmax ( itime ) yrg = [ max ( iperiod ), min ( iperiod )] ; Load color table 20 and enhance it for better visibility LOADCT , 20 , / SILENT TVLCT , r , g , b , / GET r = BYTSCL ( r , MIN = 90 , MAX = 255 ) g = BYTSCL ( g , MIN = 90 , MAX = 255 ) b = BYTSCL ( b , MIN = 90 , MAX = 255 ) TVLCT , r , g , b walsa_image_plot , ipower , xrange = xrg , yrange = yrg , nobar = 0 , zrange = minmax ( ipower , / nan ), / ylog , $ contour = 0 , / nocolor , xtitle = 'Time (s)' , $ exact = 1 , aspect = 0 , cutaspect = 0 , barpos = 1 , zlen =- 0.75 , distbar = barthick , xticklen =- 0.06 , yticklen =- 0.045 , xxlen =- 0.04 , $ barthick = barthick , charsize = charsize , position = poswave3 , ystyle = 5 , cbfac = 0.9 ztitle = '(n) Power (%) | Paul Wavelet' xyouts , poswave3 [ 0 ] + (( poswave3 [ 2 ] - poswave3 [ 0 ]) / 2. ), poswave3 [ 3 ] + 0.028 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / normal , ztitle , color = cgColor ( 'Black' ) sjhline , 1. / sf , color = cgColor ( 'Green' ) cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize , yticklen =- 0.03 cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize , yticklen =- 0.03 plots , itime , icoi , noclip = 0 , linestyle = 0 , thick = 2 , color = cgColor ( 'Black' ) ncoi = n_elements ( icoi ) & y = fltarr ( ncoi ) & for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , itime , y , icoi , color = cgColor ( 'Black' ), thick = 1 , / LINE_FILL , ORIENTATION =- 45 cgContour , sigi , / noerase , levels = 1.01 , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = 1 ; -------------------------------------------------------------------------------- cgColorFill , [ 0.025 , 0.663 , 0.663 , 0.025 ], [ 0 , 0 , 1 , 1 ], / NORMAL , COLOR = 'LightGray' ; COLOR = 'WT2' cgColorFill , [ 0.66 , 1.01 , 1.01 , 0.66 ], [ 0 , 0 , 0.20 , 0.20 ], / NORMAL , COLOR = 'LightGray' ; -------------------------------------------------------------------------------- ; Plot the detrended & apodized light curve acube = ( reform ( walsa_detrend_apod ( signal )) + mean ( signal )) title = '(c) Time series' cgplot , time , acube * 10. , Thick = 2 , Color = cgColor ( 'DodgerBlue' ), xtitle = 'Time (s)' , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 0 ], $ xs = 1 , yr = [ min ( reform ( acube * 10. )), max ( reform ( acube * 10. ))], / NOERASE , ytitle = 'DN (arb. unit)' , YTICKINTERVAL = 40 ; xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube )), ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) note = '(a) Detrended & apodized synthetic signal' xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube * 10. )) + 12.3 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , note , color = cgColor ( 'Black' ) ; xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube * 10. )) + 10.3 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , 'f (Hz)= ' + stitle , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Plot the detrended & apodized light curve + gaps ( missing data points ) acube = ( reform ( walsa_detrend_apod ( signal )) + mean ( signal )) title = '(c) Time series' cgplot , time , acube * 10. , Thick = 2 , Color = cgColor ( 'DodgerBlue' ), xtitle = 'Time (s)' , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 3 ], $ xs = 1 , yr = [ min ( reform ( acube * 10. )), max ( reform ( acube * 10. ))], / NOERASE , ytitle = 'DN (arb. unit)' , YTICKINTERVAL = 40 ; gaps : the unevenly sampled data for igaps = 0 L , 3 do $ cgColorFill , [ gaps_start [ igaps ], gaps_start [ igaps ] + gaps_size [ igaps ], gaps_start [ igaps ] + gaps_size [ igaps ], gaps_start [ igaps ]], $ [ min ( reform ( acube * 10. )), min ( reform ( acube * 10. )), max ( reform ( acube * 10. )) - 2 , max ( reform ( acube * 10. )) - 2 ], Color = 'LightGray' ; xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube )), ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) note = '(b) The synthetic signal with gaps' xyouts , min ( time ) + (( max ( time ) - min ( time )) / 2. ), max ( reform ( acube * 10. )) + 12.3 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , note , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; FFT power spectrum WaLSAtools , / fft , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , nperm = 1000 frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(c) FFT' cgplot , frequencies , pm , yr = [ 0 , 12 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 1 ], / NOERASE , $ YTICKINTERVAL = 5 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' ; sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 2 , Color = cgColor ( 'Red' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 2 sjhline , 10.5 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) loc = [ 32 , 11 ] cgPlots , [ loc [ 0 ], loc [ 0 ] + 4 ], [ loc [ 1 ] - 2. , loc [ 1 ] - 2. ], linestyle = 3 , color = cgColor ( 'Black' ), thick = 2 , / data xyouts , loc [ 0 ] - 0.2 , loc [ 1 ] - 2.5 , '95 % c onfidence level' , ALIGNMENT = 1 , CHARSIZE = charsize / 2.5 , / data , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Global Wavelet Spectrum : Morlet ( k0 = 6 ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / global , nperm = 1000 , mother = 'Morlet' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(e) GWS' cgplot , frequencies , pm , yr = [ 0 , 119 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 6 ], $ / NOERASE , YTICKINTERVAL = 30 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'DarkGreen' ) sjhline , 105 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'DarkGreen' ), linest = 3 , Thick = 2 fffff = frequencies ; Global Wavelet power spectrum : Paul ( m = 4 ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / global , nperm = 1000 , mother = 'Paul' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) oplot , frequencies , pm , Thick = 6 , Color = cgColor ( 'Blue' ), linestyle = 0 oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Blue' ), linest = 3 , Thick = 2 ; Global Wavelet power spectrum : DOG ( the real - valued Mexican hat wavelet ; m = 2 ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / global , nperm = 1000 , mother = 'DOG' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'Red' ), linestyle = 0 ; oplot , frequencies , pm , Thick = 1 , Color = cgColor ( 'black' ), linestyle = 0 oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Red' ), linest = 3 , Thick = 2 ; oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'black' ), linest = 3 , Thick = 1 ; legends loc = [ 32 , 90 ] & VSpace = 19 & ls = [ 0 , 0 , 0 ] & colors = [ 'DarkGreen' , 'Red' , 'Blue' ] & names = [ 'Morlet' , 'Mexican Hat' , 'Paul' ] for fac = 0 L , 2 do begin cgPlots , [ loc [ 0 ], loc [ 0 ] + 2.5 ], [ loc [ 1 ] - fac * VSpace , loc [ 1 ] - fac * VSpace ], linestyle = ls [ fac ], color = cgColor ( colors [ fac ]), thick = 3 , / data xyouts , loc [ 0 ] - 0.4 , loc [ 1 ] - fac * VSpace - 3.0 , names [ fac ], ALIGNMENT = 1 , CHARSIZE = charsize / 2.5 , / data , color = cgColor ( 'Black' ) endfor ; -------------------------------------------------------------------------------- ; Lomb - scargle power spectrum : suitable for unevenly sampled data . WaLSAtools , / lomb , signal = signal_uneven , time = t_uneven , power = pm , frequencies = frequencies , significance = significance , mode = 1 , nperm = 1000 frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(d) Lomb-Scargle' cgplot , frequencies , pm , yr = [ 0 , 12 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 4 ], $ / NOERASE , YTICKINTERVAL = 5 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 2 , Color = cgColor ( 'Red' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 2 sjhline , 10.5 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Refined Global Wavelet Spectrum ( power - weighted frequency distribution with significant power & unaffected by CoI ): Morlet m = 6 WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / rgws , mother = 'Morlet' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(f) RGWS' cgplot , frequencies , pm , yr = [ 0 , 119 ], XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 7 ], $ / NOERASE , YTICKINTERVAL = 30 , xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'DarkGreen' ) sjhline , 105 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; RGWS : Paul WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / rgws , nperm = 1000 , mother = 'Paul' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) oplot , frequencies , pm , Thick = 5 , Color = cgColor ( 'Blue' ), linestyle = 0 ; RGWS ( power - weighted frequency distribution with significant power & unaffected by CoI ): DOG m = 2 ( Mexican hat ) WaLSAtools , / wavelet , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , / rgws , mother = 'DOG' frequencies = frequencies / 1000. pm1 = pm pm = 100. * pm / max ( pm1 ) sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 3 , Color = cgColor ( 'Red' ), linestyle = 0 ; -------------------------------------------------------------------------------- ; ; HHT power spectrum ; WaLSAtools , / hht , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , nperm = 50 , stdlimit = 0.05 ; frequencies = frequencies / 1000. ; pm1 = pm ; pm = 100. * pm / max ( pm1 ) ; title = '(e) HHT (EMD + Hilbert)' ; cgplot , frequencies , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ ; xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 6 ], / NOERASE , YTICKINTERVAL = 30 ; ; sjvline , sf , color = cgColor ( 'Green' ) ; sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] ; oplot , frequencies , pm , Thick = 2 , Color = cgColor ( 'Red' ) ; oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 2 ; sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] ; sjhline , 105 , color = cgColor ( 'Black' ) ; xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; HHT - EMD from Python freq_bins = readfits ( 'Python_parameters/EMD_freq_bins.fits' ) power_spectrum = readfits ( 'Python_parameters/EMD_power_spectrum.fits' ) significance_level = readfits ( 'Python_parameters/EMD_significance_level.fits' ) pm = 100. * power_spectrum / max ( power_spectrum ) title = '(g) HHT (EMD + Hilbert)' cgplot , freq_bins , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 9 ], / NOERASE , YTICKINTERVAL = 30 sjvline , sf , color = cgColor ( 'Green' ) oplot , freq_bins , pm , Thick = 4 , Color = cgColor ( 'Red' ) oplot , freq_bins , 100. * significance_level / max ( power_spectrum ), color = cgColor ( 'Black' ), linest = 3 , Thick = 4 sjvline , freq_bins , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] sjhline , 105 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; EMD from Python : FFT of IMFs psd_spectra_fft = readfits ( 'Python_parameters/EMD_psd_spectra_fft.fits' ) confidence_levels_fft = readfits ( 'Python_parameters/EMD_confidence_levels_fft.fits' ) xf = reform ( psd_spectra_fft [ * , 0 , 0 ]) title = '(h) FFT of IMFs (EMD)' cgplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), yr = [ 0 , 12 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 10 ], / NOERASE , YTICKINTERVAL = 5 icolor = [ 'DodgerBlue' , 'Orange Red' , 'DarkGreen' , 'Red' , 'gray' , 'Orchid' , 'Lime Green' , 'Cyan' ] sjvline , sf , color = cgColor ( 'Green' ) oplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( 0 )) oplot , xf , 100. * reform ( confidence_levels_fft [ * , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 for ic = 1 L , 7 do oplot , reform ( psd_spectra_fft [ * , 0 , ic ]), 100. * reform ( psd_spectra_fft [ * , 1 , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( ic )) for ic = 1 L , 7 do oplot , xf , 100. * reform ( confidence_levels_fft [ * , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 sjvline , xf , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] sjhline , 10.5 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; HHT - EEMD from Python freq_bins = readfits ( 'Python_parameters/EEMD_freq_bins.fits' ) power_spectrum = readfits ( 'Python_parameters/EEMD_power_spectrum.fits' ) significance_level = readfits ( 'Python_parameters/EEMD_significance_level.fits' ) pm = 100. * power_spectrum / max ( power_spectrum ) title = '(i) HHT (EEMD + Hilbert)' cgplot , freq_bins , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 12 ], / NOERASE , YTICKINTERVAL = 30 sjvline , sf , color = cgColor ( 'Green' ) oplot , freq_bins , pm , Thick = 4 , Color = cgColor ( 'Red' ) oplot , freq_bins , 100. * significance_level / max ( power_spectrum ), color = cgColor ( 'Black' ), linest = 3 , Thick = 4 sjvline , freq_bins , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] sjhline , 105 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; EEMD from Python : FFT of IMFs psd_spectra_fft = readfits ( 'Python_parameters/EEMD_psd_spectra_fft.fits' ) confidence_levels_fft = readfits ( 'Python_parameters/EEMD_confidence_levels_fft.fits' ) xf = reform ( psd_spectra_fft [ * , 0 , 0 ]) title = '(j) FFT of IMFs (EEMD)' cgplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), yr = [ 0 , 12 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 13 ], / NOERASE , YTICKINTERVAL = 5 icolor = [ 'DodgerBlue' , 'Orange Red' , 'DarkGreen' , 'Red' , 'gray' , 'Orchid' , 'Lime Green' , 'Cyan' ] sjvline , sf , color = cgColor ( 'Green' ) oplot , xf , 100. * reform ( psd_spectra_fft [ * , 1 , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( 0 )) oplot , xf , 100. * reform ( confidence_levels_fft [ * , 0 ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 for ic = 1 L , 7 do oplot , reform ( psd_spectra_fft [ * , 0 , ic ]), 100. * reform ( psd_spectra_fft [ * , 1 , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), Thick = 4 , Color = cgColor ( icolor ( ic )) for ic = 1 L , 7 do oplot , xf , 100. * reform ( confidence_levels_fft [ * , ic ]) / max ( reform ( psd_spectra_fft [ * , 1 , 0 ])), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 sjvline , xf , color = cgColor ( 'Navy' ), yrange = [ 10.5 , 12 ] sjhline , 10.5 , color = cgColor ( 'Black' ) xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 13.5 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- ; Welch power spectrum WaLSAtools , / welch , signal = signal , time = time , power = pm , frequencies = frequencies , significance = significance , mode = 1 , window_size = 200. , overlap = 20. frequencies = frequencies / 1000. ; mHz to Hz pm1 = pm pm = 100. * pm / max ( pm1 ) title = '(k) Welch' cgplot , frequencies , pm , yr = [ 0 , 119 ], xtitle = 'Frequency (Hz)' , ytitle = 'Power (%)' , XTICKINTERVAL = 5 , xr = xr , xminor = 5 , charsize = charsize , $ xticklen =- 0.09 , yticklen =- 0.03 , pos = pos [ * , 14 ], / NOERASE , YTICKINTERVAL = 30 sjvline , sf , color = cgColor ( 'Green' ) oplot , frequencies , pm , Thick = 4 , Color = cgColor ( 'Red' ) oplot , frequencies , 100. * significance / max ( pm1 ), color = cgColor ( 'Black' ), linest = 3 , Thick = 3 sjhline , 105 , color = cgColor ( 'Black' ) sjvline , frequencies , color = cgColor ( 'Navy' ), yrange = [ 105 , 119 ] xyouts , xr [ 0 ] + (( xr [ 1 ] - xr [ 0 ]) / 2. ), 135 , ALIGNMENT = 0.5 , CHARSIZE = charsize / 2. , / data , title , color = cgColor ( 'Black' ) ; -------------------------------------------------------------------------------- walsa_endeps , filename = 'Figures/Fig3_power_spectra_1D_signal' ! P . Multi = 0 Cleanplot , / Silent done stop end", "title": "Worked Example - NRMP: Power Spectra"}, {"location": "idl/routines/", "text": "Under the Hood \u00b6 We strongly recommend everyone to follow the procedure as instructed here when using WaLSAtools \u2014 a user-friendly tool \u2014 which gives you all information you need to do your analysis. However, for experts who want to make themselves familiar with the techniques and codes under the hood, inspect them and modify/develop/improve them, some of the main codes are also provided below. Please note that all codes and their dependencies are available in the GitHub repository . Spectral Analyzer \u00b6 WaLSA_speclizer This code computes power spectrum and its statistical significance level for a 1D signal (or all pixels of an image sequence, i.e., a 3D cube) using FFT (Fast Fourier Transform), Lomb-Scargle, Wavelet, and HHT (Hilbert-Huang Transform) analysis techniques. In addition, the code can output mean power spectrum (averaged over power spectra of several pixels) as well as dominant frequency and power using the above-mentioned analysis methods. WaLSA_speclizer.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_speclizer : WaLSA Spectral Analyzer ; part of -- WaLSAtools -- ; ; PURPOSE : ; Compute power spectrum and its statistical significance level for a 1 D signal ; ( or all pixels of an image sequence , i . e . , a 3 D cube ) using ; FFT ( Fast Fourier Transform ), Lomb - Scargle , Wavelet , or ; HHT ( Hilbert - Huang Transform ) analyses . ; -- Signals are detrended ( linearly or using higher - order polynomial fits ) and ; apodized ( using a Tukey window ) prior to the spectral analysis ( unless otherwise it is omitted ) . ; -- Power ( and significance levels ) are returned in DN ^ 2 / mHz , frequencies in mHz . ; ; CALLING SEQUENCE : ; EXAMPLES : ; power = walsa_speclizer ( cube , time , mode = 1 , / fft , frequency = frequency , significance = significance , siglevel = 0.01 ) ; power = walsa_speclizer ( cube , time , mode = 1 , / wavelet , / global , frequency = frequency , significance = significance ) ; ; + INPUTS : ; data : 1 D time series , or ( x , y , t ) datacube , any type ; ( an ordered sequence of data points , typically some variable quantity measured at successive times . ) ; time : observing times of the time series in seconds ; ; + OPTIONAL KEYWORDS : ; ---- type of analysis ---- ; fft : if set , Fast Fourier Transform ( FFT ) power spectrum is computed : for regular ( evenly sampled ) time series . ; lombscargle : if set , Lomb - Scargle power spectrum is computed : for irregular ( unevenly sampled ) time series . ; hht : if set , a power spectrum associated to EMD + Hilbert Transform is computed : for regular ( evenly sampled ) time series . ; wavelet : if set , Wavelet power spectrum is computed ( default : Morlet function with omega = 6 ): for regular ( evenly sampled ) time series . ; welch : if set , Welch power spectrum is computed ; ---- padding , detrending , and apodization parameters ---- ; padding : oversampling factor : zero padding ( increasing timespan ) to increase frequency resolution ( NOTE : doesn 't add information) ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; resample if recon is set , then by setting resample , amplitudes are scaled to approximate actual values . ; ---- significance - level parameters ---- ; siglevel : significance level ( default : 0.05 = 5 % significance level = 95 % confidence level ) ; nperm : number of random permutations for the significance test -- the larger the better ( default : 1000 ) ; nosignificance : if set , no significance level is calculated . ; ---- power calibration ---- ; mode : outputted power mode : 0 = log ( power ), 1 = linear power ( default ), 2 = sqrt ( power ) = amplitude ; ---- wavelet parameters / options ---- ; mother : wavelet function , providing different localisation / resolution in frequency and in time ( also depends on param , m ) . ; currently , 'Morlet' , 'Paul' , 'DOG' ( derivative of Gaussian ) are available . default : 'Morlet' . ; param : optional mother wavelet parameter . ; For 'Morlet' this is k0 ( wavenumber ), default is 6. ; For 'Paul' this is m ( order ), default is 4. ; For 'DOG' this is m ( m - th derivative ), default is 2 ( i . e . , the real - valued Mexican - hat wavelet ) ; dj : spacing between discrete scales . default : 0.025 ; global : only if wavelet is set : returns global wavelet spectrum ( averaged over time domain ) ; oglobal : global wavelet spectrum excluding regions influenced by cone - of - influence ( CoI ; regions subject to edge effect ) ; rgws : time - integral of wavelet power excluding regions influenced by cone - of - influence and only for those above the confidence level ; this returns power - weighted frequency distribution ( with significant power & unaffected by CoI ) ; Note : this is likely the most correct spectrum ! ; colornoise : if set , noise background is based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 ; ---- HHT parameters / options ---- ; stdlimit : standard deviation to be achieved before accepting an IMF ( recommended value between 0.2 and 0.3 ; perhaps even smaller ); default : 0.2 ; nfilter : Hanning window width for two dimensional smoothing of the Hilbert spectrum . default : 3 ; ( an odd integer , prefrabely equal to or larger than 3 ; equal to 0 to avoid the windowing ) ; emd : if set , intrinsic mode functions ( IMFs ) and their associated frequencies ( i . e . , instantaneous frequencies ) are outputted ; ---- dominant frequency ---- ; nodominantfreq : if set , dominant frequency and dominant power are not calculated ( to , e . g . , save computational time for large datasets ) ; ; + OUTPUTS : ; power : a 1 D array of power ( or a 3 D array if the input is a 3 D cube ) . ; the only exception is for wavelet ( where global is not set ) . ; power is divided by the first ( non - zero ) frequency . unit : DN ^ 2 / mHz ; significance : significance levels , with the same dimension as the power . unit : DN ^ 2 / mHz ; frequency : an array of frequencies , with the same size as the power . unit : mHz ; period : 1 D array of periods ( in seconds ) ; coicube : cone - of - influence cube , only when wavelet analysis is performed --> if wavelet is set ; imf : the intrinsic mode functions ( IMFs ) from EMD alalysis within the HHT --> if hht and emd are set ; instantfreq : instantaneous frequencies of each component time series --> if hht and emd are set ; dominantfreq : dominant frequency , i . e . , frequency corresponding to the maximum power ( in mHz ): same saptial size as input data ( i . e . , 1 D or 2 D ) ; note : if there are multiple peaks with the exact same power , the lowest dominant frequency is returned ! ; dominantpower : power ( in DN ^ 2 / mHz ) corresponding to the dominant frequency : same saptial size as input data ( i . e . , 1 D or 2 D ) ; rangefreq : frequency range over which the dominant frequency is computed . default : full frequency range ; averagedpower : spatially averaged power spectrum ( of multiple 1 D power spectra ) . unit : DN ^ 2 / mHz ; amplitude : a 1 D array of oscillation amplitude ( or a 3 D array if the input is a 3 D cube ) . ; ; MODIFICATION HISTORY ; ; 2010 plotpowermap : Rob Rutten , assembly of Alfred de Wijn 's routines ; ( https : // webspace . science . uu . nl /~ rutte101 / rridl / cubelib / plotpowermap . pro ) ; 2014 - 2021 Extensively modified / extended by Shahin Jafarzadeh , with contributions from Marco Stangalini and David B . Jess ; - ; ---------------------------- HHT ( EMD + Hilbert ) ----------------------------- function getpowerHHT , cube , cadence , stdlimit , nfilter = nfilter , significance = significance , siglevel = siglevel , nperm = nperm , padding = padding , $ frequencies = frequencies , nosignificance = nosignificance , emd = emd , imf = imf , instantfreq = instantfreq , averagedpower = averagedpower , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , amplitude = amplitude , $ originalcube = originalcube , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , $ meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ; Hilbert - Huang Transform ( HHT ) power spectra if padding gt 1 then begin ; zero padding ( optional ): to increase frequency resolution if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( padding , 2 ) + ') .....' print , ' ' endif nx = n_elements ( cube [ * , 0 , 0 ]) ny = n_elements ( cube [ 0 , * , 0 ]) nt = n_elements ( cube [ 0 , 0 , * ]) padded = fltarr ( nx , ny , padding * nt ) mid_point = ROUND (( padding * nt ) / 2. ) lower_point = mid_point - nt / 2. upper_point = mid_point + nt / 2. - 1 padded [ * , * , mid_point - nt / 2. : mid_point + nt / 2. - 1 ] = cube cube = padded endif sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] if silent eq 0 then begin print , ' ' print , ' ...... output Marginal HHT Spectra ' print , ' ' endif dt = cadence IMFcal = walsa_emd_function ( reform ( cube [ 0 , 0 , * ]), stdlimit , dt = dt ) hhs = walsa_hilbert_spec ( IMFcal , dt , freq = frequencies , marginal = pm , nfilter = nfilter ) nff = n_elements ( frequencies ) if frequencies [ 0 ] eq 0 then begin frequencies = frequencies [ 1 : nff - 1 ] pm = pm [ 1 : nff - 1 ] f0 = 1 endif else f0 = 0 nf = n_elements ( frequencies ) frequencies = frequencies * 1000. ; in mHz powermap = fltarr ( nx , ny , nf ) ; HHT power spectra amplitude = fltarr ( nx , ny , nf ) if emd then begin imf = fltarr ( nx , ny , nt , 20 ) ; 20 : maximum number of IMFs that can be created instantfreq = fltarr ( nx , ny , nt , 20 ) endif if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significancec cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) IMFcal = walsa_emd_function ( signal , stdlimit , dt = dt ) hhs = walsa_hilbert_spec ( IMFcal , dt , marginal = pm , nfilter = nfilter , instfreq = instfreq , amplitudemarginal = amplitudemarginal ) nimimf = n_elements ( IMFcal [ 0 , * ]) if emd then begin imf [ ix , iy , * , 0 : nimimf - 1 ] = IMFcal instantfreq [ ix , iy , * , 0 : nimimf - 1 ] = instfreq * 1000. ; instantaneous frequencies in mHz end if f0 then powermap [ ix , iy , * ] = ( pm [ 1 : nff - 1 ] * padding ) / frequencies [ 0 ] else powermap [ ix , iy , * ] = ( pm * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz amplitude [ ix , iy , * ] = amplitudemarginal [ 1 : nff - 1 ] * padding if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) IMFcal = walsa_emd_function ( y_perm , stdlimit , dt = dt ) hhs = walsa_hilbert_spec ( IMFcal , dt , marginal = pstmp , nfilter = nfilter ) ps_perm [ * , ip ] = pstmp [ 1 : nff - 1 ] if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == HHT next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) amplitude = reform ( amplitude ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if emd then begin imf = reform ( imf ) instantfreq = reform ( instantfreq ) endif if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; --------------------------------- Lomb - Scargle ------------------------------- function getpowerLS , cube , time , OFAC = OFAC , siglevel = siglevel , frequencies = frequencies , significance = significance , nperm = nperm , $ nosignificance = nosignificance , averagedpower = averagedpower , amplitude = amplitude , originalcube = originalcube , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , $ meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ; Lomb - scargle power spectra ; The periodogram values ( from LNP_TEST ) are converted to power ( comparable to FFT values ) by myltiplying ; with 2. * variance ( signal , / double ) / nt ( see Numerical Recipes in C : The Art of Scientific Computing ; Press at al . 2007 ) sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] if OFAC gt 1 then begin if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( OFAC , 2 ) + ') .....' print , ' ' endif endif r = LNP_TEST ( reform ( time ), reform ( cube [ 0 , 0 , * ]), / DOUBLE , WK1 = frequencies , WK2 = pm , OFAC = OFAC ) frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) powermap = fltarr ( nx , ny , nf ) ; Lomb - scargle power spectra amplitude = fltarr ( nx , ny , nf ) if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significancec cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) r = LNP_TEST ( reform ( time ), signal , / DOUBLE , WK1 = freq , WK2 = pm , OFAC = OFAC ) powermap [ ix , iy , * ] = (( pm * ( 2. * variance ( signal , / double ) / nt )) * OFAC ) / frequencies [ 0 ] ; in DN ^ 2 / mHz amplitude [ ix , iy , * ] = sqrt ((( 2. * pm * ( 2. * variance ( signal , / double ) / nt )) * OFAC )) ; K . Hocke 1998 , Ann . Geophysics , 16 , 356 if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) results = LNP_TEST ( time , y_perm , / DOUBLE , WK1 = freq , WK2 = psp , OFAC = OFAC ) ps_perm [ * , ip ] = psp * ( 2. * variance ( y_perm , / double ) / nt ) if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * OFAC ) / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == Lomb-Scargle next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) amplitude = reform ( amplitude ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; ----------------------------------- Welch --------------------------------- function welch_psd , cube , cadence , frequencies = frequencies , window_size = window_size , overlap = overlap , wfft_size = wfft_size , significance = significance , $ nperm = nperm , nosignificance = nosignificance , averagedpower = averagedpower , originalcube = originalcube , siglevel = siglevel , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , apod = apod , silent = silent , $ nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original ; Initialize variables sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] ; Assume wfft_size ( nfft ) is equal to window_size for simplicity and clarity wfft_size = window_size step_size = window_size - overlap num_segments = fix (( nt - overlap ) / step_size ) if num_segments le 0 then begin PRINT , ' Number of segments: ' + strtrim ( num_segments , 2 ) + ' (!)' PRINT , ' Error: Overlap or window size too large.' stop endif ; Create a Hann window ( this should be a changable option in future versions ) window = ( 1.0 - cos ( 2 * ! pi * findgen ( window_size ) / ( window_size - 1 ))) / 2.0 frequencies = 1. / ( cadence * 2 ) * findgen ( window_size / 2 + 1 ) / ( window_size / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) powermap = fltarr ( nx , ny , nf ) ; Welch power spectra if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significance cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) ; Process each segment psd = FLTARR ( window_size / 2 + 1 ) for segment = 0 L , num_segments - 1 do begin start_index = segment * step_size end_index = start_index + window_size if end_index gt nt then continue ; Extract the segment and apply the window segment_data = signal [ start_index : end_index ] * window ; Compute the FFT segment_fft = FFT ( segment_data , wfft_size ) ; Compute power spectral density segment_psd = ( ABS ( segment_fft )) ^ 2 / ( window_size * wfft_size ) psd = psd + segment_psd [ 0 : window_size / 2 ] endfor ; Normalize the averaged PSD psd = psd / num_segments powermap [ ix , iy , * ] = psd [ 1 : nff - 1 ] / frequencies [ 0 ] ; in DN ^ 2 / mHz if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) ; Process each segment psd = FLTARR ( window_size / 2 + 1 ) for segment = 0 L , num_segments - 1 do begin start_index = segment * step_size end_index = start_index + window_size if end_index gt nt then continue ; Extract the segment and apply the window segment_data = y_perm [ start_index : end_index ] * window ; Compute the FFT segment_fft = FFT ( segment_data , wfft_size ) ; Compute power spectral density segment_psd = ( ABS ( segment_fft )) ^ 2 / ( window_size * wfft_size ) psd = psd + segment_psd [ 0 : window_size / 2 ] endfor ; Normalize the averaged PSD psd = psd / num_segments ps_perm [ * , ip ] = psd [ 1 : nff - 1 ] if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = signif / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == FFT next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; ----------------------------------- FOURIER ---------------------------------- function getpowerFFT , cube , cadence , siglevel = siglevel , padding = padding , frequencies = frequencies , significance = significance , $ nperm = nperm , nosignificance = nosignificance , averagedpower = averagedpower , amplitude = amplitude , originalcube = originalcube , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , apod = apod , silent = silent , $ nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original ; Fast Fourier Transform ( FFT ) power spectra if padding gt 1 then begin ; zero padding ( optional ): to increase frequency resolution if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( padding , 2 ) + ') .....' print , ' ' endif nx = n_elements ( cube [ * , 0 , 0 ]) ny = n_elements ( cube [ 0 , * , 0 ]) nt = n_elements ( cube [ 0 , 0 , * ]) padded = fltarr ( nx , ny , padding * nt ) mid_point = ROUND (( padding * nt ) / 2. ) lower_point = mid_point - nt / 2. upper_point = mid_point + nt / 2. - 1 padded [ * , * , mid_point - nt / 2. : mid_point + nt / 2. - 1 ] = cube cube = padded endif sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] frequencies = 1. / ( cadence * 2 ) * findgen ( nt / 2 + 1 ) / ( nt / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) powermap = fltarr ( nx , ny , nf ) ; FFT power spectra amplitude = complexarr ( nx , ny , nf ) ; FFT amplitudes if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significance cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) ; single - sided power is doubled ( compared to double - sided power ), assuming P ( \u2212 f ) = P ( f ): spec = ( fft ( signal , - 1 , / double ))[ 0 : nt / 2. ] pm = 2. * ( ABS ( spec ) ^ 2 ) powermap [ ix , iy , * ] = ( pm [ 1 : nff - 1 ] * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz amplitude [ ix , iy , * ] = spec [ 1 : nff - 1 ] * padding if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) pstmp = 2. * ( ABS (( fft ( y_perm , - 1 , / double ))[ 0 : nt / 2. ]) ^ 2. ) ps_perm [ * , ip ] = pstmp [ 1 : nff - 1 ] if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == FFT next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) amplitude = reform ( amplitude ) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; ------------------------------------ WAVELET --------------------------------- function getpowerWAVELET , cube , cadence , dj = dj , mother = mother , siglevel = siglevel , global = global , frequencies = frequencies , $ significance = significance , coicube = coicube , oglobal = oglobal , colornoise = colornoise , param = param , $ padding = padding , nosignificance = nosignificance , averagedpower = averagedpower , psd = psd , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ originalcube = originalcube , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , nperm = nperm , rgws = rgws , silent = silent ; Wavelet power spectra : either wavelet spectra , or global wavelet spectra ( traditional or improved versions ) input_data = cube ; to prevent the input data be modified by functions unintentionally if padding gt 1 then begin ; zero padding ( optional ): to increase frequency resolution if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( padding , 2 ) + ') .....' print , ' ' endif nx = n_elements ( input_data [ * , 0 , 0 ]) ny = n_elements ( input_data [ 0 , * , 0 ]) nt = n_elements ( input_data [ 0 , 0 , * ]) padded = fltarr ( nx , ny , padding * nt ) mid_point = ROUND (( padding * nt ) / 2. ) lower_point = mid_point - nt / 2. upper_point = mid_point + nt / 2. - 1 padded [ * , * , mid_point - nt / 2. : mid_point + nt / 2. - 1 ] = input_data input_data = padded endif siglevel = 1.0 - siglevel ; different convention sizecube = size ( input_data ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] col = reform ( input_data [ 0 , 0 , * ]) col = ( col - TOTAL ( col ) / nt ) ; lag1 = ( A_CORRELATE ( col , 1 ) + SQRT ( A_CORRELATE ( col , 2 ))) / 2. ; Wavelet transform : wave = walsa_wavelet ( reform ( col ), cadence , PERIOD = period , PAD = 1 , COI = coi , MOTHER = mother , / RECON , dj = dj , param = param , J = J , / nodetrendapod ) frequencies = 1. / period frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) if ( global + oglobal + rgws ) gt 1 then begin print print , ' --- [!] Only one of the /global, /oglobal, or /rgws can be flagged at a time!' print stop endif if silent eq 0 then print , ' ' if global eq 1 then begin if silent eq 0 then print , ' ...... global: output \"Traditional\" Global Wavelet Spectrum' ftcube = fltarr ( nx , ny , nf ) endif if oglobal eq 1 then begin if silent eq 0 then print , ' ...... oglobal: output Global Wavelet Spectrum excluding CoI regions' ftcube = fltarr ( nx , ny , nf ) ; power endif if rgws eq 1 then begin if silent eq 0 then print , ' ...... rgws: output rgws Wavelet Spectrum ' if silent eq 0 then print , ' ...... (power-weighted significant frequency distribution, unaffected by CoI)' ftcube = fltarr ( nx , ny , nf ) ; power endif if global eq 0 and oglobal eq 0 and rgws eq 0 then begin if silent eq 0 then print , ' ...... output Wavelet Spectra ' ftcube = fltarr ( nx , ny , nt , nf ) endif if silent eq 0 then begin print , ' ' print , ' Wavelet (mother) function: ' + mother print , ' dj: ' + strtrim ( dj , 2 ) print , ' ' endif iloop = 0 numm = nx * float ( ny ) if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif coicube = fltarr ( nx , ny , nt ) averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin col = reform ( input_data [ ix , iy , * ]) col = ( col - TOTAL ( col ) / nt ) col_copy = col ; lag1 = ( A_CORRELATE ( col , 1 ) + SQRT ( A_CORRELATE ( col , 2 ))) / 2. ; Wavelet transform : wave = walsa_wavelet ( col_copy , cadence , PERIOD = period , PAD = 1 , COI = coi , MOTHER = mother , param = param , / RECON , dj = dj , scale = scale , $ SIGNIF = SIGNIF , SIGLVL = siglevel , / nodetrendapod , colornoise = colornoise , power = power ) if global eq 1 then begin global_ws = TOTAL ( power , 1 , / nan ) / nt ; global wavelet spectrum ( GWS ) ftcube [ ix , iy , * ] = ( reform ( global_ws ) * padding ); / frequencies [ nf - 1 ] global_amp = TOTAL ( wave , 1 , / nan ) / nt if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( ftcube [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif ; GWS significance levels : if nosignificance eq 0 then begin dof = nt - scale ; the - scale corrects for padding at edges global_signif = walsa_wave_signif ( col , cadence , scale , 1 , LAG1 = 0.0 , DOF = dof , MOTHER = mother , CDELTA = Cdelta , PSI0 = psi0 , siglvl = siglevel ) significance [ ix , iy , * ] = ( reform ( global_signif ) * padding ); / frequencies [ nf - 1 ] endif averagedpower = averagedpower + reform ( ftcube [ ix , iy , * ]) endif if global eq 0 and oglobal eq 0 and rgws eq 0 then begin ftcube [ ix , iy , * , * ] = ( reform ( power ) * padding ); / frequencies [ nf - 1 ] if nosignificance eq 0 then significance [ ix , iy , * ] = ( reform ( SIGNIF ) * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 / mHz coicube [ ix , iy , * ] = reform ( coi ) endif ; oglobal : time - average wavelet power only over the areas not affected by CoI if oglobal eq 1 then begin opower = fltarr ( nt , nf ) + ! VALUES . F_NAN for i = 0 L , nt - 1 do begin pcol = reform ( power [ i , * ]) ii = where ( reform ( period ) lt coi [ i ], pnum ) if pnum gt 0 then opower ( i , ii ) = pcol ( ii ) endfor opower = mean ( opower , dimension = 1 , / nan ) ftcube [ ix , iy , * ] = ( opower * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( ftcube [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif ; GWS significance levels : if nosignificance eq 0 then begin ; dof = nt - scale ; the - scale corrects for padding at edges ; global_signif = walsa_wave_signif ( col , cadence , scale , 1 , LAG1 = 0.0 , DOF = dof , MOTHER = mother , CDELTA = Cdelta , PSI0 = psi0 , siglvl = siglevel ) ; significance [ ix , iy , * ] = ( reform ( global_signif ) * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 Nsig = n_elements ( col ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) y_perm = ( y_perm - TOTAL ( y_perm ) / nt ) wave = walsa_wavelet ( y_perm , cadence , PERIOD = period , PAD = 1 , COI = coi , MOTHER = mother , param = param , / RECON , dj = dj , scale = scale , $ / nodetrendapod , colornoise = colornoise , power = powertemp ) opower = fltarr ( nt , nf ) + ! VALUES . F_NAN for i = 0 L , nt - 1 do begin pcol = reform ( powertemp [ i , * ]) ii = where ( reform ( period ) lt coi [ i ], pnum ) if pnum gt 0 then opower ( i , ii ) = pcol ( ii ) endfor ps_perm = mean ( opower , dimension = 1 , / nan ) ; time average only over the areas not affected by CoI if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 endif averagedpower = averagedpower + reform ( ftcube [ ix , iy , * ]) endif ; rgws : time - integral of wavelet power only over the areas not affected by CoI and only for those above the significance level . ; i . e . , 'distribution' of significant frequencies ( unaffected by CoI ) weighted by power . if rgws eq 1 then begin isig = REBIN ( TRANSPOSE ( signif ), nt , nf ) istest = where ( power / isig lt 1.0 , numtest ) if numtest gt 0 then power [ istest ] = ! VALUES . F_NAN ipower = fltarr ( nt , nf ) + ! VALUES . F_NAN for i = 0 L , nt - 1 do begin pcol = reform ( power [ i , * ]) ii = where ( reform ( period ) lt coi [ i ], pnum ) if pnum gt 0 then ipower [ i , ii ] = pcol [ ii ] endfor ; ipower = mean ( ipower , dimension = 1 , / nan ) ipower = total ( ipower , 1 , / nan ) ftcube [ ix , iy , * ] = ( ipower * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( ftcube [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif averagedpower = averagedpower + reform ( ftcube [ ix , iy , * ]) endif endfor iloop = long ( iloop + 1. ) if silent eq 0 then if nx gt 1 or ny gt 1 then print , string ( 13 b ) + ' >>> % f inished: ' ,( iloop * 100. ) / nx , format = '(a,f4.0,$)' endfor powermap = reform ( ftcube ) frequencies = reform ( frequencies ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) coicube = reform ( coicube ) ; if ( global + oglobal + rgws ) gt 0 AND psd eq 1 then begin ; ; Interpolate the power spectrum to a uniform frequency array ( Wavelet 's frequency resolution changes with frequency) ; uniform_freqs = findgen ( n_elements ( frequencies )) * ( max ( frequencies ) - min ( frequencies )) / ( n_elements ( frequencies ) - 1 ) + min ( frequencies ) ; ; powermap = interpol ( powermap , frequencies , uniform_freqs , / SPLINE ) ; ; frequencies = uniform_freqs ; delta_freq = ABS ( frequencies [ 1 ] - frequencies [ 0 ]) ; ; powermap = powermap / delta_freq ; ; averagedpower = averagedpower / delta_freq ; if nodominantfreq eq 0 then dominantpower = dominantpower / delta_freq ; significance = significance / delta_freq ; endif return , powermap end ; ==================================================== MAIN ROUTINE ==================================================== function walsa_speclizer , data , time , $ ; main inputs frequencies = frequencies , significance = significance , coicube = coicube , imf = imf , instantfreq = instantfreq , $ ; main ( additional ) outputs averagedpower = averagedpower , amplitude = amplitude , period = period , $ fft = fft , lombscargle = lombscargle , wavelet = wavelet , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , psd = psd , $ siglevel = siglevel , nperm = nperm , nosignificance = nosignificance , $ ; significance - level parameters mother = mother , param = param , dj = dj , global = global , oglobal = oglobal , rgws = rgws , colornoise = colornoise , $ ; Wavelet parameters / options stdlimit = stdlimit , nfilter = nfilter , emd = emd , $ ; HHT parameters / options mode = mode , silent = silent , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ ; dominant frequency window_size = window_size , overlap = overlap , wfft_size = wfft_size ; Welch parameters cube = reform ( data ) sizecube = size ( cube ) if sizecube [ 0 ] ne 3 then begin if sizecube [ 0 ] eq 1 then begin blablacube = fltarr ( 1 , 1 , sizecube [ 1 ]) blablacube [ 0 , 0 , * ] = cube cube = blablacube endif else begin print , ' ' print , ' [!] The datacube must have either 1 or 3 dimension(s).' print , ' ' stop endelse endif ii = where ( ~ finite ( cube ), / null , cnull ) if cnull gt 0 then cube ( ii ) = median ( cube ) cadence = walsa_mode ( walsa_diff ( time )) temporal_Nyquist = 1. / ( cadence * 2. ) if n_elements ( silent ) eq 0 then silent = 0 if silent eq 0 then begin print , ' ' if sizecube [ 0 ] eq 1 then print , 'The input datacube is of size: [' + ARR2STR ( sizecube [ 1 ], / trim ) + ']' if sizecube [ 0 ] eq 3 then $ print , 'The input datacube is of size: [' + ARR2STR ( sizecube [ 1 ], / trim ) + ', ' + ARR2STR ( sizecube [ 2 ], / trim ) + ', ' + ARR2STR ( sizecube [ 3 ], / trim ) + ']' print , ' ' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + ARR2STR (( cadence * 2. ), / trim ) + ' seconds' if sizecube [ 0 ] eq 1 then print , ' Time series duration = ' + ARR2STR ( cadence * sizecube [ 1 ], / trim ) + ' seconds' if sizecube [ 0 ] eq 3 then print , ' Time series duration = ' + ARR2STR ( cadence * sizecube [ 3 ], / trim ) + ' seconds' print , ' Nyquist frequency = ' + ARR2STR ( temporal_Nyquist * 1000. , / trim ) + ' mHz' print , ' ' endif if n_elements ( global ) eq 0 then global = 0 ; if set , global wavelet will be returned ; otherwsie wavelet 2 D power spectra ( default ) if n_elements ( dj ) eq 0 then dj = 0.025 if n_elements ( fft ) eq 0 then fft = 0 if n_elements ( psd ) eq 0 then psd = 0 if n_elements ( lombscargle ) eq 0 then lombscargle = 0 if n_elements ( hht ) eq 0 then hht = 0 if n_elements ( welch ) eq 0 then welch = 0 if n_elements ( wavelet ) eq 0 then wavelet = 0 if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( nodominantfreq ) eq 0 then nodominantfreq = 0 if n_elements ( siglevel ) eq 0 then siglevel = 0.05 ; 5 % significance level = 95 % confidence level if n_elements ( nperm ) eq 0 then nperm = 1000 if n_elements ( oglobal ) eq 0 then oglobal = 0 if n_elements ( rgws ) eq 0 then rgws = 0 if n_elements ( padding ) eq 0 then padding = 1 if n_elements ( stdlimit ) eq 0 then stdlimit = 0.2 if n_elements ( nfilter ) eq 0 then nfilter = 3 if n_elements ( emd ) eq 0 then emd = 0 if n_elements ( colornoise ) eq 0 then colornoise = 0 ; if set , noise background based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 if n_elements ( mode ) eq 0 then mode = 1 if n_elements ( apod ) eq 0 then apod = 0.1 ; width of Tukey window ( for apodization ) if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 ; detrend the signal and apodize it if n_elements ( pxdetrend ) eq 0 then pxdetrend = 2 ; do proper linear detrending if n_elements ( meandetrend ) eq 0 then meandetrend = 0 ; no spatial detrending if n_elements ( mother ) eq 0 then mother = 'Morlet' ; possible functions : 'Morlet' , 'DOG' , 'Paul' if n_elements ( NFFT ) eq 0 then NFFT = 256 ; detrend and apodize the cube if nodetrendapod eq 0 then begin apocube = walsa_detrend_apod ( cube , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , cadence = cadence , resample_original = resample_original , silent = silent ) endif else apocube = cube sizecube = size ( apocube ) if sizecube [ 0 ] ne 3 then begin if sizecube [ 0 ] eq 1 then begin blablacube = fltarr ( 1 , 1 , sizecube [ 1 ]) blablacube [ 0 , 0 , * ] = apocube apocube = blablacube endif endif if fft then begin if silent eq 0 then begin print , ' ' print , ' -- Perform FFT (Fast Fourier Transform) .....' print , ' ' endif power = getpowerFFT ( apocube , cadence , siglevel = siglevel , padding = padding , frequencies = frequencies , significance = significance , averagedpower = averagedpower , $ nperm = nperm , nosignificance = nosignificance , dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ amplitude = amplitude , originalcube = cube , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , $ meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ) endif if lombscargle then begin if silent eq 0 then begin print , ' ' print , ' -- Perform Lomb-Scargle Transform .....' print , ' ' endif power = getpowerLS ( apocube , time , OFAC = padding , siglevel = siglevel , frequencies = frequencies , significance = significance , averagedpower = averagedpower , amplitude = amplitude , $ nperm = nperm , nosignificance = nosignificance , dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , originalcube = cube , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ) endif if welch then begin if silent eq 0 then begin print , ' ' print , ' -- Perform Welch method .....' print , ' ' endif power = welch_psd ( apocube , cadence , frequencies = frequencies , window_size = window_size , overlap = overlap , wfft_size = wfft_size , significance = significance , $ nperm = nperm , nosignificance = nosignificance , averagedpower = averagedpower , originalcube = cube , siglevel = siglevel , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , apod = apod , silent = silent , $ nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original ) endif if wavelet then begin if silent eq 0 then begin print , ' ' print , ' -- Perform Wavelet Transform .....' print , ' ' endif power = getpowerWAVELET ( apocube , cadence , dj = dj , mother = mother , siglevel = siglevel , global = global , frequencies = frequencies , averagedpower = averagedpower , rgws = rgws , $ significance = significance , coicube = coicube , oglobal = oglobal , colornoise = colornoise , padding = padding , nosignificance = nosignificance , originalcube = cube , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , param = param , nperm = nperm , psd = psd , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ) endif if hht then begin if silent eq 0 then begin print , ' ' print , ' -- Perform HHT (Hilbert-Huang Transform) .....' print , ' ' endif power = getpowerHHT ( apocube , cadence , stdlimit , nfilter = nfilter , significance = significance , siglevel = siglevel , nperm = nperm , originalcube = cube , $ padding = padding , frequencies = frequencies , nosignificance = nosignificance , emd = emd , imf = imf , instantfreq = instantfreq , amplitude = amplitude , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , averagedpower = averagedpower , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ resample_original = resample_original , silent = silent ) endif period = 1000. / frequencies sizecube = size ( power ) dim = sizecube [ 0 ] nx = sizecube [ 1 ] ny = sizecube [ 2 ] if dim le 2 then begin ; wavelet power spectrum if ( mode eq 0 ) then begin power = alog10 ( power ) if nosignificance eq 0 then significance = alog10 ( significance ) endif if ( mode eq 2 ) then begin power = sqrt ( power ) if nosignificance eq 0 then significance = sqrt ( significance ) endif endif if dim eq 3 then begin ; power spectra at multiple pixels nf = sizecube [ 3 ] if ( mode eq 0 ) then begin for jnn = 0 L , nf - 1 do power [ * , * , jnn ] = alog10 ( power [ * , * , jnn ]) if nosignificance eq 0 then for jnn = 0 L , nf - 1 do significance [ * , * , jnn ] = alog10 ( significance [ * , * , jnn ]) endif if ( mode eq 2 ) then begin for jnn = 0 L , nf - 1 do power [ * , * , jnn ] = sqrt ( power [ * , * , jnn ]) if nosignificance eq 0 then for jnn = 0 L , nf - 1 do significance [ * , * , jnn ] = sqrt ( significance [ * , * , jnn ]) endif endif if dim eq 4 then begin ; wavelet power spectra at multiple pixels if ( mode eq 0 ) then begin for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do power [ jx , jy , * , * ] = alog10 ( power [ jx , jy , * , * ]) if nosignificance eq 0 then for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do significance [ jx , jy , * , * ] = alog10 ( significance [ jx , jy , * , * ]) endif if ( mode eq 2 ) then begin for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do power [ jx , jy , * , * ] = sqrt ( power [ jx , jy , * , * ]) if nosignificance eq 0 then for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do significance [ jx , jy , * , * ] = sqrt ( significance [ jx , jy , * , * ]) endif endif if silent eq 0 then begin PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' print , '' print , 'COMPLETED!' print , '' endif return , power end k-\u03c9 Analysis and Fourier Filtering \u00b6 WaLSA_QUB_QUEEFF A variant of the QUEEns Fourier Filtering (QUEEFF) code , to compute k-\u03c9 diagram and perform Fourier filtering in the k-\u03c9 space. WaLSA_qub_queeff.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_QUB_QUEEFF ; part of -- WaLSAtools -- ; ; ORIGINAL CODE : QUEEns Fourier Filtering ( QUEEFF ) code ; WRITTEN , ANNOTATED , TESTED AND UPDATED BY : ; ( 1 ) Dr . David B . Jess ; ( 2 ) Dr . Samuel D . T . Grant ; The original code along with its manual can be downloaded at : https : // bit . ly / 37 mx9ic ; ; WaLSA_QUB_QUEEFF : Slightly modified ( i . e . , a few additional keywords added ) by Shahin Jafarzadeh ; ; CHECK DEPENDENCIES ( MAKE SURE ALL REQUIRED PROGRAMMES ARE INSTALLED ): ; NOTE ; @/ Users / dbj / ARC / IDL_programmes / Fourier_filtering / QUEEFF_code / QUEEFF_dependencies . bat ; ; CALLING SEQUENCE : ; EXAMPLES : ; walsa_qub_queeff , datacube , arcsecpx , time = time , power = power , wavenumber = wavenumber , frequencies = frequencies , koclt = 1 ; walsa_qub_queeff , datacube , arcsecpx , cadence , / filtering , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube ; ; + INPUTS : ; datacube input datacube , normally in the form of [ x , y , t ] ; [ note - at present the input datacube needs to have identical x and y dimensions . if not supplied like this the datacube will be cropped accordingly ! ] ; cadence delta time between sucessive frames - given in seconds . if not set , time must be provided ( see optional inputs ) ; arcsecpx spatial sampling of the input datacube - given in arcseconds per pixel ; ; + OPTIONAL INPUTS : ; ( if optional inputs not supplied , the user will need to interact with the displayed k - omega diagram to define these values ) ; time observing times in seconds ( 1 d array ) . it is ignored if cadence is provided ; filtering if set , filterring is proceeded ; f1 optional lower ( temporal ) frequency to filter - given in mhz ; f2 optional upper ( temporal ) frequency to filter - given in mhz ; k1 optional lower ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; k2 optional upper ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; spatial_torus makes the annulus used for spatial filtering have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; temporal_torus makes the temporal filter have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; no_spatial_filt optional keyword that ensures no spatial filtering is performed on the dataset ( i . e . , only temporal filtering ) ; no_temporal_filt optional keyword that ensures no temporal filtering is performed on the dataset ( i . e . , only spatial filtering ) ; silent : if set , the k - \u03c9 diagram is not plotted ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( wavenumber ) is plotted in logarithmic scale ( base 10 ) ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ( base 10 ) ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; nox2 : if set , 2 nd x - axis ( spatial size , in arcsec ) is not plotted ; ( spatial size ( i . e . , wavelength ) = ( 2 * ! pi ) / wavenumber ) ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ; + OUTPUTS : ; power : 2 d array of power ( see mode for the scale ) ; ( in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ) ; frequencies : 1 d array of frequencies ( in mhz ) ; wavenumber : 1 d array of wavenumber ( in arcsec ^- 1 ) ; filtered_cube : 3 d array of filtered datacube ( if filtering is set ) ; ; ; IF YOU USE THIS CODE , THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED : ; Jess et al . 2017 , ApJ , 842 , 59 ( http : // adsabs . harvard . edu / abs / 2017 ApJ .. .842 .. .59 J ) ; - pro walsa_qub_queeff , datacube , arcsecpx , cadence = cadence , time = time , $ ; main inputs power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube , $ ; main ( additional ) outputs filtering = filtering , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , spatial_torus = spatial_torus , temporal_torus = temporal_torus , $ ; filtering options no_spatial_filt = no_spatial_filt , no_temporal_filt = no_temporal_filt , $ clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , $ ; plotting keywords xtitle = xtitle , ytitle = ytitle , x2ndaxistitle = x2ndaxistitle , y2ndaxistitle = y2ndaxistitle , $ epsfilename = epsfilename , noy2 = noy2 , nox2 = nox2 , smooth = smooth , silent = silent , mode = mode if n_elements ( xtitle ) eq 0 then xtitle = 'Wavenumber (arcsec!U-1!N)' if n_elements ( ytitle ) eq 0 then ytitle = 'Frequency (mHz)' if n_elements ( x2ndaxistitle ) eq 0 then x2ndaxistitle = 'Spatial size (arcsec)!C' if n_elements ( y2ndaxistitle ) eq 0 then y2ndaxistitle = 'Period (s)' if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) ; DEFINE THE SCREEN RESOLUTION TO ENSURE THE PLOTS DO NOT SPILL OVER THE EDGES OF THE SCREEN dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize xsize_cube = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ysize_cube = N_ELEMENTS ( datacube [ 0 , * , 0 ]) zsize_cube = N_ELEMENTS ( datacube [ 0 , 0 , * ]) ; FORCE THE CUBES TO HAVE THE SAME SPATIAL DIMENSIONS IF xsize_cube gt ysize_cube THEN datacube = TEMPORARY ( datacube [ 0 :( ysize_cube - 1 ), * , * ]) IF xsize_cube gt ysize_cube THEN xsize_cube = ysize_cube IF ysize_cube gt xsize_cube THEN datacube = TEMPORARY ( datacube [ * , 0 :( xsize_cube - 1 ), * ]) IF ysize_cube gt xsize_cube THEN ysize_cube = xsize_cube if n_elements ( spatial_torus ) eq 0 then spatial_torus = 1 if n_elements ( temporal_torus ) eq 0 then temporal_torus = 1 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nox2 ) eq 0 then nox2 = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if not keyword_set ( mode ) then mode = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( filtering ) eq 0 then filtering = 0 else silent = 0 ; CALCULATE THE NYQUIST FREQUENCIES spatial_Nyquist = ( 2. * ! pi ) / ( arcsecpx * 2. ) temporal_Nyquist = 1. / ( cadence * 2. ) print , '' print , 'The input datacube is of size: [' + strtrim ( xsize_cube , 2 ) + ', ' + strtrim ( ysize_cube , 2 ) + ', ' + strtrim ( zsize_cube , 2 ) + ']' print , '' print , 'Spatially, the important values are:' print , ' 2-pixel size = ' + strtrim (( arcsecpx * 2. ), 2 ) + ' arcsec' print , ' Field of view size = ' + strtrim (( arcsecpx * xsize_cube ), 2 ) + ' arcsec' print , ' Nyquist wavenumber = ' + strtrim ( spatial_Nyquist , 2 ) + ' arcsec^-1' IF KEYWORD_SET ( no_spatial_filt ) THEN print , '***NO SPATIAL FILTERING WILL BE PERFORMED***' print , '' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * zsize_cube , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' IF KEYWORD_SET ( no_temporal_filt ) THEN print , '***NO TEMPORAL FILTERING WILL BE PERFORMED***' ; MAKE A k - omega DIAGRAM sp_out = DBLARR ( xsize_cube / 2 , zsize_cube / 2 ) print , '' print , 'Constructing a k-omega diagram of the input datacube..........' print , '' ; MAKE THE k - omega DIAGRAM USING THE PROVEN METHOD OF ROB RUTTEN kopower = walsa_plotkopower_funct ( datacube , sp_out , arcsecpx , cadence , apod = 0.1 , kmax = 1. , fmax = 1. ) ; X SIZE STUFF xsize_kopower = N_ELEMENTS ( kopower [ * , 0 ]) dxsize_kopower = spatial_Nyquist / FLOAT ( xsize_kopower - 1. ) kopower_xscale = ( FINDGEN ( xsize_kopower ) * dxsize_kopower ) ; IN arcsec ^- 1 ; Y SIZE STUFF ysize_kopower = N_ELEMENTS ( kopower [ 0 , * ]) dysize_kopower = temporal_Nyquist / FLOAT ( ysize_kopower - 1. ) kopower_yscale = ( FINDGEN ( ysize_kopower ) * dysize_kopower ) * 1000. ; IN mHz Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) kopower_plot = kopower kopower_plot [ * , 1 : * ] = CONVOL ( kopower [ * , 1 : * ], Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) ; normalise to frequency resolution ( in mHz ) freq = kopower_yscale [ 1 : * ] if freq [ 0 ] eq 0 then freq0 = freq [ 1 ] else freq0 = freq [ 0 ] kopower_plot = kopower_plot / freq0 if mode eq 0 then kopower_plot = ALOG10 ( kopower_plot ) if mode eq 2 then kopower_plot = SQRT ( kopower_plot ) LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. x1 = 0.12 x2 = 0.86 y1 = 0.10 y2 = 0.80 ! p . background = 255. ! p . color = 0. ; WHEN PLOTTING WE NEED TO IGNORE THE ZERO 'TH ELEMENT (I.E., THE MEAN f=0) SINCE THIS WILL MESS UP THE LOG PLOT! komegamap = ( kopower_plot )[ 1 : * , 1 : * ] > MIN (( kopower_plot )[ 1 : * , 1 : * ], / nan ) < MAX (( kopower_plot )[ 1 : * , 1 : * ], / nan ) IF silent EQ 0 THEN BEGIN if n_elements ( komega ) eq 0 then komega = 0 else komega = 1 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. positioncb = [ x1 , y2 + 0.11 , x2 , y2 + 0.13 ] IF EPS eq 1 THEN BEGIN walsa_eps , size = [ 20 , 22 ] ! p . font = 0 device , set_font = 'Times-Roman' ! p . charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 positioncb = [ x1 , y2 + 0.12 , x2 , y2 + 0.14 ] ENDIF ELSE BEGIN IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN WINDOW , 0 , xsize = 1000 , ysize = 1000 , title = 'QUEEFF: k-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN WINDOW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'QUEEFF: k-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF ENDELSE walsa_pg_plotimage_komega , komegamap , kopower_xscale [ 1 : * ], kopower_yscale [ 1 : * ], noy2 = noy2 , nox2 = nox2 , smooth = smooth , $ xtitle = 'Wavenumber (arcsec!U-1!N)' , ytitle = 'Frequency (mHz)' , xst = 8 , yst = 8 , xlog = xlog , ylog = ylog , position = [ x1 , y1 , x2 , y2 ], $ xrange = xrange , yrange = yrange , threemin = threemin , fivemin = fivemin , eps = eps tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ position = positioncb , / top , ticknames = tickmarknames , title = 'Log!d10!n(Oscillation Power)' , yticklen = 0.00001 ENDIF IF EPS eq 1 THEN walsa_endeps , filename = epsfilename , / noboundingbox power = komegamap wavenumber = kopower_xscale [ 1 : * ] frequencies = kopower_yscale [ 1 : * ] print , ' ' if filtering then print , ' ..... start filtering (in k-\u03c9 space)' else return print , ' ' ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; STEPS USED TO MAKE SURE THE FREQUENCIES ARE CHOSEN ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; NEED f1 AND k1 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , f1 , / data WAIT , 1.0 ; NEED f2 AND k2 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 IF KEYWORD_SET ( no_spatial_filt ) THEN k1 = kopower_xscale [ 1 ] IF KEYWORD_SET ( no_spatial_filt ) THEN k2 = MAX ( kopower_xscale , / nan ) IF KEYWORD_SET ( no_temporal_filt ) THEN f1 = kopower_yscale [ 1 ] IF KEYWORD_SET ( no_temporal_filt ) THEN f2 = MAX ( kopower_yscale , / nan ) IF ( k1 le 0.0 ) THEN k1 = kopower_xscale [ 1 ] IF ( k2 gt MAX ( kopower_xscale , / nan )) THEN k2 = MAX ( kopower_xscale , / nan ) IF ( f1 le 0.0 ) THEN f1 = kopower_yscale [ 1 ] IF ( f2 gt MAX ( kopower_yscale , / nan )) THEN f2 = MAX ( kopower_yscale , / nan ) IF NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN k1 = kopower_xscale [ 1 ] k2 = MAX ( kopower_xscale , / nan ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 ENDIF print , '' print , 'The preserved wavenumbers are [' + strtrim ( k1 , 2 ) + ', ' + strtrim ( k2 , 2 ) + '] arcsec^-1' print , 'The preserved spatial sizes are [' + strtrim (( 2. * ! pi ) / k2 , 2 ) + ', ' + strtrim (( 2. * ! pi ) / k1 , 2 ) + '] arcsec' print , '' print , 'The preserved frequencies are [' + strtrim ( f1 , 2 ) + ', ' + strtrim ( f2 , 2 ) + '] mHz' print , 'The preserved periods are [' + strtrim ( FIX ( 1. / ( f2 / 1000. )), 2 ) + ', ' + strtrim ( FIX ( 1. / ( f1 / 1000. )), 2 ) + '] seconds' pwavenumber = [ k1 , k2 ] pspatialsize = [( 2. * ! pi ) / k2 ,( 2. * ! pi ) / k1 ] pfrequency = [ f1 , f2 ] pperiod = [ FIX ( 1. / ( f2 / 1000. )), FIX ( 1. / ( f1 / 1000. ))] print , '' print , 'Making a 3D Fourier transform of the input datacube..........' threedft = FFT ( datacube , - 1 , / double , / center ) ; CALCULATE THE FREQUENCY AXES FOR THE 3 D FFT temp_x = FINDGEN (( xsize_cube - 1 ) / 2 ) + 1 is_N_even = ( xsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ spatial_frequencies_orig = ([ 0.0 , temp_x , xsize_cube / 2 , - xsize_cube / 2 + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) $ ELSE $ spatial_frequencies_orig = ([ 0.0 , temp_x , - ( xsize_cube / 2 + 1 ) + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) temp_x = FINDGEN (( zsize_cube - 1 ) / 2 ) + 1 is_N_even = ( zsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ temporal_frequencies_orig = [ 0.0 , temp_x , zsize_cube / 2 , - zsize_cube / 2 + temp_x ] / ( zsize_cube * cadence ) $ ELSE $ temporal_frequencies_orig = [ 0.0 , temp_x , - ( zsize_cube / 2 + 1 ) + temp_x ] / ( zsize_cube * cadence ) ; NOW COMPENSATE THESE FREQUENCY AXES DUE TO THE FACT THE / center KEYWORD IS USED FOR THE FFT TRANSFORM spatial_positive_frequencies = N_ELEMENTS ( WHERE ( spatial_frequencies_orig ge 0. )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 2 )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 NE 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 1 )) temporal_positive_frequencies = N_ELEMENTS ( WHERE ( temporal_frequencies_orig ge 0. )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 2 )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 NE 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 1 )) ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE NEW FREQUENCY AXES DESCRIBED ABOVE IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), - 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ - 1 , - 1 ]) ENDIF ; CONVERT FREQUENCIES AND WAVENUMBERS OF INTEREST INTO ( FFT ) DATACUBE PIXELS pixel_k1_positive = walsa_closest ( k1 , spatial_frequencies_orig ) pixel_k2_positive = walsa_closest ( k2 , spatial_frequencies_orig ) pixel_f1_positive = walsa_closest ( f1 / 1000. , temporal_frequencies ) pixel_f2_positive = walsa_closest ( f2 / 1000. , temporal_frequencies ) pixel_f1_negative = walsa_closest ( - f1 / 1000. , temporal_frequencies ) pixel_f2_negative = walsa_closest ( - f2 / 1000. , temporal_frequencies ) torus_depth = FIX (( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) * 2. torus_center = FIX ((( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) + pixel_k1_positive [ 0 ]) IF KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN ; CREATE A FILTER RING PRESERVING EQUAL WAVENUMBERS FOR BOTH kx AND ky ; DO THIS AS A TORUS TO PRESERVE AN INTEGRATED GAUSSIAN SHAPE ACROSS THE WIDTH OF THE ANNULUS , THEN INTEGRATE ALONG 'z' spatial_torus = FLTARR ( xsize_cube , ysize_cube , torus_depth ) FOR i = 0 , ( FIX ( torus_depth / 2. )) DO BEGIN spatial_ring = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - i )) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + i + 1 )) spatial_ring [ WHERE ( spatial_ring gt 0. )] = 1. spatial_ring [ WHERE ( spatial_ring ne 1. )] = 0. spatial_torus [ * , * , i ] = spatial_ring spatial_torus [ * , * , torus_depth - i - 1 ] = spatial_ring ENDFOR ; INTEGRATE THROUGH THE TORUS TO FIND THE SPATIAL FILTER spatial_ring_filter = TOTAL ( spatial_torus , 3 , / nan ) / FLOAT ( torus_depth ) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF NOT KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - ( FIX ( torus_depth / 2. )))) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + ( FIX ( torus_depth / 2. )) + 1 )) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 spatial_ring_filter [ WHERE ( spatial_ring_filter NE 1. )] = 0. ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = FLTARR ( xsize_cube , ysize_cube ) spatial_ring_filter [ * ] = 1. ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND KEYWORD_SET ( temporal_torus ) THEN BEGIN ; CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 25 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 3 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 25 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 30 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 4 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 30 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 40 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 5 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 40 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 45 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 6 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 45 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 50 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 7 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 50 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 55 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 8 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 55 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 60 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 9 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 60 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 65 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 10 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 65 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 70 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 11 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 70 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 80 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 12 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 80 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 90 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 13 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 90 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 100 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 14 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 100 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 110 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 15 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 110 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 16 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 17 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = temporal_Gaussian temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = temporal_Gaussian temporal_filter = temporal_filter / MAX ( temporal_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND NOT KEYWORD_SET ( temporal_torus ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = 1.0 temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = 1.0 ENDIF IF KEYWORD_SET ( no_temporal_filt ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 1. ENDIF ; MAKE SOME FIGURES FOR PLOTTING - MAKES THINGS AESTHETICALLY PLEASING ! torus_map = MAKE_MAP ( spatial_ring_filter , dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'arcsecs' ) spatial_fft = TOTAL ( threedft , 3 , / nan ) spatial_fft_map = MAKE_MAP ( ALOG10 ( spatial_fft ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'arcsecs' ) spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = MAKE_MAP ( ALOG10 ( spatial_fft_filtered > 1e-15 ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'arcsecs' ) temporal_fft = TOTAL ( TOTAL ( threedft , 2 , / nan ), 1 ) IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN WINDOW , 1 , xsize = 1500 , ysize = 1000 , title = 'QUEEFF: FFT filter specs' IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN WINDOW , 1 , xsize = smallest_screensize , ysize = FIX ( smallest_screensize * 0.8 ), title = 'QUEEFF: FFT filter specs' x1 = 0.07 x2 = 0.33 x3 = 0.40 x4 = 0.66 x5 = 0.72 x6 = 0.98 y1 = 0.07 y2 = 0.47 y3 = 0.56 y4 = 0.96 LOADCT , 5 , / silent IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN plot_map , spatial_fft_map , charsize = 2 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = 'Wavenumber (k!Dy!N ; arcsec!U-1!N)' , title = 'Spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x1 , y3 , x2 , y4 ] PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 0 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 0 LOADCT , 0 , / silent plot_map , torus_map , charsize = 2 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Spatial FFT filter' , dmin = 0 , dmax = 1 , position = [ x3 , y3 , x4 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 LOADCT , 5 , / silent plot_map , spatial_fft_filtered_map , charsize = 2 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Filtered spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x5 , y3 , x6 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 PLOT , temporal_frequencies * 1000. , ABS ( temporal_fft ), / ylog , xst = 1 , xticklen =- .026 , yticklen =- .011 , charsize = 2 , xtitle = 'Frequency (mHz)' , ytitle = 'Power (arb. units)' , position = [ x1 + 0.05 , y1 , x6 , y2 ], / noerase temporal_fft_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) temporal_fft_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) PLOTS , [ 0 , 0 ], [ temporal_fft_plot_ymin , temporal_fft_plot_ymax ], line = 2 , thick = 2 , color = 0 LOADCT , 39 , / silent OPLOT , temporal_frequencies * 1000. , ( temporal_filter ) > temporal_fft_plot_ymin , line = 2 , color = 55 , thick = 2 OPLOT , temporal_frequencies * 1000. , ( ABS ( temporal_fft * temporal_filter )) > temporal_fft_plot_ymin , line = 0 , color = 254 , thick = 2 LOADCT , 5 , / silent WAIT , 0.5 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN plot_map , spatial_fft_map , charsize = 1 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = 'Wavenumber (k!Dy!N ; arcsec!U-1!N)' , title = 'Spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x1 , y3 , x2 , y4 ] PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 0 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 0 LOADCT , 0 , / silent plot_map , torus_map , charsize = 1 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Spatial FFT filter' , dmin = 0 , dmax = 1 , position = [ x3 , y3 , x4 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 LOADCT , 5 , / silent plot_map , spatial_fft_filtered_map , charsize = 1 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Filtered spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x5 , y3 , x6 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 PLOT , temporal_frequencies * 1000. , ABS ( temporal_fft ), / ylog , xst = 1 , charsize = 1 , xticklen =- .026 , yticklen =- .011 , xtitle = 'Frequency (mHz)' , ytitle = 'Power (arb. units)' , position = [ x1 + 0.05 , y1 , x6 , y2 ], / noerase temporal_fft_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) temporal_fft_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) PLOTS , [ 0 , 0 ], [ temporal_fft_plot_ymin , temporal_fft_plot_ymax ], line = 2 , thick = 2 , color = 0 LOADCT , 39 , / silent OPLOT , temporal_frequencies * 1000. , ( temporal_filter ) > temporal_fft_plot_ymin , line = 2 , color = 55 , thick = 2 OPLOT , temporal_frequencies * 1000. , ( ABS ( temporal_fft * temporal_filter )) > temporal_fft_plot_ymin , line = 0 , color = 254 , thick = 2 LOADCT , 5 , / silent WAIT , 0.5 ENDIF ; APPLY THE GAUSSIAN FILTERS TO THE DATA TO PREVENT ALIASING FOR i = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , i ] = REFORM ( threedft [ * , * , i ]) * spatial_ring_filter FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO BEGIN threedft [ x , y , * ] = REFORM ( threedft [ x , y , * ]) * temporal_filter ENDFOR ENDFOR ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE / center CALL IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ 1 , 1 ]) ENDIF new_cube = REAL_PART ( FFT ( threedft , 1 , / double , / center )) LOADCT , 0 , / silent filtered_cube = new_cube PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' ! P . Multi = 0 Cleanplot , / Silent print , '' print , 'COMPLETED!' print , '' END This code uses the following routine (originanly from Rob Rutten) to compute the k-\u03c9 power. WaLSA_plotkopower_funct.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; NAME : plotkopower --> walsa_plotkopower_funct ; ; PURPOSE : plot \"k-omega\" diagram = Fourier power at temporal frequency ; f against horizontal spatial wavenumber k_h ; ; CALLING SEQUENCE : ; plotkopower , cube , arcsecpx , cadence , plotfilename , $ ; apod = apod , $ ; kmax = kmax , fmax = fmax , minpower = minpower , maxpower = maxpower , $ ; contours = contours , lamb = lamb , fundamental = fundamental ; ; INPUTS : ; cube : ( x , y , t ) data cube , any type ; arcsecpx = angular image scale in arcsec / px ; cadence : [ regular ] sampling cadence in sec ; plotfilename : postscript output file name ; optional keywords : ; apod : fractional extent of apodization edges ; default 0.1 ; kmax : maximum k_h axis as fraction of Nyquist value , default 0.2 ; fmax : maximum f axis as fraction of Nyquist value , default 0.5 ; minpower : minimum of power plot range , default maxpower - 5 ; maxpower : maximum of power plot range , default alog10 ( max ( power )) ; contours : set true to plot contours ; lamb : value > 0 overplots Lamb line omeha = c_s kn at c_s = lamb km / s ; fundamental : set true to overplot fundamental mode omega = sqrt ( g k_h ) ; ; MODIFICATION HISTORY : ; Sep 2010 : Rob Rutten ( RR ) assembly of Alfred de Wijn 's routines. ; Okt 2010 : RR optional overplots Lamb line and fundamental mode ; SJ modified : based on latest version of this code ( Mar 2 2012 ): Mar 2011 : RR - 1 > + 1 line 162 from Alfred de Wijn ; - ; ----------------------------------------------------------------------- function avgstd , array , stdev = stdev ; get array average + standard deviation ; RR Aug 23 2010 found in Mabula Haverkamp 's IDL, later also AdW ; RR not the same as avg . pro in ssw ; RR not the same as avg . pro in Pit Suetterlin DOT software ; RR so renamed to avgstd avrg = total ( array , / nan ) / n_elements ( array ) stdev = sqrt ( total (( array - avrg ) ^ 2 , / nan ) / n_elements ( array )) return , avrg end ; ---------------------------------------------------------------------------- function linear , x , p ; RR used in temporal detrending ymod = p [ 0 ] + x * p [ 1 ] return , ymod end ; ---------------------------------------------------------------------------- function gradient , x , y , p ; RR used in spatail detrending zmod = p [ 0 ] + x * p [ 1 ] + y * p [ 2 ] return , zmod end ; ---------------------------------------------------------------------------- function apod3dcube , cube , apod ; apodizes cube in all three coordinates , with detrending ; get cube dimensions sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] apocube = fltarr ( nx , ny , nt ) ; define temporal apodization apodt = fltarr ( nt ) + 1 if ( apod ne 0 ) then begin apodrimt = nt * apod apodt [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrimt ) / apodrimt )) ^ 2 apodt = apodt * shift ( rotate ( apodt , 2 ), 1 ) ; RR had ik nooit verzonnen endif ; temporal detrending , not per px , only mean - image trend ttrend = fltarr ( nt ) tf = findgen ( nt ) + 1 for it = 0 , nt - 1 do begin img = cube [ * , * , it ] ttrend [ it ] = avgstd ( img ) endfor fitp = mpfitfun ( 'linear' , tf , ttrend , fltarr ( nt ) + 1 , [ 1000. , 0. ], / quiet ) fit = fitp [ 0 ] + tf * fitp [ 1 ] ; temporal apodization per ( x , y ) column ; RR do not reinsert trend to keep [ 0 , 0 ] Fourier pixel from dominating for it = 0 , nt - 1 do begin img = cube [ * , * , it ] apocube [ * , * , it ] = ( img - fit [ it ]) * apodt [ it ] ; RR + ttrend [ it ] endfor ; define spatial apodization apodx = fltarr ( nx ) + 1 apody = fltarr ( ny ) + 1 if ( apod ne 0 ) then begin apodrimx = apod * nx apodrimy = apod * ny apodx [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrimx ) / apodrimx )) ^ 2 apody [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrimy ) / apodrimy )) ^ 2 apodx = apodx * shift ( rotate ( apodx , 2 ), 1 ) apody = apody * shift ( rotate ( apody , 2 ), 1 ) apodxy = apodx # apody endif if ( apod eq 0 ) then begin apodxy = apodx # apody endif ; spatial gradient removal + apodizing per image xf = fltarr ( nx , ny ) + 1. yf = xf for it = 0 , nt - 1 do begin img = apocube [ * , * , it ] avg = avgstd ( img ) ; RR mpfit2dfun = ssw / gen / idl / fitting / mpfit / mpfit2dfun . pro fitp = mpfit2dfun ( 'gradient' , xf , yf , img , fltarr ( nx , ny ) + 1 ,[ 1000. , 0. , 0. ], / quiet ) fit = fitp [ 0 ] + xf * fitp [ 1 ] + yf * fitp [ 2 ] apocube [ * , * , it ] = ( img - fit ) * apodxy + avg endfor ; done return , apocube end ; --------------------------------------------------------------------------- function ko_dist , sx , sy , double = double ; set up Pythagoras distance array from origin ; RR from Alfred de Wijn email Aug 30 2010 dx = rebin ( dindgen ( sx / 2 + 1 ) / ( sx / 2 ), sx / 2 + 1 , sy / 2 + 1 ) dy = rotate ( rebin ( dindgen ( sy / 2 + 1 ) / ( sy / 2 ), sy / 2 + 1 , sx / 2 + 1 ), 1 ) dxy = sqrt ( dx ^ 2 + dy ^ 2 ) * ( min ([ sx , sy ], / nan ) / 2 + 1. ) afstanden = dblarr ( sx , sy ) afstanden [ 0 , 0 ] = dxy ; get other quadrants afstanden [ sx / 2 , 0 ] = rotate ( dxy [ 1 : * , * ], 5 ) ; RR 5 = 90 deg afstanden [ 0 , sy / 2 ] = rotate ( dxy [ * , 1 : * ], 7 ) ; RR 7 = 270 deg afstanden [ sx / 2 , sy / 2 ] = rotate ( dxy [ 1 : * , 1 : * ], 2 ) ; RR 2 = 180 deg if not keyword_set ( double ) then afstanden = fix ( round ( afstanden )) return , afstanden end ; --------------------------------------------------------------------------- function averpower , cube ; compute 2 D ( k_h , f ) power array by circular averaging over k_x , k_y ; get cube dimensions sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] ; forward fft and throw away half of it ; perform fft in time direction first fftcube = ( fft ( fft (( fft ( cube , - 1 , dimension = 3 ))[ * , * , 0 : nt / 2 ], - 1 , dimension = 1 ), dimension = 2 )) ; set up distances fftfmt = size ( fftcube ) afstanden = ko_dist ( nx , ny ) ; RR integer - rounded Pythagoras array ; maxdist = min ([ nx , ny ]) / 2 - 1 ; RR largest quarter circle maxdist = min ([ nx , ny ], / nan ) / 2 + 1 ; RR largest quarter circle --> from RR on Mar 2011 ! ; get average power over all k_h distances , building power ( k_h , f ) avpow = fltarr ( maxdist + 1 , nt / 2 + 1 ) for i = 0 , maxdist do begin waar = where ( afstanden eq i ) for j = 0 , nt / 2 do begin w1 = ( fftcube [ * , * , j ])[ waar ] avpow [ i , j ] = total ( w1 * conj ( w1 ), / nan ) / n_elements ( waar ) endfor ;; writeu , - 1 , string ( format = '(%\" \\r computing avpow... \",i6,\"/\",i6)' , i , maxdist ) endfor ; done return , avpow end ; --------------------------------------------------------------------------- pro koplotpow , avpow , arcsecpx , cadence , kmax , fmax , minpower , maxpower ; plotting program sizepow = size ( avpow ) ; select extent = fractions of Nyquist values plotrange = [ fix ( sizepow [ 1 ] * kmax ), fix ( sizepow [ 2 ] * fmax )] plotpow = avpow [ 0 : plotrange [ 0 ] - 1 , 0 : plotrange [ 1 ] - 1 ] ; RR 5 x5 resizing , I guess for better tick positioning and contours xas = 2. * ! pi / ( arcsecpx * 2 ) * findgen ( plotrange [ 0 ]) / ( sizepow [ 1 ] - 1 ) rexas = 2. * ! pi / ( arcsecpx * 2 ) * findgen ( plotrange [ 0 ] * 5 ) / ( sizepow [ 1 ] * 5 - 1 ) yas = 1. / ( cadence * 2 ) * findgen ( plotrange [ 1 ]) / ( sizepow [ 2 ] - 1 ) * 1e3 reyas = 1. / ( cadence * 2 ) * findgen ( plotrange [ 1 ] * 5 ) / ( sizepow [ 2 ] * 5 - 1 ) * 1e3 plotpowrebin = convol ( rebin ( plotpow , plotrange [ 0 ] * 5 , plotrange [ 1 ] * 5 ), fltarr ( 6 , 6 ) + 1 / ( 6. * 6. ), / edge_truncate ) ; plotpowrebin = plotpow xrange = [ min ( xas , / nan ), max ( xas , / nan )] yrange = [ min ( yas , / nan ), max ( yas , / nan )] tvframe , alog10 ( plotpowrebin ) > minpower < maxpower , / ba , / sa , / as , xrange = xrange , yrange = yrange , xtitle = 'k_h [arcsec!U-1!N]' , ytitle = 'f [mHz]' ; plot wavelength axis along top if ( xrange [ 1 ] lt 10 ) then begin ; RR I wonder how to automate this wavtickspos = [ 10 , 5 , 3 , 2 , 1.5 , 1 ] wavticksn = [ '10' , '5' , '3' , '2' , '1.5' , '1' ] endif else if ( xrange [ 1 ] lt 20 ) then begin wavtickspos = [ 10 , 5 , 3 , 2 , 1.5 , 1 , 0.5 ] wavticksn = [ '10' , '5' , '3' , '2' , '1.5' , '1' , '0.5' ] endif else if ( xrange [ 1 ] lt 50 ) then begin wavtickspos = [ 5.0 , 2.0 , 1.0 , 0.5 , 0.2 ] wavticksn = [ '5' , '2' , '1' , '0.5' , '0.2' ] endif else begin wavtickspos = [ 5.0 , 2.0 , 1.0 , 0.5 , 0.2 , 0.1 , 0.05 ] wavticksn = [ '5' , '2' , '1' , '0.5' , '0.2' , '0.1' , '0.05' ] endelse wavticks = n_elements ( wavtickspos ) - 1 wavticksv = 2. * ! pi / wavtickspos ; RR wavelength from circle frequency axis , / xaxis , xticks = wavticks , xtickv = wavticksv , xtickname = wavticksn , ticklen =- 0.015 / 0.53 , xminor = 1 , xtitle = 'wavelength [arcsec]' ; plot period axis along righthand side if ( yrange [ 1 ] lt 10 ) then begin ; RR I wonder how to automate this pertickspos = [ 20 , 10 , 5 , 3 , 2 , 1 ] perticksn = [ '20' , '10' , '5' , '3' , '2' , '1' ] endif else if ( yrange [ 1 ] lt 20 ) then begin pertickspos = [ 10 , 5 , 3 , 2 , 1.5 , 1 , 0.5 ] perticksn = [ '10' , '5' , '3' , '2' , '1.5' , '1' , '0.5' ] endif else if ( yrange [ 1 ] lt 50 ) then begin pertickspos = [ 10 , 5 , 2 , 1 , 0.5 , 0.2 , 0.1 ] perticksn = [ '10' , '5' , '2' , '1' , '0.5' , '0.2' , '0.1' ] endif else if ( yrange [ 1 ] lt 100 ) then begin pertickspos = [ 2 , 1 , 0.5 , 0.2 , 0.1 ] perticksn = [ '2' , '1' , '0.5' , '0.2' , '0.1' ] endif else begin pertickspos = [ 0.5 , 0.2 , 0.1 , 0.05 , 0.02 ] perticksn = [ '0.5' , '0.2' , '0.1' , '0.05' , '0.02' ] endelse perticks = n_elements ( pertickspos ) - 1 perticksv = 1e3 / pertickspos / 60. ; RR period , from mHz to min axis , / yaxis , yticks = perticks , ytickv = perticksv , ytickname = perticksn , ticklen =- 0.015 / 0.7 , yminor = 1 , ytitle = 'period [min]' end ; --------------------------- main part ------------------------------ FUNCTION walsa_plotkopower_funct , cube , sp_out , arcsecpx , cadence , apod = apod , kmax = kmax , fmax = fmax , minpower = minpower , maxpower = maxpower ; wrapper calling the above subroutines if ( n_elements ( apod ) ne 0 ) then apod = apod else apod = 0.1 if ( n_elements ( kmax ) ne 0 ) then kmax = kmax else kmax = 1.0 if ( n_elements ( fmax ) ne 0 ) then fmax = fmax else fmax = 1.0 if ( kmax gt 1 ) then kmax = 1 if ( fmax gt 1 ) then fmax = 1 ; apodize the cube apocube = apod3dcube ( cube , apod ) ; compute radially - averaged power avpow = averpower ( apocube ) sp_out = avpow ; set min , max cutoffs maxavpow = alog10 ( max ( avpow , / nan )) minavpow = alog10 ( min ( avpow , / nan )) print , ' max log(power) = ' , maxavpow , ' min log(power) = ' , minavpow if ( n_elements ( maxpower ) ne 0 ) then maxpower = maxpower else maxpower = maxavpow if ( n_elements ( minpower ) ne 0 ) then minpower = minpower else minpower = maxpower - 5 ; print , kmax , fmax ; plot the diagram ; koplotpow , avpow , arcsecpx , cadence , kmax , fmax , minpower , maxpower ; done RETURN , sp_out end B-\u03c9 Analysis \u00b6 WaLSA_bomega This routine computes and plots B-\u03c9 diagram, based on the approach introduced in this scientific article . WaLSA_bomega.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_Bomega ; part of -- WaLSAtools -- ; ; PURPOSE : ; Compute ( and plot ) B - \u03c9 diagram : average FFT power spectra ; for various magnetic - field bins within the FoV ; Note : ( 1 ) The entire cube is detrended ( linearly ) ; and apodized ( in both spatial and temporal domains ) ; prior to the FFT analysis ; ( 2 ) Plotted B - \u03c9 is smoothed for better visibility ; ; CALLING SEQUENCE : ; walsa_bomega , datacube , Bmap , time , power = power , frequencies = frequencies , Barray = Barray ; ; + INPUTS : ; datacube : datacube in the form of [ x , y , t ] ; bmap : magnetic - field map ( in G ), in the form of [ x , y ] ; -- should spatially be the same size as the datacube ; time : time of the observations in sec ; ; + OPTIONAL KEYWORDS : ; binsize : magnetic - field bin size ( default : 50 G ) ; silent : if set , the B - \u03c9 map is not displayed . ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( magnetic field ) is plotted in logarithmic scale ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; normalizedbins if set , power at each bin is normalized to its maximum value ; ( this facilitates visibility of relatively small power ) ; xtickinterval x - asis ( i . e . , magnetic fields ) tick intervals in G ( default : 400 G ) ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ---- detrending , and apodization parameters ---- ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; ; + OUTPUTS : ; power : B - \u03c9 map , a stack of average power spectra ( in magnetic - field bins ) ; along y axis -> The x and y axes are B ( in G ) and ; frequency ( in mHz ); in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ( see mode for the scale ) ; frequencies : frequencies of the power spectra ; ( i . e . , values of the y axis of the B - \u03c9 map ) ; barray : magnetic - field values of the middle of the bins ; ( i . e . , values of the x axis of the B - \u03c9 map ) ; ; ; + CREDITS : ; Author : Shahin Jafarzadeh , March 2021. ; Note : if YOU USE THIS CODE , then PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS INTRODUCED : ; Stangalini et al . 2021 , A & A , in press ( https : // ui . adsabs . harvard . edu / abs / 2021 arXiv210311639S ) ; - pro walsa_bomega , datacube , Bmap , cadence = cadence , time = time , binsize = binsize , power = power , frequencies = frequencies , Barray = Barray , $ silent = silent , clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , $ ; plotting keywords xrange = xrange , yrange = yrange , epsfilename = epsfilename , noy2 = noy2 , smooth = smooth , normalizedbins = normalizedbins , $ xtickinterval = xtickinterval , mode = mode if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) nx = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ny = N_ELEMENTS ( datacube [ 0 , * , 0 ]) nt = N_ELEMENTS ( datacube [ 0 , 0 , * ]) temporal_Nyquist = 1. / ( cadence * 2. ) print , ' ' print , 'The input datacube is of size: [' + strtrim ( nx , 2 ) + ', ' + strtrim ( ny , 2 ) + ', ' + strtrim ( nt , 2 ) + ']' print , ' ' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * nt , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' print , ' ' nxb = N_ELEMENTS ( Bmap [ * , 0 , 0 ]) nyb = N_ELEMENTS ( Bmap [ 0 , * , 0 ]) dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize if nx gt nxb OR ny gt nyb then begin print , ' [!] The datacube and B-map must have the same [x,y] size.' print , ' ' stop endif if n_elements ( binsize ) eq 0 then binsize = 50. ; in G if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if n_elements ( normalizedbins ) eq 0 then normalizedbins = 0 else normalizedbins = 1 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( xtickinterval ) eq 0 then xtickinterval = 400 ; in G if n_elements ( mode ) eq 0 then mode = 0 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 else nodetrendapod = 1 Bmap = ABS ( Bmap ) brange = minmax ( Bmap , / nan ) nbin = floor (( brange [ 1 ] - brange [ 0 ]) / binsize ) ; detrend and apodize the cube if nodetrendapod eq 0 then begin print , ' ' print , ' -- Detrend and apodize the cube .....' datacube = walsa_detrend_apod ( datacube , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , cadence = cadence ) endif frequencies = 1. / ( cadence * 2 ) * findgen ( nt / 2 + 1 ) / ( nt / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz numf = n_elements ( frequencies ) Barray = fltarr ( nbin ) bopower = fltarr ( nbin , numf ) fac = 0 PRINT for i = 0 L , nbin - 1 do begin ii = where ( Bmap le brange [ 1 ] - ( fac * float ( binsize )) AND Bmap gt brange [ 1 ] - (( fac + 1 ) * float ( binsize )), num ) Barray [ i ] = ( brange [ 1 ] - ( fac * float ( binsize ))) - ( float ( binsize ) / 2. ) if num gt 0 then begin coords = array_indices ( Bmap , ii ) xx = reform ( coords [ 0 , * ]) & yy = reform ( coords [ 1 , * ]) nxy = n_elements ( xx ) poweravg = fltarr ( numf ) for ixy = 0 L , nxy - 1 do begin poweri = ( 2. * ( ABS (( fft ( reform ( datacube [ xx [ ixy ], yy [ ixy ], * ]), - 1 ))[ 0 : nt / 2. ]) ^ 2 )) / frequencies [ 0 ] ; in DN ^ 2 / mHz poweravg = poweravg + poweri [ 1 : nff - 1 ] endfor poweravg = poweravg / float ( nxy ) if normalizedbins eq 1 then poweravg = 100. * poweravg / max ( poweravg ) bopower [ i , * ] = poweravg endif print , string ( 13 b ) + '.... % f inished (through bins, from larger B): ' , float ( i ) * 100. / ( nbin - 1 ), format = '(a,f4.0,$)' if brange [ 1 ] - (( fac + 1 ) * float ( binsize )) le 0 then break fac = fac + 1 endfor PRINT bopower = reverse ( bopower , 1 ) Barray = reverse ( Barray ) nb = n_elements ( Barray ) Barray [ 0 ] = brange [ 0 ] Barray [ nb - 1 ] = brange [ 1 ] ppp = bopower Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) bopower = CONVOL ( bopower , Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) if mode eq 0 then bopower = ALOG10 ( bopower ) if mode eq 2 then bopower = SQRT ( bopower ) nlevels = 256 step = ( Max ( bopower ) - Min ( bopower )) / nlevels vals = Indgen ( nlevels ) * step + Min ( bopower ) bopower = ( bopower )[ 0 : * , 0 : * ] > MIN (( bopower )[ 0 : * , 0 : * ], / nan ) < MAX (( bopower )[ 0 : * , 0 : * ], / nan ) if silent eq 0 then begin LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. x1 = 0.12 x2 = 0.86 y1 = 0.10 y2 = 0.80 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. positioncb = [ x1 , y2 + 0.05 , x2 , y2 + 0.07 ] if EPS eq 1 then begin walsa_eps , size = [ 20 , 22 ] ! p . font = 0 device , set_font = 'Times-Roman' ! p . charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 endif else begin if ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) then begin WINdoW , 0 , xsize = 1000 , ysize = 1000 , title = 'B-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 endif if ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) then begin WINdoW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'B-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 endif endelse walsa_pg_plotimage_komega , bopower , Barray , frequencies , $ ytitle = 'Frequency (mHz)' , xtitle = 'B (G)' , xst = 1 , yst = 8 , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , eps = eps , $ position = [ x1 , y1 , x2 , y2 ], noy2 = noy2 , nox2 = 1 , smooth = smooth , threemin = threemin , fivemin = fivemin , xtickinter = xtickinterval tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( bopower [ 1 : * , 1 : * ], / nan ) - MIN ( bopower [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( bopower [ 1 : * , 1 : * ], / nan ) - MIN ( bopower [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) if normalizedbins eq 1 then cbtitle = 'Log!d10!n(Normalized Oscillation Power)' else cbtitle = 'Log!d10!n(Oscillation Power)' cgcolorbar , bottom = 0 , ncolors = 255 , minrange = MIN ( bopower [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( bopower [ 1 : * , 1 : * ], / nan ), / top , $ ticknames = tickmarknames , yticklen = 0.00001 , position = positioncb , title = cbtitle if EPS eq 1 then walsa_endeps , filename = epsfilename , / noboundingbox endif power = bopower PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' ! P . Multi = 0 Cleanplot , / Silent PRINT PRINT , 'COMPLETED!' PRINT end Detrending and Apodisation \u00b6 WaLSA_detrend_apod All signals are detrended (linearly, or using higher-order polynomial fits if desired) and apodised (using a Tukey window, i.e., tapered cosine) prior to all spectral analyses (unless otherwise it is omitted). Here is the code used for detrending and apodising the signals. The spatial apodisation for the k-\u03c9 diagram, are performed inside the WaLSA_plotkopower_funct.pro . WaLSA_detrend_apod.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_detrend_apod ; part of -- WaLSAtools -- ; ; PURPOSE : ; Detrend and apodise time series to account for their nonlinear and nonstationary nature ; ( apodisation is also known as 'windowing' in some other communities ) ; ; DESCRIPTION : ; Each 1 D time series is detrended by subtracting the signal from its fitted linear or higher ; polynomial degrees function ( or only from the mean signal ), and finally apodised by the ; Tukey ( tapered cosine ) window to bring the edges to zero . If set , the edge effects are ; more conservatively examined by means of a wavelet - based approach ( walsa_wave_recon . pro ) ; ; CALLING SEQUENCE : ; corrected_cube = walsa_detrend_apod ( cube , apod , meandetrend , pxdetrend ) ; ; + INPUTS : ; data : 1 D time series , or ( x , y , t ) datacube , any type ; ( an ordered sequence of data points , typically some variable quantity ; measured at successive times . ) ; apod : extent of apodization edges of the Tukey ( tapered cosine ) window ; default : 0.1 ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; ; + OPTIONAL KEYWORDS : ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting ; the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ; ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; cadence : cadence of the observations . it is required when recon is set . ; resample_original if recon is set , then this keyword allow setting a range ( i . e . , min_resample and max_resample ) ; to which the unpreserved amplitudes are approximated . ; min_resample minimum value for resample_original . Default : min of each 1 D array ( time series ) in data . ; max_resample maximum value for resample_original . Default : max of each 1 D array ( time series ) in data . ; ; + OUTPUTS : ; corrected_cube : The detrended and apodised cube ; ; MODIFICATION HISTORY ; ; 2010 plotpowermap : Rob Rutten , assembly of Alfred de Wijn 's routines ; ( https : // webspace . science . uu . nl /~ rutte101 / rridl / cubelib / plotpowermap . pro ) ; 2018 - 2021 modified / extended by Shahin Jafarzadeh & David B . Jess ; - FUNCTION linear , x , p ; used by mpfitfun ymod = p [ 0 ] + x * p [ 1 ] return , ymod END FUNCTION walsa_detrend_apod , cube , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , $ recon = recon , cadence = cadence , resample_original = resample_original , min_resample = min_resample , $ max_resample = max_resample , silent = silent , dj = dj , lo_cutoff = lo_cutoff , hi_cutoff = hi_cutoff , upper = upper if ( n_elements ( apod ) ne 0 ) then apod = apod else apod = 0.1 if ( n_elements ( polyfit ) eq 0 ) then apolyfit = 0 else apolyfit = 1 if not keyword_set ( meandetrend ) then meandetrend = 0 if not keyword_set ( silent ) then silent = 0 if ( n_elements ( pxdetrend ) ne 0 ) then pxdetrend = pxdetrend else pxdetrend = 2 if silent eq 0 then begin print , ' ' print , ' -- Detrend and apodize the cube .....' print , ' ' endif sizecube = size ( cube ) if sizecube [ 0 ] ne 3 then begin if sizecube [ 0 ] eq 1 then begin blablacube = fltarr ( 1 , 1 , sizecube [ 1 ]) blablacube [ 0 , 0 , * ] = cube cube = blablacube endif else begin print , ' ' print , ' [!] The datacube must have either 1 or 3 dimension(s).' print , ' ' stop endelse endif sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] apocube = cube tf = findgen ( nt ) + 1 col = fltarr ( nt ) apodt = fltarr ( nt ) + 1 if ( apod ne 0 ) then begin ; Tukey window apodrim = apod * nt apodt [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrim ) / apodrim )) ^ 2 apodt = apodt * shift ( rotate ( apodt , 2 ), 1 ) endif ; meandetrend : get spatially - averaged trend fit = 0 if ( meandetrend ) then begin avgseq = fltarr ( nt ) for it = 0 , nt - 1 do avgseq [ it ] = total ( cube [ * , * , it ]) avgseq = avgseq / ( double ( nx ) * double ( ny )) meanfitp = mpfitfun ( 'linear' , tf , avgseq , fltarr ( nt ) + 1 ,[ 1000. , 0. ], / quiet ) meanfit = meanfitp [ 0 ] + tf * meanfitp [ 1 ] - total ( avgseq ) / double ( nt ) endif ; apodize per [ x , y ] temporal column = time sequence per pixel for ix = long ( 0 ), long ( nx ) - 1 do begin for iy = long ( 0 ), long ( ny ) - 1 do begin col = cube [ ix , iy , * ] IF KEYWORD_SET ( recon ) THEN col = walsa_wave_recon ( reform ( col ), cadence , dj = dj , lo_cutoff = lo_cutoff , hi_cutoff = hi_cutoff , upper = upper ) meancol = walsa_avgstd ( col ) if ( meandetrend ) then col = col - meanfit if n_elements ( meantemporal ) eq 0 then begin if apolyfit eq 0 then begin if ( pxdetrend eq 1 ) then begin pxfitp = poly_fit ( tf , col , 1 ) col = col - pxfitp [ 0 ] - tf * pxfitp [ 1 ] + meancol endif if ( pxdetrend eq 2 ) then begin pxfitp = mpfitfun ( 'linear' , tf , col , fltarr ( nt ) + 1 ,[ meancol , 0. ], / quiet ) col = col - pxfitp [ 0 ] - tf * pxfitp [ 1 ] + meancol endif endif else begin lc_fit = GOODPOLY ( FINDGEN ( nt ), col , polyfit , 3 , lc_yfit , lc_newx , lc_newy ) col = col - lc_yfit endelse endif ocol = ( col - meancol ) * apodt + meancol if not KEYWORD_SET ( min_resample ) then min_resample = min ( cube [ ix , iy , * ]) if not KEYWORD_SET ( max_resample ) then max_resample = max ( cube [ ix , iy , * ]) IF KEYWORD_SET ( recon ) THEN if KEYWORD_SET ( resample_original ) then ocol = scale_vector ( ocol , min_resample , max_resample ) apocube [ ix , iy , * ] = ocol endfor if silent eq 0 then if long ( nx ) gt 1 then if ( pxdetrend ne 0 ) then $ writeu , - 1 , string ( format = '(%\" \\r == detrend next row... \",i5,\"/\",i5)' , ix + 1 , nx ) endfor if silent eq 0 then if long ( nx ) gt 1 then if ( pxdetrend ne 0 ) then PRINT return , reform ( apocube ) END Wavelet Analysis \u00b6 WaLSA_wavelet A modified/extended variant of wavelet.pro (of Torrence & Compo) to compute wavelet power spectrum and its related parameters. WaLSA_wavelet.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_wavelet ; part of -- WaLSAtools -- ; modification of WAVELET . pro ; ; PURPOSE : ; Compute the WAVELET transform of a 1 D time series . ; Based on the original code from Torrenc & Compo ; ( see Torrence , C . and G . P . Compo , 1998 : A Practical Guide to ; Wavelet Analysis . Bull . Amer . Meteor . Soc . , 79 , 61 - 78. ) ; ; CALLING SEQUENCE : ; wave = WaLSA_wavelet ( Y , DT ) ; ; INPUTS : ; ; Y = the time series of length N . ; ; DT = amount of time between each Y value , i . e . the sampling time . ; ; OUTPUTS : ; ; WAVE is the WAVELET transform of Y . This is a complex array ; of dimensions ( N , J + 1 ) . FLOAT ( WAVE ) gives the WAVELET amplitude , ; ATAN ( IMAGINARY ( WAVE ), FLOAT ( WAVE )) gives the WAVELET phase . ; The WAVELET power spectrum is ABS ( WAVE ) ^ 2. ; ; ; OPTIONAL KEYWORD INPUTS : ; ; S0 = the smallest scale of the wavelet . Default is 2 * DT . ; ; DJ = the spacing between discrete scales . Default is 0.125 . ; A smaller # will give better scale resolution, but be slower to plot. ; ; J = the # of scales minus one. Scales range from S0 up to S0*2^(J*DJ), ; to give a total of ( J + 1 ) scales . Default is J = ( LOG2 ( N DT / S0 )) / DJ . ; ; MOTHER = A string giving the mother wavelet to use . ; Currently , 'Morlet' , 'Paul' , 'DOG' ( derivative of Gaussian ) ; are available . Default is 'Morlet' . ; ; PARAM = optional mother wavelet parameter . ; For 'Morlet' this is k0 ( wavenumber ), default is 6. ; For 'Paul' this is m ( order ), default is 4. ; For 'DOG' this is m ( m - th derivative ), default is 2. ; ; PAD = if set , then pad the time series with enough zeroes to get ; N up to the next higher power of 2. This prevents wraparound ; from the end of the time series to the beginning , and also ; speeds up the FFT 's used to do the wavelet transform. ; This will not eliminate all edge effects ( see COI below ) . ; ; LAG1 = LAG 1 Autocorrelation , used for SIGNIF levels . Default is 0.0 ; ; SIGLVL = significance level to use . Default is 0.95 ; ; VERBOSE = if set , then print out info for each analyzed scale . ; ; RECON = if set , then reconstruct the time series , and store in Y . ; Note that this will destroy the original time series , ; so be sure to input a dummy copy of Y . ; ; FFT_THEOR = theoretical background spectrum as a function of ; Fourier frequency . This will be smoothed by the ; wavelet function and returned as a function of PERIOD . ; ; colornoise = if set , noise background is based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 ; ; OPTIONAL KEYWORD OUTPUTS : ; ; PERIOD = the vector of \"Fourier\" periods ( in time units ) that corresponds ; to the SCALEs . ; ; POWER = Wavelet power spectrum ; ; SCALE = the vector of scale indices , given by S0 * 2 ^ ( j * DJ ), j = 0. .. J ; where J + 1 is the total # of scales. ; ; COI = if specified , then return the Cone - of - Influence , which is a vector ; of N points that contains the maximum period of useful information ; at that particular time . ; Periods greater than this are subject to edge effects . ; This can be used to plot COI lines on a contour plot by doing : ; IDL > CONTOUR , wavelet , time , period ; IDL > PLOTS , time , coi , NOCLIP = 0 ; ; YPAD = returns the padded time series that was actually used in the ; wavelet transform . ; ; DAUGHTER = if initially set to 1 , then return the daughter wavelets . ; This is a complex array of the same size as WAVELET . At each scale ; the daughter wavelet is located in the center of the array . ; ; SIGNIF = output significance levels as a function of PERIOD ; ; FFT_THEOR = output theoretical background spectrum ( smoothed by the ; wavelet function ), as a function of PERIOD . ; ; Plot = if set , the wavelet power spectrum is plotted . ; ; colorct = the IDL color table number . Default : 20 ; ; w = window number ( for IDL ) . Default : 6 ; ; ---- detrending , and apodization parameters ---- ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; ; [ Defunct INPUTS : ; [ OCT = the # of octaves to analyze over. ] ; [ Largest scale will be S0 * 2 ^ OCT . ] ; [ Default is ( LOG2 ( N ) - 1 ) . ] ; [ VOICE = # of voices in each octave. Default is 8. ] ; [ Higher # gives better scale resolution, ] ; [ but is slower to plot . ] ; ] ; ;; ---------------------------------------------------------------------------- ; ; EXAMPLE : ; ; IDL > ntime = 256 ; IDL > y = RANDOMN ( s , ntime ) ; *** create a random time series ; IDL > dt = 0.25 ; IDL > time = FINDGEN ( ntime ) * dt ; *** create the time index ; IDL > ; IDL > wave = WaLSA_wavelet ( y , dt , PERIOD = period , PAD = 1 , COI = coi , MOTHER = 'Morlet' , / RECON , dj = 0.025 , scale = scale , SIGNIF = SIGNIF , SIGLVL = 0.99 , / apod , / plot ) ; ;; ---------------------------------------------------------------------------- ; This routine is originally based on WAVELET . pro ; Copyright ( C ) 1995 - 2004 , Christopher Torrence and Gilbert P . Compo ; ; This software may be used , copied , or redistributed as long as it is not ; sold and this copyright notice is reproduced on each copy made . ; This routine is provided as is without any express or implied warranties ; whatsoever . ; ; Notice : Please acknowledge the use of the above software in any publications : ; `` Wavelet software was provided by C . Torrence and G . Compo , ; and is available at URL : http : // paos . colorado . edu / research / wavelets / '' . ; ; Reference : Torrence , C . and G . P . Compo , 1998 : A Practical Guide to ; Wavelet Analysis . < I > Bull . Amer . Meteor . Soc .</ I > , 79 , 61 - 78. ; ; Please send a copy of such publications to either C . Torrence or G . Compo : ; Dr . Christopher Torrence Dr . Gilbert P . Compo ; Research Systems , Inc . Climate Diagnostics Center ; 4990 Pearl East Circle 325 Broadway R / CDC1 ; Boulder , CO 80301 , USA Boulder , CO 80305 - 3328 , USA ; E - mail : chris [ AT ] rsinc [ DOT ] com E - mail : compo [ AT ] colorado [ DOT ] edu ;; ---------------------------------------------------------------------------- ; Modified / extended by Shahin Jafarzadeh 2016 - 2021 ; - FUNCTION morlet , $ ; *********************************************** MORLET k0 , scale , k , period , coi , dofmin , Cdelta , psi0 IF ( k0 EQ - 1 ) THEN k0 = 6 d n = N_ELEMENTS ( k ) expnt = - ( scale * k - k0 ) ^ 2 / 2 d * ( k GT 0. ) dt = 2 * ! PI / ( n * k ( 1 )) norm = SQRT ( 2 * ! PI * scale / dt ) * ( ! PI ^ ( - 0.25 )) ; total energy = N [ Eqn ( 7 )] morlet = norm * EXP ( expnt > ( - 100 d )) morlet = morlet * ( expnt GT - 100 ) ; avoid underflow errors morlet = morlet * ( k GT 0. ) ; Heaviside step function ( Morlet is complex ) fourier_factor = ( 4 * ! PI ) / ( k0 + SQRT ( 2 + k0 ^ 2 )) ; Scale --> Fourier [ Sec .3 h ] period = scale * fourier_factor coi = fourier_factor / SQRT ( 2 ) ; Cone - of - influence [ Sec .3 g ] dofmin = 2 ; Degrees of freedom with no smoothing Cdelta = - 1 IF ( k0 EQ 6 ) THEN Cdelta = 0.776 ; reconstruction factor psi0 = ! PI ^ ( - 0.25 ) ; PRINT , scale , n , SQRT ( TOTAL ( ABS ( morlet ) ^ 2 , / DOUBLE )) RETURN , morlet END FUNCTION paul , $ ; ************************************************** PAUL m , scale , k , period , coi , dofmin , Cdelta , psi0 IF ( m EQ - 1 ) THEN m = 4 d n = N_ELEMENTS ( k ) expnt = - ( scale * k ) * ( k GT 0. ) dt = 2 d * ! PI / ( n * k ( 1 )) norm = SQRT ( 2 * ! PI * scale / dt ) * ( 2 ^ m / SQRT ( m * FACTORIAL ( 2 * m - 1 ))) paul = norm * (( scale * k ) ^ m ) * EXP ( expnt > ( - 100 d )) * ( expnt GT - 100 ) paul = paul * ( k GT 0. ) fourier_factor = 4 * ! PI / ( 2 * m + 1 ) period = scale * fourier_factor coi = fourier_factor * SQRT ( 2 ) dofmin = 2 ; Degrees of freedom with no smoothing Cdelta = - 1 IF ( m EQ 4 ) THEN Cdelta = 1.132 ; reconstruction factor psi0 = 2. ^ m * FACTORIAL ( m ) / SQRT ( ! PI * FACTORIAL ( 2 * m )) ; PRINT , scale , n , norm , SQRT ( TOTAL ( paul ^ 2 , / DOUBLE )) * SQRT ( n ) RETURN , paul END FUNCTION dog , $ ; *************************************************** DOG m , scale , k , period , coi , dofmin , Cdelta , psi0 IF ( m EQ - 1 ) THEN m = 2 n = N_ELEMENTS ( k ) expnt = - ( scale * k ) ^ 2 / 2 d dt = 2 d * ! PI / ( n * k ( 1 )) norm = SQRT ( 2 * ! PI * scale / dt ) * SQRT ( 1 d / GAMMA ( m + 0.5 )) I = DCOMPLEX ( 0 , 1 ) gauss = - norm * ( I ^ m ) * ( scale * k ) ^ m * EXP ( expnt > ( - 100 d )) * ( expnt GT - 100 ) fourier_factor = 2 * ! PI * SQRT ( 2. / ( 2 * m + 1 )) period = scale * fourier_factor coi = fourier_factor / SQRT ( 2 ) dofmin = 1 ; Degrees of freedom with no smoothing Cdelta = - 1 psi0 = - 1 IF ( m EQ 2 ) THEN BEGIN Cdelta = 3.541 ; reconstruction factor psi0 = 0.867325 ENDIF IF ( m EQ 6 ) THEN BEGIN Cdelta = 1.966 ; reconstruction factor psi0 = 0.88406 ENDIF ; PRINT , scale , n , norm , SQRT ( TOTAL ( ABS ( gauss ) ^ 2 , / DOUBLE )) * SQRT ( n ) RETURN , gauss END ; ****************************************************************** WAVELET FUNCTION walsa_wavelet , y1 , dt , $ ; *** required inputs S0 = s0 , DJ = dj , J = j , $ ; *** optional inputs PAD = pad , MOTHER = mother , PARAM = param , $ VERBOSE = verbose , NO_WAVE = no_wave , RECON = recon , $ LAG1 = lag1 , SIGLVL = siglvl , DOF = dof , GLOBAL = global , $ ; *** optional inputs SCALE = scale , PERIOD = period , YPAD = ypad , $ ; *** optional outputs DAUGHTER = daughter , COI = coi , removespace = removespace , koclt = koclt , $ SIGNIF = signif , FFT_THEOR = fft_theor , $ OCT = oct , VOICE = voice , log = log , silent = silent , normal = normal , $ plot = plot , colorct = colorct , w = w , apod = apod , nodetrendapod = nodetrendapod , $ pxdetrend = pxdetrend , meandetrend = meandetrend , power = power , $ polyfit = polyfit , meantemporal = meantemporal , colornoise = colornoise , $ clt = clt , epsfilename = epsfilename ON_ERROR , 2 r = CHECK_MATH ( 0 , 1 ) n = N_ELEMENTS ( y1 ) n1 = n base2 = FIX ( ALOG ( n ) / ALOG ( 2 ) + 0.4999 ) ; power of 2 nearest to N ; .... check keywords & optional inputs if n_elements ( log ) eq 0 THEN log = 0 if n_elements ( pad ) eq 0 THEN pad = 1 IF ( N_ELEMENTS ( s0 ) LT 1 ) THEN s0 = 2.0 * dt IF ( N_ELEMENTS ( voice ) EQ 1 ) THEN dj = 1. / voice IF ( N_ELEMENTS ( dj ) LT 1 ) THEN dj = 0.025 if n_elements ( colornoise ) eq 0 then colornoise = 0 IF ( N_ELEMENTS ( oct ) EQ 1 ) THEN J = FLOAT ( oct ) / dj IF ( N_ELEMENTS ( J ) LT 1 ) THEN J = FIX (( ALOG ( FLOAT ( n ) * dt / s0 ) / ALOG ( 2 )) / dj ) ;[ Eqn ( 10 )] IF ( N_ELEMENTS ( mother ) LT 1 ) THEN mother = 'MORLET' IF ( N_ELEMENTS ( param ) LT 1 ) THEN param = - 1 IF ( N_ELEMENTS ( siglvl ) LT 1 ) THEN siglvl = 0.95 IF ( N_ELEMENTS ( lag1 ) LT 1 ) THEN lag1 = 0.0 if n_elements ( plot ) eq 0 then plot = 0 if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 lag1 = lag1 ( 0 ) verbose = KEYWORD_SET ( verbose ) do_daughter = KEYWORD_SET ( daughter ) do_wave = NOT KEYWORD_SET ( no_wave ) recon = KEYWORD_SET ( recon ) if colornoise ne 0 then begin ; Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 nt = n_elements ( y1 ) J = FIX ( alog ( nt / 2.0 ) / alog ( 2 ) / dj ) s0 = 2 * dt endif IF KEYWORD_SET ( global ) THEN MESSAGE , $ 'Please use WAVE_SIGNIF for global significance tests' ; detrend and apodize the cube if nodetrendapod eq 0 then $ y1 = walsa_detrend_apod ( y1 , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , cadence = dt , silent = silent ) ; .... construct time series to analyze , pad if necessary ypad = y1 - TOTAL ( y1 ) / n ; remove mean IF KEYWORD_SET ( pad ) THEN BEGIN ; pad with extra zeroes , up to power of 2 ypad = [ ypad , FLTARR ( 2 L ^ ( base2 + 1 ) - n )] n = N_ELEMENTS ( ypad ) ENDIF ; .... construct SCALE array & empty PERIOD & WAVE arrays na = J + 1 ; # of scales scale = DINDGEN ( na ) * dj ; array of j - values scale = 2 d0 ^ ( scale ) * s0 ; array of scales 2 ^ j [ Eqn ( 9 )] period = FLTARR ( na , / NOZERO ) ; empty period array ( filled in below ) wave = COMPLEXARR ( n , na , / NOZERO ) ; empty wavelet array IF ( do_daughter ) THEN daughter = wave ; empty daughter array ; .... construct wavenumber array used in transform [ Eqn ( 5 )] k = ( DINDGEN ( n / 2 ) + 1 ) * ( 2 * ! PI ) / ( DOUBLE ( n ) * dt ) k = [ 0 d , k , - REVERSE ( k ( 0 :( n - 1 ) / 2 - 1 ))] ; .... compute FFT of the ( padded ) time series yfft = FFT ( ypad , - 1 , / DOUBLE ) ; [ Eqn ( 3 )] IF ( verbose ) THEN BEGIN ; verbose PRINT PRINT , mother PRINT , '#points=' , n1 , ' s0=' , s0 , ' dj=' , dj , ' J=' , FIX ( J ) IF ( n1 NE n ) THEN PRINT , '(padded with ' , n - n1 , ' zeroes)' PRINT ,[ 'j' , 'scale' , 'period' , 'variance' , 'mathflag' ], $ FORMAT = '(/,A3,3A11,A10)' ENDIF ; verbose IF ( N_ELEMENTS ( fft_theor ) EQ n ) THEN fft_theor_k = fft_theor ELSE $ fft_theor_k = ( 1 - lag1 ^ 2 ) / ( 1 - 2 * lag1 * COS ( k * dt ) + lag1 ^ 2 ) ; [ Eqn ( 16 )] fft_theor = FLTARR ( na ) ; .... loop thru each SCALE FOR a1 = 0 , na - 1 DO BEGIN ; scale psi_fft = CALL_FUNCTION ( mother , param , scale ( a1 ), k , period1 , coi , dofmin , Cdelta , psi0 ) IF ( do_wave ) THEN $ wave ( * , a1 ) = FFT ( yfft * psi_fft , 1 , / DOUBLE ) ; wavelet transform [ Eqn ( 4 )] period ( a1 ) = period1 ; save period fft_theor ( a1 ) = TOTAL (( ABS ( psi_fft ) ^ 2 ) * fft_theor_k ) / n IF ( do_daughter ) THEN $ daughter ( * , a1 ) = FFT ( psi_fft , 1 , / DOUBLE ) ; save daughter IF ( verbose ) THEN PRINT , a1 , scale ( a1 ), period ( a1 ), $ TOTAL ( ABS ( wave ( * , a1 )) ^ 2 ), CHECK_MATH ( 0 ), $ FORMAT = '(I3,3F11.3,I6)' ENDFOR ; scale coi = coi * [ FINDGEN (( n1 + 1 ) / 2 ), REVERSE ( FINDGEN ( n1 / 2 ))] * dt ; COI [ Sec .3 g ] IF ( do_daughter ) THEN $ ; shift so DAUGHTERs are in middle of array daughter = [ daughter ( n - n1 / 2 : * , * ), daughter ( 0 : n1 / 2 - 1 , * )] ; .... significance levels [ Sec .4 ] sdev = ( MOMENT ( y1 ))( 1 ) fft_theor = sdev * fft_theor ; include time - series variance dof = dofmin signif = fft_theor * CHISQR_CVF ( 1. - siglvl , dof ) / dof ; [ Eqn ( 18 )] IF ( recon ) THEN BEGIN ; Reconstruction [ Eqn ( 11 )] IF ( Cdelta EQ - 1 ) THEN BEGIN y1 = - 1 MESSAGE , / INFO , $ 'Cdelta undefined, cannot reconstruct with this wavelet' ENDIF ELSE BEGIN y1 = dj * SQRT ( dt ) / ( Cdelta * psi0 ) * ( FLOAT ( wave ) # (1./SQRT(scale))) y1 = y1 [ 0 : n1 - 1 ] ENDELSE ENDIF time = findgen ( n1 ) * dt amplitude = wave ( 0 : n1 - 1 , * ) ; get rid of padding before returning amplitudes power = ABS ( amplitude ) ^ 2 if plot ne 0 then begin powplot = power perplot = period timplot = time coiplot = coi sigplot = signif walsa_plot_wavelet_spectrum , powplot , perplot , timplot , coiplot , sigplot , clt = clt , w = w , log = log , removespace = removespace , $ koclt = koclt , normal = normal , epsfilename = epsfilename endif RETURN , amplitude END This code also uses the following routine to plot the wavelet power spectrum (along with confidence levels and cone-of-influence regions). WaLSA_plot_wavelet_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- pro walsa_plot_wavelet_spectrum , power , period , time , coi , significance , clt = clt , w = w , log = log , removespace = removespace , $ koclt = koclt , normal = normal , epsfilename = epsfilename , maxperiod = maxperiod , mHz = mHz if n_elements ( log ) eq 0 then log = 1 if n_elements ( mHz ) eq 0 then mHz = 1 if n_elements ( removespace ) eq 0 then removespace = 0 if n_elements ( normal ) eq 0 then normal = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 nt = n_elements ( reform ( time )) & np = n_elements ( reform ( period )) significance = REBIN ( TRANSPOSE ( significance ), nt , np ) fundf = 1000. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz if n_elements ( maxperiod ) eq 0 then maxp = 1000. / fundf else maxp = maxperiod ; longest period to be plotted if n_elements ( maxperiod ) eq 0 then if removespace ne 0 then maxp = max ( coi ) ; remove areas below the COI iit = closest_index ( maxp , period ) period = period [ 0 : iit ] significance = reform ( significance [ * , 0 : iit ]) power = reform ( power [ * , 0 : iit ]) power = reverse ( power , 2 ) significance = reverse ( significance , 2 ) sigi = power / significance if n_elements ( w ) eq 0 then w = 6 dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize if EPS eq 1 then begin walsa_eps , size = [ 18 , 13 ] ! p . font = 0 device , set_font = 'Times-Roman' charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.033 ! y . ticklen =- 0.021 barthick = 550 distbar = 550 coithick = 3. arrowsize = 20. arrowthick = 3.5 c_thick = 3. h_thick = 1.4 ; arrowheadsize = 10. endif else begin if ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) then begin window , w , xs = 900 , ys = 650 , title = strtrim ( w , 2 ) + ': Wavelet Power Spectrum' charsize = 2.0 ! x . thick = 2. ! y . thick = 2. ! x . ticklen =- 0.033 ! y . ticklen =- 0.021 ; ! X . MINOR = 6 distbar = 30 barthick = 30 coithick = 2 c_thick = 2. h_thick = 1. endif if ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) then begin window , w , xs = FIX ( smallest_screensize * 0.9 ), ys = FIX ( smallest_screensize * 0.9 ), title = strtrim ( w , 2 ) + ': Wavelet Power Spectrum' charsize = 1.7 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.033 ! y . ticklen =- 0.021 distbar = 25 barthick = 25 coithick = 2 c_thick = 2. h_thick = 1. endif endelse colset device , decomposed = 0 xtitle = 'Time (s)' ztitle = 'Power!C' if log ne 0 then ztitle = 'Log!d10!n(Power)!C' if normal ne 0 then begin ztitle = 'Normalised Power!C' if log ne 0 then ztitle = 'Log!d10!n(Normalised Power)!C' endif ii = where ( power lt 0. , cii ) if cii gt 0 then power ( ii ) = 0. if normal ne 0 then power = 100. * power / max ( power ) xrg = [ min ( time ), max ( time )] yrg = [ max ( period ), min ( period )] if n_elements ( clt ) eq 0 then clt = 20 loadct , clt if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt if log ne 0 then power = alog10 ( power ) walsa_image_plot , power , xrange = xrg , yrange = yrg , $ nobar = 0 , zrange = minmax ( power , / nan ), / ylog , $ contour = 0 , / nocolor , charsize = charsize , $ ztitle = ztitle , xtitle = xtitle , $ exact = 1 , aspect = 0 , cutaspect = 0 , ystyle = 5 , $ barpos = 1 , zlen =- 0.6 , distbar = distbar , $ barthick = barthick , position = [ 0.14 , 0.14 , 0.87 , 0.87 ] cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize if mHz then cgAxis , YAxis = 1 , YRange = [ 1000. / yrg [ 0 ], 1000. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (mHz)' , charsize = charsize $ else cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize ; plot the Cone - of - Influence plots , time , coi , noclip = 0 , linestyle = 0 , thick = coithick , color = cgColor ( 'Black' ) ; shade the area above the Cone - of - Influence , with hashed lines : ncoi = n_elements ( coi ) y = fltarr ( ncoi ) for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION =- 45 ; contours mark significance level cgContour , sigi , / noerase , levels = 1. , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = c_thick if EPS eq 1 then walsa_endeps , filename = epsfilename , / pdf end Cross Correlations: 1D power spectra \u00b6 WaLSA_cross_spectrum Calculating cross-spectrum (also known as co-spectrum or cross-power), coherence, and phase relationships between two time series, where the 1D power spectra are obtained with FFT (Fast Fourier Transform), Lomb-Scargle, Wavelet (global, oglobal, and sensible), and HHT (Hilbert-Huang Transform), using the WaLSA_speclizer.pro . WaLSA_cross_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_cross_spectrum ; part of -- WaLSAtools -- ; ; PURPOSE : ; ; Calculate cross - spectral relationships of two time series whose amplitudes and powers ; are computed using the WaLSA_speclizer routine . ; The cross - spectrum is complex valued , thus its magnitude is returned as the ; co - spectrum . The phase lags between the two time series are are estimated ; from the imaginary and real arguments of the complex cross spectrum . ; The coherence is calculated from the normalized square of the amplitude ; of the complex cross - spectrum ; ; CALLING SEQUENCE : ; walsa_cross_spectrum ( data1 = data1 , data2 = data2 , time = time , phase_angle = phase_angle , coherence = coherence , cospectrum = cospectrum , frequencies = frequencies ) ; ; + INPUTS : ; ; data1 : first ( 1 D ) time series ; data2 : second ( 1 D ) time series , co - aligned with data1 ; time : observing times in seconds ( 1 D array ) ; ; + OPTIONAL KEYWORDS : ; ---- type of analysis ---- ; fft : if set , Fast Fourier Transform ( FFT ) power spectrum is computed : for regular ( evenly sampled ) time series . ; lombscargle : if set , Lomb - Scargle power spectrum is computed : for irregular ( unevenly sampled ) time series . ; hht : if set , a power spectrum associated to EMD + Hilbert Transform is computed : for regular ( evenly sampled ) time series . ; ---- padding , detrending , and apodization parameters ---- ; padding : oversampling factor : zero padding ( increasing timespan ) to increase frequency resolution ( NOTE : doesn 't add information) ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; ---- significance - level parameters ---- ; siglevel : significance level ( default : 0.05 = 5 % significance level = 95 % confidence level ) ; nperm : number of random permutations for the significance test -- the larger the better ( default : 1000 ) ; nosignificance : if set , no significance level is calculated . ; ---- HHT parameters / options ---- ; stdlimit : standard deviation to be achieved before accepting an IMF ( recommended value between 0.2 and 0.3 ; perhaps even smaller ); default : 0.2 ; nfilter : Hanning window width for two dimensional smoothing of the Hilbert spectrum . default : 3 ; ( an odd integer , prefrabely equal to or larger than 3 ; equal to 0 to avoid the windowing ) ; ; n_segments : number of euqal segments ( to which both datasets are broken prior to the analyses ; default : 1 ) ; Each of these segments is considered an independent realisation of the underlying process . ; The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency . ; ; + OUTPUTS : ; ; cospectrum : co - spectrum , i . e . , magnitude of the complex cross spectrum ; frequencies : an array of frequencies . unit : mHz ; phase_angle : phase angles ; coherence : coherence of two series ; signif_cross : significance levels for the cospectrum ( 1 D array ) ; signif_coh : significance levels for the coherence ( 1 D array ) ; d1_power : power spectrum of data1 ; d2_power : power spectrum of data2 ; ; Shahin Jafarzadeh & David B . Jess | WaLSA Team ; + some routines / recipe from CROSS_SPECTRUM.pro of Simon Vaughan ; - function walsa_getcross_spectrum , data1 , data2 , time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , $ fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ stdlimit = stdlimit , nfilter = nfilter , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power cadence = walsa_mode ( walsa_diff ( time )) nt = n_elements ( data1 ) ; number of segments if ( n_elements ( n_segments ) eq 0 ) then n_segments = 1 ; number of segments to break the time series into . mn = nt / n_segments n_cut = mn * n_segments x_1 = reform ( data1 [ 0 : n_cut - 1 ], mn , n_segments ) x_2 = reform ( data2 [ 0 : n_cut - 1 ], mn , n_segments ) xtime = reform ( time [ 0 : n_cut - 1 ], mn , n_segments ) frequencies = 1. / ( cadence * 2 ) * findgen ( mn / 2 + 1 ) / ( mn / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) amplitude1 = complexarr ( nf , n_segments ) amplitude2 = complexarr ( nf , n_segments ) for iseg = 0 L , n_segments - 1 do begin power1s = walsa_speclizer ( reform ( x_1 [ * , iseg ]), reform ( xtime [ * , iseg ]), $ ; main inputs frequencies = frequencies , amplitude = amplitude1s , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ nosignificance = 1 , $ ; significance - level parameters stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options mode = 1 , / silent ) ; power calibration power2s = walsa_speclizer ( reform ( x_2 [ * , iseg ]), reform ( xtime [ * , iseg ]), $ ; main inputs frequencies = frequencies , amplitude = amplitude2s , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ nosignificance = 1 , $ ; significance - level parameters stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options mode = 1 , / silent ) ; power calibration amplitude1 [ * , iseg ] = amplitude1s amplitude2 [ * , iseg ] = amplitude2s endfor amplitude1 = reform ( amplitude1 ) amplitude2 = reform ( amplitude2 ) power1 = abs ( amplitude1 ) ^ 2 power2 = abs ( amplitude2 ) ^ 2 ; complex cross - power spectrum cross_power = amplitude1 * CONJ ( amplitude2 ) ; co - spectrum ( real parts of cross - power spectrum ) cospectrum = ABS ( cross_power ) ; ---------------------------------------------------------- ; Average over the ensamble of time series segments and adjacent frequencies ; average the second - order quantities : C , P_1 , P_2 over the ensemble of M segments if ( n_segments gt 1 ) then begin binC = total ( cross_power , 2 ) / float ( n_segments ) binP_1 = total ( power1 , 2 ) / float ( n_segments ) binP_2 = total ( power2 , 2 ) / float ( n_segments ) endif else begin binC = cross_power binP_1 = power1 binP_2 = power2 endelse ; ---------------------------------------------------------- ; calculate coherence coherence = abs ( binC ) ^ 2 / ( binP_1 * binP_2 ) ; calculate the phase lag ( phase of complex cross spectrum ) phase_angle = atan ( binC , / phase ) * ( 180. / ! pi ) ; ---------------------------------------------------------- cospectrum = abs ( binC ) d1_power = binP_1 d2_power = binP_2 return , cospectrum end ; ==================================================== MAIN ROUTINE ==================================================== pro walsa_cross_spectrum , data1 = data1 , data2 = data2 , time = time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , cospectrum = cospectrum , $ fft = fft , lombscargle = lombscargle , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , nperm = nperm , siglevel = siglevel , $ stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options nosignificance = nosignificance , signif_coh = signif_coh , signif_cross = signif_cross , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( nperm ) eq 0 then nperm = 50 if n_elements ( siglevel ) eq 0 then siglevel = 0.05 ; 5 % significance level = 95 % confidence level time1 = time & time2 = time if n_elements ( silent ) eq 0 then silent = 0 sizecube1 = size ( reform ( data1 )) sizecube2 = size ( reform ( data2 )) givewarning = 0 if sizecube1 [ 0 ] eq 1 and sizecube1 [ 0 ] eq 1 then begin if sizecube1 [ 1 ] ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube2 [ 1 ] then givewarning = 1 endif else givewarning = 1 if givewarning eq 1 then begin print , ' ' print , ' [!] data1, data2, and time must be one diemnsional and have identical lengths.' print , ' ' stop endif if silent eq 0 then begin cadence = walsa_mode ( walsa_diff ( time )) temporal_Nyquist = 1. / ( cadence * 2. ) print , ' ' print , 'The input datacubes are of size: [' + ARR2STR ( sizecube1 [ 1 ], / trim ) + ']' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + ARR2STR (( cadence * 2. ), / trim ) + ' seconds' print , ' Time series duration = ' + ARR2STR ( cadence * sizecube1 [ 1 ], / trim ) + ' seconds' print , ' Nyquist frequency = ' + ARR2STR ( temporal_Nyquist * 1000. , / trim ) + ' mHz' print , ' ' endif cospectrum = walsa_getcross_spectrum ( data1 , data2 , time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , $ fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ stdlimit = stdlimit , nfilter = nfilter , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power ) d1_power = d1_power / frequencies [ 0 ] ; in DN ^ 2 / mHz d2_power = d2_power / frequencies [ 0 ] ; in DN ^ 2 / mHz if nosignificance eq 0 then begin nf = n_elements ( frequencies ) ndata1 = n_elements ( data1 ) dt1 = walsa_mode ( walsa_diff ( time1 )) ndata2 = n_elements ( data2 ) dt2 = round ( walsa_mode ( walsa_diff ( time2 ))) coh_perm = fltarr ( nf , nperm ) cross_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation1 = walsa_randperm ( ndata1 ) y_perm1 = data1 ( permutation1 ) permutation2 = walsa_randperm ( ndata2 ) y_perm2 = data2 ( permutation2 ) cospectrumsig = walsa_getcross_spectrum ( y_perm1 , y_perm2 , time , coherence = cohsig , $ fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ stdlimit = stdlimit , nfilter = nfilter , n_segments = n_segments ) coh_perm [ * , ip ] = cohsig cross_perm [ * , ip ] = cospectrumsig if ip eq 0 then PRINT print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor PRINT PRINT signif_coh = walsa_confidencelevel ( coh_perm , siglevel = siglevel , nf = nf ) signif_cross = walsa_confidencelevel ( cross_perm , siglevel = siglevel , nf = nf ) endif print , '' print , 'COMPLETED!' print , '' end Cross Correlations: Wavelet power spectra \u00b6 WaLSA_wavelet_cross_spectrum As a largely modified/extended variant of the wave_coherency.pro (of Torrence), this code calculates co-spectrum, coherence, and phase relationships between two time series, where the wavelet power spectra are obtained, thus cross-correlation parameters also have two dimensions. WaLSA_wavelet_cross_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_wavelet_cross_spectrum ; part of -- WaLSAtools -- ; ; PURPOSE : ; Compute ( and optionally plot ) wavelet cospectrum ( cross - spectrum ), coherence , and phase angles ; between two time series as well as thier statistical significance levels . ; ; CALLING SEQUENCE : ; ; WaLSA_wavelet_cross_spectrum , data1 , time1 , data2 , time2 , / plot ; ; + INPUTS : ; ; data1 : first ( 1 D ) time series ( evenly sampled ) ; data2 : second ( 1 D ) time series ( evenly sampled ), co - aligned with data1 ; time : observing times in seconds ( 1 D array ) ; ; + OPTIONAL KEYWORDS : ; ; ---- wavelet parameters / options ---- ; mother : wavelet function , providing different localisation / resolution in frequency and in time ( also depends on param , m ) . ; currently , 'Morlet' , 'Paul' , 'DOG' ( derivative of Gaussian ) are available . default : 'Morlet' . ; param : optional mother wavelet parameter . ; For 'Morlet' this is k0 ( wavenumber ), default is 6. ; For 'Paul' this is m ( order ), default is 4. ; For 'DOG' this is m ( m - th derivative ), default is 2 ( i . e . , the real - valued Mexican - hat wavelet ) ; dj : spacing between discrete scales . default : 0.025 ; colornoise : if set , noise background is based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 ; ---- significance - level parameters ---- ; siglevel : significance level ( default : 0.05 = 5 % significance level = 95 % confidence level ) ; nperm : number of random permutations for the significance test ( default = 50 ) ; note : the default value is set for quick tests . Choose a large number ( e . g . , 2000 or larger ) ; for a better statistical result . ; nosignificance : if set , the significance levels are calculated . ; ( thus not overplotted as contours when plot option is set ) ; ---- padding , detrending , and apodization parameters ---- ; padding : oversampling factor : zero padding ( increasing timespan ) to increase frequency resolution ( NOTE : doesn 't add information) ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; ---- plotting ---- ; plot : if set , wavelet power sepctra of the two time series as well as ; their wavelet cospectrum ( cross - spectrum ) and coherence , along with the ; significance levels as contours , are plotted . ; The phase angles between the two time series are also depicted by default . ; Arrows pointing right mark zero phase ( meaning in - phase oscillations ), ; arrows pointing straight up indicate data2 lags behind data1 by 90 degrees . ; noarrow : if set , the phase angles are not overplotted as arrows . ; arrowdensity : number of arrows ( iluustrating phase angles ) in x and y directions ( default : [ 30 , 18 ]) ; arrowsize : size of the arrows ( default : 1 ) ; arrowheadsize : size of the arrows ' head (default: 1) ; pownormal : if set , the power is normalised to its maximum value ; log : if set , the power spectra and the cospectrum are plotted in log10 scale ; removespace : if set , the time - period areas affected by the coi over the entire time range are not plotted . ; clt : color table number ( idl ctload ) ; koclt : custom color tables ( currently available : 1 and 2 ) ; ; + OUTPUTS : ; ; cospectrum : absolute values of the cross wavelet map ; coherence : wavelet coherence map , as a function of time and scale ; phase_angle : phase angles in degrees ; time : time vector , given by the overlap of time1 and time2 ; ( it is not used : it is assumed the two time series are temporally aligned ) ; frequency : the frequency vector ; in mHz ; scale : scale vector of scale indices , given by the overlap of scale1 and scale2 ; computed by WaLSA_wavelet . pro ; coi : vector of the cone - of - influence ; signif_coh : significance map for the coherence ( same 2 D size as the coherence map ) ; coherence / signif_coh indicates regions above the siglevel ; signif_cross : significance map for the cospectrum ( same 2 D size as the cospectrum map ) ; cospectrum / signif_coh indicates regions above the siglevel ; coh_global : global ( or mean ) coherence averaged over all times ; phase_global : global ( or mean ) phase averaged over all times ; cross_global : global ( or mean ) cross wavelet averaged over all times ; coh_oglobal : global ( or mean ) coherence averaged over all times , excluding areas affected by COI ( oglobal ) ; phase_oglobal : global ( or mean ) phase averaged over all times , excluding areas affected by COI ( oglobal ) ; cross_oglobal : global ( or mean ) cross wavelet averaged over all times , excluding areas affected by COI ( oglobal ) ;; ---------------------------------------------------------------------------- ; This routine is originally based on WAVE_COHERENCY . pro ; Copyright ( C ) 1998 - 2005 , Christopher Torrence ; This software may be used , copied , or redistributed as long as it is not ; sold and this copyright notice is reproduced on each copy made . This ; routine is provided as is without any express or ; implied warranties whatsoever . ; ; Reference : Torrence , C . and P . J . Webster , 1999 : Interdecadal changes in the ; ENSO - monsoon system . < I > J . Climate </ I > , 12 , 2679 - 2690. ;; ---------------------------------------------------------------------------- ; Largely modified / extended by Shahin Jafarzadeh 2016 - 2021 ; - function walsa_getcorss_spectrum_wavelet , $ data1 , time1 , data2 , time2 , $ mother = mother , param = param , dj = dj , colornoise = colornoise , $ coherence = coherence , phase_angle = phase_angle , $ time_out = time_out , scale_out = scale_out , coi_out = coi_out , $ cross_wavelet = cross_wavelet , power1 = power1 , power2 = power2 , $ frequency = frequency , period = period , silent = silent , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ nosignificance = nosignificance , removespace = removespace , $ nodetrendapod = nodetrendapod , log = log , plot = plot , clt = clt , koclt = koclt , $ padding = padding , apod = apod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal dt1 = walsa_mode ( walsa_diff ( time1 )) wave1 = walsa_wavelet ( data1 , dt1 , scale = scale1 , nodetrendapod = nodetrendapod , PERIOD = period , COI = coi1 , plot = plot , w = 4 , log = log , silent = silent , $ removespace = removespace , koclt = koclt , clt = clt , mother = mother , param = param , dj = dj , colornoise = colornoise ) frequency = 1000. / period ; in mHz nf = n_elements ( frequency ) dt2 = walsa_mode ( walsa_diff ( time2 )) wave2 = walsa_wavelet ( data2 , dt2 , scale = scale2 , nodetrendapod = nodetrendapod , plot = plot , w = 5 , log = log , silent = silent , removespace = removespace , koclt = koclt , $ clt = clt , mother = mother , param = param , dj = dj , colornoise = colornoise ) ; *** find overlapping times time_start = MIN ( time1 ) > MIN ( time2 ) time_end = MAX ( time1 ) < MAX ( time2 ) time1_start = MIN ( WHERE (( time1 ge time_start ))) time1_end = MAX ( WHERE (( time1 le time_end ))) time2_start = MIN ( WHERE (( time2 ge time_start ))) time2_end = MAX ( WHERE (( time2 le time_end ))) ; *** find overlapping scales scale_start = MIN ( scale1 ) > MIN ( scale2 ) scale_end = MAX ( scale1 ) < MAX ( scale2 ) scale1_start = MIN ( WHERE (( scale1 ge scale_start ))) scale1_end = MAX ( WHERE (( scale1 le scale_end ))) scale2_start = MIN ( WHERE (( scale2 ge scale_start ))) scale2_end = MAX ( WHERE (( scale2 le scale_end ))) period = period ( scale1_start : scale1_end ) ; *** cross wavelet & individual wavelet power cross_wavelet = wave1 ( time1_start : time1_end , scale1_start : scale1_end ) * CONJ ( wave2 ( time2_start : time2_end , scale2_start : scale2_end )) power1 = ABS ( wave1 ( time1_start : time1_end , scale1_start : scale1_end )) ^ 2 power2 = ABS ( wave2 ( time2_start : time2_end , scale2_start : scale2_end )) ^ 2 dt = dt1 ntime = time1_end - time1_start + 1 nj = scale1_end - scale1_start + 1 if ( N_EleMENTS ( dj ) le 0 ) then dj = ALOG ( scale1 ( 1 ) / scale1 ( 0 )) / ALOG ( 2 ) scale = scale1 ( scale1_start : scale1_end ) time_out = time1 ( time1_start : time1_end ) scale_out = scale1 ( scale1_start : scale1_end ) if ( N_EleMENTS ( coi1 ) EQ N_EleMENTS ( time1 )) then $ coi_out = coi1 ( time1_start : time1_end ) nt = n_elements ( time_out ) ; calculate global cross - power , coherency , and phase angle ; global wavelet is the time average of the wavelet spectrum global1 = TOTAL ( power1 , 1 , / nan ) / nt global2 = TOTAL ( power2 , 1 , / nan ) / nt cross_global = TOTAL ( cross_wavelet , 1 ) / nt coh_global = ABS ( cross_global ) ^ 2 / ( global1 * global2 ) phase_global = reform ( ATAN ( IMAGINARY ( cross_global ), REAL_PART ( cross_global ))) * ( 180. / ! pi ) global1 = global1 ; / frequency [ nf - 1 ] ; in DN ^ 2 global2 = global2 ; / frequency [ nf - 1 ] ; in DN ^ 2 cross_global = ABS ( cross_global ); / frequency [ nf - 1 ] ; in DN ^ 2 ; calculate global cross - power , coherency , and phase angle excluding areas affected by COI ( oglobal ) oglobal_power1 = fltarr ( nt , nf ) oglobal_power2 = fltarr ( nt , nf ) oglobal_cross_wavelet = fltarr ( nt , nf ) for i = 0 L , nt - 1 do begin ii = where ( reform ( period ) lt coi_out [ i ], pnum ) oglobal_power1 [ i , ii ] = reform ( power1 [ i , ii ]) oglobal_power2 [ i , ii ] = reform ( power2 [ i , ii ]) oglobal_cross_wavelet [ i , ii ] = reform ( cross_wavelet [ i , ii ]) endfor oglobal_global1 = TOTAL ( oglobal_power1 , 1 , / nan ) / nt oglobal_global2 = TOTAL ( oglobal_power2 , 1 , / nan ) / nt cross_oglobal = TOTAL ( oglobal_cross_wavelet , 1 ) / nt coh_oglobal = ABS ( cross_oglobal ) ^ 2 / ( oglobal_global1 * oglobal_global2 ) phase_oglobal = reform ( ATAN ( IMAGINARY ( cross_oglobal ), REAL_PART ( cross_oglobal ))) * ( 180. / ! pi ) oglobal1 = oglobal_global1 ; / frequency [ nf - 1 ] ; in DN ^ 2 oglobal2 = oglobal_global2 ; / frequency [ nf - 1 ] ; in DN ^ 2 cross_oglobal = ABS ( cross_oglobal ); / frequency [ nf - 1 ] ; in DN ^ 2 for j = 0 , nj - 1 do begin ; *** time - smoothing st1 = SYSTIME ( 1 ) nt = LONG ( 4 L * scale ( j ) / dt ) / 2 L * 4 + 1 L time_wavelet = ( FINDgeN ( nt ) - nt / 2 ) * dt / scale ( j ) wave_function = EXP ( - time_wavelet ^ 2 / 2. ) ; *** Morlet wave_function = FLOAT ( wave_function / TOTAL ( wave_function )) ; normalize nz = nt / 2 zeros = COMPleX ( FltARR ( nz ), FltARR ( nz )) cross_wave_slice = [ zeros , cross_wavelet ( * , j ), zeros ] cross_wave_slice = CONVOL ( cross_wave_slice , wave_function ) cross_wavelet ( * , j ) = cross_wave_slice ( nz : ntime + nz - 1 ) zeros = FLOAT ( zeros ) power_slice = [ zeros , power1 ( * , j ), zeros ] power_slice = CONVOL ( power_slice , wave_function ) power1 ( * , j ) = power_slice ( nz : ntime + nz - 1 ) power_slice = [ zeros , power2 ( * , j ), zeros ] power_slice = CONVOL ( power_slice , wave_function ) power2 ( * , j ) = power_slice ( nz : ntime + nz - 1 ) endfor ; *** time - smoothing ; *** normalize by scale scales = REBIN ( TRANSPOSE ( scale ), ntime , nj ) cross_wavelet = TEMPORARY ( cross_wavelet ) / scales power1 = TEMPORARY ( power1 ) / scales power2 = TEMPORARY ( power2 ) / scales nweights = FIX ( 0.6 / dj / 2 + 0.5 ) * 2 - 1 ; closest ( smaller ) odd integer weights = REPLICATE ( 1. , nweights ) weights = weights / TOTAL ( weights ) ; normalize for i = 0 , ntime - 1 do begin ; *** scale - smoothing cross_wavelet ( i , * ) = CONVOL (( cross_wavelet ( i , * ))( * ), weights , / EDGE_TRUNCATE ) power1 ( i , * ) = CONVOL (( power1 ( i , * ))( * ), weights , / EDGE_TRUNCATE ) power2 ( i , * ) = CONVOL (( power2 ( i , * ))( * ), weights , / EDGE_TRUNCATE ) endfor ; *** scale - smoothing wave_phase = reform ( ATAN ( IMAGINARY ( cross_wavelet ), REAL_PART ( cross_wavelet ))) * ( 180. / ! pi ) wave_coher = ( ABS ( cross_wavelet ) ^ 2 ) / ( power1 * power2 > 1E-9 ) ; cospectrum = ABS ( REAL_PART ( cross_wavelet )) cospectrum = ABS ( cross_wavelet ); / frequency [ nf - 1 ] ; in DN ^ 2 coherence = reform ( wave_coher ) phase_angle = reform ( wave_phase ) return , cospectrum end ; ==================================================== MAIN ROUTINE ==================================================== pro walsa_wavelet_cross_spectrum , $ data1 , data2 , time , $ ; *** required inputs mother = mother , param = param , dj = dj , colornoise = colornoise , $ coherence = coherence , phase_angle = phase_angle , $ scale = scale , coi = coi , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ cospectrum = cospectrum , period = period , $ frequency = frequency , signif_coh = signif_coh , signif_cross = signif_cross , $ padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal , $ nosignificance = nosignificance , pownormal = pownormal , siglevel = siglevel , $ plot = plot , clt = clt , log = log , nperm = nperm , removespace = removespace , koclt = koclt , $ arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , noarrow = noarrow , silent = silent ; assuming the two time series are temporally aligned time1 = time time2 = time if n_elements ( plot ) eq 0 then plot = 0 if n_elements ( log ) eq 0 then log = 0 if n_elements ( dj ) eq 0 then dj = 0.025 if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 if n_elements ( nperm ) eq 0 then nperm = 50 if n_elements ( siglevel ) eq 0 then siglevel = 0.05 ; 5 % significance level = 95 % confidence level if n_elements ( removespace ) eq 0 then removespace = 0 if n_elements ( silent ) eq 0 then silent = 0 sizecube1 = size ( reform ( data1 )) sizecube2 = size ( reform ( data2 )) givewarning = 0 if sizecube1 [ 0 ] eq 1 and sizecube1 [ 0 ] eq 1 then begin if sizecube1 [ 1 ] ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube2 [ 1 ] then givewarning = 1 endif else givewarning = 1 if givewarning eq 1 then begin print , ' ' print , ' [!] data1, data2, and time must be one diemnsional and have identical lengths.' print , ' ' stop endif if silent eq 0 then begin cadence = walsa_mode ( walsa_diff ( time )) temporal_Nyquist = 1. / ( cadence * 2. ) print , ' ' print , 'The input datacubes are of size: [' + ARR2STR ( sizecube1 [ 1 ], / trim ) + ']' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + ARR2STR (( cadence * 2. ), / trim ) + ' seconds' print , ' Time series duration = ' + ARR2STR ( cadence * sizecube1 [ 1 ], / trim ) + ' seconds' print , ' Nyquist frequency = ' + ARR2STR ( temporal_Nyquist * 1000. , / trim ) + ' mHz' print , ' ' endif cospectrum = walsa_getcorss_spectrum_wavelet ( data1 , time1 , data2 , time2 , mother = mother , param = param , dj = dj , colornoise = colornoise , coherence = coherence , phase_angle = phase_angle , $ TIME_OUT = time_out , SCAle_OUT = scale_out , COI_OUT = coi_out , CROSS_WAVEleT = cross_wavelet , POWER1 = power1 , POWER2 = power2 , $ frequency = frequency , nosignificance = nosignificance , koclt = koclt , $ log = log , period = period , plot = plot , clt = clt , removespace = removespace , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal ) nxx = n_elements ( cospectrum [ * , 0 ]) nyy = n_elements ( cospectrum [ 0 , * ]) if nosignificance eq 0 then begin ndata1 = n_elements ( data1 ) dt1 = walsa_mode ( walsa_diff ( time1 )) ndata2 = n_elements ( data2 ) dt2 = round ( walsa_mode ( walsa_diff ( time2 ))) coh_perm = fltarr ( nxx , nyy , nperm ) cross_perm = fltarr ( nxx , nyy , nperm ) for ip = 0 L , nperm - 1 do begin permutation1 = walsa_randperm ( ndata1 ) y_perm1 = data1 ( permutation1 ) permutation2 = walsa_randperm ( ndata2 ) y_perm2 = data2 ( permutation2 ) cospectrumsig = walsa_getcorss_spectrum_wavelet ( y_perm1 , time1 , y_perm2 , time2 , coherence = cohsig , $ mother = mother , param = param , dj = dj , colornoise = colornoise , $ log = 0 , plot = 0 , silent = 1 , padding = padding , apod = apod , nodetrendapod = nodetrendapod , $ pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal ) coh_perm [ * , * , ip ] = cohsig cross_perm [ * , * , ip ] = cospectrumsig if ip eq 0 then PRINT print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor PRINT PRINT signif_coh = walsa_confidencelevel_wavelet ( coh_perm , siglevel = siglevel ) signif_cross = walsa_confidencelevel_wavelet ( cross_perm , siglevel = siglevel ) endif if plot eq 1 then begin powplot = cospectrum perplot = period timplot = time_out coiplot = coi_out walsa_plot_wavelet_cross_spectrum , powplot , perplot , timplot , coiplot , clt = clt , w = 8 , phase_angle = phase_angle , log = log , normal = pownormal , $ / crossspectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , significancelevel = signif_cross , nosignificance = nosignificance , removespace = removespace powplot = coherence perplot = period timplot = time_out coiplot = coi_out walsa_plot_wavelet_cross_spectrum , powplot , perplot , timplot , coiplot , clt = clt , w = 9 , phase_angle = phase_angle , log = 0 , normal = pownormal , $ / coherencespectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , significancelevel = signif_coh , nosignificance = nosignificance , removespace = removespace endif frequency = 1000. / period ; in mHz time = time_out coi = coi_out scale = scale_out print , '' print , 'COMPLETED!' print , '' end This code also uses the following routine to plot the wavelet co-spectrum and coherence spectrum (along with confidence levels, cone-of-influence regions, and phase lags). WaLSA_plot_wavelet_cross_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- function walsa_plot_vector , u , v , x , y , angle = angle , head_len = head_len , $ maxmag = maxmag , align = align , length = length , $ ref_text = ref_text , COLOR = color , THICK = thick , cstyle = cstyle , myphi = myphi , charsize = charsize ; Procedure to calculate and plot a vector mylen = 300.0 ; length of default arrow in pixels rev = 1.0 x0 = 0.0 y0 = 0.0 x1 = u / maxmag * mylen * length y1 = v / maxmag * mylen * length dx = x1 - x0 if ( dx LT 0.0 ) then rev =- 1.0 dy = y1 - y0 r = SQRT ( dx ^ 2 + dy ^ 2 ) theta = ATAN ( dy / dx ) phi = angle * ! dtor rfrac = head_len x2 = x1 - r * rfrac * rev * COS ( theta - phi ) y2 = y1 - r * rfrac * rev * SIN ( theta - phi ) x3 = x1 - r * rfrac * rev * COS ( theta + phi ) y3 = y1 - r * rfrac * rev * SIN ( theta + phi ) x4 = x1 - rfrac / 2 * r * rev * COS ( theta ) y4 = y1 - rfrac / 2 * r * rev * SIN ( theta ) ; Calculate intersection of vector shaft and head points either ; side of the shaft - see ; http : // astronomy . swin . edu . au /~ pbourke / geometry / lineline2d ; for more details ua = (( x3 - x2 ) * ( y0 - y2 ) - ( y3 - y2 ) * ( x0 - x2 )) / $ (( y3 - y2 ) * ( x1 - x0 ) - ( x3 - x2 ) * ( y1 - y0 )) x5 = x0 + ua * ( x1 - x0 ) y5 = y0 + ua * ( y1 - y0 ) outputval = 1 ; Plot vectors in data space - cstyle = 0 ; Position in device coordinates and then convert to data coordinates if ( cstyle EQ 0 ) then begin pt1 = CONVERT_COORD ( x , y , / DATA , / TO_DEVICE ) xpts = [ x0 , x1 , x2 , x3 , x4 , x5 ] + pt1 [ 0 ] - align * dx ypts = [ y0 , y1 , y2 , y3 , y4 , y5 ] + pt1 [ 1 ] - align * dy pts = CONVERT_COORD ( xpts , ypts , / DEVICE , / TO_DATA ) xpts = pts [ 0 , * ] ypts = pts [ 1 , * ] x0 = xpts [ 0 ] x1 = xpts [ 1 ] x2 = xpts [ 2 ] x3 = xpts [ 3 ] x4 = xpts [ 4 ] x5 = xpts [ 5 ] y0 = ypts [ 0 ] y1 = ypts [ 1 ] y2 = ypts [ 2 ] y3 = ypts [ 3 ] y4 = ypts [ 4 ] y5 = ypts [ 5 ] ; Plot the vectors omiting any vectors with NaNs z = [ xpts , ypts ] if ( TOTAL ( FINITE ( z )) EQ 12 ) then begin PLOTS , [ x0 , x5 , x3 , x1 , x2 , x5 ], [ y0 , y5 , y3 , y1 , y2 , y5 ], COLOR = color , THICK = thick , NOCLIP = 0 POLYFILL , [ x2 , x1 , x3 ],[ y2 , y1 , y3 ], COLOR = color , THICK = thick , NOCLIP = 0 endif endif ; Plot reference vector - cstyle = 1 ; Position in device coordinates and then convert to data coordinates if ( cstyle EQ 1 ) then begin pt1 = CONVERT_COORD ( x , y , / NORMAL , / TO_DEVICE ) xpts = [ x0 , x1 , x2 , x3 , x4 , x5 ] + pt1 [ 0 ] ypts = [ y0 , y1 , y2 , y3 , y4 , y5 ] + pt1 [ 1 ] x0 = xpts [ 0 ] x1 = xpts [ 1 ] x2 = xpts [ 2 ] x3 = xpts [ 3 ] x4 = xpts [ 4 ] x5 = xpts [ 5 ] y0 = ypts [ 0 ] y1 = ypts [ 1 ] y2 = ypts [ 2 ] y3 = ypts [ 3 ] y4 = ypts [ 4 ] y5 = ypts [ 5 ] ; Plot the vectors omiting any vectors with NaNs z = [ xpts , ypts ] if ( TOTAL ( FINITE ( z )) EQ 12 ) then begin PLOTS , [ x0 , x5 , x3 , x1 , x2 , x5 ], [ y0 , y5 , y3 , y1 , y2 , y5 ], COLOR = color , THICK = thick , / DEVICE POLYFILL , [ x2 , x1 , x3 ],[ y2 , y1 , y3 ], COLOR = color , THICK = thick , / DEVICE endif ; Add the reference vector text xoffset = round ( abs ( x3 - x2 )) / 2. yoffset = round ( abs ( y3 - y2 )) if myphi eq 0 then CGTEXT , x0 , y0 + ( 2.5 * yoffset ), cgGreek ( 'phi' ) + '=0' + cgSymbol ( 'deg' ), ALIGNMENT = 0.0 , COLOR = color , / DEVICE , charsize = charsize if myphi eq 90 then CGTEXT , x0 + ( 2. * xoffset ), y0 + ( 2. * xoffset ), cgGreek ( 'phi' ) + '=90' + cgSymbol ( 'deg' ), ALIGNMENT = 0.0 , COLOR = color , / DEVICE , charsize = charsize endif return , outputval end ; ---------------------------------------------------------------------------- function walsa_vector , u , v , x , y , LENGTH = length , $ Color = color , XSTRIDE = xstride , YSTRIDE = ystride , ALIGN = align , $ REF_MAG = ref_mag , ANGLE = angle , HEAD_LEN = head_len , $ REF_POS = ref_pos , REF_TEXT = ref_text , OVERPLOT = overplot , _EXTRA = extra , THICK = thick , charsize = charsize a = SIZE ( u ) b = SIZE ( v ) c = SIZE ( x ) d = SIZE ( y ) ; Initialise parameters if undefined if ( N_ELEMENTS ( XSTRIDE ) EQ 0 ) then xstride = 0 if ( N_ELEMENTS ( YSTRIDE ) EQ 0 ) then ystride = 0 if N_ELEMENTS ( LENGTH ) EQ 0 then length = 1.0 if N_ELEMENTS ( COLOR ) EQ 0 then color = ! P . COLOR if ( N_ELEMENTS ( ANGLE ) EQ 0 ) then angle = 22.5 if ( N_ELEMENTS ( HEAD_LEN ) EQ 0 ) then head_len = 0.3 if ( N_ELEMENTS ( TYPE ) EQ 0 ) then TYPE = 0 if ( N_ELEMENTS ( ALIGN ) EQ 0 ) then align = 0.5 if ( N_ELEMENTS ( REF_TEXT ) EQ 0 ) then ref_text = ' ' if ( N_ELEMENTS ( REF_MAG ) EQ 0 ) then begin maxmag = MAX ( ABS ( SQRT ( u ^ 2. + v ^ 2. ))) endif ELSE begin maxmag = ref_mag endELSE outputval = 1 ; Setup the plot area if undefined if ( NOT KEYWORD_SET ( overplot )) then begin xs = x [ 0 ] - ( x ( 1 ) - x ( 0 )) xf = x [ N_ELEMENTS ( x ) - 1 ] + ( x ( 1 ) - x ( 0 )) ys = y [ 0 ] - ( y ( 1 ) - y ( 0 )) yf = y [ N_ELEMENTS ( y ) - 1 ] + ( y ( 1 ) - y ( 0 )) PLOT ,[ xs , xf ],[ ys , yf ], XSTYLE = 1 , YSTYLE = 1 , / NODATA , $ COLOR = color , _EXTRA = extra endif ; do stride data reduction if needed if ( xstride GT 1 ) then begin mypts = FLTARR ( a [ 1 ], a [ 2 ]) mypts [ * , * ] = 0.0 for iy = 0 , a [ 2 ] - 1 , xstride do begin for ix = 0 , a [ 1 ] - 1 , ystride do begin if ( (( ix / xstride ) EQ FIX ( ix / xstride )) AND $ (( iy / ystride ) EQ FIX ( iy / ystride )) ) then mypts [ ix , iy ] = 1.0 endfor endfor pts = WHERE ( mypts LT 1.0 ) u [ pts ] = 0.0 v [ pts ] = 0.0 endif ; Main vector plotting loop for ix = 1 , N_ELEMENTS ( x ) - 1 do begin for iy = 1 , N_ELEMENTS ( y ) - 1 do begin tempt = walsa_plot_vector ( u ( ix , iy ), v ( ix , iy ), x ( ix ), y ( iy ), $ angle = angle , head_len = head_len , $ maxmag = maxmag , align = align , length = length , $ color = color , cstyle = 0 , THICK = thick ) endfor endfor ; Plot reference arrow ( s ) if ( N_ELEMENTS ( REF_POS ) NE 0 ) then begin tempt = walsa_plot_vector ( 2. * maxmag , 0.0 , ref_pos [ 0 ], ref_pos [ 1 ], $ angle = angle , ref_text = ref_text , head_len = head_len - 0.2 , $ maxmag = maxmag , align = align , length = length , $ color = color , cstyle = 1 , thick = thick , myphi = 0 , charsize = charsize ) tempt = walsa_plot_vector ( 0.0 , 2. * maxmag , ref_pos [ 0 ], ref_pos [ 1 ] + 0.10 , $ angle = angle , ref_text = ref_text , head_len = head_len - 0.2 , $ maxmag = maxmag , align = align , length = length , $ color = color , cstyle = 1 , thick = thick , myphi = 90 , charsize = charsize ) endif return , outputval end ; ---------------------------------------------------------------------------- pro walsa_plot_wavelet_cross_spectrum , power , period , time , coi , significancelevel = significancelevel , clt = clt , ylog = ylog , $ phase_angle = phase_angle , log = log , crossspectrum = crossspectrum , normal = normal , epsfilename = epsfilename , $ coherencespectrum = coherencespectrum , noarrow = noarrow , w = w , nosignificance = nosignificance , maxperiod = maxperiod , $ arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , removespace = removespace , koclt = koclt , arrowthick = arrowthick if n_elements ( crossspectrum ) eq 0 then crossspectrum = 0 if n_elements ( coherencespectrum ) eq 0 then coherencespectrum = 0 if n_elements ( log ) eq 0 then log = 1 if n_elements ( ylog ) eq 0 then ylog = 1. if n_elements ( arrowdensity ) eq 0 then arrowdensity = [ 30 , 18 ] if n_elements ( arrowsize ) eq 0 then arrowsize = 1. if n_elements ( arrowheadsize ) eq 0 then arrowheadsize = 1. if n_elements ( arrowthick ) eq 0 then arrowthick = 2. if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( noarrow ) eq 0 then noarrow = 0 if n_elements ( removespace ) eq 0 then removespace = 0 if n_elements ( normal ) eq 0 then normal = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if crossspectrum eq 0 and coherencespectrum eq 0 then begin PRINT PRINT , ' Please define which one to plot: cross spectrum or coherence' PRINT stop endif if crossspectrum ne 0 and coherencespectrum ne 0 then begin PRINT PRINT , ' Please define which one to plot: cross spectrum or coherence' PRINT stop endif nt = n_elements ( reform ( time )) np = n_elements ( reform ( period )) fundf = 1000. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz if n_elements ( maxperiod ) eq 0 then maxp = 1000. / fundf else maxp = maxperiod ; longest period to be plotted if n_elements ( maxperiod ) eq 0 then if removespace ne 0 then maxp = max ( coi ) ; remove areas below the COI iit = closest_index ( maxp , period ) period = period [ 0 : iit ] if nosignificance eq 0 then isig = reform ( significancelevel [ * , 0 : iit ]) power = reform ( power [ * , 0 : iit ]) power = reverse ( power , 2 ) np = n_elements ( reform ( period )) aphaseangle = phase_angle aphaseangle = reform ( aphaseangle [ * , 0 : iit ]) if nosignificance eq 0 then isig = reverse ( isig , 2 ) if nosignificance eq 0 then sigi = power / isig if n_elements ( w ) eq 0 then w = 8 dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize if EPS eq 1 then begin walsa_eps , size = [ 18 , 13 ] ! p . font = 0 device , set_font = 'Times-Roman' charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.033 ! y . ticklen =- 0.024 ; ! y . minor = 10 barthick = 550 distbar = 550 coithick = 3. arrowsize = 20. * arrowsize arrowthick = ( 3.5 / 2. ) * arrowthick c_thick = 3. h_thick = 1.4 ; ! y . tickinterval = 100. ; arrowheadsize = 10. endif else begin if ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) then begin if crossspectrum ne 0 then window , w , xs = 900 , ys = 650 , title = strtrim ( w , 2 ) + ': Cross Wavelet Spectrum' if coherencespectrum ne 0 then window , w , xs = 900 , ys = 650 , title = strtrim ( w , 2 ) + ': Coherence' charsize = 2.0 ! x . thick = 2. ! y . thick = 2. ! x . ticklen =- 0.033 ! y . ticklen =- 0.022 ; ! X . MINOR = 6 distbar = 30 barthick = 30 coithick = 2 c_thick = 2. h_thick = 1. endif if ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) then begin if crossspectrum ne 0 then window , w , xs = FIX ( smallest_screensize * 0.9 ), ys = FIX ( smallest_screensize * 0.9 ), title = strtrim ( w , 2 ) + ': Cross Wavelet Spectrum' if coherencespectrum ne 0 then window , w , xs = FIX ( smallest_screensize * 0.9 ), ys = FIX ( smallest_screensize * 0.9 ), title = strtrim ( w , 2 ) + ': Coherence' charsize = 1.7 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.033 ! y . ticklen =- 0.022 distbar = 25 barthick = 25 coithick = 2 c_thick = 2. h_thick = 1. endif endelse colset device , decomposed = 0 xtitle = 'Time (s)' if crossspectrum ne 0 then begin if normal ne 0 then begin ztitle = 'Normalised Cross Power!C' if log ne 0 then ztitle = 'Log!d10!n(Normalised Cross Power)!C' endif else begin ztitle = 'Cross Power!C' if log ne 0 then ztitle = 'Log!d10!n(Cross Power)!C' endelse endif if coherencespectrum ne 0 then begin ztitle = 'Coherence!C' if log ne 0 then ztitle = 'Log!d10!n(Coherence)!C' endif ii = where ( power lt 0. , cii ) if cii gt 0 then power ( ii ) = 0. if crossspectrum ne 0 then if normal ne 0 then power = 100. * power / max ( power ) xrg = minmax ( time ) yrg = [ max ( period ), min ( period )] ; userlct , / full , verbose = 0 , coltab = nnn if n_elements ( clt ) eq 0 then clt = 20 loadct , clt if n_elements ( koclt ) ne 0 then walsa_kopowercolor , koclt if log ne 0 then power = alog10 ( power ) walsa_image_plot , power , xrange = xrg , yrange = yrg , $ nobar = 0 , zrange = minmax ( power , / nan ), ylog = ylog , $ contour = 0 , / nocolor , charsize = charsize , $ ztitle = ztitle , xtitle = xtitle , $ exact = 1 , aspect = 0 , cutaspect = 0 , ystyle = 5 , $ barpos = 1 , zlen =- 0.6 , distbar = distbar , $ barthick = barthick , position = [ 0.14 , 0.14 , 0.87 , 0.87 ] cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , ylog = ylog , charsize = charsize , ytitle = 'Period (s)' ; Lblv = LOGLEVELS ([ max ( period ), min ( period )]) ; axlabel , Lblv , charsize = charsize , color = cgColor ( 'Black' ) , format = '(i12)' cgAxis , YAxis = 1 , YRange = [ 1000. / yrg [ 0 ], 1000. / yrg [ 1 ]], ystyle = 1 , ylog = ylog , title = 'Frequency (mHz)' , charsize = charsize ; plot phase angles as arrows angle = aphaseangle UU = cos ( d2r ( angle )) VV = sin ( d2r ( angle )) if noarrow eq 0 then $ tempt = walsa_vector ( UU , VV , time , period , / overplot , color = cgColor ( 'Black' ), length = 0.04 * arrowsize , ySTRIDE = round ( nt / float ( ArrowDensity [ 0 ])), $ xSTRIDE = round ( np / float ( ArrowDensity [ 1 ])), thick = arrowthick , head_len = 0.5 * arrowheadsize , ref_pos = [ 0.025 , 0.815 ], align = 0.5 , charsize = charsize ) ; plot the Cone - of - Influence plots , time , coi , noclip = 0 , linestyle = 0 , thick = coithick , color = cgColor ( 'Black' ) ; shade the area above the Cone - of - Influence , with hashed lines : ncoi = n_elements ( coi ) y = fltarr ( ncoi ) for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION =- 45 ; contours mark significance level if nosignificance eq 0 then $ cgContour , sigi , / noerase , levels = 1. , XTICKforMAT = \"(A1)\" , YTICKforMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = c_thick if EPS eq 1 then walsa_endeps , filename = epsfilename , / pdf end", "title": "Main Routines"}, {"location": "idl/routines/#under-the-hood", "text": "We strongly recommend everyone to follow the procedure as instructed here when using WaLSAtools \u2014 a user-friendly tool \u2014 which gives you all information you need to do your analysis. However, for experts who want to make themselves familiar with the techniques and codes under the hood, inspect them and modify/develop/improve them, some of the main codes are also provided below. Please note that all codes and their dependencies are available in the GitHub repository .", "title": "Under the Hood"}, {"location": "idl/routines/#spectral-analyzer", "text": "WaLSA_speclizer This code computes power spectrum and its statistical significance level for a 1D signal (or all pixels of an image sequence, i.e., a 3D cube) using FFT (Fast Fourier Transform), Lomb-Scargle, Wavelet, and HHT (Hilbert-Huang Transform) analysis techniques. In addition, the code can output mean power spectrum (averaged over power spectra of several pixels) as well as dominant frequency and power using the above-mentioned analysis methods. WaLSA_speclizer.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_speclizer : WaLSA Spectral Analyzer ; part of -- WaLSAtools -- ; ; PURPOSE : ; Compute power spectrum and its statistical significance level for a 1 D signal ; ( or all pixels of an image sequence , i . e . , a 3 D cube ) using ; FFT ( Fast Fourier Transform ), Lomb - Scargle , Wavelet , or ; HHT ( Hilbert - Huang Transform ) analyses . ; -- Signals are detrended ( linearly or using higher - order polynomial fits ) and ; apodized ( using a Tukey window ) prior to the spectral analysis ( unless otherwise it is omitted ) . ; -- Power ( and significance levels ) are returned in DN ^ 2 / mHz , frequencies in mHz . ; ; CALLING SEQUENCE : ; EXAMPLES : ; power = walsa_speclizer ( cube , time , mode = 1 , / fft , frequency = frequency , significance = significance , siglevel = 0.01 ) ; power = walsa_speclizer ( cube , time , mode = 1 , / wavelet , / global , frequency = frequency , significance = significance ) ; ; + INPUTS : ; data : 1 D time series , or ( x , y , t ) datacube , any type ; ( an ordered sequence of data points , typically some variable quantity measured at successive times . ) ; time : observing times of the time series in seconds ; ; + OPTIONAL KEYWORDS : ; ---- type of analysis ---- ; fft : if set , Fast Fourier Transform ( FFT ) power spectrum is computed : for regular ( evenly sampled ) time series . ; lombscargle : if set , Lomb - Scargle power spectrum is computed : for irregular ( unevenly sampled ) time series . ; hht : if set , a power spectrum associated to EMD + Hilbert Transform is computed : for regular ( evenly sampled ) time series . ; wavelet : if set , Wavelet power spectrum is computed ( default : Morlet function with omega = 6 ): for regular ( evenly sampled ) time series . ; welch : if set , Welch power spectrum is computed ; ---- padding , detrending , and apodization parameters ---- ; padding : oversampling factor : zero padding ( increasing timespan ) to increase frequency resolution ( NOTE : doesn 't add information) ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; resample if recon is set , then by setting resample , amplitudes are scaled to approximate actual values . ; ---- significance - level parameters ---- ; siglevel : significance level ( default : 0.05 = 5 % significance level = 95 % confidence level ) ; nperm : number of random permutations for the significance test -- the larger the better ( default : 1000 ) ; nosignificance : if set , no significance level is calculated . ; ---- power calibration ---- ; mode : outputted power mode : 0 = log ( power ), 1 = linear power ( default ), 2 = sqrt ( power ) = amplitude ; ---- wavelet parameters / options ---- ; mother : wavelet function , providing different localisation / resolution in frequency and in time ( also depends on param , m ) . ; currently , 'Morlet' , 'Paul' , 'DOG' ( derivative of Gaussian ) are available . default : 'Morlet' . ; param : optional mother wavelet parameter . ; For 'Morlet' this is k0 ( wavenumber ), default is 6. ; For 'Paul' this is m ( order ), default is 4. ; For 'DOG' this is m ( m - th derivative ), default is 2 ( i . e . , the real - valued Mexican - hat wavelet ) ; dj : spacing between discrete scales . default : 0.025 ; global : only if wavelet is set : returns global wavelet spectrum ( averaged over time domain ) ; oglobal : global wavelet spectrum excluding regions influenced by cone - of - influence ( CoI ; regions subject to edge effect ) ; rgws : time - integral of wavelet power excluding regions influenced by cone - of - influence and only for those above the confidence level ; this returns power - weighted frequency distribution ( with significant power & unaffected by CoI ) ; Note : this is likely the most correct spectrum ! ; colornoise : if set , noise background is based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 ; ---- HHT parameters / options ---- ; stdlimit : standard deviation to be achieved before accepting an IMF ( recommended value between 0.2 and 0.3 ; perhaps even smaller ); default : 0.2 ; nfilter : Hanning window width for two dimensional smoothing of the Hilbert spectrum . default : 3 ; ( an odd integer , prefrabely equal to or larger than 3 ; equal to 0 to avoid the windowing ) ; emd : if set , intrinsic mode functions ( IMFs ) and their associated frequencies ( i . e . , instantaneous frequencies ) are outputted ; ---- dominant frequency ---- ; nodominantfreq : if set , dominant frequency and dominant power are not calculated ( to , e . g . , save computational time for large datasets ) ; ; + OUTPUTS : ; power : a 1 D array of power ( or a 3 D array if the input is a 3 D cube ) . ; the only exception is for wavelet ( where global is not set ) . ; power is divided by the first ( non - zero ) frequency . unit : DN ^ 2 / mHz ; significance : significance levels , with the same dimension as the power . unit : DN ^ 2 / mHz ; frequency : an array of frequencies , with the same size as the power . unit : mHz ; period : 1 D array of periods ( in seconds ) ; coicube : cone - of - influence cube , only when wavelet analysis is performed --> if wavelet is set ; imf : the intrinsic mode functions ( IMFs ) from EMD alalysis within the HHT --> if hht and emd are set ; instantfreq : instantaneous frequencies of each component time series --> if hht and emd are set ; dominantfreq : dominant frequency , i . e . , frequency corresponding to the maximum power ( in mHz ): same saptial size as input data ( i . e . , 1 D or 2 D ) ; note : if there are multiple peaks with the exact same power , the lowest dominant frequency is returned ! ; dominantpower : power ( in DN ^ 2 / mHz ) corresponding to the dominant frequency : same saptial size as input data ( i . e . , 1 D or 2 D ) ; rangefreq : frequency range over which the dominant frequency is computed . default : full frequency range ; averagedpower : spatially averaged power spectrum ( of multiple 1 D power spectra ) . unit : DN ^ 2 / mHz ; amplitude : a 1 D array of oscillation amplitude ( or a 3 D array if the input is a 3 D cube ) . ; ; MODIFICATION HISTORY ; ; 2010 plotpowermap : Rob Rutten , assembly of Alfred de Wijn 's routines ; ( https : // webspace . science . uu . nl /~ rutte101 / rridl / cubelib / plotpowermap . pro ) ; 2014 - 2021 Extensively modified / extended by Shahin Jafarzadeh , with contributions from Marco Stangalini and David B . Jess ; - ; ---------------------------- HHT ( EMD + Hilbert ) ----------------------------- function getpowerHHT , cube , cadence , stdlimit , nfilter = nfilter , significance = significance , siglevel = siglevel , nperm = nperm , padding = padding , $ frequencies = frequencies , nosignificance = nosignificance , emd = emd , imf = imf , instantfreq = instantfreq , averagedpower = averagedpower , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , amplitude = amplitude , $ originalcube = originalcube , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , $ meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ; Hilbert - Huang Transform ( HHT ) power spectra if padding gt 1 then begin ; zero padding ( optional ): to increase frequency resolution if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( padding , 2 ) + ') .....' print , ' ' endif nx = n_elements ( cube [ * , 0 , 0 ]) ny = n_elements ( cube [ 0 , * , 0 ]) nt = n_elements ( cube [ 0 , 0 , * ]) padded = fltarr ( nx , ny , padding * nt ) mid_point = ROUND (( padding * nt ) / 2. ) lower_point = mid_point - nt / 2. upper_point = mid_point + nt / 2. - 1 padded [ * , * , mid_point - nt / 2. : mid_point + nt / 2. - 1 ] = cube cube = padded endif sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] if silent eq 0 then begin print , ' ' print , ' ...... output Marginal HHT Spectra ' print , ' ' endif dt = cadence IMFcal = walsa_emd_function ( reform ( cube [ 0 , 0 , * ]), stdlimit , dt = dt ) hhs = walsa_hilbert_spec ( IMFcal , dt , freq = frequencies , marginal = pm , nfilter = nfilter ) nff = n_elements ( frequencies ) if frequencies [ 0 ] eq 0 then begin frequencies = frequencies [ 1 : nff - 1 ] pm = pm [ 1 : nff - 1 ] f0 = 1 endif else f0 = 0 nf = n_elements ( frequencies ) frequencies = frequencies * 1000. ; in mHz powermap = fltarr ( nx , ny , nf ) ; HHT power spectra amplitude = fltarr ( nx , ny , nf ) if emd then begin imf = fltarr ( nx , ny , nt , 20 ) ; 20 : maximum number of IMFs that can be created instantfreq = fltarr ( nx , ny , nt , 20 ) endif if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significancec cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) IMFcal = walsa_emd_function ( signal , stdlimit , dt = dt ) hhs = walsa_hilbert_spec ( IMFcal , dt , marginal = pm , nfilter = nfilter , instfreq = instfreq , amplitudemarginal = amplitudemarginal ) nimimf = n_elements ( IMFcal [ 0 , * ]) if emd then begin imf [ ix , iy , * , 0 : nimimf - 1 ] = IMFcal instantfreq [ ix , iy , * , 0 : nimimf - 1 ] = instfreq * 1000. ; instantaneous frequencies in mHz end if f0 then powermap [ ix , iy , * ] = ( pm [ 1 : nff - 1 ] * padding ) / frequencies [ 0 ] else powermap [ ix , iy , * ] = ( pm * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz amplitude [ ix , iy , * ] = amplitudemarginal [ 1 : nff - 1 ] * padding if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) IMFcal = walsa_emd_function ( y_perm , stdlimit , dt = dt ) hhs = walsa_hilbert_spec ( IMFcal , dt , marginal = pstmp , nfilter = nfilter ) ps_perm [ * , ip ] = pstmp [ 1 : nff - 1 ] if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == HHT next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) amplitude = reform ( amplitude ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if emd then begin imf = reform ( imf ) instantfreq = reform ( instantfreq ) endif if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; --------------------------------- Lomb - Scargle ------------------------------- function getpowerLS , cube , time , OFAC = OFAC , siglevel = siglevel , frequencies = frequencies , significance = significance , nperm = nperm , $ nosignificance = nosignificance , averagedpower = averagedpower , amplitude = amplitude , originalcube = originalcube , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , $ meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ; Lomb - scargle power spectra ; The periodogram values ( from LNP_TEST ) are converted to power ( comparable to FFT values ) by myltiplying ; with 2. * variance ( signal , / double ) / nt ( see Numerical Recipes in C : The Art of Scientific Computing ; Press at al . 2007 ) sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] if OFAC gt 1 then begin if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( OFAC , 2 ) + ') .....' print , ' ' endif endif r = LNP_TEST ( reform ( time ), reform ( cube [ 0 , 0 , * ]), / DOUBLE , WK1 = frequencies , WK2 = pm , OFAC = OFAC ) frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) powermap = fltarr ( nx , ny , nf ) ; Lomb - scargle power spectra amplitude = fltarr ( nx , ny , nf ) if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significancec cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) r = LNP_TEST ( reform ( time ), signal , / DOUBLE , WK1 = freq , WK2 = pm , OFAC = OFAC ) powermap [ ix , iy , * ] = (( pm * ( 2. * variance ( signal , / double ) / nt )) * OFAC ) / frequencies [ 0 ] ; in DN ^ 2 / mHz amplitude [ ix , iy , * ] = sqrt ((( 2. * pm * ( 2. * variance ( signal , / double ) / nt )) * OFAC )) ; K . Hocke 1998 , Ann . Geophysics , 16 , 356 if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) results = LNP_TEST ( time , y_perm , / DOUBLE , WK1 = freq , WK2 = psp , OFAC = OFAC ) ps_perm [ * , ip ] = psp * ( 2. * variance ( y_perm , / double ) / nt ) if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * OFAC ) / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == Lomb-Scargle next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) amplitude = reform ( amplitude ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; ----------------------------------- Welch --------------------------------- function welch_psd , cube , cadence , frequencies = frequencies , window_size = window_size , overlap = overlap , wfft_size = wfft_size , significance = significance , $ nperm = nperm , nosignificance = nosignificance , averagedpower = averagedpower , originalcube = originalcube , siglevel = siglevel , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , apod = apod , silent = silent , $ nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original ; Initialize variables sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] ; Assume wfft_size ( nfft ) is equal to window_size for simplicity and clarity wfft_size = window_size step_size = window_size - overlap num_segments = fix (( nt - overlap ) / step_size ) if num_segments le 0 then begin PRINT , ' Number of segments: ' + strtrim ( num_segments , 2 ) + ' (!)' PRINT , ' Error: Overlap or window size too large.' stop endif ; Create a Hann window ( this should be a changable option in future versions ) window = ( 1.0 - cos ( 2 * ! pi * findgen ( window_size ) / ( window_size - 1 ))) / 2.0 frequencies = 1. / ( cadence * 2 ) * findgen ( window_size / 2 + 1 ) / ( window_size / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) powermap = fltarr ( nx , ny , nf ) ; Welch power spectra if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significance cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) ; Process each segment psd = FLTARR ( window_size / 2 + 1 ) for segment = 0 L , num_segments - 1 do begin start_index = segment * step_size end_index = start_index + window_size if end_index gt nt then continue ; Extract the segment and apply the window segment_data = signal [ start_index : end_index ] * window ; Compute the FFT segment_fft = FFT ( segment_data , wfft_size ) ; Compute power spectral density segment_psd = ( ABS ( segment_fft )) ^ 2 / ( window_size * wfft_size ) psd = psd + segment_psd [ 0 : window_size / 2 ] endfor ; Normalize the averaged PSD psd = psd / num_segments powermap [ ix , iy , * ] = psd [ 1 : nff - 1 ] / frequencies [ 0 ] ; in DN ^ 2 / mHz if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) ; Process each segment psd = FLTARR ( window_size / 2 + 1 ) for segment = 0 L , num_segments - 1 do begin start_index = segment * step_size end_index = start_index + window_size if end_index gt nt then continue ; Extract the segment and apply the window segment_data = y_perm [ start_index : end_index ] * window ; Compute the FFT segment_fft = FFT ( segment_data , wfft_size ) ; Compute power spectral density segment_psd = ( ABS ( segment_fft )) ^ 2 / ( window_size * wfft_size ) psd = psd + segment_psd [ 0 : window_size / 2 ] endfor ; Normalize the averaged PSD psd = psd / num_segments ps_perm [ * , ip ] = psd [ 1 : nff - 1 ] if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = signif / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == FFT next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; ----------------------------------- FOURIER ---------------------------------- function getpowerFFT , cube , cadence , siglevel = siglevel , padding = padding , frequencies = frequencies , significance = significance , $ nperm = nperm , nosignificance = nosignificance , averagedpower = averagedpower , amplitude = amplitude , originalcube = originalcube , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , apod = apod , silent = silent , $ nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original ; Fast Fourier Transform ( FFT ) power spectra if padding gt 1 then begin ; zero padding ( optional ): to increase frequency resolution if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( padding , 2 ) + ') .....' print , ' ' endif nx = n_elements ( cube [ * , 0 , 0 ]) ny = n_elements ( cube [ 0 , * , 0 ]) nt = n_elements ( cube [ 0 , 0 , * ]) padded = fltarr ( nx , ny , padding * nt ) mid_point = ROUND (( padding * nt ) / 2. ) lower_point = mid_point - nt / 2. upper_point = mid_point + nt / 2. - 1 padded [ * , * , mid_point - nt / 2. : mid_point + nt / 2. - 1 ] = cube cube = padded endif sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] frequencies = 1. / ( cadence * 2 ) * findgen ( nt / 2 + 1 ) / ( nt / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) powermap = fltarr ( nx , ny , nf ) ; FFT power spectra amplitude = complexarr ( nx , ny , nf ) ; FFT amplitudes if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) ; significance cube if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin signal = reform ( cube [ ix , iy , * ]) ; single - sided power is doubled ( compared to double - sided power ), assuming P ( \u2212 f ) = P ( f ): spec = ( fft ( signal , - 1 , / double ))[ 0 : nt / 2. ] pm = 2. * ( ABS ( spec ) ^ 2 ) powermap [ ix , iy , * ] = ( pm [ 1 : nff - 1 ] * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz amplitude [ ix , iy , * ] = spec [ 1 : nff - 1 ] * padding if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( powermap [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif if nosignificance eq 0 then begin Nsig = n_elements ( signal ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) pstmp = 2. * ( ABS (( fft ( y_perm , - 1 , / double ))[ 0 : nt / 2. ]) ^ 2. ) ps_perm [ * , ip ] = pstmp [ 1 : nff - 1 ] if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance test): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * padding ) / frequencies [ 0 ] ; in DN ^ 2 / mHz endif averagedpower = averagedpower + reform ( powermap [ ix , iy , * ]) endfor if long ( nx ) gt 1 then $ writeu , - 1 , string ( format = '(%\" \\r == FFT next row... \",i5,\"/\",i5)' , ix , nx ) endfor powermap = reform ( powermap ) frequencies = reform ( frequencies ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) amplitude = reform ( amplitude ) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) return , powermap end ; ------------------------------------ WAVELET --------------------------------- function getpowerWAVELET , cube , cadence , dj = dj , mother = mother , siglevel = siglevel , global = global , frequencies = frequencies , $ significance = significance , coicube = coicube , oglobal = oglobal , colornoise = colornoise , param = param , $ padding = padding , nosignificance = nosignificance , averagedpower = averagedpower , psd = psd , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ originalcube = originalcube , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , nperm = nperm , rgws = rgws , silent = silent ; Wavelet power spectra : either wavelet spectra , or global wavelet spectra ( traditional or improved versions ) input_data = cube ; to prevent the input data be modified by functions unintentionally if padding gt 1 then begin ; zero padding ( optional ): to increase frequency resolution if silent eq 0 then begin print , ' ' print , ' -- Zero Padding (oversampling factor: ' + strtrim ( padding , 2 ) + ') .....' print , ' ' endif nx = n_elements ( input_data [ * , 0 , 0 ]) ny = n_elements ( input_data [ 0 , * , 0 ]) nt = n_elements ( input_data [ 0 , 0 , * ]) padded = fltarr ( nx , ny , padding * nt ) mid_point = ROUND (( padding * nt ) / 2. ) lower_point = mid_point - nt / 2. upper_point = mid_point + nt / 2. - 1 padded [ * , * , mid_point - nt / 2. : mid_point + nt / 2. - 1 ] = input_data input_data = padded endif siglevel = 1.0 - siglevel ; different convention sizecube = size ( input_data ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] col = reform ( input_data [ 0 , 0 , * ]) col = ( col - TOTAL ( col ) / nt ) ; lag1 = ( A_CORRELATE ( col , 1 ) + SQRT ( A_CORRELATE ( col , 2 ))) / 2. ; Wavelet transform : wave = walsa_wavelet ( reform ( col ), cadence , PERIOD = period , PAD = 1 , COI = coi , MOTHER = mother , / RECON , dj = dj , param = param , J = J , / nodetrendapod ) frequencies = 1. / period frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) if ( global + oglobal + rgws ) gt 1 then begin print print , ' --- [!] Only one of the /global, /oglobal, or /rgws can be flagged at a time!' print stop endif if silent eq 0 then print , ' ' if global eq 1 then begin if silent eq 0 then print , ' ...... global: output \"Traditional\" Global Wavelet Spectrum' ftcube = fltarr ( nx , ny , nf ) endif if oglobal eq 1 then begin if silent eq 0 then print , ' ...... oglobal: output Global Wavelet Spectrum excluding CoI regions' ftcube = fltarr ( nx , ny , nf ) ; power endif if rgws eq 1 then begin if silent eq 0 then print , ' ...... rgws: output rgws Wavelet Spectrum ' if silent eq 0 then print , ' ...... (power-weighted significant frequency distribution, unaffected by CoI)' ftcube = fltarr ( nx , ny , nf ) ; power endif if global eq 0 and oglobal eq 0 and rgws eq 0 then begin if silent eq 0 then print , ' ...... output Wavelet Spectra ' ftcube = fltarr ( nx , ny , nt , nf ) endif if silent eq 0 then begin print , ' ' print , ' Wavelet (mother) function: ' + mother print , ' dj: ' + strtrim ( dj , 2 ) print , ' ' endif iloop = 0 numm = nx * float ( ny ) if nosignificance eq 0 then significance = fltarr ( nx , ny , nf ) if nodominantfreq eq 0 then begin dominantfreq = fltarr ( nx , ny ) ; dominant - frequency map dominantpower = fltarr ( nx , ny ) ; dominant - power map ( i . e . , powers corresponding to dominant frequencies ) endif coicube = fltarr ( nx , ny , nt ) averagedpower = fltarr ( nf ) for ix = 0 , nx - 1 do begin for iy = 0 , ny - 1 do begin col = reform ( input_data [ ix , iy , * ]) col = ( col - TOTAL ( col ) / nt ) col_copy = col ; lag1 = ( A_CORRELATE ( col , 1 ) + SQRT ( A_CORRELATE ( col , 2 ))) / 2. ; Wavelet transform : wave = walsa_wavelet ( col_copy , cadence , PERIOD = period , PAD = 1 , COI = coi , MOTHER = mother , param = param , / RECON , dj = dj , scale = scale , $ SIGNIF = SIGNIF , SIGLVL = siglevel , / nodetrendapod , colornoise = colornoise , power = power ) if global eq 1 then begin global_ws = TOTAL ( power , 1 , / nan ) / nt ; global wavelet spectrum ( GWS ) ftcube [ ix , iy , * ] = ( reform ( global_ws ) * padding ); / frequencies [ nf - 1 ] global_amp = TOTAL ( wave , 1 , / nan ) / nt if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( ftcube [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif ; GWS significance levels : if nosignificance eq 0 then begin dof = nt - scale ; the - scale corrects for padding at edges global_signif = walsa_wave_signif ( col , cadence , scale , 1 , LAG1 = 0.0 , DOF = dof , MOTHER = mother , CDELTA = Cdelta , PSI0 = psi0 , siglvl = siglevel ) significance [ ix , iy , * ] = ( reform ( global_signif ) * padding ); / frequencies [ nf - 1 ] endif averagedpower = averagedpower + reform ( ftcube [ ix , iy , * ]) endif if global eq 0 and oglobal eq 0 and rgws eq 0 then begin ftcube [ ix , iy , * , * ] = ( reform ( power ) * padding ); / frequencies [ nf - 1 ] if nosignificance eq 0 then significance [ ix , iy , * ] = ( reform ( SIGNIF ) * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 / mHz coicube [ ix , iy , * ] = reform ( coi ) endif ; oglobal : time - average wavelet power only over the areas not affected by CoI if oglobal eq 1 then begin opower = fltarr ( nt , nf ) + ! VALUES . F_NAN for i = 0 L , nt - 1 do begin pcol = reform ( power [ i , * ]) ii = where ( reform ( period ) lt coi [ i ], pnum ) if pnum gt 0 then opower ( i , ii ) = pcol ( ii ) endfor opower = mean ( opower , dimension = 1 , / nan ) ftcube [ ix , iy , * ] = ( opower * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( ftcube [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif ; GWS significance levels : if nosignificance eq 0 then begin ; dof = nt - scale ; the - scale corrects for padding at edges ; global_signif = walsa_wave_signif ( col , cadence , scale , 1 , LAG1 = 0.0 , DOF = dof , MOTHER = mother , CDELTA = Cdelta , PSI0 = psi0 , siglvl = siglevel ) ; significance [ ix , iy , * ] = ( reform ( global_signif ) * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 Nsig = n_elements ( col ) ps_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation = walsa_randperm ( Nsig ) signalo = reform ( originalcube [ ix , iy , * ]) y_perm = signalo ( permutation ) if nodetrendapod eq 0 then $ y_perm = walsa_detrend_apod ( y_perm , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , cadence = cadence , / silent ) y_perm = ( y_perm - TOTAL ( y_perm ) / nt ) wave = walsa_wavelet ( y_perm , cadence , PERIOD = period , PAD = 1 , COI = coi , MOTHER = mother , param = param , / RECON , dj = dj , scale = scale , $ / nodetrendapod , colornoise = colornoise , power = powertemp ) opower = fltarr ( nt , nf ) + ! VALUES . F_NAN for i = 0 L , nt - 1 do begin pcol = reform ( powertemp [ i , * ]) ii = where ( reform ( period ) lt coi [ i ], pnum ) if pnum gt 0 then opower ( i , ii ) = pcol ( ii ) endfor ps_perm = mean ( opower , dimension = 1 , / nan ) ; time average only over the areas not affected by CoI if silent eq 0 then print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor signif = walsa_confidencelevel ( ps_perm , siglevel = siglevel , nf = nf ) significance [ ix , iy , * ] = ( signif * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 endif averagedpower = averagedpower + reform ( ftcube [ ix , iy , * ]) endif ; rgws : time - integral of wavelet power only over the areas not affected by CoI and only for those above the significance level . ; i . e . , 'distribution' of significant frequencies ( unaffected by CoI ) weighted by power . if rgws eq 1 then begin isig = REBIN ( TRANSPOSE ( signif ), nt , nf ) istest = where ( power / isig lt 1.0 , numtest ) if numtest gt 0 then power [ istest ] = ! VALUES . F_NAN ipower = fltarr ( nt , nf ) + ! VALUES . F_NAN for i = 0 L , nt - 1 do begin pcol = reform ( power [ i , * ]) ii = where ( reform ( period ) lt coi [ i ], pnum ) if pnum gt 0 then ipower [ i , ii ] = pcol [ ii ] endfor ; ipower = mean ( ipower , dimension = 1 , / nan ) ipower = total ( ipower , 1 , / nan ) ftcube [ ix , iy , * ] = ( ipower * padding ); / frequencies [ nf - 1 ] ; in DN ^ 2 if nodominantfreq eq 0 then begin dominantfreq [ ix , iy ] = walsa_dominant_frequency ( reform ( ftcube [ ix , iy , * ]), frequencies , rangefreq , dominantpower = dompm ) dominantpower [ ix , iy ] = dompm endif averagedpower = averagedpower + reform ( ftcube [ ix , iy , * ]) endif endfor iloop = long ( iloop + 1. ) if silent eq 0 then if nx gt 1 or ny gt 1 then print , string ( 13 b ) + ' >>> % f inished: ' ,( iloop * 100. ) / nx , format = '(a,f4.0,$)' endfor powermap = reform ( ftcube ) frequencies = reform ( frequencies ) averagedpower = reform ( averagedpower / float ( nx ) / float ( ny )) if nodominantfreq eq 0 then begin dominantfreq = reform ( dominantfreq ) dominantpower = reform ( dominantpower ) endif if nosignificance eq 0 then significance = reform ( significance ) coicube = reform ( coicube ) ; if ( global + oglobal + rgws ) gt 0 AND psd eq 1 then begin ; ; Interpolate the power spectrum to a uniform frequency array ( Wavelet 's frequency resolution changes with frequency) ; uniform_freqs = findgen ( n_elements ( frequencies )) * ( max ( frequencies ) - min ( frequencies )) / ( n_elements ( frequencies ) - 1 ) + min ( frequencies ) ; ; powermap = interpol ( powermap , frequencies , uniform_freqs , / SPLINE ) ; ; frequencies = uniform_freqs ; delta_freq = ABS ( frequencies [ 1 ] - frequencies [ 0 ]) ; ; powermap = powermap / delta_freq ; ; averagedpower = averagedpower / delta_freq ; if nodominantfreq eq 0 then dominantpower = dominantpower / delta_freq ; significance = significance / delta_freq ; endif return , powermap end ; ==================================================== MAIN ROUTINE ==================================================== function walsa_speclizer , data , time , $ ; main inputs frequencies = frequencies , significance = significance , coicube = coicube , imf = imf , instantfreq = instantfreq , $ ; main ( additional ) outputs averagedpower = averagedpower , amplitude = amplitude , period = period , $ fft = fft , lombscargle = lombscargle , wavelet = wavelet , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , psd = psd , $ siglevel = siglevel , nperm = nperm , nosignificance = nosignificance , $ ; significance - level parameters mother = mother , param = param , dj = dj , global = global , oglobal = oglobal , rgws = rgws , colornoise = colornoise , $ ; Wavelet parameters / options stdlimit = stdlimit , nfilter = nfilter , emd = emd , $ ; HHT parameters / options mode = mode , silent = silent , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ ; dominant frequency window_size = window_size , overlap = overlap , wfft_size = wfft_size ; Welch parameters cube = reform ( data ) sizecube = size ( cube ) if sizecube [ 0 ] ne 3 then begin if sizecube [ 0 ] eq 1 then begin blablacube = fltarr ( 1 , 1 , sizecube [ 1 ]) blablacube [ 0 , 0 , * ] = cube cube = blablacube endif else begin print , ' ' print , ' [!] The datacube must have either 1 or 3 dimension(s).' print , ' ' stop endelse endif ii = where ( ~ finite ( cube ), / null , cnull ) if cnull gt 0 then cube ( ii ) = median ( cube ) cadence = walsa_mode ( walsa_diff ( time )) temporal_Nyquist = 1. / ( cadence * 2. ) if n_elements ( silent ) eq 0 then silent = 0 if silent eq 0 then begin print , ' ' if sizecube [ 0 ] eq 1 then print , 'The input datacube is of size: [' + ARR2STR ( sizecube [ 1 ], / trim ) + ']' if sizecube [ 0 ] eq 3 then $ print , 'The input datacube is of size: [' + ARR2STR ( sizecube [ 1 ], / trim ) + ', ' + ARR2STR ( sizecube [ 2 ], / trim ) + ', ' + ARR2STR ( sizecube [ 3 ], / trim ) + ']' print , ' ' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + ARR2STR (( cadence * 2. ), / trim ) + ' seconds' if sizecube [ 0 ] eq 1 then print , ' Time series duration = ' + ARR2STR ( cadence * sizecube [ 1 ], / trim ) + ' seconds' if sizecube [ 0 ] eq 3 then print , ' Time series duration = ' + ARR2STR ( cadence * sizecube [ 3 ], / trim ) + ' seconds' print , ' Nyquist frequency = ' + ARR2STR ( temporal_Nyquist * 1000. , / trim ) + ' mHz' print , ' ' endif if n_elements ( global ) eq 0 then global = 0 ; if set , global wavelet will be returned ; otherwsie wavelet 2 D power spectra ( default ) if n_elements ( dj ) eq 0 then dj = 0.025 if n_elements ( fft ) eq 0 then fft = 0 if n_elements ( psd ) eq 0 then psd = 0 if n_elements ( lombscargle ) eq 0 then lombscargle = 0 if n_elements ( hht ) eq 0 then hht = 0 if n_elements ( welch ) eq 0 then welch = 0 if n_elements ( wavelet ) eq 0 then wavelet = 0 if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( nodominantfreq ) eq 0 then nodominantfreq = 0 if n_elements ( siglevel ) eq 0 then siglevel = 0.05 ; 5 % significance level = 95 % confidence level if n_elements ( nperm ) eq 0 then nperm = 1000 if n_elements ( oglobal ) eq 0 then oglobal = 0 if n_elements ( rgws ) eq 0 then rgws = 0 if n_elements ( padding ) eq 0 then padding = 1 if n_elements ( stdlimit ) eq 0 then stdlimit = 0.2 if n_elements ( nfilter ) eq 0 then nfilter = 3 if n_elements ( emd ) eq 0 then emd = 0 if n_elements ( colornoise ) eq 0 then colornoise = 0 ; if set , noise background based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 if n_elements ( mode ) eq 0 then mode = 1 if n_elements ( apod ) eq 0 then apod = 0.1 ; width of Tukey window ( for apodization ) if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 ; detrend the signal and apodize it if n_elements ( pxdetrend ) eq 0 then pxdetrend = 2 ; do proper linear detrending if n_elements ( meandetrend ) eq 0 then meandetrend = 0 ; no spatial detrending if n_elements ( mother ) eq 0 then mother = 'Morlet' ; possible functions : 'Morlet' , 'DOG' , 'Paul' if n_elements ( NFFT ) eq 0 then NFFT = 256 ; detrend and apodize the cube if nodetrendapod eq 0 then begin apocube = walsa_detrend_apod ( cube , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , cadence = cadence , resample_original = resample_original , silent = silent ) endif else apocube = cube sizecube = size ( apocube ) if sizecube [ 0 ] ne 3 then begin if sizecube [ 0 ] eq 1 then begin blablacube = fltarr ( 1 , 1 , sizecube [ 1 ]) blablacube [ 0 , 0 , * ] = apocube apocube = blablacube endif endif if fft then begin if silent eq 0 then begin print , ' ' print , ' -- Perform FFT (Fast Fourier Transform) .....' print , ' ' endif power = getpowerFFT ( apocube , cadence , siglevel = siglevel , padding = padding , frequencies = frequencies , significance = significance , averagedpower = averagedpower , $ nperm = nperm , nosignificance = nosignificance , dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , $ amplitude = amplitude , originalcube = cube , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , $ meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ) endif if lombscargle then begin if silent eq 0 then begin print , ' ' print , ' -- Perform Lomb-Scargle Transform .....' print , ' ' endif power = getpowerLS ( apocube , time , OFAC = padding , siglevel = siglevel , frequencies = frequencies , significance = significance , averagedpower = averagedpower , amplitude = amplitude , $ nperm = nperm , nosignificance = nosignificance , dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , originalcube = cube , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ) endif if welch then begin if silent eq 0 then begin print , ' ' print , ' -- Perform Welch method .....' print , ' ' endif power = welch_psd ( apocube , cadence , frequencies = frequencies , window_size = window_size , overlap = overlap , wfft_size = wfft_size , significance = significance , $ nperm = nperm , nosignificance = nosignificance , averagedpower = averagedpower , originalcube = cube , siglevel = siglevel , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , apod = apod , silent = silent , $ nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original ) endif if wavelet then begin if silent eq 0 then begin print , ' ' print , ' -- Perform Wavelet Transform .....' print , ' ' endif power = getpowerWAVELET ( apocube , cadence , dj = dj , mother = mother , siglevel = siglevel , global = global , frequencies = frequencies , averagedpower = averagedpower , rgws = rgws , $ significance = significance , coicube = coicube , oglobal = oglobal , colornoise = colornoise , padding = padding , nosignificance = nosignificance , originalcube = cube , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , param = param , nperm = nperm , psd = psd , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , silent = silent ) endif if hht then begin if silent eq 0 then begin print , ' ' print , ' -- Perform HHT (Hilbert-Huang Transform) .....' print , ' ' endif power = getpowerHHT ( apocube , cadence , stdlimit , nfilter = nfilter , significance = significance , siglevel = siglevel , nperm = nperm , originalcube = cube , $ padding = padding , frequencies = frequencies , nosignificance = nosignificance , emd = emd , imf = imf , instantfreq = instantfreq , amplitude = amplitude , $ dominantfreq = dominantfreq , rangefreq = rangefreq , nodominantfreq = nodominantfreq , dominantpower = dominantpower , averagedpower = averagedpower , $ apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ resample_original = resample_original , silent = silent ) endif period = 1000. / frequencies sizecube = size ( power ) dim = sizecube [ 0 ] nx = sizecube [ 1 ] ny = sizecube [ 2 ] if dim le 2 then begin ; wavelet power spectrum if ( mode eq 0 ) then begin power = alog10 ( power ) if nosignificance eq 0 then significance = alog10 ( significance ) endif if ( mode eq 2 ) then begin power = sqrt ( power ) if nosignificance eq 0 then significance = sqrt ( significance ) endif endif if dim eq 3 then begin ; power spectra at multiple pixels nf = sizecube [ 3 ] if ( mode eq 0 ) then begin for jnn = 0 L , nf - 1 do power [ * , * , jnn ] = alog10 ( power [ * , * , jnn ]) if nosignificance eq 0 then for jnn = 0 L , nf - 1 do significance [ * , * , jnn ] = alog10 ( significance [ * , * , jnn ]) endif if ( mode eq 2 ) then begin for jnn = 0 L , nf - 1 do power [ * , * , jnn ] = sqrt ( power [ * , * , jnn ]) if nosignificance eq 0 then for jnn = 0 L , nf - 1 do significance [ * , * , jnn ] = sqrt ( significance [ * , * , jnn ]) endif endif if dim eq 4 then begin ; wavelet power spectra at multiple pixels if ( mode eq 0 ) then begin for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do power [ jx , jy , * , * ] = alog10 ( power [ jx , jy , * , * ]) if nosignificance eq 0 then for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do significance [ jx , jy , * , * ] = alog10 ( significance [ jx , jy , * , * ]) endif if ( mode eq 2 ) then begin for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do power [ jx , jy , * , * ] = sqrt ( power [ jx , jy , * , * ]) if nosignificance eq 0 then for jx = 0 L , nx - 1 do for jy = 0 L , ny - 1 do significance [ jx , jy , * , * ] = sqrt ( significance [ jx , jy , * , * ]) endif endif if silent eq 0 then begin PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' print , '' print , 'COMPLETED!' print , '' endif return , power end", "title": "Spectral Analyzer"}, {"location": "idl/routines/#k-analysis-and-fourier-filtering", "text": "WaLSA_QUB_QUEEFF A variant of the QUEEns Fourier Filtering (QUEEFF) code , to compute k-\u03c9 diagram and perform Fourier filtering in the k-\u03c9 space. WaLSA_qub_queeff.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_QUB_QUEEFF ; part of -- WaLSAtools -- ; ; ORIGINAL CODE : QUEEns Fourier Filtering ( QUEEFF ) code ; WRITTEN , ANNOTATED , TESTED AND UPDATED BY : ; ( 1 ) Dr . David B . Jess ; ( 2 ) Dr . Samuel D . T . Grant ; The original code along with its manual can be downloaded at : https : // bit . ly / 37 mx9ic ; ; WaLSA_QUB_QUEEFF : Slightly modified ( i . e . , a few additional keywords added ) by Shahin Jafarzadeh ; ; CHECK DEPENDENCIES ( MAKE SURE ALL REQUIRED PROGRAMMES ARE INSTALLED ): ; NOTE ; @/ Users / dbj / ARC / IDL_programmes / Fourier_filtering / QUEEFF_code / QUEEFF_dependencies . bat ; ; CALLING SEQUENCE : ; EXAMPLES : ; walsa_qub_queeff , datacube , arcsecpx , time = time , power = power , wavenumber = wavenumber , frequencies = frequencies , koclt = 1 ; walsa_qub_queeff , datacube , arcsecpx , cadence , / filtering , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube ; ; + INPUTS : ; datacube input datacube , normally in the form of [ x , y , t ] ; [ note - at present the input datacube needs to have identical x and y dimensions . if not supplied like this the datacube will be cropped accordingly ! ] ; cadence delta time between sucessive frames - given in seconds . if not set , time must be provided ( see optional inputs ) ; arcsecpx spatial sampling of the input datacube - given in arcseconds per pixel ; ; + OPTIONAL INPUTS : ; ( if optional inputs not supplied , the user will need to interact with the displayed k - omega diagram to define these values ) ; time observing times in seconds ( 1 d array ) . it is ignored if cadence is provided ; filtering if set , filterring is proceeded ; f1 optional lower ( temporal ) frequency to filter - given in mhz ; f2 optional upper ( temporal ) frequency to filter - given in mhz ; k1 optional lower ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; k2 optional upper ( spatial ) wavenumber to filter - given in arcsec ^- 1 ( where k = ( 2 * ! pi ) / wavelength ) ; spatial_torus makes the annulus used for spatial filtering have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; temporal_torus makes the temporal filter have a gaussian - shaped profile ( useful for preventing aliasing ) . default : 1 ; if equal to 0 , it is not applied . ; no_spatial_filt optional keyword that ensures no spatial filtering is performed on the dataset ( i . e . , only temporal filtering ) ; no_temporal_filt optional keyword that ensures no temporal filtering is performed on the dataset ( i . e . , only spatial filtering ) ; silent : if set , the k - \u03c9 diagram is not plotted ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( wavenumber ) is plotted in logarithmic scale ( base 10 ) ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ( base 10 ) ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; nox2 : if set , 2 nd x - axis ( spatial size , in arcsec ) is not plotted ; ( spatial size ( i . e . , wavelength ) = ( 2 * ! pi ) / wavenumber ) ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ; + OUTPUTS : ; power : 2 d array of power ( see mode for the scale ) ; ( in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ) ; frequencies : 1 d array of frequencies ( in mhz ) ; wavenumber : 1 d array of wavenumber ( in arcsec ^- 1 ) ; filtered_cube : 3 d array of filtered datacube ( if filtering is set ) ; ; ; IF YOU USE THIS CODE , THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED : ; Jess et al . 2017 , ApJ , 842 , 59 ( http : // adsabs . harvard . edu / abs / 2017 ApJ .. .842 .. .59 J ) ; - pro walsa_qub_queeff , datacube , arcsecpx , cadence = cadence , time = time , $ ; main inputs power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube , $ ; main ( additional ) outputs filtering = filtering , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , spatial_torus = spatial_torus , temporal_torus = temporal_torus , $ ; filtering options no_spatial_filt = no_spatial_filt , no_temporal_filt = no_temporal_filt , $ clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , $ ; plotting keywords xtitle = xtitle , ytitle = ytitle , x2ndaxistitle = x2ndaxistitle , y2ndaxistitle = y2ndaxistitle , $ epsfilename = epsfilename , noy2 = noy2 , nox2 = nox2 , smooth = smooth , silent = silent , mode = mode if n_elements ( xtitle ) eq 0 then xtitle = 'Wavenumber (arcsec!U-1!N)' if n_elements ( ytitle ) eq 0 then ytitle = 'Frequency (mHz)' if n_elements ( x2ndaxistitle ) eq 0 then x2ndaxistitle = 'Spatial size (arcsec)!C' if n_elements ( y2ndaxistitle ) eq 0 then y2ndaxistitle = 'Period (s)' if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) ; DEFINE THE SCREEN RESOLUTION TO ENSURE THE PLOTS DO NOT SPILL OVER THE EDGES OF THE SCREEN dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize xsize_cube = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ysize_cube = N_ELEMENTS ( datacube [ 0 , * , 0 ]) zsize_cube = N_ELEMENTS ( datacube [ 0 , 0 , * ]) ; FORCE THE CUBES TO HAVE THE SAME SPATIAL DIMENSIONS IF xsize_cube gt ysize_cube THEN datacube = TEMPORARY ( datacube [ 0 :( ysize_cube - 1 ), * , * ]) IF xsize_cube gt ysize_cube THEN xsize_cube = ysize_cube IF ysize_cube gt xsize_cube THEN datacube = TEMPORARY ( datacube [ * , 0 :( xsize_cube - 1 ), * ]) IF ysize_cube gt xsize_cube THEN ysize_cube = xsize_cube if n_elements ( spatial_torus ) eq 0 then spatial_torus = 1 if n_elements ( temporal_torus ) eq 0 then temporal_torus = 1 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nox2 ) eq 0 then nox2 = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if not keyword_set ( mode ) then mode = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( filtering ) eq 0 then filtering = 0 else silent = 0 ; CALCULATE THE NYQUIST FREQUENCIES spatial_Nyquist = ( 2. * ! pi ) / ( arcsecpx * 2. ) temporal_Nyquist = 1. / ( cadence * 2. ) print , '' print , 'The input datacube is of size: [' + strtrim ( xsize_cube , 2 ) + ', ' + strtrim ( ysize_cube , 2 ) + ', ' + strtrim ( zsize_cube , 2 ) + ']' print , '' print , 'Spatially, the important values are:' print , ' 2-pixel size = ' + strtrim (( arcsecpx * 2. ), 2 ) + ' arcsec' print , ' Field of view size = ' + strtrim (( arcsecpx * xsize_cube ), 2 ) + ' arcsec' print , ' Nyquist wavenumber = ' + strtrim ( spatial_Nyquist , 2 ) + ' arcsec^-1' IF KEYWORD_SET ( no_spatial_filt ) THEN print , '***NO SPATIAL FILTERING WILL BE PERFORMED***' print , '' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * zsize_cube , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' IF KEYWORD_SET ( no_temporal_filt ) THEN print , '***NO TEMPORAL FILTERING WILL BE PERFORMED***' ; MAKE A k - omega DIAGRAM sp_out = DBLARR ( xsize_cube / 2 , zsize_cube / 2 ) print , '' print , 'Constructing a k-omega diagram of the input datacube..........' print , '' ; MAKE THE k - omega DIAGRAM USING THE PROVEN METHOD OF ROB RUTTEN kopower = walsa_plotkopower_funct ( datacube , sp_out , arcsecpx , cadence , apod = 0.1 , kmax = 1. , fmax = 1. ) ; X SIZE STUFF xsize_kopower = N_ELEMENTS ( kopower [ * , 0 ]) dxsize_kopower = spatial_Nyquist / FLOAT ( xsize_kopower - 1. ) kopower_xscale = ( FINDGEN ( xsize_kopower ) * dxsize_kopower ) ; IN arcsec ^- 1 ; Y SIZE STUFF ysize_kopower = N_ELEMENTS ( kopower [ 0 , * ]) dysize_kopower = temporal_Nyquist / FLOAT ( ysize_kopower - 1. ) kopower_yscale = ( FINDGEN ( ysize_kopower ) * dysize_kopower ) * 1000. ; IN mHz Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) kopower_plot = kopower kopower_plot [ * , 1 : * ] = CONVOL ( kopower [ * , 1 : * ], Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) ; normalise to frequency resolution ( in mHz ) freq = kopower_yscale [ 1 : * ] if freq [ 0 ] eq 0 then freq0 = freq [ 1 ] else freq0 = freq [ 0 ] kopower_plot = kopower_plot / freq0 if mode eq 0 then kopower_plot = ALOG10 ( kopower_plot ) if mode eq 2 then kopower_plot = SQRT ( kopower_plot ) LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. x1 = 0.12 x2 = 0.86 y1 = 0.10 y2 = 0.80 ! p . background = 255. ! p . color = 0. ; WHEN PLOTTING WE NEED TO IGNORE THE ZERO 'TH ELEMENT (I.E., THE MEAN f=0) SINCE THIS WILL MESS UP THE LOG PLOT! komegamap = ( kopower_plot )[ 1 : * , 1 : * ] > MIN (( kopower_plot )[ 1 : * , 1 : * ], / nan ) < MAX (( kopower_plot )[ 1 : * , 1 : * ], / nan ) IF silent EQ 0 THEN BEGIN if n_elements ( komega ) eq 0 then komega = 0 else komega = 1 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. positioncb = [ x1 , y2 + 0.11 , x2 , y2 + 0.13 ] IF EPS eq 1 THEN BEGIN walsa_eps , size = [ 20 , 22 ] ! p . font = 0 device , set_font = 'Times-Roman' ! p . charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 positioncb = [ x1 , y2 + 0.12 , x2 , y2 + 0.14 ] ENDIF ELSE BEGIN IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN WINDOW , 0 , xsize = 1000 , ysize = 1000 , title = 'QUEEFF: k-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN WINDOW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'QUEEFF: k-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 ENDIF ENDELSE walsa_pg_plotimage_komega , komegamap , kopower_xscale [ 1 : * ], kopower_yscale [ 1 : * ], noy2 = noy2 , nox2 = nox2 , smooth = smooth , $ xtitle = 'Wavenumber (arcsec!U-1!N)' , ytitle = 'Frequency (mHz)' , xst = 8 , yst = 8 , xlog = xlog , ylog = ylog , position = [ x1 , y1 , x2 , y2 ], $ xrange = xrange , yrange = yrange , threemin = threemin , fivemin = fivemin , eps = eps tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ) - MIN ( kopower_plot [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) cgcolorbar , bottom = 0 , ncolors = 255 , divisions = 3 , minrange = MIN ( kopower_plot [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( kopower_plot [ 1 : * , 1 : * ], / nan ), $ position = positioncb , / top , ticknames = tickmarknames , title = 'Log!d10!n(Oscillation Power)' , yticklen = 0.00001 ENDIF IF EPS eq 1 THEN walsa_endeps , filename = epsfilename , / noboundingbox power = komegamap wavenumber = kopower_xscale [ 1 : * ] frequencies = kopower_yscale [ 1 : * ] print , ' ' if filtering then print , ' ..... start filtering (in k-\u03c9 space)' else return print , ' ' ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; STEPS USED TO MAKE SURE THE FREQUENCIES ARE CHOSEN ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; NEED f1 AND k1 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , f1 , / data WAIT , 1.0 ; NEED f2 AND k2 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency/wavenumber value you wish to preserve.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k1 , k1 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ k2 , k2 ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY f1 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f1 , / data WAIT , 1.0 ; NEED ONLY f2 ( spatial filtering OFF ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmin ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmax , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST frequency value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , nonsense , f2 , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f1 , f1 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ f2 , f2 ], line = 1 , thick = 3 , color = 255 IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND NOT KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 ; NEED ONLY k1 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the LOWEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f1 ) AND NOT KEYWORD_SET ( k1 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k1 , nonsense , / data WAIT , 1.0 ; NEED ONLY k2 ( temporal filtering ON ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmin = 10 ^ MIN ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_xmax = 10 ^ MAX ( ! x . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN kopower_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymin , kopower_plot_ymin ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN PLOTS , [ kopower_plot_xmin , kopower_plot_xmax ], [ kopower_plot_ymax , kopower_plot_ymax ], line = 1 , thick = 3 , color = 255 IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , '' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN print , 'Please click on the HIGHEST wavenumber value you wish to preserve inside the dotted lines.....' IF NOT KEYWORD_SET ( f2 ) AND NOT KEYWORD_SET ( k2 ) AND NOT KEYWORD_SET ( no_spatial_filt ) AND KEYWORD_SET ( no_temporal_filt ) THEN CURSOR , k2 , nonsense , / data WAIT , 1.0 IF KEYWORD_SET ( no_spatial_filt ) THEN k1 = kopower_xscale [ 1 ] IF KEYWORD_SET ( no_spatial_filt ) THEN k2 = MAX ( kopower_xscale , / nan ) IF KEYWORD_SET ( no_temporal_filt ) THEN f1 = kopower_yscale [ 1 ] IF KEYWORD_SET ( no_temporal_filt ) THEN f2 = MAX ( kopower_yscale , / nan ) IF ( k1 le 0.0 ) THEN k1 = kopower_xscale [ 1 ] IF ( k2 gt MAX ( kopower_xscale , / nan )) THEN k2 = MAX ( kopower_xscale , / nan ) IF ( f1 le 0.0 ) THEN f1 = kopower_yscale [ 1 ] IF ( f2 gt MAX ( kopower_yscale , / nan )) THEN f2 = MAX ( kopower_yscale , / nan ) IF NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN k1 = kopower_xscale [ 1 ] k2 = MAX ( kopower_xscale , / nan ) PLOTS , [ k1 , k2 ], [ f1 , f1 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k2 ], [ f2 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k1 , k1 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 PLOTS , [ k2 , k2 ], [ f1 , f2 ], line = 2 , thick = 2 , color = 255 ENDIF print , '' print , 'The preserved wavenumbers are [' + strtrim ( k1 , 2 ) + ', ' + strtrim ( k2 , 2 ) + '] arcsec^-1' print , 'The preserved spatial sizes are [' + strtrim (( 2. * ! pi ) / k2 , 2 ) + ', ' + strtrim (( 2. * ! pi ) / k1 , 2 ) + '] arcsec' print , '' print , 'The preserved frequencies are [' + strtrim ( f1 , 2 ) + ', ' + strtrim ( f2 , 2 ) + '] mHz' print , 'The preserved periods are [' + strtrim ( FIX ( 1. / ( f2 / 1000. )), 2 ) + ', ' + strtrim ( FIX ( 1. / ( f1 / 1000. )), 2 ) + '] seconds' pwavenumber = [ k1 , k2 ] pspatialsize = [( 2. * ! pi ) / k2 ,( 2. * ! pi ) / k1 ] pfrequency = [ f1 , f2 ] pperiod = [ FIX ( 1. / ( f2 / 1000. )), FIX ( 1. / ( f1 / 1000. ))] print , '' print , 'Making a 3D Fourier transform of the input datacube..........' threedft = FFT ( datacube , - 1 , / double , / center ) ; CALCULATE THE FREQUENCY AXES FOR THE 3 D FFT temp_x = FINDGEN (( xsize_cube - 1 ) / 2 ) + 1 is_N_even = ( xsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ spatial_frequencies_orig = ([ 0.0 , temp_x , xsize_cube / 2 , - xsize_cube / 2 + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) $ ELSE $ spatial_frequencies_orig = ([ 0.0 , temp_x , - ( xsize_cube / 2 + 1 ) + temp_x ] / ( xsize_cube * arcsecpx )) * ( 2. * ! pi ) temp_x = FINDGEN (( zsize_cube - 1 ) / 2 ) + 1 is_N_even = ( zsize_cube MOD 2 ) EQ 0 IF ( is_N_even ) THEN $ temporal_frequencies_orig = [ 0.0 , temp_x , zsize_cube / 2 , - zsize_cube / 2 + temp_x ] / ( zsize_cube * cadence ) $ ELSE $ temporal_frequencies_orig = [ 0.0 , temp_x , - ( zsize_cube / 2 + 1 ) + temp_x ] / ( zsize_cube * cadence ) ; NOW COMPENSATE THESE FREQUENCY AXES DUE TO THE FACT THE / center KEYWORD IS USED FOR THE FFT TRANSFORM spatial_positive_frequencies = N_ELEMENTS ( WHERE ( spatial_frequencies_orig ge 0. )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 2 )) IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 NE 0 THEN spatial_frequencies = SHIFT ( spatial_frequencies_orig , ( spatial_positive_frequencies - 1 )) temporal_positive_frequencies = N_ELEMENTS ( WHERE ( temporal_frequencies_orig ge 0. )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 2 )) IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 NE 0 THEN temporal_frequencies = SHIFT ( temporal_frequencies_orig , ( temporal_positive_frequencies - 1 )) ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE NEW FREQUENCY AXES DESCRIBED ABOVE IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), - 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ - 1 , - 1 ]) ENDIF ; CONVERT FREQUENCIES AND WAVENUMBERS OF INTEREST INTO ( FFT ) DATACUBE PIXELS pixel_k1_positive = walsa_closest ( k1 , spatial_frequencies_orig ) pixel_k2_positive = walsa_closest ( k2 , spatial_frequencies_orig ) pixel_f1_positive = walsa_closest ( f1 / 1000. , temporal_frequencies ) pixel_f2_positive = walsa_closest ( f2 / 1000. , temporal_frequencies ) pixel_f1_negative = walsa_closest ( - f1 / 1000. , temporal_frequencies ) pixel_f2_negative = walsa_closest ( - f2 / 1000. , temporal_frequencies ) torus_depth = FIX (( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) * 2. torus_center = FIX ((( pixel_k2_positive [ 0 ] - pixel_k1_positive [ 0 ]) / 2. ) + pixel_k1_positive [ 0 ]) IF KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN ; CREATE A FILTER RING PRESERVING EQUAL WAVENUMBERS FOR BOTH kx AND ky ; DO THIS AS A TORUS TO PRESERVE AN INTEGRATED GAUSSIAN SHAPE ACROSS THE WIDTH OF THE ANNULUS , THEN INTEGRATE ALONG 'z' spatial_torus = FLTARR ( xsize_cube , ysize_cube , torus_depth ) FOR i = 0 , ( FIX ( torus_depth / 2. )) DO BEGIN spatial_ring = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - i )) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + i + 1 )) spatial_ring [ WHERE ( spatial_ring gt 0. )] = 1. spatial_ring [ WHERE ( spatial_ring ne 1. )] = 0. spatial_torus [ * , * , i ] = spatial_ring spatial_torus [ * , * , torus_depth - i - 1 ] = spatial_ring ENDFOR ; INTEGRATE THROUGH THE TORUS TO FIND THE SPATIAL FILTER spatial_ring_filter = TOTAL ( spatial_torus , 3 , / nan ) / FLOAT ( torus_depth ) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF NOT KEYWORD_SET ( spatial_torus ) AND NOT KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center - ( FIX ( torus_depth / 2. )))) - $ ( walsa_radial_distances ([ 1 , xsize_cube , ysize_cube ]) LE ( torus_center + ( FIX ( torus_depth / 2. )) + 1 )) spatial_ring_filter = spatial_ring_filter / MAX ( spatial_ring_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 spatial_ring_filter [ WHERE ( spatial_ring_filter NE 1. )] = 0. ; IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN spatial_ring_filter = SHIFT ( spatial_ring_filter , [ - 1 , - 1 ]) ENDIF IF KEYWORD_SET ( no_spatial_filt ) THEN BEGIN spatial_ring_filter = FLTARR ( xsize_cube , ysize_cube ) spatial_ring_filter [ * ] = 1. ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND KEYWORD_SET ( temporal_torus ) THEN BEGIN ; CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 25 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 3 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 25 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 30 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 4 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 30 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 40 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 5 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 40 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 45 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 6 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 45 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 50 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 7 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 50 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 55 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 8 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 55 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 60 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 9 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 60 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 65 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 10 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 65 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 70 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 11 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 70 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 80 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 12 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 80 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 90 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 13 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 90 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 100 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 14 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 100 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 110 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 15 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 110 ) AND (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) LT 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 16 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) IF (( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ) GE 130 ) THEN temporal_Gaussian = GAUSSIAN_FUNCTION ( 17 , WIDTH = ( pixel_f2_positive [ 0 ] - pixel_f1_positive [ 0 ] + 1 ), MAXIMUM = 1 , / double ) temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = temporal_Gaussian temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = temporal_Gaussian temporal_filter = temporal_filter / MAX ( temporal_filter , / nan ) ; TO ENSURE THE PEAKS ARE AT 1.0 ENDIF IF NOT KEYWORD_SET ( no_temporal_filt ) AND NOT KEYWORD_SET ( temporal_torus ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 0. temporal_filter [ pixel_f1_positive ( 0 ): pixel_f2_positive ( 0 )] = 1.0 temporal_filter [ pixel_f2_negative ( 0 ): pixel_f1_negative ( 0 )] = 1.0 ENDIF IF KEYWORD_SET ( no_temporal_filt ) THEN BEGIN temporal_filter = FLTARR ( zsize_cube ) temporal_filter [ * ] = 1. ENDIF ; MAKE SOME FIGURES FOR PLOTTING - MAKES THINGS AESTHETICALLY PLEASING ! torus_map = MAKE_MAP ( spatial_ring_filter , dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'arcsecs' ) spatial_fft = TOTAL ( threedft , 3 , / nan ) spatial_fft_map = MAKE_MAP ( ALOG10 ( spatial_fft ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'arcsecs' ) spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = MAKE_MAP ( ALOG10 ( spatial_fft_filtered > 1e-15 ), dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ], xc = 0 , yc = 0 , time = '' , units = 'arcsecs' ) temporal_fft = TOTAL ( TOTAL ( threedft , 2 , / nan ), 1 ) IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN WINDOW , 1 , xsize = 1500 , ysize = 1000 , title = 'QUEEFF: FFT filter specs' IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN WINDOW , 1 , xsize = smallest_screensize , ysize = FIX ( smallest_screensize * 0.8 ), title = 'QUEEFF: FFT filter specs' x1 = 0.07 x2 = 0.33 x3 = 0.40 x4 = 0.66 x5 = 0.72 x6 = 0.98 y1 = 0.07 y2 = 0.47 y3 = 0.56 y4 = 0.96 LOADCT , 5 , / silent IF ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) THEN BEGIN plot_map , spatial_fft_map , charsize = 2 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = 'Wavenumber (k!Dy!N ; arcsec!U-1!N)' , title = 'Spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x1 , y3 , x2 , y4 ] PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 0 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 0 LOADCT , 0 , / silent plot_map , torus_map , charsize = 2 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Spatial FFT filter' , dmin = 0 , dmax = 1 , position = [ x3 , y3 , x4 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 LOADCT , 5 , / silent plot_map , spatial_fft_filtered_map , charsize = 2 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Filtered spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x5 , y3 , x6 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 PLOT , temporal_frequencies * 1000. , ABS ( temporal_fft ), / ylog , xst = 1 , xticklen =- .026 , yticklen =- .011 , charsize = 2 , xtitle = 'Frequency (mHz)' , ytitle = 'Power (arb. units)' , position = [ x1 + 0.05 , y1 , x6 , y2 ], / noerase temporal_fft_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) temporal_fft_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) PLOTS , [ 0 , 0 ], [ temporal_fft_plot_ymin , temporal_fft_plot_ymax ], line = 2 , thick = 2 , color = 0 LOADCT , 39 , / silent OPLOT , temporal_frequencies * 1000. , ( temporal_filter ) > temporal_fft_plot_ymin , line = 2 , color = 55 , thick = 2 OPLOT , temporal_frequencies * 1000. , ( ABS ( temporal_fft * temporal_filter )) > temporal_fft_plot_ymin , line = 0 , color = 254 , thick = 2 LOADCT , 5 , / silent WAIT , 0.5 ENDIF IF ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) THEN BEGIN plot_map , spatial_fft_map , charsize = 1 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = 'Wavenumber (k!Dy!N ; arcsec!U-1!N)' , title = 'Spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x1 , y3 , x2 , y4 ] PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 0 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 0 LOADCT , 0 , / silent plot_map , torus_map , charsize = 1 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Spatial FFT filter' , dmin = 0 , dmax = 1 , position = [ x3 , y3 , x4 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 LOADCT , 5 , / silent plot_map , spatial_fft_filtered_map , charsize = 1 , xticklen =- .025 , yticklen =- .025 , xtitle = 'Wavenumber (k!Dx!N ; arcsec!U-1!N)' , ytitle = '' , title = 'Filtered spatial FFT' , dmin = MIN ( spatial_fft_map . data , / nan ) + 1. , dmax = MAX ( spatial_fft_map . data , / nan ) - 1. , position = [ x5 , y3 , x6 , y4 ], / noerase PLOTS , [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], [ 0 , 0 ], line = 2 , thick = 2 , color = 255 PLOTS , [ 0 , 0 ], [ MIN ( spatial_frequencies , / nan ), MAX ( spatial_frequencies , / nan )], line = 2 , thick = 2 , color = 255 PLOT , temporal_frequencies * 1000. , ABS ( temporal_fft ), / ylog , xst = 1 , charsize = 1 , xticklen =- .026 , yticklen =- .011 , xtitle = 'Frequency (mHz)' , ytitle = 'Power (arb. units)' , position = [ x1 + 0.05 , y1 , x6 , y2 ], / noerase temporal_fft_plot_ymin = 10 ^ MIN ( ! y . crange , / nan ) temporal_fft_plot_ymax = 10 ^ MAX ( ! y . crange , / nan ) PLOTS , [ 0 , 0 ], [ temporal_fft_plot_ymin , temporal_fft_plot_ymax ], line = 2 , thick = 2 , color = 0 LOADCT , 39 , / silent OPLOT , temporal_frequencies * 1000. , ( temporal_filter ) > temporal_fft_plot_ymin , line = 2 , color = 55 , thick = 2 OPLOT , temporal_frequencies * 1000. , ( ABS ( temporal_fft * temporal_filter )) > temporal_fft_plot_ymin , line = 0 , color = 254 , thick = 2 LOADCT , 5 , / silent WAIT , 0.5 ENDIF ; APPLY THE GAUSSIAN FILTERS TO THE DATA TO PREVENT ALIASING FOR i = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , i ] = REFORM ( threedft [ * , * , i ]) * spatial_ring_filter FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO BEGIN threedft [ x , y , * ] = REFORM ( threedft [ x , y , * ]) * temporal_filter ENDFOR ENDFOR ; ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE / center CALL IF N_ELEMENTS ( temporal_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR x = 0 , ( xsize_cube - 1 ) DO BEGIN FOR y = 0 , ( ysize_cube - 1 ) DO threedft [ x , y , * ] = SHIFT ( REFORM ( threedft [ x , y , * ]), 1 ) ENDFOR ENDIF IF N_ELEMENTS ( spatial_frequencies_orig ) MOD 2 EQ 0 THEN BEGIN FOR z = 0 , ( zsize_cube - 1 ) DO threedft [ * , * , z ] = SHIFT ( REFORM ( threedft [ * , * , z ]), [ 1 , 1 ]) ENDIF new_cube = REAL_PART ( FFT ( threedft , 1 , / double , / center )) LOADCT , 0 , / silent filtered_cube = new_cube PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' ! P . Multi = 0 Cleanplot , / Silent print , '' print , 'COMPLETED!' print , '' END This code uses the following routine (originanly from Rob Rutten) to compute the k-\u03c9 power. WaLSA_plotkopower_funct.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; NAME : plotkopower --> walsa_plotkopower_funct ; ; PURPOSE : plot \"k-omega\" diagram = Fourier power at temporal frequency ; f against horizontal spatial wavenumber k_h ; ; CALLING SEQUENCE : ; plotkopower , cube , arcsecpx , cadence , plotfilename , $ ; apod = apod , $ ; kmax = kmax , fmax = fmax , minpower = minpower , maxpower = maxpower , $ ; contours = contours , lamb = lamb , fundamental = fundamental ; ; INPUTS : ; cube : ( x , y , t ) data cube , any type ; arcsecpx = angular image scale in arcsec / px ; cadence : [ regular ] sampling cadence in sec ; plotfilename : postscript output file name ; optional keywords : ; apod : fractional extent of apodization edges ; default 0.1 ; kmax : maximum k_h axis as fraction of Nyquist value , default 0.2 ; fmax : maximum f axis as fraction of Nyquist value , default 0.5 ; minpower : minimum of power plot range , default maxpower - 5 ; maxpower : maximum of power plot range , default alog10 ( max ( power )) ; contours : set true to plot contours ; lamb : value > 0 overplots Lamb line omeha = c_s kn at c_s = lamb km / s ; fundamental : set true to overplot fundamental mode omega = sqrt ( g k_h ) ; ; MODIFICATION HISTORY : ; Sep 2010 : Rob Rutten ( RR ) assembly of Alfred de Wijn 's routines. ; Okt 2010 : RR optional overplots Lamb line and fundamental mode ; SJ modified : based on latest version of this code ( Mar 2 2012 ): Mar 2011 : RR - 1 > + 1 line 162 from Alfred de Wijn ; - ; ----------------------------------------------------------------------- function avgstd , array , stdev = stdev ; get array average + standard deviation ; RR Aug 23 2010 found in Mabula Haverkamp 's IDL, later also AdW ; RR not the same as avg . pro in ssw ; RR not the same as avg . pro in Pit Suetterlin DOT software ; RR so renamed to avgstd avrg = total ( array , / nan ) / n_elements ( array ) stdev = sqrt ( total (( array - avrg ) ^ 2 , / nan ) / n_elements ( array )) return , avrg end ; ---------------------------------------------------------------------------- function linear , x , p ; RR used in temporal detrending ymod = p [ 0 ] + x * p [ 1 ] return , ymod end ; ---------------------------------------------------------------------------- function gradient , x , y , p ; RR used in spatail detrending zmod = p [ 0 ] + x * p [ 1 ] + y * p [ 2 ] return , zmod end ; ---------------------------------------------------------------------------- function apod3dcube , cube , apod ; apodizes cube in all three coordinates , with detrending ; get cube dimensions sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] apocube = fltarr ( nx , ny , nt ) ; define temporal apodization apodt = fltarr ( nt ) + 1 if ( apod ne 0 ) then begin apodrimt = nt * apod apodt [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrimt ) / apodrimt )) ^ 2 apodt = apodt * shift ( rotate ( apodt , 2 ), 1 ) ; RR had ik nooit verzonnen endif ; temporal detrending , not per px , only mean - image trend ttrend = fltarr ( nt ) tf = findgen ( nt ) + 1 for it = 0 , nt - 1 do begin img = cube [ * , * , it ] ttrend [ it ] = avgstd ( img ) endfor fitp = mpfitfun ( 'linear' , tf , ttrend , fltarr ( nt ) + 1 , [ 1000. , 0. ], / quiet ) fit = fitp [ 0 ] + tf * fitp [ 1 ] ; temporal apodization per ( x , y ) column ; RR do not reinsert trend to keep [ 0 , 0 ] Fourier pixel from dominating for it = 0 , nt - 1 do begin img = cube [ * , * , it ] apocube [ * , * , it ] = ( img - fit [ it ]) * apodt [ it ] ; RR + ttrend [ it ] endfor ; define spatial apodization apodx = fltarr ( nx ) + 1 apody = fltarr ( ny ) + 1 if ( apod ne 0 ) then begin apodrimx = apod * nx apodrimy = apod * ny apodx [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrimx ) / apodrimx )) ^ 2 apody [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrimy ) / apodrimy )) ^ 2 apodx = apodx * shift ( rotate ( apodx , 2 ), 1 ) apody = apody * shift ( rotate ( apody , 2 ), 1 ) apodxy = apodx # apody endif if ( apod eq 0 ) then begin apodxy = apodx # apody endif ; spatial gradient removal + apodizing per image xf = fltarr ( nx , ny ) + 1. yf = xf for it = 0 , nt - 1 do begin img = apocube [ * , * , it ] avg = avgstd ( img ) ; RR mpfit2dfun = ssw / gen / idl / fitting / mpfit / mpfit2dfun . pro fitp = mpfit2dfun ( 'gradient' , xf , yf , img , fltarr ( nx , ny ) + 1 ,[ 1000. , 0. , 0. ], / quiet ) fit = fitp [ 0 ] + xf * fitp [ 1 ] + yf * fitp [ 2 ] apocube [ * , * , it ] = ( img - fit ) * apodxy + avg endfor ; done return , apocube end ; --------------------------------------------------------------------------- function ko_dist , sx , sy , double = double ; set up Pythagoras distance array from origin ; RR from Alfred de Wijn email Aug 30 2010 dx = rebin ( dindgen ( sx / 2 + 1 ) / ( sx / 2 ), sx / 2 + 1 , sy / 2 + 1 ) dy = rotate ( rebin ( dindgen ( sy / 2 + 1 ) / ( sy / 2 ), sy / 2 + 1 , sx / 2 + 1 ), 1 ) dxy = sqrt ( dx ^ 2 + dy ^ 2 ) * ( min ([ sx , sy ], / nan ) / 2 + 1. ) afstanden = dblarr ( sx , sy ) afstanden [ 0 , 0 ] = dxy ; get other quadrants afstanden [ sx / 2 , 0 ] = rotate ( dxy [ 1 : * , * ], 5 ) ; RR 5 = 90 deg afstanden [ 0 , sy / 2 ] = rotate ( dxy [ * , 1 : * ], 7 ) ; RR 7 = 270 deg afstanden [ sx / 2 , sy / 2 ] = rotate ( dxy [ 1 : * , 1 : * ], 2 ) ; RR 2 = 180 deg if not keyword_set ( double ) then afstanden = fix ( round ( afstanden )) return , afstanden end ; --------------------------------------------------------------------------- function averpower , cube ; compute 2 D ( k_h , f ) power array by circular averaging over k_x , k_y ; get cube dimensions sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] ; forward fft and throw away half of it ; perform fft in time direction first fftcube = ( fft ( fft (( fft ( cube , - 1 , dimension = 3 ))[ * , * , 0 : nt / 2 ], - 1 , dimension = 1 ), dimension = 2 )) ; set up distances fftfmt = size ( fftcube ) afstanden = ko_dist ( nx , ny ) ; RR integer - rounded Pythagoras array ; maxdist = min ([ nx , ny ]) / 2 - 1 ; RR largest quarter circle maxdist = min ([ nx , ny ], / nan ) / 2 + 1 ; RR largest quarter circle --> from RR on Mar 2011 ! ; get average power over all k_h distances , building power ( k_h , f ) avpow = fltarr ( maxdist + 1 , nt / 2 + 1 ) for i = 0 , maxdist do begin waar = where ( afstanden eq i ) for j = 0 , nt / 2 do begin w1 = ( fftcube [ * , * , j ])[ waar ] avpow [ i , j ] = total ( w1 * conj ( w1 ), / nan ) / n_elements ( waar ) endfor ;; writeu , - 1 , string ( format = '(%\" \\r computing avpow... \",i6,\"/\",i6)' , i , maxdist ) endfor ; done return , avpow end ; --------------------------------------------------------------------------- pro koplotpow , avpow , arcsecpx , cadence , kmax , fmax , minpower , maxpower ; plotting program sizepow = size ( avpow ) ; select extent = fractions of Nyquist values plotrange = [ fix ( sizepow [ 1 ] * kmax ), fix ( sizepow [ 2 ] * fmax )] plotpow = avpow [ 0 : plotrange [ 0 ] - 1 , 0 : plotrange [ 1 ] - 1 ] ; RR 5 x5 resizing , I guess for better tick positioning and contours xas = 2. * ! pi / ( arcsecpx * 2 ) * findgen ( plotrange [ 0 ]) / ( sizepow [ 1 ] - 1 ) rexas = 2. * ! pi / ( arcsecpx * 2 ) * findgen ( plotrange [ 0 ] * 5 ) / ( sizepow [ 1 ] * 5 - 1 ) yas = 1. / ( cadence * 2 ) * findgen ( plotrange [ 1 ]) / ( sizepow [ 2 ] - 1 ) * 1e3 reyas = 1. / ( cadence * 2 ) * findgen ( plotrange [ 1 ] * 5 ) / ( sizepow [ 2 ] * 5 - 1 ) * 1e3 plotpowrebin = convol ( rebin ( plotpow , plotrange [ 0 ] * 5 , plotrange [ 1 ] * 5 ), fltarr ( 6 , 6 ) + 1 / ( 6. * 6. ), / edge_truncate ) ; plotpowrebin = plotpow xrange = [ min ( xas , / nan ), max ( xas , / nan )] yrange = [ min ( yas , / nan ), max ( yas , / nan )] tvframe , alog10 ( plotpowrebin ) > minpower < maxpower , / ba , / sa , / as , xrange = xrange , yrange = yrange , xtitle = 'k_h [arcsec!U-1!N]' , ytitle = 'f [mHz]' ; plot wavelength axis along top if ( xrange [ 1 ] lt 10 ) then begin ; RR I wonder how to automate this wavtickspos = [ 10 , 5 , 3 , 2 , 1.5 , 1 ] wavticksn = [ '10' , '5' , '3' , '2' , '1.5' , '1' ] endif else if ( xrange [ 1 ] lt 20 ) then begin wavtickspos = [ 10 , 5 , 3 , 2 , 1.5 , 1 , 0.5 ] wavticksn = [ '10' , '5' , '3' , '2' , '1.5' , '1' , '0.5' ] endif else if ( xrange [ 1 ] lt 50 ) then begin wavtickspos = [ 5.0 , 2.0 , 1.0 , 0.5 , 0.2 ] wavticksn = [ '5' , '2' , '1' , '0.5' , '0.2' ] endif else begin wavtickspos = [ 5.0 , 2.0 , 1.0 , 0.5 , 0.2 , 0.1 , 0.05 ] wavticksn = [ '5' , '2' , '1' , '0.5' , '0.2' , '0.1' , '0.05' ] endelse wavticks = n_elements ( wavtickspos ) - 1 wavticksv = 2. * ! pi / wavtickspos ; RR wavelength from circle frequency axis , / xaxis , xticks = wavticks , xtickv = wavticksv , xtickname = wavticksn , ticklen =- 0.015 / 0.53 , xminor = 1 , xtitle = 'wavelength [arcsec]' ; plot period axis along righthand side if ( yrange [ 1 ] lt 10 ) then begin ; RR I wonder how to automate this pertickspos = [ 20 , 10 , 5 , 3 , 2 , 1 ] perticksn = [ '20' , '10' , '5' , '3' , '2' , '1' ] endif else if ( yrange [ 1 ] lt 20 ) then begin pertickspos = [ 10 , 5 , 3 , 2 , 1.5 , 1 , 0.5 ] perticksn = [ '10' , '5' , '3' , '2' , '1.5' , '1' , '0.5' ] endif else if ( yrange [ 1 ] lt 50 ) then begin pertickspos = [ 10 , 5 , 2 , 1 , 0.5 , 0.2 , 0.1 ] perticksn = [ '10' , '5' , '2' , '1' , '0.5' , '0.2' , '0.1' ] endif else if ( yrange [ 1 ] lt 100 ) then begin pertickspos = [ 2 , 1 , 0.5 , 0.2 , 0.1 ] perticksn = [ '2' , '1' , '0.5' , '0.2' , '0.1' ] endif else begin pertickspos = [ 0.5 , 0.2 , 0.1 , 0.05 , 0.02 ] perticksn = [ '0.5' , '0.2' , '0.1' , '0.05' , '0.02' ] endelse perticks = n_elements ( pertickspos ) - 1 perticksv = 1e3 / pertickspos / 60. ; RR period , from mHz to min axis , / yaxis , yticks = perticks , ytickv = perticksv , ytickname = perticksn , ticklen =- 0.015 / 0.7 , yminor = 1 , ytitle = 'period [min]' end ; --------------------------- main part ------------------------------ FUNCTION walsa_plotkopower_funct , cube , sp_out , arcsecpx , cadence , apod = apod , kmax = kmax , fmax = fmax , minpower = minpower , maxpower = maxpower ; wrapper calling the above subroutines if ( n_elements ( apod ) ne 0 ) then apod = apod else apod = 0.1 if ( n_elements ( kmax ) ne 0 ) then kmax = kmax else kmax = 1.0 if ( n_elements ( fmax ) ne 0 ) then fmax = fmax else fmax = 1.0 if ( kmax gt 1 ) then kmax = 1 if ( fmax gt 1 ) then fmax = 1 ; apodize the cube apocube = apod3dcube ( cube , apod ) ; compute radially - averaged power avpow = averpower ( apocube ) sp_out = avpow ; set min , max cutoffs maxavpow = alog10 ( max ( avpow , / nan )) minavpow = alog10 ( min ( avpow , / nan )) print , ' max log(power) = ' , maxavpow , ' min log(power) = ' , minavpow if ( n_elements ( maxpower ) ne 0 ) then maxpower = maxpower else maxpower = maxavpow if ( n_elements ( minpower ) ne 0 ) then minpower = minpower else minpower = maxpower - 5 ; print , kmax , fmax ; plot the diagram ; koplotpow , avpow , arcsecpx , cadence , kmax , fmax , minpower , maxpower ; done RETURN , sp_out end", "title": "k-&#969; Analysis and Fourier Filtering"}, {"location": "idl/routines/#b-analysis", "text": "WaLSA_bomega This routine computes and plots B-\u03c9 diagram, based on the approach introduced in this scientific article . WaLSA_bomega.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_Bomega ; part of -- WaLSAtools -- ; ; PURPOSE : ; Compute ( and plot ) B - \u03c9 diagram : average FFT power spectra ; for various magnetic - field bins within the FoV ; Note : ( 1 ) The entire cube is detrended ( linearly ) ; and apodized ( in both spatial and temporal domains ) ; prior to the FFT analysis ; ( 2 ) Plotted B - \u03c9 is smoothed for better visibility ; ; CALLING SEQUENCE : ; walsa_bomega , datacube , Bmap , time , power = power , frequencies = frequencies , Barray = Barray ; ; + INPUTS : ; datacube : datacube in the form of [ x , y , t ] ; bmap : magnetic - field map ( in G ), in the form of [ x , y ] ; -- should spatially be the same size as the datacube ; time : time of the observations in sec ; ; + OPTIONAL KEYWORDS : ; binsize : magnetic - field bin size ( default : 50 G ) ; silent : if set , the B - \u03c9 map is not displayed . ; clt : color table number ( idl ctload ) ; koclt : custom color tables for k - \u03c9 diagram ( currently available : 1 and 2 ) ; threemin : if set , a horizontal line marks the three - minute periodicity ; fivemin : if set , a horizontal line marks the five - minute periodicity ; xlog : if set , x - axis ( magnetic field ) is plotted in logarithmic scale ; ylog : if set , y - axis ( frequency ) is plotted in logarithmic scale ; xrange : x - axis ( wavenumber ) range ; yrange : y - axis ( frequency ) range ; noy2 : if set , 2 nd y - axis ( period , in sec ) is not plotted ; ( p = 1000 / frequency ) ; smooth : if set , power is smoothed ; normalizedbins if set , power at each bin is normalized to its maximum value ; ( this facilitates visibility of relatively small power ) ; xtickinterval x - asis ( i . e . , magnetic fields ) tick intervals in G ( default : 400 G ) ; epsfilename : if provided ( as a string ), an eps file of the k - \u03c9 diagram is made ; mode : outputted power mode : 0 = log ( power ) ( default ), 1 = linear power , 2 = sqrt ( power ) = amplitude ; ---- detrending , and apodization parameters ---- ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; ; + OUTPUTS : ; power : B - \u03c9 map , a stack of average power spectra ( in magnetic - field bins ) ; along y axis -> The x and y axes are B ( in G ) and ; frequency ( in mHz ); in dn ^ 2 / mhz , i . e . , normalized to frequency resolution ( see mode for the scale ) ; frequencies : frequencies of the power spectra ; ( i . e . , values of the y axis of the B - \u03c9 map ) ; barray : magnetic - field values of the middle of the bins ; ( i . e . , values of the x axis of the B - \u03c9 map ) ; ; ; + CREDITS : ; Author : Shahin Jafarzadeh , March 2021. ; Note : if YOU USE THIS CODE , then PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS INTRODUCED : ; Stangalini et al . 2021 , A & A , in press ( https : // ui . adsabs . harvard . edu / abs / 2021 arXiv210311639S ) ; - pro walsa_bomega , datacube , Bmap , cadence = cadence , time = time , binsize = binsize , power = power , frequencies = frequencies , Barray = Barray , $ silent = silent , clt = clt , koclt = koclt , threemin = threemin , fivemin = fivemin , xlog = xlog , ylog = ylog , $ ; plotting keywords xrange = xrange , yrange = yrange , epsfilename = epsfilename , noy2 = noy2 , smooth = smooth , normalizedbins = normalizedbins , $ xtickinterval = xtickinterval , mode = mode if n_elements ( cadence ) eq 0 then cadence = walsa_mode ( walsa_diff ( time )) nx = N_ELEMENTS ( datacube [ * , 0 , 0 ]) ny = N_ELEMENTS ( datacube [ 0 , * , 0 ]) nt = N_ELEMENTS ( datacube [ 0 , 0 , * ]) temporal_Nyquist = 1. / ( cadence * 2. ) print , ' ' print , 'The input datacube is of size: [' + strtrim ( nx , 2 ) + ', ' + strtrim ( ny , 2 ) + ', ' + strtrim ( nt , 2 ) + ']' print , ' ' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + strtrim (( cadence * 2. ), 2 ) + ' seconds' print , ' Time series duration = ' + strtrim ( cadence * nt , 2 ) + ' seconds' print , ' Nyquist frequency = ' + strtrim ( temporal_Nyquist * 1000. , 2 ) + ' mHz' print , ' ' nxb = N_ELEMENTS ( Bmap [ * , 0 , 0 ]) nyb = N_ELEMENTS ( Bmap [ 0 , * , 0 ]) dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize if nx gt nxb OR ny gt nyb then begin print , ' [!] The datacube and B-map must have the same [x,y] size.' print , ' ' stop endif if n_elements ( binsize ) eq 0 then binsize = 50. ; in G if n_elements ( silent ) eq 0 then silent = 0 if n_elements ( noy2 ) eq 0 then noy2 = 0 if n_elements ( normalizedbins ) eq 0 then normalizedbins = 0 else normalizedbins = 1 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if n_elements ( xtickinterval ) eq 0 then xtickinterval = 400 ; in G if n_elements ( mode ) eq 0 then mode = 0 if n_elements ( xlog ) eq 0 then xlog = 0 if n_elements ( ylog ) eq 0 then ylog = 0 if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 else nodetrendapod = 1 Bmap = ABS ( Bmap ) brange = minmax ( Bmap , / nan ) nbin = floor (( brange [ 1 ] - brange [ 0 ]) / binsize ) ; detrend and apodize the cube if nodetrendapod eq 0 then begin print , ' ' print , ' -- Detrend and apodize the cube .....' datacube = walsa_detrend_apod ( datacube , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , recon = recon , cadence = cadence ) endif frequencies = 1. / ( cadence * 2 ) * findgen ( nt / 2 + 1 ) / ( nt / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz numf = n_elements ( frequencies ) Barray = fltarr ( nbin ) bopower = fltarr ( nbin , numf ) fac = 0 PRINT for i = 0 L , nbin - 1 do begin ii = where ( Bmap le brange [ 1 ] - ( fac * float ( binsize )) AND Bmap gt brange [ 1 ] - (( fac + 1 ) * float ( binsize )), num ) Barray [ i ] = ( brange [ 1 ] - ( fac * float ( binsize ))) - ( float ( binsize ) / 2. ) if num gt 0 then begin coords = array_indices ( Bmap , ii ) xx = reform ( coords [ 0 , * ]) & yy = reform ( coords [ 1 , * ]) nxy = n_elements ( xx ) poweravg = fltarr ( numf ) for ixy = 0 L , nxy - 1 do begin poweri = ( 2. * ( ABS (( fft ( reform ( datacube [ xx [ ixy ], yy [ ixy ], * ]), - 1 ))[ 0 : nt / 2. ]) ^ 2 )) / frequencies [ 0 ] ; in DN ^ 2 / mHz poweravg = poweravg + poweri [ 1 : nff - 1 ] endfor poweravg = poweravg / float ( nxy ) if normalizedbins eq 1 then poweravg = 100. * poweravg / max ( poweravg ) bopower [ i , * ] = poweravg endif print , string ( 13 b ) + '.... % f inished (through bins, from larger B): ' , float ( i ) * 100. / ( nbin - 1 ), format = '(a,f4.0,$)' if brange [ 1 ] - (( fac + 1 ) * float ( binsize )) le 0 then break fac = fac + 1 endfor PRINT bopower = reverse ( bopower , 1 ) Barray = reverse ( Barray ) nb = n_elements ( Barray ) Barray [ 0 ] = brange [ 0 ] Barray [ nb - 1 ] = brange [ 1 ] ppp = bopower Gaussian_kernel = GAUSSIAN_FUNCTION ([ 0.65 , 0.65 ], WIDTH = 3 , MAXIMUM = 1 , / double ) Gaussian_kernel_norm = TOTAL ( Gaussian_kernel , / nan ) bopower = CONVOL ( bopower , Gaussian_kernel , Gaussian_kernel_norm , / edge_truncate ) if mode eq 0 then bopower = ALOG10 ( bopower ) if mode eq 2 then bopower = SQRT ( bopower ) nlevels = 256 step = ( Max ( bopower ) - Min ( bopower )) / nlevels vals = Indgen ( nlevels ) * step + Min ( bopower ) bopower = ( bopower )[ 0 : * , 0 : * ] > MIN (( bopower )[ 0 : * , 0 : * ], / nan ) < MAX (( bopower )[ 0 : * , 0 : * ], / nan ) if silent eq 0 then begin LOADCT , 0 , / silent ! p . background = 255. ! p . color = 0. x1 = 0.12 x2 = 0.86 y1 = 0.10 y2 = 0.80 if n_elements ( clt ) eq 0 then clt = 13 else clt = clt ctload , clt , / silent if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt ! p . background = 255. ! p . color = 0. positioncb = [ x1 , y2 + 0.05 , x2 , y2 + 0.07 ] if EPS eq 1 then begin walsa_eps , size = [ 20 , 22 ] ! p . font = 0 device , set_font = 'Times-Roman' ! p . charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 endif else begin if ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) then begin WINdoW , 0 , xsize = 1000 , ysize = 1000 , title = 'B-omega diagram' ! p . charsize = 1.7 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 endif if ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) then begin WINdoW , 0 , xsize = FIX ( smallest_screensize * 0.9 ), ysize = FIX ( smallest_screensize * 0.9 ), title = 'B-omega diagram' ! p . charsize = 1 ! p . charthick = 1 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.025 ! y . ticklen =- 0.025 endif endelse walsa_pg_plotimage_komega , bopower , Barray , frequencies , $ ytitle = 'Frequency (mHz)' , xtitle = 'B (G)' , xst = 1 , yst = 8 , xlog = xlog , ylog = ylog , xrange = xrange , yrange = yrange , eps = eps , $ position = [ x1 , y1 , x2 , y2 ], noy2 = noy2 , nox2 = 1 , smooth = smooth , threemin = threemin , fivemin = fivemin , xtickinter = xtickinterval tickmarknames = STRARR ( 4 ) tickmarknames [ 0 ] = STRING ( MIN ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 1 ] = STRING ((( MAX ( bopower [ 1 : * , 1 : * ], / nan ) - MIN ( bopower [ 1 : * , 1 : * ], / nan )) * 0.33 ) + MIN ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F5.1)' ) tickmarknames [ 2 ] = STRING ((( MAX ( bopower [ 1 : * , 1 : * ], / nan ) - MIN ( bopower [ 1 : * , 1 : * ], / nan )) * 0.67 ) + MIN ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) tickmarknames [ 3 ] = STRING ( MAX ( bopower [ 1 : * , 1 : * ], / nan ), FORMAT = '(F4.1)' ) if normalizedbins eq 1 then cbtitle = 'Log!d10!n(Normalized Oscillation Power)' else cbtitle = 'Log!d10!n(Oscillation Power)' cgcolorbar , bottom = 0 , ncolors = 255 , minrange = MIN ( bopower [ 1 : * , 1 : * ], / nan ), maxrange = MAX ( bopower [ 1 : * , 1 : * ], / nan ), / top , $ ticknames = tickmarknames , yticklen = 0.00001 , position = positioncb , title = cbtitle if EPS eq 1 then walsa_endeps , filename = epsfilename , / noboundingbox endif power = bopower PRINT if ( mode eq 0 ) then print , ' mode = 0: log(power)' if ( mode eq 1 ) then print , ' mode = 1: linear power' if ( mode eq 2 ) then print , ' mode = 2: sqrt(power)' ! P . Multi = 0 Cleanplot , / Silent PRINT PRINT , 'COMPLETED!' PRINT end", "title": "B-&#969; Analysis"}, {"location": "idl/routines/#detrending-and-apodisation", "text": "WaLSA_detrend_apod All signals are detrended (linearly, or using higher-order polynomial fits if desired) and apodised (using a Tukey window, i.e., tapered cosine) prior to all spectral analyses (unless otherwise it is omitted). Here is the code used for detrending and apodising the signals. The spatial apodisation for the k-\u03c9 diagram, are performed inside the WaLSA_plotkopower_funct.pro . WaLSA_detrend_apod.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_detrend_apod ; part of -- WaLSAtools -- ; ; PURPOSE : ; Detrend and apodise time series to account for their nonlinear and nonstationary nature ; ( apodisation is also known as 'windowing' in some other communities ) ; ; DESCRIPTION : ; Each 1 D time series is detrended by subtracting the signal from its fitted linear or higher ; polynomial degrees function ( or only from the mean signal ), and finally apodised by the ; Tukey ( tapered cosine ) window to bring the edges to zero . If set , the edge effects are ; more conservatively examined by means of a wavelet - based approach ( walsa_wave_recon . pro ) ; ; CALLING SEQUENCE : ; corrected_cube = walsa_detrend_apod ( cube , apod , meandetrend , pxdetrend ) ; ; + INPUTS : ; data : 1 D time series , or ( x , y , t ) datacube , any type ; ( an ordered sequence of data points , typically some variable quantity ; measured at successive times . ) ; apod : extent of apodization edges of the Tukey ( tapered cosine ) window ; default : 0.1 ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; ; + OPTIONAL KEYWORDS : ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting ; the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ; ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; cadence : cadence of the observations . it is required when recon is set . ; resample_original if recon is set , then this keyword allow setting a range ( i . e . , min_resample and max_resample ) ; to which the unpreserved amplitudes are approximated . ; min_resample minimum value for resample_original . Default : min of each 1 D array ( time series ) in data . ; max_resample maximum value for resample_original . Default : max of each 1 D array ( time series ) in data . ; ; + OUTPUTS : ; corrected_cube : The detrended and apodised cube ; ; MODIFICATION HISTORY ; ; 2010 plotpowermap : Rob Rutten , assembly of Alfred de Wijn 's routines ; ( https : // webspace . science . uu . nl /~ rutte101 / rridl / cubelib / plotpowermap . pro ) ; 2018 - 2021 modified / extended by Shahin Jafarzadeh & David B . Jess ; - FUNCTION linear , x , p ; used by mpfitfun ymod = p [ 0 ] + x * p [ 1 ] return , ymod END FUNCTION walsa_detrend_apod , cube , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , $ recon = recon , cadence = cadence , resample_original = resample_original , min_resample = min_resample , $ max_resample = max_resample , silent = silent , dj = dj , lo_cutoff = lo_cutoff , hi_cutoff = hi_cutoff , upper = upper if ( n_elements ( apod ) ne 0 ) then apod = apod else apod = 0.1 if ( n_elements ( polyfit ) eq 0 ) then apolyfit = 0 else apolyfit = 1 if not keyword_set ( meandetrend ) then meandetrend = 0 if not keyword_set ( silent ) then silent = 0 if ( n_elements ( pxdetrend ) ne 0 ) then pxdetrend = pxdetrend else pxdetrend = 2 if silent eq 0 then begin print , ' ' print , ' -- Detrend and apodize the cube .....' print , ' ' endif sizecube = size ( cube ) if sizecube [ 0 ] ne 3 then begin if sizecube [ 0 ] eq 1 then begin blablacube = fltarr ( 1 , 1 , sizecube [ 1 ]) blablacube [ 0 , 0 , * ] = cube cube = blablacube endif else begin print , ' ' print , ' [!] The datacube must have either 1 or 3 dimension(s).' print , ' ' stop endelse endif sizecube = size ( cube ) nx = sizecube [ 1 ] ny = sizecube [ 2 ] nt = sizecube [ 3 ] apocube = cube tf = findgen ( nt ) + 1 col = fltarr ( nt ) apodt = fltarr ( nt ) + 1 if ( apod ne 0 ) then begin ; Tukey window apodrim = apod * nt apodt [ 0 ] = ( sin ( ! pi / 2. * findgen ( apodrim ) / apodrim )) ^ 2 apodt = apodt * shift ( rotate ( apodt , 2 ), 1 ) endif ; meandetrend : get spatially - averaged trend fit = 0 if ( meandetrend ) then begin avgseq = fltarr ( nt ) for it = 0 , nt - 1 do avgseq [ it ] = total ( cube [ * , * , it ]) avgseq = avgseq / ( double ( nx ) * double ( ny )) meanfitp = mpfitfun ( 'linear' , tf , avgseq , fltarr ( nt ) + 1 ,[ 1000. , 0. ], / quiet ) meanfit = meanfitp [ 0 ] + tf * meanfitp [ 1 ] - total ( avgseq ) / double ( nt ) endif ; apodize per [ x , y ] temporal column = time sequence per pixel for ix = long ( 0 ), long ( nx ) - 1 do begin for iy = long ( 0 ), long ( ny ) - 1 do begin col = cube [ ix , iy , * ] IF KEYWORD_SET ( recon ) THEN col = walsa_wave_recon ( reform ( col ), cadence , dj = dj , lo_cutoff = lo_cutoff , hi_cutoff = hi_cutoff , upper = upper ) meancol = walsa_avgstd ( col ) if ( meandetrend ) then col = col - meanfit if n_elements ( meantemporal ) eq 0 then begin if apolyfit eq 0 then begin if ( pxdetrend eq 1 ) then begin pxfitp = poly_fit ( tf , col , 1 ) col = col - pxfitp [ 0 ] - tf * pxfitp [ 1 ] + meancol endif if ( pxdetrend eq 2 ) then begin pxfitp = mpfitfun ( 'linear' , tf , col , fltarr ( nt ) + 1 ,[ meancol , 0. ], / quiet ) col = col - pxfitp [ 0 ] - tf * pxfitp [ 1 ] + meancol endif endif else begin lc_fit = GOODPOLY ( FINDGEN ( nt ), col , polyfit , 3 , lc_yfit , lc_newx , lc_newy ) col = col - lc_yfit endelse endif ocol = ( col - meancol ) * apodt + meancol if not KEYWORD_SET ( min_resample ) then min_resample = min ( cube [ ix , iy , * ]) if not KEYWORD_SET ( max_resample ) then max_resample = max ( cube [ ix , iy , * ]) IF KEYWORD_SET ( recon ) THEN if KEYWORD_SET ( resample_original ) then ocol = scale_vector ( ocol , min_resample , max_resample ) apocube [ ix , iy , * ] = ocol endfor if silent eq 0 then if long ( nx ) gt 1 then if ( pxdetrend ne 0 ) then $ writeu , - 1 , string ( format = '(%\" \\r == detrend next row... \",i5,\"/\",i5)' , ix + 1 , nx ) endfor if silent eq 0 then if long ( nx ) gt 1 then if ( pxdetrend ne 0 ) then PRINT return , reform ( apocube ) END", "title": "Detrending and Apodisation"}, {"location": "idl/routines/#wavelet-analysis", "text": "WaLSA_wavelet A modified/extended variant of wavelet.pro (of Torrence & Compo) to compute wavelet power spectrum and its related parameters. WaLSA_wavelet.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_wavelet ; part of -- WaLSAtools -- ; modification of WAVELET . pro ; ; PURPOSE : ; Compute the WAVELET transform of a 1 D time series . ; Based on the original code from Torrenc & Compo ; ( see Torrence , C . and G . P . Compo , 1998 : A Practical Guide to ; Wavelet Analysis . Bull . Amer . Meteor . Soc . , 79 , 61 - 78. ) ; ; CALLING SEQUENCE : ; wave = WaLSA_wavelet ( Y , DT ) ; ; INPUTS : ; ; Y = the time series of length N . ; ; DT = amount of time between each Y value , i . e . the sampling time . ; ; OUTPUTS : ; ; WAVE is the WAVELET transform of Y . This is a complex array ; of dimensions ( N , J + 1 ) . FLOAT ( WAVE ) gives the WAVELET amplitude , ; ATAN ( IMAGINARY ( WAVE ), FLOAT ( WAVE )) gives the WAVELET phase . ; The WAVELET power spectrum is ABS ( WAVE ) ^ 2. ; ; ; OPTIONAL KEYWORD INPUTS : ; ; S0 = the smallest scale of the wavelet . Default is 2 * DT . ; ; DJ = the spacing between discrete scales . Default is 0.125 . ; A smaller # will give better scale resolution, but be slower to plot. ; ; J = the # of scales minus one. Scales range from S0 up to S0*2^(J*DJ), ; to give a total of ( J + 1 ) scales . Default is J = ( LOG2 ( N DT / S0 )) / DJ . ; ; MOTHER = A string giving the mother wavelet to use . ; Currently , 'Morlet' , 'Paul' , 'DOG' ( derivative of Gaussian ) ; are available . Default is 'Morlet' . ; ; PARAM = optional mother wavelet parameter . ; For 'Morlet' this is k0 ( wavenumber ), default is 6. ; For 'Paul' this is m ( order ), default is 4. ; For 'DOG' this is m ( m - th derivative ), default is 2. ; ; PAD = if set , then pad the time series with enough zeroes to get ; N up to the next higher power of 2. This prevents wraparound ; from the end of the time series to the beginning , and also ; speeds up the FFT 's used to do the wavelet transform. ; This will not eliminate all edge effects ( see COI below ) . ; ; LAG1 = LAG 1 Autocorrelation , used for SIGNIF levels . Default is 0.0 ; ; SIGLVL = significance level to use . Default is 0.95 ; ; VERBOSE = if set , then print out info for each analyzed scale . ; ; RECON = if set , then reconstruct the time series , and store in Y . ; Note that this will destroy the original time series , ; so be sure to input a dummy copy of Y . ; ; FFT_THEOR = theoretical background spectrum as a function of ; Fourier frequency . This will be smoothed by the ; wavelet function and returned as a function of PERIOD . ; ; colornoise = if set , noise background is based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 ; ; OPTIONAL KEYWORD OUTPUTS : ; ; PERIOD = the vector of \"Fourier\" periods ( in time units ) that corresponds ; to the SCALEs . ; ; POWER = Wavelet power spectrum ; ; SCALE = the vector of scale indices , given by S0 * 2 ^ ( j * DJ ), j = 0. .. J ; where J + 1 is the total # of scales. ; ; COI = if specified , then return the Cone - of - Influence , which is a vector ; of N points that contains the maximum period of useful information ; at that particular time . ; Periods greater than this are subject to edge effects . ; This can be used to plot COI lines on a contour plot by doing : ; IDL > CONTOUR , wavelet , time , period ; IDL > PLOTS , time , coi , NOCLIP = 0 ; ; YPAD = returns the padded time series that was actually used in the ; wavelet transform . ; ; DAUGHTER = if initially set to 1 , then return the daughter wavelets . ; This is a complex array of the same size as WAVELET . At each scale ; the daughter wavelet is located in the center of the array . ; ; SIGNIF = output significance levels as a function of PERIOD ; ; FFT_THEOR = output theoretical background spectrum ( smoothed by the ; wavelet function ), as a function of PERIOD . ; ; Plot = if set , the wavelet power spectrum is plotted . ; ; colorct = the IDL color table number . Default : 20 ; ; w = window number ( for IDL ) . Default : 6 ; ; ---- detrending , and apodization parameters ---- ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; ; [ Defunct INPUTS : ; [ OCT = the # of octaves to analyze over. ] ; [ Largest scale will be S0 * 2 ^ OCT . ] ; [ Default is ( LOG2 ( N ) - 1 ) . ] ; [ VOICE = # of voices in each octave. Default is 8. ] ; [ Higher # gives better scale resolution, ] ; [ but is slower to plot . ] ; ] ; ;; ---------------------------------------------------------------------------- ; ; EXAMPLE : ; ; IDL > ntime = 256 ; IDL > y = RANDOMN ( s , ntime ) ; *** create a random time series ; IDL > dt = 0.25 ; IDL > time = FINDGEN ( ntime ) * dt ; *** create the time index ; IDL > ; IDL > wave = WaLSA_wavelet ( y , dt , PERIOD = period , PAD = 1 , COI = coi , MOTHER = 'Morlet' , / RECON , dj = 0.025 , scale = scale , SIGNIF = SIGNIF , SIGLVL = 0.99 , / apod , / plot ) ; ;; ---------------------------------------------------------------------------- ; This routine is originally based on WAVELET . pro ; Copyright ( C ) 1995 - 2004 , Christopher Torrence and Gilbert P . Compo ; ; This software may be used , copied , or redistributed as long as it is not ; sold and this copyright notice is reproduced on each copy made . ; This routine is provided as is without any express or implied warranties ; whatsoever . ; ; Notice : Please acknowledge the use of the above software in any publications : ; `` Wavelet software was provided by C . Torrence and G . Compo , ; and is available at URL : http : // paos . colorado . edu / research / wavelets / '' . ; ; Reference : Torrence , C . and G . P . Compo , 1998 : A Practical Guide to ; Wavelet Analysis . < I > Bull . Amer . Meteor . Soc .</ I > , 79 , 61 - 78. ; ; Please send a copy of such publications to either C . Torrence or G . Compo : ; Dr . Christopher Torrence Dr . Gilbert P . Compo ; Research Systems , Inc . Climate Diagnostics Center ; 4990 Pearl East Circle 325 Broadway R / CDC1 ; Boulder , CO 80301 , USA Boulder , CO 80305 - 3328 , USA ; E - mail : chris [ AT ] rsinc [ DOT ] com E - mail : compo [ AT ] colorado [ DOT ] edu ;; ---------------------------------------------------------------------------- ; Modified / extended by Shahin Jafarzadeh 2016 - 2021 ; - FUNCTION morlet , $ ; *********************************************** MORLET k0 , scale , k , period , coi , dofmin , Cdelta , psi0 IF ( k0 EQ - 1 ) THEN k0 = 6 d n = N_ELEMENTS ( k ) expnt = - ( scale * k - k0 ) ^ 2 / 2 d * ( k GT 0. ) dt = 2 * ! PI / ( n * k ( 1 )) norm = SQRT ( 2 * ! PI * scale / dt ) * ( ! PI ^ ( - 0.25 )) ; total energy = N [ Eqn ( 7 )] morlet = norm * EXP ( expnt > ( - 100 d )) morlet = morlet * ( expnt GT - 100 ) ; avoid underflow errors morlet = morlet * ( k GT 0. ) ; Heaviside step function ( Morlet is complex ) fourier_factor = ( 4 * ! PI ) / ( k0 + SQRT ( 2 + k0 ^ 2 )) ; Scale --> Fourier [ Sec .3 h ] period = scale * fourier_factor coi = fourier_factor / SQRT ( 2 ) ; Cone - of - influence [ Sec .3 g ] dofmin = 2 ; Degrees of freedom with no smoothing Cdelta = - 1 IF ( k0 EQ 6 ) THEN Cdelta = 0.776 ; reconstruction factor psi0 = ! PI ^ ( - 0.25 ) ; PRINT , scale , n , SQRT ( TOTAL ( ABS ( morlet ) ^ 2 , / DOUBLE )) RETURN , morlet END FUNCTION paul , $ ; ************************************************** PAUL m , scale , k , period , coi , dofmin , Cdelta , psi0 IF ( m EQ - 1 ) THEN m = 4 d n = N_ELEMENTS ( k ) expnt = - ( scale * k ) * ( k GT 0. ) dt = 2 d * ! PI / ( n * k ( 1 )) norm = SQRT ( 2 * ! PI * scale / dt ) * ( 2 ^ m / SQRT ( m * FACTORIAL ( 2 * m - 1 ))) paul = norm * (( scale * k ) ^ m ) * EXP ( expnt > ( - 100 d )) * ( expnt GT - 100 ) paul = paul * ( k GT 0. ) fourier_factor = 4 * ! PI / ( 2 * m + 1 ) period = scale * fourier_factor coi = fourier_factor * SQRT ( 2 ) dofmin = 2 ; Degrees of freedom with no smoothing Cdelta = - 1 IF ( m EQ 4 ) THEN Cdelta = 1.132 ; reconstruction factor psi0 = 2. ^ m * FACTORIAL ( m ) / SQRT ( ! PI * FACTORIAL ( 2 * m )) ; PRINT , scale , n , norm , SQRT ( TOTAL ( paul ^ 2 , / DOUBLE )) * SQRT ( n ) RETURN , paul END FUNCTION dog , $ ; *************************************************** DOG m , scale , k , period , coi , dofmin , Cdelta , psi0 IF ( m EQ - 1 ) THEN m = 2 n = N_ELEMENTS ( k ) expnt = - ( scale * k ) ^ 2 / 2 d dt = 2 d * ! PI / ( n * k ( 1 )) norm = SQRT ( 2 * ! PI * scale / dt ) * SQRT ( 1 d / GAMMA ( m + 0.5 )) I = DCOMPLEX ( 0 , 1 ) gauss = - norm * ( I ^ m ) * ( scale * k ) ^ m * EXP ( expnt > ( - 100 d )) * ( expnt GT - 100 ) fourier_factor = 2 * ! PI * SQRT ( 2. / ( 2 * m + 1 )) period = scale * fourier_factor coi = fourier_factor / SQRT ( 2 ) dofmin = 1 ; Degrees of freedom with no smoothing Cdelta = - 1 psi0 = - 1 IF ( m EQ 2 ) THEN BEGIN Cdelta = 3.541 ; reconstruction factor psi0 = 0.867325 ENDIF IF ( m EQ 6 ) THEN BEGIN Cdelta = 1.966 ; reconstruction factor psi0 = 0.88406 ENDIF ; PRINT , scale , n , norm , SQRT ( TOTAL ( ABS ( gauss ) ^ 2 , / DOUBLE )) * SQRT ( n ) RETURN , gauss END ; ****************************************************************** WAVELET FUNCTION walsa_wavelet , y1 , dt , $ ; *** required inputs S0 = s0 , DJ = dj , J = j , $ ; *** optional inputs PAD = pad , MOTHER = mother , PARAM = param , $ VERBOSE = verbose , NO_WAVE = no_wave , RECON = recon , $ LAG1 = lag1 , SIGLVL = siglvl , DOF = dof , GLOBAL = global , $ ; *** optional inputs SCALE = scale , PERIOD = period , YPAD = ypad , $ ; *** optional outputs DAUGHTER = daughter , COI = coi , removespace = removespace , koclt = koclt , $ SIGNIF = signif , FFT_THEOR = fft_theor , $ OCT = oct , VOICE = voice , log = log , silent = silent , normal = normal , $ plot = plot , colorct = colorct , w = w , apod = apod , nodetrendapod = nodetrendapod , $ pxdetrend = pxdetrend , meandetrend = meandetrend , power = power , $ polyfit = polyfit , meantemporal = meantemporal , colornoise = colornoise , $ clt = clt , epsfilename = epsfilename ON_ERROR , 2 r = CHECK_MATH ( 0 , 1 ) n = N_ELEMENTS ( y1 ) n1 = n base2 = FIX ( ALOG ( n ) / ALOG ( 2 ) + 0.4999 ) ; power of 2 nearest to N ; .... check keywords & optional inputs if n_elements ( log ) eq 0 THEN log = 0 if n_elements ( pad ) eq 0 THEN pad = 1 IF ( N_ELEMENTS ( s0 ) LT 1 ) THEN s0 = 2.0 * dt IF ( N_ELEMENTS ( voice ) EQ 1 ) THEN dj = 1. / voice IF ( N_ELEMENTS ( dj ) LT 1 ) THEN dj = 0.025 if n_elements ( colornoise ) eq 0 then colornoise = 0 IF ( N_ELEMENTS ( oct ) EQ 1 ) THEN J = FLOAT ( oct ) / dj IF ( N_ELEMENTS ( J ) LT 1 ) THEN J = FIX (( ALOG ( FLOAT ( n ) * dt / s0 ) / ALOG ( 2 )) / dj ) ;[ Eqn ( 10 )] IF ( N_ELEMENTS ( mother ) LT 1 ) THEN mother = 'MORLET' IF ( N_ELEMENTS ( param ) LT 1 ) THEN param = - 1 IF ( N_ELEMENTS ( siglvl ) LT 1 ) THEN siglvl = 0.95 IF ( N_ELEMENTS ( lag1 ) LT 1 ) THEN lag1 = 0.0 if n_elements ( plot ) eq 0 then plot = 0 if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 lag1 = lag1 ( 0 ) verbose = KEYWORD_SET ( verbose ) do_daughter = KEYWORD_SET ( daughter ) do_wave = NOT KEYWORD_SET ( no_wave ) recon = KEYWORD_SET ( recon ) if colornoise ne 0 then begin ; Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 nt = n_elements ( y1 ) J = FIX ( alog ( nt / 2.0 ) / alog ( 2 ) / dj ) s0 = 2 * dt endif IF KEYWORD_SET ( global ) THEN MESSAGE , $ 'Please use WAVE_SIGNIF for global significance tests' ; detrend and apodize the cube if nodetrendapod eq 0 then $ y1 = walsa_detrend_apod ( y1 , apod , meandetrend , pxdetrend , polyfit = polyfit , meantemporal = meantemporal , cadence = dt , silent = silent ) ; .... construct time series to analyze , pad if necessary ypad = y1 - TOTAL ( y1 ) / n ; remove mean IF KEYWORD_SET ( pad ) THEN BEGIN ; pad with extra zeroes , up to power of 2 ypad = [ ypad , FLTARR ( 2 L ^ ( base2 + 1 ) - n )] n = N_ELEMENTS ( ypad ) ENDIF ; .... construct SCALE array & empty PERIOD & WAVE arrays na = J + 1 ; # of scales scale = DINDGEN ( na ) * dj ; array of j - values scale = 2 d0 ^ ( scale ) * s0 ; array of scales 2 ^ j [ Eqn ( 9 )] period = FLTARR ( na , / NOZERO ) ; empty period array ( filled in below ) wave = COMPLEXARR ( n , na , / NOZERO ) ; empty wavelet array IF ( do_daughter ) THEN daughter = wave ; empty daughter array ; .... construct wavenumber array used in transform [ Eqn ( 5 )] k = ( DINDGEN ( n / 2 ) + 1 ) * ( 2 * ! PI ) / ( DOUBLE ( n ) * dt ) k = [ 0 d , k , - REVERSE ( k ( 0 :( n - 1 ) / 2 - 1 ))] ; .... compute FFT of the ( padded ) time series yfft = FFT ( ypad , - 1 , / DOUBLE ) ; [ Eqn ( 3 )] IF ( verbose ) THEN BEGIN ; verbose PRINT PRINT , mother PRINT , '#points=' , n1 , ' s0=' , s0 , ' dj=' , dj , ' J=' , FIX ( J ) IF ( n1 NE n ) THEN PRINT , '(padded with ' , n - n1 , ' zeroes)' PRINT ,[ 'j' , 'scale' , 'period' , 'variance' , 'mathflag' ], $ FORMAT = '(/,A3,3A11,A10)' ENDIF ; verbose IF ( N_ELEMENTS ( fft_theor ) EQ n ) THEN fft_theor_k = fft_theor ELSE $ fft_theor_k = ( 1 - lag1 ^ 2 ) / ( 1 - 2 * lag1 * COS ( k * dt ) + lag1 ^ 2 ) ; [ Eqn ( 16 )] fft_theor = FLTARR ( na ) ; .... loop thru each SCALE FOR a1 = 0 , na - 1 DO BEGIN ; scale psi_fft = CALL_FUNCTION ( mother , param , scale ( a1 ), k , period1 , coi , dofmin , Cdelta , psi0 ) IF ( do_wave ) THEN $ wave ( * , a1 ) = FFT ( yfft * psi_fft , 1 , / DOUBLE ) ; wavelet transform [ Eqn ( 4 )] period ( a1 ) = period1 ; save period fft_theor ( a1 ) = TOTAL (( ABS ( psi_fft ) ^ 2 ) * fft_theor_k ) / n IF ( do_daughter ) THEN $ daughter ( * , a1 ) = FFT ( psi_fft , 1 , / DOUBLE ) ; save daughter IF ( verbose ) THEN PRINT , a1 , scale ( a1 ), period ( a1 ), $ TOTAL ( ABS ( wave ( * , a1 )) ^ 2 ), CHECK_MATH ( 0 ), $ FORMAT = '(I3,3F11.3,I6)' ENDFOR ; scale coi = coi * [ FINDGEN (( n1 + 1 ) / 2 ), REVERSE ( FINDGEN ( n1 / 2 ))] * dt ; COI [ Sec .3 g ] IF ( do_daughter ) THEN $ ; shift so DAUGHTERs are in middle of array daughter = [ daughter ( n - n1 / 2 : * , * ), daughter ( 0 : n1 / 2 - 1 , * )] ; .... significance levels [ Sec .4 ] sdev = ( MOMENT ( y1 ))( 1 ) fft_theor = sdev * fft_theor ; include time - series variance dof = dofmin signif = fft_theor * CHISQR_CVF ( 1. - siglvl , dof ) / dof ; [ Eqn ( 18 )] IF ( recon ) THEN BEGIN ; Reconstruction [ Eqn ( 11 )] IF ( Cdelta EQ - 1 ) THEN BEGIN y1 = - 1 MESSAGE , / INFO , $ 'Cdelta undefined, cannot reconstruct with this wavelet' ENDIF ELSE BEGIN y1 = dj * SQRT ( dt ) / ( Cdelta * psi0 ) * ( FLOAT ( wave ) # (1./SQRT(scale))) y1 = y1 [ 0 : n1 - 1 ] ENDELSE ENDIF time = findgen ( n1 ) * dt amplitude = wave ( 0 : n1 - 1 , * ) ; get rid of padding before returning amplitudes power = ABS ( amplitude ) ^ 2 if plot ne 0 then begin powplot = power perplot = period timplot = time coiplot = coi sigplot = signif walsa_plot_wavelet_spectrum , powplot , perplot , timplot , coiplot , sigplot , clt = clt , w = w , log = log , removespace = removespace , $ koclt = koclt , normal = normal , epsfilename = epsfilename endif RETURN , amplitude END This code also uses the following routine to plot the wavelet power spectrum (along with confidence levels and cone-of-influence regions). WaLSA_plot_wavelet_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- pro walsa_plot_wavelet_spectrum , power , period , time , coi , significance , clt = clt , w = w , log = log , removespace = removespace , $ koclt = koclt , normal = normal , epsfilename = epsfilename , maxperiod = maxperiod , mHz = mHz if n_elements ( log ) eq 0 then log = 1 if n_elements ( mHz ) eq 0 then mHz = 1 if n_elements ( removespace ) eq 0 then removespace = 0 if n_elements ( normal ) eq 0 then normal = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 nt = n_elements ( reform ( time )) & np = n_elements ( reform ( period )) significance = REBIN ( TRANSPOSE ( significance ), nt , np ) fundf = 1000. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz if n_elements ( maxperiod ) eq 0 then maxp = 1000. / fundf else maxp = maxperiod ; longest period to be plotted if n_elements ( maxperiod ) eq 0 then if removespace ne 0 then maxp = max ( coi ) ; remove areas below the COI iit = closest_index ( maxp , period ) period = period [ 0 : iit ] significance = reform ( significance [ * , 0 : iit ]) power = reform ( power [ * , 0 : iit ]) power = reverse ( power , 2 ) significance = reverse ( significance , 2 ) sigi = power / significance if n_elements ( w ) eq 0 then w = 6 dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize if EPS eq 1 then begin walsa_eps , size = [ 18 , 13 ] ! p . font = 0 device , set_font = 'Times-Roman' charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.033 ! y . ticklen =- 0.021 barthick = 550 distbar = 550 coithick = 3. arrowsize = 20. arrowthick = 3.5 c_thick = 3. h_thick = 1.4 ; arrowheadsize = 10. endif else begin if ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) then begin window , w , xs = 900 , ys = 650 , title = strtrim ( w , 2 ) + ': Wavelet Power Spectrum' charsize = 2.0 ! x . thick = 2. ! y . thick = 2. ! x . ticklen =- 0.033 ! y . ticklen =- 0.021 ; ! X . MINOR = 6 distbar = 30 barthick = 30 coithick = 2 c_thick = 2. h_thick = 1. endif if ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) then begin window , w , xs = FIX ( smallest_screensize * 0.9 ), ys = FIX ( smallest_screensize * 0.9 ), title = strtrim ( w , 2 ) + ': Wavelet Power Spectrum' charsize = 1.7 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.033 ! y . ticklen =- 0.021 distbar = 25 barthick = 25 coithick = 2 c_thick = 2. h_thick = 1. endif endelse colset device , decomposed = 0 xtitle = 'Time (s)' ztitle = 'Power!C' if log ne 0 then ztitle = 'Log!d10!n(Power)!C' if normal ne 0 then begin ztitle = 'Normalised Power!C' if log ne 0 then ztitle = 'Log!d10!n(Normalised Power)!C' endif ii = where ( power lt 0. , cii ) if cii gt 0 then power ( ii ) = 0. if normal ne 0 then power = 100. * power / max ( power ) xrg = [ min ( time ), max ( time )] yrg = [ max ( period ), min ( period )] if n_elements ( clt ) eq 0 then clt = 20 loadct , clt if n_elements ( koclt ) ne 0 then walsa_powercolor , koclt if log ne 0 then power = alog10 ( power ) walsa_image_plot , power , xrange = xrg , yrange = yrg , $ nobar = 0 , zrange = minmax ( power , / nan ), / ylog , $ contour = 0 , / nocolor , charsize = charsize , $ ztitle = ztitle , xtitle = xtitle , $ exact = 1 , aspect = 0 , cutaspect = 0 , ystyle = 5 , $ barpos = 1 , zlen =- 0.6 , distbar = distbar , $ barthick = barthick , position = [ 0.14 , 0.14 , 0.87 , 0.87 ] cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , / ylog , title = 'Period (s)' , charsize = charsize if mHz then cgAxis , YAxis = 1 , YRange = [ 1000. / yrg [ 0 ], 1000. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (mHz)' , charsize = charsize $ else cgAxis , YAxis = 1 , YRange = [ 1. / yrg [ 0 ], 1. / yrg [ 1 ]], ystyle = 1 , / ylog , title = 'Frequency (Hz)' , charsize = charsize ; plot the Cone - of - Influence plots , time , coi , noclip = 0 , linestyle = 0 , thick = coithick , color = cgColor ( 'Black' ) ; shade the area above the Cone - of - Influence , with hashed lines : ncoi = n_elements ( coi ) y = fltarr ( ncoi ) for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION =- 45 ; contours mark significance level cgContour , sigi , / noerase , levels = 1. , XTICKFORMAT = \"(A1)\" , YTICKFORMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = c_thick if EPS eq 1 then walsa_endeps , filename = epsfilename , / pdf end", "title": "Wavelet Analysis"}, {"location": "idl/routines/#cross-correlations-1d-power-spectra", "text": "WaLSA_cross_spectrum Calculating cross-spectrum (also known as co-spectrum or cross-power), coherence, and phase relationships between two time series, where the 1D power spectra are obtained with FFT (Fast Fourier Transform), Lomb-Scargle, Wavelet (global, oglobal, and sensible), and HHT (Hilbert-Huang Transform), using the WaLSA_speclizer.pro . WaLSA_cross_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_cross_spectrum ; part of -- WaLSAtools -- ; ; PURPOSE : ; ; Calculate cross - spectral relationships of two time series whose amplitudes and powers ; are computed using the WaLSA_speclizer routine . ; The cross - spectrum is complex valued , thus its magnitude is returned as the ; co - spectrum . The phase lags between the two time series are are estimated ; from the imaginary and real arguments of the complex cross spectrum . ; The coherence is calculated from the normalized square of the amplitude ; of the complex cross - spectrum ; ; CALLING SEQUENCE : ; walsa_cross_spectrum ( data1 = data1 , data2 = data2 , time = time , phase_angle = phase_angle , coherence = coherence , cospectrum = cospectrum , frequencies = frequencies ) ; ; + INPUTS : ; ; data1 : first ( 1 D ) time series ; data2 : second ( 1 D ) time series , co - aligned with data1 ; time : observing times in seconds ( 1 D array ) ; ; + OPTIONAL KEYWORDS : ; ---- type of analysis ---- ; fft : if set , Fast Fourier Transform ( FFT ) power spectrum is computed : for regular ( evenly sampled ) time series . ; lombscargle : if set , Lomb - Scargle power spectrum is computed : for irregular ( unevenly sampled ) time series . ; hht : if set , a power spectrum associated to EMD + Hilbert Transform is computed : for regular ( evenly sampled ) time series . ; ---- padding , detrending , and apodization parameters ---- ; padding : oversampling factor : zero padding ( increasing timespan ) to increase frequency resolution ( NOTE : doesn 't add information) ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; recon : optional keyword that will Fourier reconstruct the input timeseries . ; note : this does not preserve the amplitudes and is only useful when attempting ; to examine frequencies that are far away from the 'untrustworthy' low frequencies . ; ---- significance - level parameters ---- ; siglevel : significance level ( default : 0.05 = 5 % significance level = 95 % confidence level ) ; nperm : number of random permutations for the significance test -- the larger the better ( default : 1000 ) ; nosignificance : if set , no significance level is calculated . ; ---- HHT parameters / options ---- ; stdlimit : standard deviation to be achieved before accepting an IMF ( recommended value between 0.2 and 0.3 ; perhaps even smaller ); default : 0.2 ; nfilter : Hanning window width for two dimensional smoothing of the Hilbert spectrum . default : 3 ; ( an odd integer , prefrabely equal to or larger than 3 ; equal to 0 to avoid the windowing ) ; ; n_segments : number of euqal segments ( to which both datasets are broken prior to the analyses ; default : 1 ) ; Each of these segments is considered an independent realisation of the underlying process . ; The cross spectrum for each segement are averaged together to provide phase and coherence estimates at each frequency . ; ; + OUTPUTS : ; ; cospectrum : co - spectrum , i . e . , magnitude of the complex cross spectrum ; frequencies : an array of frequencies . unit : mHz ; phase_angle : phase angles ; coherence : coherence of two series ; signif_cross : significance levels for the cospectrum ( 1 D array ) ; signif_coh : significance levels for the coherence ( 1 D array ) ; d1_power : power spectrum of data1 ; d2_power : power spectrum of data2 ; ; Shahin Jafarzadeh & David B . Jess | WaLSA Team ; + some routines / recipe from CROSS_SPECTRUM.pro of Simon Vaughan ; - function walsa_getcross_spectrum , data1 , data2 , time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , $ fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ stdlimit = stdlimit , nfilter = nfilter , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power cadence = walsa_mode ( walsa_diff ( time )) nt = n_elements ( data1 ) ; number of segments if ( n_elements ( n_segments ) eq 0 ) then n_segments = 1 ; number of segments to break the time series into . mn = nt / n_segments n_cut = mn * n_segments x_1 = reform ( data1 [ 0 : n_cut - 1 ], mn , n_segments ) x_2 = reform ( data2 [ 0 : n_cut - 1 ], mn , n_segments ) xtime = reform ( time [ 0 : n_cut - 1 ], mn , n_segments ) frequencies = 1. / ( cadence * 2 ) * findgen ( mn / 2 + 1 ) / ( mn / 2 ) nff = n_elements ( frequencies ) frequencies = frequencies [ 1 : nff - 1 ] frequencies = frequencies * 1000. ; in mHz nf = n_elements ( frequencies ) amplitude1 = complexarr ( nf , n_segments ) amplitude2 = complexarr ( nf , n_segments ) for iseg = 0 L , n_segments - 1 do begin power1s = walsa_speclizer ( reform ( x_1 [ * , iseg ]), reform ( xtime [ * , iseg ]), $ ; main inputs frequencies = frequencies , amplitude = amplitude1s , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ nosignificance = 1 , $ ; significance - level parameters stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options mode = 1 , / silent ) ; power calibration power2s = walsa_speclizer ( reform ( x_2 [ * , iseg ]), reform ( xtime [ * , iseg ]), $ ; main inputs frequencies = frequencies , amplitude = amplitude2s , $ ; main ( additional ) outputs fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ nosignificance = 1 , $ ; significance - level parameters stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options mode = 1 , / silent ) ; power calibration amplitude1 [ * , iseg ] = amplitude1s amplitude2 [ * , iseg ] = amplitude2s endfor amplitude1 = reform ( amplitude1 ) amplitude2 = reform ( amplitude2 ) power1 = abs ( amplitude1 ) ^ 2 power2 = abs ( amplitude2 ) ^ 2 ; complex cross - power spectrum cross_power = amplitude1 * CONJ ( amplitude2 ) ; co - spectrum ( real parts of cross - power spectrum ) cospectrum = ABS ( cross_power ) ; ---------------------------------------------------------- ; Average over the ensamble of time series segments and adjacent frequencies ; average the second - order quantities : C , P_1 , P_2 over the ensemble of M segments if ( n_segments gt 1 ) then begin binC = total ( cross_power , 2 ) / float ( n_segments ) binP_1 = total ( power1 , 2 ) / float ( n_segments ) binP_2 = total ( power2 , 2 ) / float ( n_segments ) endif else begin binC = cross_power binP_1 = power1 binP_2 = power2 endelse ; ---------------------------------------------------------- ; calculate coherence coherence = abs ( binC ) ^ 2 / ( binP_1 * binP_2 ) ; calculate the phase lag ( phase of complex cross spectrum ) phase_angle = atan ( binC , / phase ) * ( 180. / ! pi ) ; ---------------------------------------------------------- cospectrum = abs ( binC ) d1_power = binP_1 d2_power = binP_2 return , cospectrum end ; ==================================================== MAIN ROUTINE ==================================================== pro walsa_cross_spectrum , data1 = data1 , data2 = data2 , time = time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , cospectrum = cospectrum , $ fft = fft , lombscargle = lombscargle , hht = hht , welch = welch , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , resample_original = resample_original , nperm = nperm , siglevel = siglevel , $ stdlimit = stdlimit , nfilter = nfilter , $ ; HHT parameters / options nosignificance = nosignificance , signif_coh = signif_coh , signif_cross = signif_cross , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( nperm ) eq 0 then nperm = 50 if n_elements ( siglevel ) eq 0 then siglevel = 0.05 ; 5 % significance level = 95 % confidence level time1 = time & time2 = time if n_elements ( silent ) eq 0 then silent = 0 sizecube1 = size ( reform ( data1 )) sizecube2 = size ( reform ( data2 )) givewarning = 0 if sizecube1 [ 0 ] eq 1 and sizecube1 [ 0 ] eq 1 then begin if sizecube1 [ 1 ] ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube2 [ 1 ] then givewarning = 1 endif else givewarning = 1 if givewarning eq 1 then begin print , ' ' print , ' [!] data1, data2, and time must be one diemnsional and have identical lengths.' print , ' ' stop endif if silent eq 0 then begin cadence = walsa_mode ( walsa_diff ( time )) temporal_Nyquist = 1. / ( cadence * 2. ) print , ' ' print , 'The input datacubes are of size: [' + ARR2STR ( sizecube1 [ 1 ], / trim ) + ']' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + ARR2STR (( cadence * 2. ), / trim ) + ' seconds' print , ' Time series duration = ' + ARR2STR ( cadence * sizecube1 [ 1 ], / trim ) + ' seconds' print , ' Nyquist frequency = ' + ARR2STR ( temporal_Nyquist * 1000. , / trim ) + ' mHz' print , ' ' endif cospectrum = walsa_getcross_spectrum ( data1 , data2 , time , phase_angle = phase_angle , coherence = coherence , frequencies = frequencies , $ fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ stdlimit = stdlimit , nfilter = nfilter , n_segments = n_segments , d1_power = d1_power , d2_power = d2_power ) d1_power = d1_power / frequencies [ 0 ] ; in DN ^ 2 / mHz d2_power = d2_power / frequencies [ 0 ] ; in DN ^ 2 / mHz if nosignificance eq 0 then begin nf = n_elements ( frequencies ) ndata1 = n_elements ( data1 ) dt1 = walsa_mode ( walsa_diff ( time1 )) ndata2 = n_elements ( data2 ) dt2 = round ( walsa_mode ( walsa_diff ( time2 ))) coh_perm = fltarr ( nf , nperm ) cross_perm = fltarr ( nf , nperm ) for ip = 0 L , nperm - 1 do begin permutation1 = walsa_randperm ( ndata1 ) y_perm1 = data1 ( permutation1 ) permutation2 = walsa_randperm ( ndata2 ) y_perm2 = data2 ( permutation2 ) cospectrumsig = walsa_getcross_spectrum ( y_perm1 , y_perm2 , time , coherence = cohsig , $ fft = fft , lombscargle = lombscargle , hht = hht , $ ; type of analysis padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ ; padding and apodization parameters polyfit = polyfit , meantemporal = meantemporal , recon = recon , $ stdlimit = stdlimit , nfilter = nfilter , n_segments = n_segments ) coh_perm [ * , ip ] = cohsig cross_perm [ * , ip ] = cospectrumsig if ip eq 0 then PRINT print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor PRINT PRINT signif_coh = walsa_confidencelevel ( coh_perm , siglevel = siglevel , nf = nf ) signif_cross = walsa_confidencelevel ( cross_perm , siglevel = siglevel , nf = nf ) endif print , '' print , 'COMPLETED!' print , '' end", "title": "Cross Correlations: 1D power spectra"}, {"location": "idl/routines/#cross-correlations-wavelet-power-spectra", "text": "WaLSA_wavelet_cross_spectrum As a largely modified/extended variant of the wave_coherency.pro (of Torrence), this code calculates co-spectrum, coherence, and phase relationships between two time series, where the wavelet power spectra are obtained, thus cross-correlation parameters also have two dimensions. WaLSA_wavelet_cross_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- ; + ; NAME : WaLSA_wavelet_cross_spectrum ; part of -- WaLSAtools -- ; ; PURPOSE : ; Compute ( and optionally plot ) wavelet cospectrum ( cross - spectrum ), coherence , and phase angles ; between two time series as well as thier statistical significance levels . ; ; CALLING SEQUENCE : ; ; WaLSA_wavelet_cross_spectrum , data1 , time1 , data2 , time2 , / plot ; ; + INPUTS : ; ; data1 : first ( 1 D ) time series ( evenly sampled ) ; data2 : second ( 1 D ) time series ( evenly sampled ), co - aligned with data1 ; time : observing times in seconds ( 1 D array ) ; ; + OPTIONAL KEYWORDS : ; ; ---- wavelet parameters / options ---- ; mother : wavelet function , providing different localisation / resolution in frequency and in time ( also depends on param , m ) . ; currently , 'Morlet' , 'Paul' , 'DOG' ( derivative of Gaussian ) are available . default : 'Morlet' . ; param : optional mother wavelet parameter . ; For 'Morlet' this is k0 ( wavenumber ), default is 6. ; For 'Paul' this is m ( order ), default is 4. ; For 'DOG' this is m ( m - th derivative ), default is 2 ( i . e . , the real - valued Mexican - hat wavelet ) ; dj : spacing between discrete scales . default : 0.025 ; colornoise : if set , noise background is based on Auch\u00e8re et al . 2017 , ApJ , 838 , 166 / 2016 , ApJ , 825 , 110 ; ---- significance - level parameters ---- ; siglevel : significance level ( default : 0.05 = 5 % significance level = 95 % confidence level ) ; nperm : number of random permutations for the significance test ( default = 50 ) ; note : the default value is set for quick tests . Choose a large number ( e . g . , 2000 or larger ) ; for a better statistical result . ; nosignificance : if set , the significance levels are calculated . ; ( thus not overplotted as contours when plot option is set ) ; ---- padding , detrending , and apodization parameters ---- ; padding : oversampling factor : zero padding ( increasing timespan ) to increase frequency resolution ( NOTE : doesn 't add information) ; apod : extent of apodization edges ( of a Tukey window ); default 0.1 ; nodetrendapod : if set , neither detrending nor apodization is performed ! ; pxdetrend : subtract linear trend with time per pixel . options : 1 = simple , 2 = advanced ; default : 2 ; polyfit : the degree of polynomial fit to the data to detrend it . ; if set , instead of linear fit this polynomial fit is performed . ; meantemporal : if set , only a very simple temporal detrending is performed by subtracting the mean signal from the signal . ; i . e . , the fitting procedure ( linear or higher polynomial degrees ) is omitted . ; meandetrend : if set , subtract linear trend with time for the image means ( i . e . , spatial detrending ) ; ---- plotting ---- ; plot : if set , wavelet power sepctra of the two time series as well as ; their wavelet cospectrum ( cross - spectrum ) and coherence , along with the ; significance levels as contours , are plotted . ; The phase angles between the two time series are also depicted by default . ; Arrows pointing right mark zero phase ( meaning in - phase oscillations ), ; arrows pointing straight up indicate data2 lags behind data1 by 90 degrees . ; noarrow : if set , the phase angles are not overplotted as arrows . ; arrowdensity : number of arrows ( iluustrating phase angles ) in x and y directions ( default : [ 30 , 18 ]) ; arrowsize : size of the arrows ( default : 1 ) ; arrowheadsize : size of the arrows ' head (default: 1) ; pownormal : if set , the power is normalised to its maximum value ; log : if set , the power spectra and the cospectrum are plotted in log10 scale ; removespace : if set , the time - period areas affected by the coi over the entire time range are not plotted . ; clt : color table number ( idl ctload ) ; koclt : custom color tables ( currently available : 1 and 2 ) ; ; + OUTPUTS : ; ; cospectrum : absolute values of the cross wavelet map ; coherence : wavelet coherence map , as a function of time and scale ; phase_angle : phase angles in degrees ; time : time vector , given by the overlap of time1 and time2 ; ( it is not used : it is assumed the two time series are temporally aligned ) ; frequency : the frequency vector ; in mHz ; scale : scale vector of scale indices , given by the overlap of scale1 and scale2 ; computed by WaLSA_wavelet . pro ; coi : vector of the cone - of - influence ; signif_coh : significance map for the coherence ( same 2 D size as the coherence map ) ; coherence / signif_coh indicates regions above the siglevel ; signif_cross : significance map for the cospectrum ( same 2 D size as the cospectrum map ) ; cospectrum / signif_coh indicates regions above the siglevel ; coh_global : global ( or mean ) coherence averaged over all times ; phase_global : global ( or mean ) phase averaged over all times ; cross_global : global ( or mean ) cross wavelet averaged over all times ; coh_oglobal : global ( or mean ) coherence averaged over all times , excluding areas affected by COI ( oglobal ) ; phase_oglobal : global ( or mean ) phase averaged over all times , excluding areas affected by COI ( oglobal ) ; cross_oglobal : global ( or mean ) cross wavelet averaged over all times , excluding areas affected by COI ( oglobal ) ;; ---------------------------------------------------------------------------- ; This routine is originally based on WAVE_COHERENCY . pro ; Copyright ( C ) 1998 - 2005 , Christopher Torrence ; This software may be used , copied , or redistributed as long as it is not ; sold and this copyright notice is reproduced on each copy made . This ; routine is provided as is without any express or ; implied warranties whatsoever . ; ; Reference : Torrence , C . and P . J . Webster , 1999 : Interdecadal changes in the ; ENSO - monsoon system . < I > J . Climate </ I > , 12 , 2679 - 2690. ;; ---------------------------------------------------------------------------- ; Largely modified / extended by Shahin Jafarzadeh 2016 - 2021 ; - function walsa_getcorss_spectrum_wavelet , $ data1 , time1 , data2 , time2 , $ mother = mother , param = param , dj = dj , colornoise = colornoise , $ coherence = coherence , phase_angle = phase_angle , $ time_out = time_out , scale_out = scale_out , coi_out = coi_out , $ cross_wavelet = cross_wavelet , power1 = power1 , power2 = power2 , $ frequency = frequency , period = period , silent = silent , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ nosignificance = nosignificance , removespace = removespace , $ nodetrendapod = nodetrendapod , log = log , plot = plot , clt = clt , koclt = koclt , $ padding = padding , apod = apod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal dt1 = walsa_mode ( walsa_diff ( time1 )) wave1 = walsa_wavelet ( data1 , dt1 , scale = scale1 , nodetrendapod = nodetrendapod , PERIOD = period , COI = coi1 , plot = plot , w = 4 , log = log , silent = silent , $ removespace = removespace , koclt = koclt , clt = clt , mother = mother , param = param , dj = dj , colornoise = colornoise ) frequency = 1000. / period ; in mHz nf = n_elements ( frequency ) dt2 = walsa_mode ( walsa_diff ( time2 )) wave2 = walsa_wavelet ( data2 , dt2 , scale = scale2 , nodetrendapod = nodetrendapod , plot = plot , w = 5 , log = log , silent = silent , removespace = removespace , koclt = koclt , $ clt = clt , mother = mother , param = param , dj = dj , colornoise = colornoise ) ; *** find overlapping times time_start = MIN ( time1 ) > MIN ( time2 ) time_end = MAX ( time1 ) < MAX ( time2 ) time1_start = MIN ( WHERE (( time1 ge time_start ))) time1_end = MAX ( WHERE (( time1 le time_end ))) time2_start = MIN ( WHERE (( time2 ge time_start ))) time2_end = MAX ( WHERE (( time2 le time_end ))) ; *** find overlapping scales scale_start = MIN ( scale1 ) > MIN ( scale2 ) scale_end = MAX ( scale1 ) < MAX ( scale2 ) scale1_start = MIN ( WHERE (( scale1 ge scale_start ))) scale1_end = MAX ( WHERE (( scale1 le scale_end ))) scale2_start = MIN ( WHERE (( scale2 ge scale_start ))) scale2_end = MAX ( WHERE (( scale2 le scale_end ))) period = period ( scale1_start : scale1_end ) ; *** cross wavelet & individual wavelet power cross_wavelet = wave1 ( time1_start : time1_end , scale1_start : scale1_end ) * CONJ ( wave2 ( time2_start : time2_end , scale2_start : scale2_end )) power1 = ABS ( wave1 ( time1_start : time1_end , scale1_start : scale1_end )) ^ 2 power2 = ABS ( wave2 ( time2_start : time2_end , scale2_start : scale2_end )) ^ 2 dt = dt1 ntime = time1_end - time1_start + 1 nj = scale1_end - scale1_start + 1 if ( N_EleMENTS ( dj ) le 0 ) then dj = ALOG ( scale1 ( 1 ) / scale1 ( 0 )) / ALOG ( 2 ) scale = scale1 ( scale1_start : scale1_end ) time_out = time1 ( time1_start : time1_end ) scale_out = scale1 ( scale1_start : scale1_end ) if ( N_EleMENTS ( coi1 ) EQ N_EleMENTS ( time1 )) then $ coi_out = coi1 ( time1_start : time1_end ) nt = n_elements ( time_out ) ; calculate global cross - power , coherency , and phase angle ; global wavelet is the time average of the wavelet spectrum global1 = TOTAL ( power1 , 1 , / nan ) / nt global2 = TOTAL ( power2 , 1 , / nan ) / nt cross_global = TOTAL ( cross_wavelet , 1 ) / nt coh_global = ABS ( cross_global ) ^ 2 / ( global1 * global2 ) phase_global = reform ( ATAN ( IMAGINARY ( cross_global ), REAL_PART ( cross_global ))) * ( 180. / ! pi ) global1 = global1 ; / frequency [ nf - 1 ] ; in DN ^ 2 global2 = global2 ; / frequency [ nf - 1 ] ; in DN ^ 2 cross_global = ABS ( cross_global ); / frequency [ nf - 1 ] ; in DN ^ 2 ; calculate global cross - power , coherency , and phase angle excluding areas affected by COI ( oglobal ) oglobal_power1 = fltarr ( nt , nf ) oglobal_power2 = fltarr ( nt , nf ) oglobal_cross_wavelet = fltarr ( nt , nf ) for i = 0 L , nt - 1 do begin ii = where ( reform ( period ) lt coi_out [ i ], pnum ) oglobal_power1 [ i , ii ] = reform ( power1 [ i , ii ]) oglobal_power2 [ i , ii ] = reform ( power2 [ i , ii ]) oglobal_cross_wavelet [ i , ii ] = reform ( cross_wavelet [ i , ii ]) endfor oglobal_global1 = TOTAL ( oglobal_power1 , 1 , / nan ) / nt oglobal_global2 = TOTAL ( oglobal_power2 , 1 , / nan ) / nt cross_oglobal = TOTAL ( oglobal_cross_wavelet , 1 ) / nt coh_oglobal = ABS ( cross_oglobal ) ^ 2 / ( oglobal_global1 * oglobal_global2 ) phase_oglobal = reform ( ATAN ( IMAGINARY ( cross_oglobal ), REAL_PART ( cross_oglobal ))) * ( 180. / ! pi ) oglobal1 = oglobal_global1 ; / frequency [ nf - 1 ] ; in DN ^ 2 oglobal2 = oglobal_global2 ; / frequency [ nf - 1 ] ; in DN ^ 2 cross_oglobal = ABS ( cross_oglobal ); / frequency [ nf - 1 ] ; in DN ^ 2 for j = 0 , nj - 1 do begin ; *** time - smoothing st1 = SYSTIME ( 1 ) nt = LONG ( 4 L * scale ( j ) / dt ) / 2 L * 4 + 1 L time_wavelet = ( FINDgeN ( nt ) - nt / 2 ) * dt / scale ( j ) wave_function = EXP ( - time_wavelet ^ 2 / 2. ) ; *** Morlet wave_function = FLOAT ( wave_function / TOTAL ( wave_function )) ; normalize nz = nt / 2 zeros = COMPleX ( FltARR ( nz ), FltARR ( nz )) cross_wave_slice = [ zeros , cross_wavelet ( * , j ), zeros ] cross_wave_slice = CONVOL ( cross_wave_slice , wave_function ) cross_wavelet ( * , j ) = cross_wave_slice ( nz : ntime + nz - 1 ) zeros = FLOAT ( zeros ) power_slice = [ zeros , power1 ( * , j ), zeros ] power_slice = CONVOL ( power_slice , wave_function ) power1 ( * , j ) = power_slice ( nz : ntime + nz - 1 ) power_slice = [ zeros , power2 ( * , j ), zeros ] power_slice = CONVOL ( power_slice , wave_function ) power2 ( * , j ) = power_slice ( nz : ntime + nz - 1 ) endfor ; *** time - smoothing ; *** normalize by scale scales = REBIN ( TRANSPOSE ( scale ), ntime , nj ) cross_wavelet = TEMPORARY ( cross_wavelet ) / scales power1 = TEMPORARY ( power1 ) / scales power2 = TEMPORARY ( power2 ) / scales nweights = FIX ( 0.6 / dj / 2 + 0.5 ) * 2 - 1 ; closest ( smaller ) odd integer weights = REPLICATE ( 1. , nweights ) weights = weights / TOTAL ( weights ) ; normalize for i = 0 , ntime - 1 do begin ; *** scale - smoothing cross_wavelet ( i , * ) = CONVOL (( cross_wavelet ( i , * ))( * ), weights , / EDGE_TRUNCATE ) power1 ( i , * ) = CONVOL (( power1 ( i , * ))( * ), weights , / EDGE_TRUNCATE ) power2 ( i , * ) = CONVOL (( power2 ( i , * ))( * ), weights , / EDGE_TRUNCATE ) endfor ; *** scale - smoothing wave_phase = reform ( ATAN ( IMAGINARY ( cross_wavelet ), REAL_PART ( cross_wavelet ))) * ( 180. / ! pi ) wave_coher = ( ABS ( cross_wavelet ) ^ 2 ) / ( power1 * power2 > 1E-9 ) ; cospectrum = ABS ( REAL_PART ( cross_wavelet )) cospectrum = ABS ( cross_wavelet ); / frequency [ nf - 1 ] ; in DN ^ 2 coherence = reform ( wave_coher ) phase_angle = reform ( wave_phase ) return , cospectrum end ; ==================================================== MAIN ROUTINE ==================================================== pro walsa_wavelet_cross_spectrum , $ data1 , data2 , time , $ ; *** required inputs mother = mother , param = param , dj = dj , colornoise = colornoise , $ coherence = coherence , phase_angle = phase_angle , $ scale = scale , coi = coi , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ cospectrum = cospectrum , period = period , $ frequency = frequency , signif_coh = signif_coh , signif_cross = signif_cross , $ padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal , $ nosignificance = nosignificance , pownormal = pownormal , siglevel = siglevel , $ plot = plot , clt = clt , log = log , nperm = nperm , removespace = removespace , koclt = koclt , $ arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , noarrow = noarrow , silent = silent ; assuming the two time series are temporally aligned time1 = time time2 = time if n_elements ( plot ) eq 0 then plot = 0 if n_elements ( log ) eq 0 then log = 0 if n_elements ( dj ) eq 0 then dj = 0.025 if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( nodetrendapod ) eq 0 then nodetrendapod = 0 if n_elements ( nperm ) eq 0 then nperm = 50 if n_elements ( siglevel ) eq 0 then siglevel = 0.05 ; 5 % significance level = 95 % confidence level if n_elements ( removespace ) eq 0 then removespace = 0 if n_elements ( silent ) eq 0 then silent = 0 sizecube1 = size ( reform ( data1 )) sizecube2 = size ( reform ( data2 )) givewarning = 0 if sizecube1 [ 0 ] eq 1 and sizecube1 [ 0 ] eq 1 then begin if sizecube1 [ 1 ] ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube1 [ 1 ] then givewarning = 1 if n_elements ( time ) ne sizecube2 [ 1 ] then givewarning = 1 endif else givewarning = 1 if givewarning eq 1 then begin print , ' ' print , ' [!] data1, data2, and time must be one diemnsional and have identical lengths.' print , ' ' stop endif if silent eq 0 then begin cadence = walsa_mode ( walsa_diff ( time )) temporal_Nyquist = 1. / ( cadence * 2. ) print , ' ' print , 'The input datacubes are of size: [' + ARR2STR ( sizecube1 [ 1 ], / trim ) + ']' print , 'Temporally, the important values are:' print , ' 2-element duration (Nyquist period) = ' + ARR2STR (( cadence * 2. ), / trim ) + ' seconds' print , ' Time series duration = ' + ARR2STR ( cadence * sizecube1 [ 1 ], / trim ) + ' seconds' print , ' Nyquist frequency = ' + ARR2STR ( temporal_Nyquist * 1000. , / trim ) + ' mHz' print , ' ' endif cospectrum = walsa_getcorss_spectrum_wavelet ( data1 , time1 , data2 , time2 , mother = mother , param = param , dj = dj , colornoise = colornoise , coherence = coherence , phase_angle = phase_angle , $ TIME_OUT = time_out , SCAle_OUT = scale_out , COI_OUT = coi_out , CROSS_WAVEleT = cross_wavelet , POWER1 = power1 , POWER2 = power2 , $ frequency = frequency , nosignificance = nosignificance , koclt = koclt , $ log = log , period = period , plot = plot , clt = clt , removespace = removespace , $ coh_global = coh_global , phase_global = phase_global , cross_global = cross_global , $ coh_oglobal = coh_oglobal , phase_oglobal = phase_oglobal , cross_oglobal = cross_oglobal , $ padding = padding , apod = apod , nodetrendapod = nodetrendapod , pxdetrend = pxdetrend , meandetrend = meandetrend , $ polyfit = polyfit , meantemporal = meantemporal ) nxx = n_elements ( cospectrum [ * , 0 ]) nyy = n_elements ( cospectrum [ 0 , * ]) if nosignificance eq 0 then begin ndata1 = n_elements ( data1 ) dt1 = walsa_mode ( walsa_diff ( time1 )) ndata2 = n_elements ( data2 ) dt2 = round ( walsa_mode ( walsa_diff ( time2 ))) coh_perm = fltarr ( nxx , nyy , nperm ) cross_perm = fltarr ( nxx , nyy , nperm ) for ip = 0 L , nperm - 1 do begin permutation1 = walsa_randperm ( ndata1 ) y_perm1 = data1 ( permutation1 ) permutation2 = walsa_randperm ( ndata2 ) y_perm2 = data2 ( permutation2 ) cospectrumsig = walsa_getcorss_spectrum_wavelet ( y_perm1 , time1 , y_perm2 , time2 , coherence = cohsig , $ mother = mother , param = param , dj = dj , colornoise = colornoise , $ log = 0 , plot = 0 , silent = 1 , padding = padding , apod = apod , nodetrendapod = nodetrendapod , $ pxdetrend = pxdetrend , meandetrend = meandetrend , polyfit = polyfit , meantemporal = meantemporal ) coh_perm [ * , * , ip ] = cohsig cross_perm [ * , * , ip ] = cospectrumsig if ip eq 0 then PRINT print , string ( 13 b ) + ' >>> % Running Monte Carlo (significance): ' ,( ip * 100. ) / ( nperm - 1 ), format = '(a,f4.0,$)' endfor PRINT PRINT signif_coh = walsa_confidencelevel_wavelet ( coh_perm , siglevel = siglevel ) signif_cross = walsa_confidencelevel_wavelet ( cross_perm , siglevel = siglevel ) endif if plot eq 1 then begin powplot = cospectrum perplot = period timplot = time_out coiplot = coi_out walsa_plot_wavelet_cross_spectrum , powplot , perplot , timplot , coiplot , clt = clt , w = 8 , phase_angle = phase_angle , log = log , normal = pownormal , $ / crossspectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , significancelevel = signif_cross , nosignificance = nosignificance , removespace = removespace powplot = coherence perplot = period timplot = time_out coiplot = coi_out walsa_plot_wavelet_cross_spectrum , powplot , perplot , timplot , coiplot , clt = clt , w = 9 , phase_angle = phase_angle , log = 0 , normal = pownormal , $ / coherencespectrum , arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , $ noarrow = noarrow , significancelevel = signif_coh , nosignificance = nosignificance , removespace = removespace endif frequency = 1000. / period ; in mHz time = time_out coi = coi_out scale = scale_out print , '' print , 'COMPLETED!' print , '' end This code also uses the following routine to plot the wavelet co-spectrum and coherence spectrum (along with confidence levels, cone-of-influence regions, and phase lags). WaLSA_plot_wavelet_cross_spectrum.pro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 ; ----------------------------------------------------------------------------------------------------- ; WaLSAtools : Wave analysis tools ; Copyright ( C ) 2025 WaLSA Team - Shahin Jafarzadeh et al . ; ; Licensed under the Apache License , Version 2.0 ( the \"License\" ); ; you may not use this file except in compliance with the License . ; You may obtain a copy of the License at ; ; http : // www . apache . org / licenses / LICENSE - 2.0 ; ; Unless required by applicable law or agreed to in writing , software ; distributed under the License is distributed on an \"AS IS\" BASIS , ; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND , either express or implied . ; See the License for the specific language governing permissions and ; limitations under the License . ; ; Note : If you use WaLSAtools for research , please consider citing : ; Jafarzadeh , S . , Jess , D . B . , Stangalini , M . et al . 2025 , Nature Reviews Methods Primers , in press . ; ----------------------------------------------------------------------------------------------------- function walsa_plot_vector , u , v , x , y , angle = angle , head_len = head_len , $ maxmag = maxmag , align = align , length = length , $ ref_text = ref_text , COLOR = color , THICK = thick , cstyle = cstyle , myphi = myphi , charsize = charsize ; Procedure to calculate and plot a vector mylen = 300.0 ; length of default arrow in pixels rev = 1.0 x0 = 0.0 y0 = 0.0 x1 = u / maxmag * mylen * length y1 = v / maxmag * mylen * length dx = x1 - x0 if ( dx LT 0.0 ) then rev =- 1.0 dy = y1 - y0 r = SQRT ( dx ^ 2 + dy ^ 2 ) theta = ATAN ( dy / dx ) phi = angle * ! dtor rfrac = head_len x2 = x1 - r * rfrac * rev * COS ( theta - phi ) y2 = y1 - r * rfrac * rev * SIN ( theta - phi ) x3 = x1 - r * rfrac * rev * COS ( theta + phi ) y3 = y1 - r * rfrac * rev * SIN ( theta + phi ) x4 = x1 - rfrac / 2 * r * rev * COS ( theta ) y4 = y1 - rfrac / 2 * r * rev * SIN ( theta ) ; Calculate intersection of vector shaft and head points either ; side of the shaft - see ; http : // astronomy . swin . edu . au /~ pbourke / geometry / lineline2d ; for more details ua = (( x3 - x2 ) * ( y0 - y2 ) - ( y3 - y2 ) * ( x0 - x2 )) / $ (( y3 - y2 ) * ( x1 - x0 ) - ( x3 - x2 ) * ( y1 - y0 )) x5 = x0 + ua * ( x1 - x0 ) y5 = y0 + ua * ( y1 - y0 ) outputval = 1 ; Plot vectors in data space - cstyle = 0 ; Position in device coordinates and then convert to data coordinates if ( cstyle EQ 0 ) then begin pt1 = CONVERT_COORD ( x , y , / DATA , / TO_DEVICE ) xpts = [ x0 , x1 , x2 , x3 , x4 , x5 ] + pt1 [ 0 ] - align * dx ypts = [ y0 , y1 , y2 , y3 , y4 , y5 ] + pt1 [ 1 ] - align * dy pts = CONVERT_COORD ( xpts , ypts , / DEVICE , / TO_DATA ) xpts = pts [ 0 , * ] ypts = pts [ 1 , * ] x0 = xpts [ 0 ] x1 = xpts [ 1 ] x2 = xpts [ 2 ] x3 = xpts [ 3 ] x4 = xpts [ 4 ] x5 = xpts [ 5 ] y0 = ypts [ 0 ] y1 = ypts [ 1 ] y2 = ypts [ 2 ] y3 = ypts [ 3 ] y4 = ypts [ 4 ] y5 = ypts [ 5 ] ; Plot the vectors omiting any vectors with NaNs z = [ xpts , ypts ] if ( TOTAL ( FINITE ( z )) EQ 12 ) then begin PLOTS , [ x0 , x5 , x3 , x1 , x2 , x5 ], [ y0 , y5 , y3 , y1 , y2 , y5 ], COLOR = color , THICK = thick , NOCLIP = 0 POLYFILL , [ x2 , x1 , x3 ],[ y2 , y1 , y3 ], COLOR = color , THICK = thick , NOCLIP = 0 endif endif ; Plot reference vector - cstyle = 1 ; Position in device coordinates and then convert to data coordinates if ( cstyle EQ 1 ) then begin pt1 = CONVERT_COORD ( x , y , / NORMAL , / TO_DEVICE ) xpts = [ x0 , x1 , x2 , x3 , x4 , x5 ] + pt1 [ 0 ] ypts = [ y0 , y1 , y2 , y3 , y4 , y5 ] + pt1 [ 1 ] x0 = xpts [ 0 ] x1 = xpts [ 1 ] x2 = xpts [ 2 ] x3 = xpts [ 3 ] x4 = xpts [ 4 ] x5 = xpts [ 5 ] y0 = ypts [ 0 ] y1 = ypts [ 1 ] y2 = ypts [ 2 ] y3 = ypts [ 3 ] y4 = ypts [ 4 ] y5 = ypts [ 5 ] ; Plot the vectors omiting any vectors with NaNs z = [ xpts , ypts ] if ( TOTAL ( FINITE ( z )) EQ 12 ) then begin PLOTS , [ x0 , x5 , x3 , x1 , x2 , x5 ], [ y0 , y5 , y3 , y1 , y2 , y5 ], COLOR = color , THICK = thick , / DEVICE POLYFILL , [ x2 , x1 , x3 ],[ y2 , y1 , y3 ], COLOR = color , THICK = thick , / DEVICE endif ; Add the reference vector text xoffset = round ( abs ( x3 - x2 )) / 2. yoffset = round ( abs ( y3 - y2 )) if myphi eq 0 then CGTEXT , x0 , y0 + ( 2.5 * yoffset ), cgGreek ( 'phi' ) + '=0' + cgSymbol ( 'deg' ), ALIGNMENT = 0.0 , COLOR = color , / DEVICE , charsize = charsize if myphi eq 90 then CGTEXT , x0 + ( 2. * xoffset ), y0 + ( 2. * xoffset ), cgGreek ( 'phi' ) + '=90' + cgSymbol ( 'deg' ), ALIGNMENT = 0.0 , COLOR = color , / DEVICE , charsize = charsize endif return , outputval end ; ---------------------------------------------------------------------------- function walsa_vector , u , v , x , y , LENGTH = length , $ Color = color , XSTRIDE = xstride , YSTRIDE = ystride , ALIGN = align , $ REF_MAG = ref_mag , ANGLE = angle , HEAD_LEN = head_len , $ REF_POS = ref_pos , REF_TEXT = ref_text , OVERPLOT = overplot , _EXTRA = extra , THICK = thick , charsize = charsize a = SIZE ( u ) b = SIZE ( v ) c = SIZE ( x ) d = SIZE ( y ) ; Initialise parameters if undefined if ( N_ELEMENTS ( XSTRIDE ) EQ 0 ) then xstride = 0 if ( N_ELEMENTS ( YSTRIDE ) EQ 0 ) then ystride = 0 if N_ELEMENTS ( LENGTH ) EQ 0 then length = 1.0 if N_ELEMENTS ( COLOR ) EQ 0 then color = ! P . COLOR if ( N_ELEMENTS ( ANGLE ) EQ 0 ) then angle = 22.5 if ( N_ELEMENTS ( HEAD_LEN ) EQ 0 ) then head_len = 0.3 if ( N_ELEMENTS ( TYPE ) EQ 0 ) then TYPE = 0 if ( N_ELEMENTS ( ALIGN ) EQ 0 ) then align = 0.5 if ( N_ELEMENTS ( REF_TEXT ) EQ 0 ) then ref_text = ' ' if ( N_ELEMENTS ( REF_MAG ) EQ 0 ) then begin maxmag = MAX ( ABS ( SQRT ( u ^ 2. + v ^ 2. ))) endif ELSE begin maxmag = ref_mag endELSE outputval = 1 ; Setup the plot area if undefined if ( NOT KEYWORD_SET ( overplot )) then begin xs = x [ 0 ] - ( x ( 1 ) - x ( 0 )) xf = x [ N_ELEMENTS ( x ) - 1 ] + ( x ( 1 ) - x ( 0 )) ys = y [ 0 ] - ( y ( 1 ) - y ( 0 )) yf = y [ N_ELEMENTS ( y ) - 1 ] + ( y ( 1 ) - y ( 0 )) PLOT ,[ xs , xf ],[ ys , yf ], XSTYLE = 1 , YSTYLE = 1 , / NODATA , $ COLOR = color , _EXTRA = extra endif ; do stride data reduction if needed if ( xstride GT 1 ) then begin mypts = FLTARR ( a [ 1 ], a [ 2 ]) mypts [ * , * ] = 0.0 for iy = 0 , a [ 2 ] - 1 , xstride do begin for ix = 0 , a [ 1 ] - 1 , ystride do begin if ( (( ix / xstride ) EQ FIX ( ix / xstride )) AND $ (( iy / ystride ) EQ FIX ( iy / ystride )) ) then mypts [ ix , iy ] = 1.0 endfor endfor pts = WHERE ( mypts LT 1.0 ) u [ pts ] = 0.0 v [ pts ] = 0.0 endif ; Main vector plotting loop for ix = 1 , N_ELEMENTS ( x ) - 1 do begin for iy = 1 , N_ELEMENTS ( y ) - 1 do begin tempt = walsa_plot_vector ( u ( ix , iy ), v ( ix , iy ), x ( ix ), y ( iy ), $ angle = angle , head_len = head_len , $ maxmag = maxmag , align = align , length = length , $ color = color , cstyle = 0 , THICK = thick ) endfor endfor ; Plot reference arrow ( s ) if ( N_ELEMENTS ( REF_POS ) NE 0 ) then begin tempt = walsa_plot_vector ( 2. * maxmag , 0.0 , ref_pos [ 0 ], ref_pos [ 1 ], $ angle = angle , ref_text = ref_text , head_len = head_len - 0.2 , $ maxmag = maxmag , align = align , length = length , $ color = color , cstyle = 1 , thick = thick , myphi = 0 , charsize = charsize ) tempt = walsa_plot_vector ( 0.0 , 2. * maxmag , ref_pos [ 0 ], ref_pos [ 1 ] + 0.10 , $ angle = angle , ref_text = ref_text , head_len = head_len - 0.2 , $ maxmag = maxmag , align = align , length = length , $ color = color , cstyle = 1 , thick = thick , myphi = 90 , charsize = charsize ) endif return , outputval end ; ---------------------------------------------------------------------------- pro walsa_plot_wavelet_cross_spectrum , power , period , time , coi , significancelevel = significancelevel , clt = clt , ylog = ylog , $ phase_angle = phase_angle , log = log , crossspectrum = crossspectrum , normal = normal , epsfilename = epsfilename , $ coherencespectrum = coherencespectrum , noarrow = noarrow , w = w , nosignificance = nosignificance , maxperiod = maxperiod , $ arrowdensity = arrowdensity , arrowsize = arrowsize , arrowheadsize = arrowheadsize , removespace = removespace , koclt = koclt , arrowthick = arrowthick if n_elements ( crossspectrum ) eq 0 then crossspectrum = 0 if n_elements ( coherencespectrum ) eq 0 then coherencespectrum = 0 if n_elements ( log ) eq 0 then log = 1 if n_elements ( ylog ) eq 0 then ylog = 1. if n_elements ( arrowdensity ) eq 0 then arrowdensity = [ 30 , 18 ] if n_elements ( arrowsize ) eq 0 then arrowsize = 1. if n_elements ( arrowheadsize ) eq 0 then arrowheadsize = 1. if n_elements ( arrowthick ) eq 0 then arrowthick = 2. if n_elements ( nosignificance ) eq 0 then nosignificance = 0 if n_elements ( noarrow ) eq 0 then noarrow = 0 if n_elements ( removespace ) eq 0 then removespace = 0 if n_elements ( normal ) eq 0 then normal = 0 if n_elements ( epsfilename ) eq 0 then eps = 0 else eps = 1 if crossspectrum eq 0 and coherencespectrum eq 0 then begin PRINT PRINT , ' Please define which one to plot: cross spectrum or coherence' PRINT stop endif if crossspectrum ne 0 and coherencespectrum ne 0 then begin PRINT PRINT , ' Please define which one to plot: cross spectrum or coherence' PRINT stop endif nt = n_elements ( reform ( time )) np = n_elements ( reform ( period )) fundf = 1000. / ( time [ nt - 1 ]) ; fundamental frequency ( frequency resolution ) in mHz if n_elements ( maxperiod ) eq 0 then maxp = 1000. / fundf else maxp = maxperiod ; longest period to be plotted if n_elements ( maxperiod ) eq 0 then if removespace ne 0 then maxp = max ( coi ) ; remove areas below the COI iit = closest_index ( maxp , period ) period = period [ 0 : iit ] if nosignificance eq 0 then isig = reform ( significancelevel [ * , 0 : iit ]) power = reform ( power [ * , 0 : iit ]) power = reverse ( power , 2 ) np = n_elements ( reform ( period )) aphaseangle = phase_angle aphaseangle = reform ( aphaseangle [ * , 0 : iit ]) if nosignificance eq 0 then isig = reverse ( isig , 2 ) if nosignificance eq 0 then sigi = power / isig if n_elements ( w ) eq 0 then w = 8 dimensions = GET_SCREEN_SIZE ( RESOLUTION = resolution ) xscreensize = dimensions [ 0 ] yscreensize = dimensions [ 1 ] IF ( xscreensize le yscreensize ) THEN smallest_screensize = xscreensize IF ( yscreensize le xscreensize ) THEN smallest_screensize = yscreensize if EPS eq 1 then begin walsa_eps , size = [ 18 , 13 ] ! p . font = 0 device , set_font = 'Times-Roman' charsize = 1.3 ! x . thick = 4. ! y . thick = 4. ! x . ticklen =- 0.033 ! y . ticklen =- 0.024 ; ! y . minor = 10 barthick = 550 distbar = 550 coithick = 3. arrowsize = 20. * arrowsize arrowthick = ( 3.5 / 2. ) * arrowthick c_thick = 3. h_thick = 1.4 ; ! y . tickinterval = 100. ; arrowheadsize = 10. endif else begin if ( xscreensize ge 1000 ) AND ( yscreensize ge 1000 ) then begin if crossspectrum ne 0 then window , w , xs = 900 , ys = 650 , title = strtrim ( w , 2 ) + ': Cross Wavelet Spectrum' if coherencespectrum ne 0 then window , w , xs = 900 , ys = 650 , title = strtrim ( w , 2 ) + ': Coherence' charsize = 2.0 ! x . thick = 2. ! y . thick = 2. ! x . ticklen =- 0.033 ! y . ticklen =- 0.022 ; ! X . MINOR = 6 distbar = 30 barthick = 30 coithick = 2 c_thick = 2. h_thick = 1. endif if ( xscreensize lt 1000 ) OR ( yscreensize lt 1000 ) then begin if crossspectrum ne 0 then window , w , xs = FIX ( smallest_screensize * 0.9 ), ys = FIX ( smallest_screensize * 0.9 ), title = strtrim ( w , 2 ) + ': Cross Wavelet Spectrum' if coherencespectrum ne 0 then window , w , xs = FIX ( smallest_screensize * 0.9 ), ys = FIX ( smallest_screensize * 0.9 ), title = strtrim ( w , 2 ) + ': Coherence' charsize = 1.7 ! x . thick = 2 ! y . thick = 2 ! x . ticklen =- 0.033 ! y . ticklen =- 0.022 distbar = 25 barthick = 25 coithick = 2 c_thick = 2. h_thick = 1. endif endelse colset device , decomposed = 0 xtitle = 'Time (s)' if crossspectrum ne 0 then begin if normal ne 0 then begin ztitle = 'Normalised Cross Power!C' if log ne 0 then ztitle = 'Log!d10!n(Normalised Cross Power)!C' endif else begin ztitle = 'Cross Power!C' if log ne 0 then ztitle = 'Log!d10!n(Cross Power)!C' endelse endif if coherencespectrum ne 0 then begin ztitle = 'Coherence!C' if log ne 0 then ztitle = 'Log!d10!n(Coherence)!C' endif ii = where ( power lt 0. , cii ) if cii gt 0 then power ( ii ) = 0. if crossspectrum ne 0 then if normal ne 0 then power = 100. * power / max ( power ) xrg = minmax ( time ) yrg = [ max ( period ), min ( period )] ; userlct , / full , verbose = 0 , coltab = nnn if n_elements ( clt ) eq 0 then clt = 20 loadct , clt if n_elements ( koclt ) ne 0 then walsa_kopowercolor , koclt if log ne 0 then power = alog10 ( power ) walsa_image_plot , power , xrange = xrg , yrange = yrg , $ nobar = 0 , zrange = minmax ( power , / nan ), ylog = ylog , $ contour = 0 , / nocolor , charsize = charsize , $ ztitle = ztitle , xtitle = xtitle , $ exact = 1 , aspect = 0 , cutaspect = 0 , ystyle = 5 , $ barpos = 1 , zlen =- 0.6 , distbar = distbar , $ barthick = barthick , position = [ 0.14 , 0.14 , 0.87 , 0.87 ] cgAxis , YAxis = 0 , YRange = yrg , ystyle = 1 , ylog = ylog , charsize = charsize , ytitle = 'Period (s)' ; Lblv = LOGLEVELS ([ max ( period ), min ( period )]) ; axlabel , Lblv , charsize = charsize , color = cgColor ( 'Black' ) , format = '(i12)' cgAxis , YAxis = 1 , YRange = [ 1000. / yrg [ 0 ], 1000. / yrg [ 1 ]], ystyle = 1 , ylog = ylog , title = 'Frequency (mHz)' , charsize = charsize ; plot phase angles as arrows angle = aphaseangle UU = cos ( d2r ( angle )) VV = sin ( d2r ( angle )) if noarrow eq 0 then $ tempt = walsa_vector ( UU , VV , time , period , / overplot , color = cgColor ( 'Black' ), length = 0.04 * arrowsize , ySTRIDE = round ( nt / float ( ArrowDensity [ 0 ])), $ xSTRIDE = round ( np / float ( ArrowDensity [ 1 ])), thick = arrowthick , head_len = 0.5 * arrowheadsize , ref_pos = [ 0.025 , 0.815 ], align = 0.5 , charsize = charsize ) ; plot the Cone - of - Influence plots , time , coi , noclip = 0 , linestyle = 0 , thick = coithick , color = cgColor ( 'Black' ) ; shade the area above the Cone - of - Influence , with hashed lines : ncoi = n_elements ( coi ) y = fltarr ( ncoi ) for j = 0 , ncoi - 1 do y ( j ) = maxp walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION = 45 walsa_curvefill , time , y , coi , color = cgColor ( 'Black' ), thick = h_thick , / LINE_FILL , ORIENTATION =- 45 ; contours mark significance level if nosignificance eq 0 then $ cgContour , sigi , / noerase , levels = 1. , XTICKforMAT = \"(A1)\" , YTICKforMAT = \"(A1)\" , $ xthick = 1.e-40 , ythick = 1.e-40 , xticklen = 1.e-40 , yticklen = 1.e-40 , xticks = 1.e-40 , yticks = 1.e-40 , $ c_colors = [ cgColor ( 'Navy' )], label = 0 , $ c_linestyle = 0 , c_thick = c_thick if EPS eq 1 then walsa_endeps , filename = epsfilename , / pdf end", "title": "Cross Correlations: Wavelet power spectra"}, {"location": "idl/setting-idl-path/", "text": "Setting IDL PATH \u00b6 After you have installed WaLSAtools , you need to add its path to your IDL_PATH . The IDL_PATH tells IDL where to find .pro files (IDL procedures and functions). The easiest way to add WaLSAtools to your IDL path is by navigating to the WaLSAtools' idl directory in your terminal (under codes ), starting IDL, and running the following command: .run setup. pro This will automatically configure your IDL path to include the WaLSAtools library. If for any reason the above method doesn't work, you can manually add the WaLSAtools path to your IDL_PATH. The process for setting the IDL search path varies depending on your operating system and shell environment. Below are instructions for some common environments. For detailed information, please refer to IDL's support pages . Using the Terminal \u00b6 You can define and add custom search paths to your IDL_PATH system environment variable in the terminal. Mac OS X and Linux Microsoft Windows On Unix-like systems, such as Mac OS X and Linux, first determine your shell environment. Type the following command in your terminal: echo $0 Common shells include bash (Bourne Again shell) and csh (C shell)/ tcsh (TC shell). Instructions for customizing IDL_PATH in these shells are provided below. bash csh / tcsh Add the following lines to your .bashrc file (located in your home directory) or to the script where you set your IDL_PATH variable: export IDL_DIR=PATH-TO-IDL-DIRECTORY export IDL_PATH=+${IDL_DIR}/lib:+PATH-TO-THE-DIRECTORY/WaLSAtools Replace PATH-TO-IDL-DIRECTORY and PATH-TO-THE-DIRECTORY with the actual paths to your IDL installation and the WaLSAtools directory, respectively. You can add multiple paths to IDL_PATH by separating them with :+ . After saving the changes, run the following command in your terminal to apply them: source ~/.bashrc Add the following lines to your .cshrc or .tcshrc file: setenv IDL_DIR PATH-TO-IDL-DIRECTORY setenv IDL_PATH +$IDL_DIR/lib:+PATH-TO-THE-DIRECTORY/WaLSAtools Replace PATH-TO-IDL-DIRECTORY and PATH-TO-THE-DIRECTORY with the actual paths. You can add multiple paths by separating them with :+ . After saving the changes, run the following command in your terminal: source ~/.cshrc # or source ~/.tcshrc Open the Environment Variables dialog: Start > Control Panel > System and Security > System > Advanced system settings > Advanced > Environment Variables (On Windows 7, select Start > Control Panel > System and Security > System > Advanced system settings > Environment Variables ) Set the IDL_PATH variable. If it doesn't exist, create a new system or user variable named IDL_PATH . Define the IDL packages/libraries in your path: +C:\\Program Files\\PATH-TO-IDL-DIRECTORY\\lib;C:\\PATH-TO-THE-DIRECTORY\\WaLSAtools Replace PATH-TO-IDL-DIRECTORY and PATH-TO-THE-DIRECTORY with the actual paths. Separate multiple paths with semicolons ( ; ), without adding any spaces. Using IDL Workbench \u00b6 You can also customize the IDL_PATH through the IDL Workbench (idlde) Preferences dialog. Open the Preferences dialog. : IDL > Preferences and : Window > Preferences Expand and select IDL > Paths in the left pane. Select \"IDL path\" from the dropdown menu on the right. Insert your additional IDL program search paths. If is not already included, press the \"Insert Default\" button. Click \"Apply\" and then \"OK\" to save your changes. Verifying the path \u00b6 To test if the path is set correctly, start IDL and run: WaLSAtools, /version The package is successfully installed if the output shows the WaLSAtools version and a brief overview of its functionalities.", "title": "Setting IDL PATH"}, {"location": "idl/setting-idl-path/#setting-idl-path", "text": "After you have installed WaLSAtools , you need to add its path to your IDL_PATH . The IDL_PATH tells IDL where to find .pro files (IDL procedures and functions). The easiest way to add WaLSAtools to your IDL path is by navigating to the WaLSAtools' idl directory in your terminal (under codes ), starting IDL, and running the following command: .run setup. pro This will automatically configure your IDL path to include the WaLSAtools library. If for any reason the above method doesn't work, you can manually add the WaLSAtools path to your IDL_PATH. The process for setting the IDL search path varies depending on your operating system and shell environment. Below are instructions for some common environments. For detailed information, please refer to IDL's support pages .", "title": "Setting IDL PATH"}, {"location": "idl/setting-idl-path/#using-the-terminal", "text": "You can define and add custom search paths to your IDL_PATH system environment variable in the terminal. Mac OS X and Linux Microsoft Windows On Unix-like systems, such as Mac OS X and Linux, first determine your shell environment. Type the following command in your terminal: echo $0 Common shells include bash (Bourne Again shell) and csh (C shell)/ tcsh (TC shell). Instructions for customizing IDL_PATH in these shells are provided below. bash csh / tcsh Add the following lines to your .bashrc file (located in your home directory) or to the script where you set your IDL_PATH variable: export IDL_DIR=PATH-TO-IDL-DIRECTORY export IDL_PATH=+${IDL_DIR}/lib:+PATH-TO-THE-DIRECTORY/WaLSAtools Replace PATH-TO-IDL-DIRECTORY and PATH-TO-THE-DIRECTORY with the actual paths to your IDL installation and the WaLSAtools directory, respectively. You can add multiple paths to IDL_PATH by separating them with :+ . After saving the changes, run the following command in your terminal to apply them: source ~/.bashrc Add the following lines to your .cshrc or .tcshrc file: setenv IDL_DIR PATH-TO-IDL-DIRECTORY setenv IDL_PATH +$IDL_DIR/lib:+PATH-TO-THE-DIRECTORY/WaLSAtools Replace PATH-TO-IDL-DIRECTORY and PATH-TO-THE-DIRECTORY with the actual paths. You can add multiple paths by separating them with :+ . After saving the changes, run the following command in your terminal: source ~/.cshrc # or source ~/.tcshrc Open the Environment Variables dialog: Start > Control Panel > System and Security > System > Advanced system settings > Advanced > Environment Variables (On Windows 7, select Start > Control Panel > System and Security > System > Advanced system settings > Environment Variables ) Set the IDL_PATH variable. If it doesn't exist, create a new system or user variable named IDL_PATH . Define the IDL packages/libraries in your path: +C:\\Program Files\\PATH-TO-IDL-DIRECTORY\\lib;C:\\PATH-TO-THE-DIRECTORY\\WaLSAtools Replace PATH-TO-IDL-DIRECTORY and PATH-TO-THE-DIRECTORY with the actual paths. Separate multiple paths with semicolons ( ; ), without adding any spaces.", "title": "Using the Terminal"}, {"location": "idl/setting-idl-path/#using-idl-workbench", "text": "You can also customize the IDL_PATH through the IDL Workbench (idlde) Preferences dialog. Open the Preferences dialog. : IDL > Preferences and : Window > Preferences Expand and select IDL > Paths in the left pane. Select \"IDL path\" from the dropdown menu on the right. Insert your additional IDL program search paths. If is not already included, press the \"Insert Default\" button. Click \"Apply\" and then \"OK\" to save your changes.", "title": "Using IDL Workbench"}, {"location": "idl/setting-idl-path/#verifying-the-path", "text": "To test if the path is set correctly, start IDL and run: WaLSAtools, /version The package is successfully installed if the output shows the WaLSAtools version and a brief overview of its functionalities.", "title": "Verifying the path"}, {"location": "idl/spod-example/", "text": "Worked Example - NRMP: Spectral Proper Orthogonal Decomposition (SPOD) Analysis \u00b6 The IDL version of this example is currently under development .....", "title": "SPOD analysis"}, {"location": "idl/spod-example/#worked-example-nrmp-spectral-proper-orthogonal-decomposition-spod-analysis", "text": "The IDL version of this example is currently under development .....", "title": "Worked Example - NRMP: Spectral Proper Orthogonal Decomposition (SPOD) Analysis"}, {"location": "idl/troubleshooting/", "text": "Troubleshooting \u00b6 This page provides solutions to common issues encountered during the installation or usage of WaLSAtools in IDL. If you encounter a problem not listed here, please refer to the WaLSAtools documentation or contact us for assistance. WaLSAtools Not Recognized \u00b6 Operating systems: macOS Linux Windows Error: Undefined procedure IDL> WaLSAtools % Attempt to call undefined procedure: 'WALSATOOLS'. % Execution halted at: $MAIN$ If you encounter this error, it usually means that your IDL_PATH is not set correctly, and IDL cannot find the WaLSAtools package. Please check the Setting IDL PATH page for instructions on how to configure your IDL_PATH correctly. Undefined Procedure or Keyword \u00b6 Operating systems: macOS Linux Windows Error: Syntax error IDL> WaLSAtools ... param[*,i] = example_function(bla[*,i],t=t[j]) ^ % Syntax error. If IDL reports a syntax error , the reason might not be immediately obvious. Here are some common causes: Undefined function Procedure conflict IDL version Wrong syntax If IDL doesn't recognize a function, it might interpret the function's name as an array. Make sure the function is compiled before the line where the error occurs. If you have installed WaLSAtools correctly, all its dependencies should have been added to your IDL_PATH . If you have another function or procedure with the same name in your IDL_PATH , IDL might be calling the wrong one. To check the location of the function/procedure, use the which command in IDL: IDL > which, 'example_function' ~/ idlLibrary / WaLSAtools / codes / dependencies / example_function. pro This will show you the path to the example_function.pro file. Ensure that the file is located within the WaLSAtools directory. If not, you might need to rename the conflicting function/procedure in your path. Note that the which command is part of SolarSoft . If you don't have SolarSoft installed, you can search for the function/procedure manually in your IDL library or the directories included in your IDL_PATH . In some older IDL versions, using parentheses to index an array, like x(i) , might be interpreted as a function call. If you encounter this issue, use square brackets for indexing: x[i] . A simple typo or incorrect syntax can also cause a Syntax error . While WaLSAtools has been extensively tested, please let us know if you find any such errors. Questions and Discussions If you have any further questions or issues with WaLSAtools, please submit them on our GitHub Discussions page. We actively monitor this forum and will be happy to assist you.", "title": "Troubleshooting"}, {"location": "idl/troubleshooting/#troubleshooting", "text": "This page provides solutions to common issues encountered during the installation or usage of WaLSAtools in IDL. If you encounter a problem not listed here, please refer to the WaLSAtools documentation or contact us for assistance.", "title": "Troubleshooting"}, {"location": "idl/troubleshooting/#walsatools-not-recognized", "text": "Operating systems: macOS Linux Windows Error: Undefined procedure IDL> WaLSAtools % Attempt to call undefined procedure: 'WALSATOOLS'. % Execution halted at: $MAIN$ If you encounter this error, it usually means that your IDL_PATH is not set correctly, and IDL cannot find the WaLSAtools package. Please check the Setting IDL PATH page for instructions on how to configure your IDL_PATH correctly.", "title": "WaLSAtools Not Recognized"}, {"location": "idl/troubleshooting/#undefined-procedure-or-keyword", "text": "Operating systems: macOS Linux Windows Error: Syntax error IDL> WaLSAtools ... param[*,i] = example_function(bla[*,i],t=t[j]) ^ % Syntax error. If IDL reports a syntax error , the reason might not be immediately obvious. Here are some common causes: Undefined function Procedure conflict IDL version Wrong syntax If IDL doesn't recognize a function, it might interpret the function's name as an array. Make sure the function is compiled before the line where the error occurs. If you have installed WaLSAtools correctly, all its dependencies should have been added to your IDL_PATH . If you have another function or procedure with the same name in your IDL_PATH , IDL might be calling the wrong one. To check the location of the function/procedure, use the which command in IDL: IDL > which, 'example_function' ~/ idlLibrary / WaLSAtools / codes / dependencies / example_function. pro This will show you the path to the example_function.pro file. Ensure that the file is located within the WaLSAtools directory. If not, you might need to rename the conflicting function/procedure in your path. Note that the which command is part of SolarSoft . If you don't have SolarSoft installed, you can search for the function/procedure manually in your IDL library or the directories included in your IDL_PATH . In some older IDL versions, using parentheses to index an array, like x(i) , might be interpreted as a function call. If you encounter this issue, use square brackets for indexing: x[i] . A simple typo or incorrect syntax can also cause a Syntax error . While WaLSAtools has been extensively tested, please let us know if you find any such errors. Questions and Discussions If you have any further questions or issues with WaLSAtools, please submit them on our GitHub Discussions page. We actively monitor this forum and will be happy to assist you.", "title": "Undefined Procedure or Keyword"}, {"location": "images/python/", "text": "WaLSAtools: images for Python documentations \u00b6", "title": "Index"}, {"location": "images/python/#walsatools-images-for-python-documentations", "text": "", "title": "WaLSAtools: images for Python documentations"}, {"location": "python/WaLSAtools/", "text": "WaLSAtools \u00b6 WaLSAtools is designed for ease of use and accessibility. Its interactive interface guides you through the analysis process, providing clear instructions and helpful information at each step. This section demonstrates how to use WaLSAtools and highlights its key features. Before diving into the interactive demonstration, we recommend familiarizing yourself with the various analysis methods available in WaLSAtools. You can find detailed descriptions of these methods in the Introduction section. Additionally, this page provides several Worked Examples of different analysis techniques applied to synthetic datasets (see the left menu). To learn more about its capabilities and how to apply it to your research, we encourage you to explore the WaLSAtools documentation, the associated Nature Reviews Methods Primers article ( full-text access to a view-only version and its Supplementary Information ), and the provided examples. If you use WaLSAtools in your work, please remember to cite it appropriately (see Citation ). The \"Under the Hood\" section provides details on the individual routines used for wave analysis within the WaLSAtools package, for those interested in exploring the underlying code. However, we strongly encourage all users to perform their analyses by running WaLSAtools directly, as this ensures the correct execution of the analysis workflow and provides a more user-friendly experience. Interactive Demonstration WaLSAtools provides an interactive interface that simplifies wave analysis. To launch the interface, simply import the WaLSAtools package and run the WaLSAtools command in a Python terminal or Jupyter notebook. The interface will guide you through the following steps: Select a category of analysis: Choose from single time series analysis or cross-correlation analysis. Choose the data type: Specify the type of data you are working with (e.g., 1D signal, 3D datacube). Pick a specific analysis method: Select the method most suitable for your data and research question. The interface will then provide information on the selected method, including its calling sequence, input parameters, and expected outputs. Here's an example of the execution of WaLSAtools in a Jupyter notebook: .dropdown-container { margin-left: 30px; margin-top: 20px; font-size: 0.9em; line-height: 2; display: flex; flex-direction: column; gap: 10px; } .dropdown-row { display: flex; align-items: center; gap: 10px; } select { width: 270px !important; height: 33px !important; padding: 5px 10px; font-size: 1em; color: #333; border: 1px solid #ccc; border-radius: 2px; background-color: #f9f9f9; appearance: none; -webkit-appearance: none; -moz-appearance: none; background-image: url('data:image/svg+xml,%3Csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"12\" viewBox=\"0 0 12 12\"%3E%3Cpath d=\"M1,4 L6,9 L11,4\" fill=\"none\" stroke=\"%23000\" stroke-width=\"2.0\" /%3E%3C/svg%3E'); background-repeat: no-repeat; background-position: right 10px center; background-size: 12px 12px; cursor: pointer; } select:focus { outline: none; border-color: #4caf50; box-shadow: 0 0 5px rgba(76, 175, 80, 0.6); } select:disabled { background-color: #eaeaea; cursor: not-allowed; } .output-container { margin-left: 30px; margin-top: 5px; padding: 0; display: none; /* Hidden by default */ } .parameters-table { border-collapse: collapse; border: 1px solid #222; width: calc(100% - 30px); box-sizing: border-box; table-layout: auto; margin-top: 20px; font-size: 0.9em; } .parameters-table td { border: 1px solid #222; padding: 8px; text-align: left; } .parameters-table th { padding: 8px; text-align: left; } .code-container { font-family: monospace; position: relative; background-color: #f7f7f7; border: 1px solid #ddd; margin-left: 30px; padding: 10px; padding-left: 40px; /* For line numbers */ font-size: 14px; line-height: 1.6; display: inline-block; width: calc(100% - 30px); box-sizing: border-box; } .line-numbers { position: absolute; top: 10px; left: 10px; color: #888; text-align: right; line-height: 1.6; font-size: 14px; } .execute-btn { background-color: #4caf50; color: white; border: none; border-radius: 50%; width: 20px; height: 20px; display: flex; justify-content: center; align-items: center; font-size: 16px; font-weight: bold; cursor: pointer; position: absolute; left: -30px; /* Place the button outside the box */ top: 2px; } .execute-btn:hover { background-color: #45a049; } .index-number { position: absolute; bottom: 0px; left: -30px; color: #888; font-size: 12px; } .python-label { position: absolute; bottom: 2px; right: 6px; font-size: 12px; color: #888; } .walsa-gear-code { border-left: 4px solid rgb(189, 26, 31); background-color: rgba(255, 255, 255, 0.1); padding: 16px; border-radius: 1px; margin-bottom: 16px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); } 1 2 from WaLSAtools import WaLSAtools WaLSAtools [1] Python \u00a9 WaLSA Team ( www.WaLSA.team ) WaLSAtools v1.0.0 - Wave analysis tools Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools If you use WaLSAtools in your research, please cite: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers , 5, 21 Choose a category, data type, and analysis method from the list below, to get hints on the calling sequence and parameters: Category: Select Category Single Time Series Analysis Cross-Correlation Between Two Time Series Data Type: Select Data Type Method: Select Method Sub-method: Select Sub-method FFT Wavelet Lomb-Scargle Welch Please select appropriate options from all dropdown menus. Calling Sequence: Note: Parameters (**kwargs) Parameter Type Description const parameters = { single_series: { fft: { returnValues: 'power, frequency, significance, amplitude', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, nosignificance: { type: 'bool', description: 'If True, skip significance calculation. Default: False.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, amplitude: { type: 'bool', description: ' If True, return the amplitudes of the Fourier transform. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, wavelet: { returnValues: 'power, period, significance, coi, gws_power, gws_significance, rgws_power', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, mother: { type: 'str', description: 'The mother wavelet function to use. Default: \"morlet\".' }, GWS: { type: 'bool', description: 'If True, calculate the Global Wavelet Spectrum. Default: False.' }, RGWS: { type: 'bool', description: 'If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False.' }, dj: { type: 'float', description: 'Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025.' }, s0: { type: 'float', description: 'Initial (smallest) scale of the wavelet. Default: 2 * dt.' }, J: { type: 'int', description: 'Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj.' }, lag1: { type: 'float', description: 'Lag-1 autocorrelation. Default: 0.0.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, lombscargle: { returnValues: 'power, frequency, significance', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, dy: { type: 'array', description: 'Errors or observational uncertainties associated with the time series.' }, fit_mean: { type: 'bool', description: 'If True, include a constant offset as part of the model at each frequency. This improves accuracy, especially for incomplete phase coverage.' }, center_data: { type: 'bool', description: 'If True, pre-center the data by subtracting the weighted mean of the input data. This is especially important if fit_mean=False.' }, nterms: { type: 'int', description: 'Number of terms to use in the Fourier fit. Default: 1.' }, normalization: { type: 'str', description: 'The normalization method for the periodogram. Options: \"standard\", \"model\", \"log\", \"psd\". Default: \"standard\".' }, nosignificance: { type: 'bool', description: 'If True, skip significance calculation. Default: False.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, welch: { returnValues: 'power, frequency, significance', parameters: { signal: { type: 'array', description: 'The 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, nperseg: { type: 'int', description: 'Length of each segment for analysis. Default: 256.' }, noverlap: { type: 'int', description: 'Number of points to overlap between segments. Default: 128.' }, window: { type: 'str', description: 'Type of window function used in the Welch method. Default: \"hann\".' }, siglevel: { type: 'float', description: 'Significance level for confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, emd: { returnValues: 'HHT_power, HHT_significance, HHT_frequency, psd_spectra, psd_significance, IMFs, IMF_significance, instantaneous_frequency', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array of the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, EEMD: { type: 'bool', description: 'If True, use Ensemble Empirical Mode Decomposition (EEMD) instead of Empirical Mode Decomposition (EMD). Default: False.' }, Welch_psd: { type: 'bool', description: 'If True, calculate Welch PSD spectra instead of FFT PSD spectra (for the psd_spectra and psd_confidence_levels). Default: False.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None.' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, komega: { returnValues: 'power, wavenumber, frequency, filtered_cube, spatial_fft_map, torus_map, spatial_fft_filtered_map, temporal_fft, temporal_filter, temporal_frequencies, spatial_frequencies', parameters: { signal: { type: 'array', description: 'Input datacube, normally in the form of [x, y, t] or [t, x, y]. Note that the input datacube must have identical x and y dimensions. If not, the datacube will be cropped accordingly.' }, time: { type: 'array', description: 'Time array corresponding to the input datacube.' }, pixelsize: { type: 'float', description: 'Spatial sampling of the input datacube. If not given, it is plotted in units of \"pixel\".' }, filtering: { type: 'bool', description: 'If True, filtering is applied, and the filtered datacube (filtered_cube) is returned. Otherwise, None is returned. Default: False.' }, f1: { type: 'float', description: 'Optional lower (temporal) frequency to filter, in Hz.' }, f2: { type: 'float', description: 'Optional upper (temporal) frequency to filter, in Hz.' }, k1: { type: 'float', description: 'Optional lower (spatial) wavenumber to filter, in units of pixelsize^-1 (k = (2 * \u03c0) / wavelength).' }, k2: { type: 'float', description: 'Optional upper (spatial) wavenumber to filter, in units of pixelsize^-1.' }, spatial_torus: { type: 'bool', description: 'If True, makes the annulus used for spatial filtering have a Gaussian-shaped profile, useful for preventing aliasing. Default: True.' }, temporal_torus: { type: 'bool', description: 'If True, makes the temporal filter have a Gaussian-shaped profile, useful for preventing aliasing. Default: True.' }, no_spatial_filt: { type: 'bool', description: 'If True, ensures no spatial filtering is performed on the dataset (i.e., only temporal filtering is applied).' }, no_temporal_filt: { type: 'bool', description: 'If True, ensures no temporal filtering is performed on the dataset (i.e., only spatial filtering is applied).' }, silent: { type: 'bool', description: 'If True, suppresses the k-\u03c9 diagram plot.' }, smooth: { type: 'bool', description: 'If True, power is smoothed. Default: True.' }, mode: { type: 'int', description: 'Output power mode: 0 = log10(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude.' }, processing_maps: { type: 'bool', description: 'If True, the function returns the processing maps (spatial_fft_map, torus_map, spatial_fft_filtered_map, temporal_fft, temporal_filter, temporal_frequencies, spatial_frequencies). Otherwise, they are all returned as None. Default: False.' } } }, pod: { returnValues: 'pod_results', parameters: { signal: { type: 'array', description: '3D data cube with shape (time, x, y) or similar.' }, time: { type: 'array', description: '1D array representing the time points for each time step in the data.' }, num_modes: { type: 'int, optional', description: 'Number of top modes to compute. Default is None (all modes).' }, num_top_frequencies: { type: 'int, optional', description: 'Number of top frequencies to consider. Default is None (all frequencies).' }, top_frequencies: { type: 'list, optional', description: 'List of top frequencies to consider. Default is None.' }, num_cumulative_modes: { type: 'int, optional', description: 'Number of cumulative modes to consider. Default is None (all modes).' }, welch_nperseg: { type: 'int, optional', description: \"Number of samples per segment for Welch's method. Default is 150.\" }, welch_noverlap: { type: 'int, optional', description: \"Number of overlapping samples for Welch's method. Default is 25.\" }, welch_nfft: { type: 'int, optional', description: 'Number of points for the FFT. Default is 2^14.' }, welch_fs: { type: 'int, optional', description: 'Sampling frequency for the data. Default is 2.' }, nperm: { type: 'int, optional', description: 'Number of permutations for significance testing. Default is 1000.' }, siglevel: { type: 'float, optional', description: 'Significance level for the Welch spectrum. Default is 0.95.' }, timestep_to_reconstruct: { type: 'int, optional', description: 'Timestep of the datacube to reconstruct using the top modes. Default is 0.' }, num_modes_reconstruct: { type: 'int, optional', description: 'Number of modes to use for reconstruction. Default is None (all modes).' }, spod: { type: 'bool, optional', description: 'If True, perform Spectral Proper Orthogonal Decomposition (SPOD) analysis. Default is False.' }, spod_filter_size: { type: 'int, optional', description: 'Filter size for SPOD analysis. Default is None.' }, spod_num_modes: { type: 'int, optional', description: 'Number of SPOD modes to compute. Default is None.' }, print_results: { type: 'bool, optional', description: 'If True, print a summary of results. Default is True.' } } }, dominantfreq: { returnValues: 'power, frequency, significance', parameters: { signal: { type: 'array', description: 'Input signal array (1D or 2D).' }, time: { type: 'array', description: 'Time array corresponding to the signal.' }, method: { type: 'string', description: 'Analysis method (e.g., fft, wavelet, etc.).' }, kwargs: { type: 'object', description: 'Additional optional parameters for customization.' } } } }, cross_correlation: { wavelet: { returnValues: 'cross_power, cross_period, cross_sig, cross_coi, coherence, coh_period, coh_sig, coh_coi, phase_angle', parameters: { data1: { type: 'array', description: 'The first 1D time series signal.' }, data2: { type: 'array', description: 'The second 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signals.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, mother: { type: 'str', description: 'The mother wavelet function to use. Default: \"morlet\".' }, GWS: { type: 'bool', description: 'If True, calculate the Global Wavelet Spectrum. Default: False.' }, RGWS: { type: 'bool', description: 'If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False.' }, dj: { type: 'float', description: 'Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025.' }, s0: { type: 'float', description: 'Initial (smallest) scale of the wavelet. Default: 2 * dt.' }, J: { type: 'int', description: 'Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj.' }, lag1: { type: 'float', description: 'Lag-1 autocorrelation. Default: 0.0.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None.' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, welch: { returnValues: 'frequency, cospectrum, phase_angle, power_data1, power_data2, frequency_coherence, coherence', parameters: { data1: { type: 'array', description: 'The first 1D time series signal.' }, data2: { type: 'array', description: 'The second 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signals.' }, nperseg: { type: 'int', description: 'Length of each segment for analysis. Default: 256.' }, noverlap: { type: 'int', description: 'Number of points to overlap between segments. Default: 128.' }, window: { type: 'str', description: 'Type of window function used in the Welch method. Default: \"hann\".' }, siglevel: { type: 'float', description: 'Significance level for confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, fft: { returnValues: 'frequency, cospectrum, phase_angle, power_data1, power_data2, frequency_coherence, coherence', warning: 'Selecting FFT for cross-correlation automatically runs Welch instead, to improve noise handling by averaging over segments. Consider adjusting \"nperseg\" to tune resolution.', parameters: { data1: { type: 'array', description: 'The first 1D time series signal.' }, data2: { type: 'array', description: 'The second 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signals.' }, nperseg: { type: 'int', description: 'Length of each segment for analysis. Default: 256.' }, noverlap: { type: 'int', description: 'Number of points to overlap between segments. Default: 128.' }, window: { type: 'str', description: 'Type of window function used in the Welch method. Default: \"hann\".' }, siglevel: { type: 'float', description: 'Significance level for confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } } } }; const categoryDropdown = document.getElementById('category'); const datatypeDropdown = document.getElementById('datatype'); const analysisMethodDropdown = document.getElementById('analysisMethod'); const subMethodDropdown = document.getElementById('subMethod'); const subMethodLabel = document.getElementById('subMethodLabel'); const outputContainer = document.getElementById('outputContainer'); const callingSequence = document.getElementById('callingSequence'); const parameterTableBody = document.getElementById('parameterTableBody'); function resetDropdown(dropdown, placeholder = \"Select ...\") { dropdown.innerHTML = `<option value=\"\">${placeholder}</option>`; dropdown.disabled = true; } function hideOutput() { outputContainer.style.display = 'none'; } function clearOutput() { callingSequence.innerHTML = ''; parameterTableBody.innerHTML = ''; hideOutput(); } document.addEventListener('DOMContentLoaded', () => { updateOutput(); // Attach event listeners categoryDropdown.addEventListener('change', () => { const category = categoryDropdown.value; resetDropdown(datatypeDropdown, \"Select Data Type\"); resetDropdown(analysisMethodDropdown, \"Select Method\"); resetDropdown(subMethodDropdown, \"Select Sub-method\"); subMethodDropdown.style.display = 'none'; subMethodLabel.style.display = 'none'; clearOutput(); if (category) { datatypeDropdown.disabled = false; if (category === 'a') { datatypeDropdown.innerHTML += ` <option value=\"1\">1D Signal</option> <option value=\"2\">3D Datacube</option>`; } else if (category === 'b') { datatypeDropdown.innerHTML += `<option value=\"1\">1D Signal</option>`; } } updateOutput(); }); datatypeDropdown.addEventListener('change', () => { const category = categoryDropdown.value; const datatype = datatypeDropdown.value; resetDropdown(analysisMethodDropdown, \"Select Method\"); resetDropdown(subMethodDropdown, \"Select Sub-method\"); subMethodDropdown.style.display = 'none'; subMethodLabel.style.display = 'none'; clearOutput(); if (datatype) { analysisMethodDropdown.disabled = false; if (category === 'a' && datatype === '1') { analysisMethodDropdown.innerHTML += ` <option value=\"fft\">FFT</option> <option value=\"wavelet\">Wavelet</option> <option value=\"lombscargle\">Lomb-Scargle</option> <option value=\"welch\">Welch</option> <option value=\"emd\">EMD</option>`; } else if (category === 'a' && datatype === '2') { analysisMethodDropdown.innerHTML += ` <option value=\"komega\">k-omega</option> <option value=\"pod\">POD</option> <option value=\"dominantfreq\">Dominant Freq / Mean Power Spectrum</option>`; } else if (category === 'b') { analysisMethodDropdown.innerHTML += ` <option value=\"fft\">FFT</option> <option value=\"wavelet\">Wavelet</option> <option value=\"welch\">Welch</option>`; } } updateOutput(); }); analysisMethodDropdown.addEventListener('change', () => { const category = categoryDropdown.value; const datatype = datatypeDropdown.value; const analysisMethod = analysisMethodDropdown.value; resetDropdown(subMethodDropdown, \"Select Sub-method\"); subMethodDropdown.style.display = 'none'; subMethodLabel.style.display = 'none'; subMethodDropdown.disabled = true; clearOutput(); if ( category === 'a' && datatype === '2' && analysisMethod === 'dominantfreq' ) { subMethodDropdown.style.display = 'inline-block'; subMethodLabel.style.display = 'inline-block'; subMethodDropdown.disabled = false; subMethodDropdown.innerHTML = ` <option value=\"\">Select Sub-method</option> <option value=\"fft\">FFT</option> <option value=\"wavelet\">Wavelet</option> <option value=\"lombscargle\">Lomb-Scargle</option> <option value=\"welch\">Welch</option>`; } updateOutput(); }); subMethodDropdown.addEventListener('change', updateOutput); updateOutput(); }); // Update Output Container function updateOutput() { const category = categoryDropdown.value; const datatype = datatypeDropdown.value; const analysisMethod = analysisMethodDropdown.value; const subMethod = subMethodDropdown.value; const message = document.getElementById('dropdownMessage'); // Hide output and show a message if selections are incomplete if (!category || !datatype || !analysisMethod || (subMethodDropdown.style.display === 'inline-block' && !subMethod)) { message.style.display = 'block'; hideOutput(); return; } // Hide the message when all selections are made message.style.display = 'none'; // Retrieve returnValues based on category and analysisMethod let returnValues = ''; if (category === 'a') { returnValues = parameters.single_series[analysisMethod]?.returnValues || 'No return values available'; } else if (category === 'b') { returnValues = parameters.cross_correlation[analysisMethod]?.returnValues || 'No return values available'; } // Construct the command string let command1 = ''; if (category === 'a' && datatype === '1') { command1 = `${returnValues} = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method='${analysisMethod}', **kwargs)`; } else if (category === 'b') { command1 = `${returnValues} = WaLSAtools(data1=INPUT_DATA1, data2=INPUT_DATA2, time=TIME_ARRAY, method='${analysisMethod}', **kwargs)`; } else if (category === 'a' && datatype === '2') { if (analysisMethod === 'dominantfreq') { retValues = 'dominant_frequency, mean_power, frequency, power_map' command1 = `${retValues} = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, averagedpower=True, dominantfreq=True, method='${subMethod}', **kwargs)`; } else { if (analysisMethod === 'komega') { analysisMethodout = 'k-omega'; } else { analysisMethodout = analysisMethod; } command1 = `${returnValues} = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method='${analysisMethodout}', **kwargs)`; } } const command = ` <div style=\"display: flex; align-items: baseline;\"> <span style=\"color: #222; min-width: 4ch; margin: 0 !important; line-height: 1.5;\">>>> </span> <pre style=\" white-space: pre-wrap; word-wrap: break-word; color: #01016D; margin: 0 !important; line-height: 1.5; \">${command1}</pre> </div> `; // Update calling sequence and parameter table callingSequence.innerHTML = command; const warningBox = document.getElementById('warningNote'); const warningMessage = document.getElementById('warningMessage'); if (category === 'b' && analysisMethod === 'fft') { warningMessage.innerText = parameters.cross_correlation.fft.warning; warningBox.style.display = 'block'; } else { warningBox.style.display = 'none'; warningMessage.innerText = ''; } if (analysisMethod === 'dominantfreq') { updateParameterTable(subMethod); } else { updateParameterTable(analysisMethod); } outputContainer.style.display = 'block'; } function updateParameterTable(datatype) { parameterTableBody.innerHTML = ''; const paramData = parameters.single_series[datatype]?.parameters || parameters.cross_correlation[datatype]?.parameters; if (!paramData) { parameterTableBody.innerHTML = ` <tr> <td colspan=\"3\" style=\"text-align: center;\">No parameters available.</td> </tr>`; return; } Object.entries(paramData).forEach(([key, value]) => { parameterTableBody.innerHTML += ` <tr> <td>${key}</td> <td>${value.type}</td> <td>${value.description}</td> </tr>`; }); } document.addEventListener('DOMContentLoaded', () => { updateOutput(); }); Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from .analysis_modules.WaLSA_speclizer import WaLSA_speclizer from .analysis_modules.WaLSA_k_omega import WaLSA_k_omega from .analysis_modules.WaLSA_pod import WaLSA_pod from .analysis_modules.WaLSA_cross_spectra import WaLSA_cross_spectra from .analysis_modules.WaLSA_interactive import interactive class WaLSAtools : \"\"\" Main class to perform spectral analysis using different methods. It runs interactively if called without (or empty and acts as a function if called with parentheses and parameters. \"\"\" def __call__ ( self , signal = None , time = None , method = None , ** kwargs ): \"\"\" Main function to perform spectral analysis using different methods. Parameters: signal (array): The input signal (1D, or 3D). time (array): The time array of the signal. method (str): The method to use for spectral analysis ('fft', 'lombscargle', 'k-omega', etc.) **kwargs: Additional parameters for data preparation and analysis methods. Returns: Results of the selected analysis method. \"\"\" if signal is None and time is None and method is None : interactive () # Run interactive (help) mode if no inputs are provided return None method_map = { 'fft' : WaLSA_speclizer , 'lombscargle' : WaLSA_speclizer , 'wavelet' : WaLSA_speclizer , 'welch' : WaLSA_speclizer , 'emd' : WaLSA_speclizer , 'k-omega' : WaLSA_k_omega , 'pod' : WaLSA_pod } if method not in method_map : raise ValueError ( f \"Unknown method ' { method } '. Please choose from { list ( method_map . keys ()) } .\" ) func = method_map [ method ] if method in [ 'fft' , 'lombscargle' , 'wavelet' , 'welch' , 'emd' ] and 'data1' in kwargs and 'data2' in kwargs : return WaLSA_cross_spectra ( signal = np . ones ( 10 ), time = time , method = method , ** kwargs ) else : return func ( signal = signal , time = time , method = method , ** kwargs ) def __repr__ ( self ): \"\"\" Custom representation to allow interactive mode when 'WaLSAtools' is typed without parentheses. \"\"\" interactive () # Call the interactive (help) function return '' # Return an empty string so that no additional output is shown # Instantiate the object so that it works like a function and runs interactively WaLSAtools = WaLSAtools ()", "title": "WaLSAtools"}, {"location": "python/WaLSAtools/#walsatools", "text": "WaLSAtools is designed for ease of use and accessibility. Its interactive interface guides you through the analysis process, providing clear instructions and helpful information at each step. This section demonstrates how to use WaLSAtools and highlights its key features. Before diving into the interactive demonstration, we recommend familiarizing yourself with the various analysis methods available in WaLSAtools. You can find detailed descriptions of these methods in the Introduction section. Additionally, this page provides several Worked Examples of different analysis techniques applied to synthetic datasets (see the left menu). To learn more about its capabilities and how to apply it to your research, we encourage you to explore the WaLSAtools documentation, the associated Nature Reviews Methods Primers article ( full-text access to a view-only version and its Supplementary Information ), and the provided examples. If you use WaLSAtools in your work, please remember to cite it appropriately (see Citation ). The \"Under the Hood\" section provides details on the individual routines used for wave analysis within the WaLSAtools package, for those interested in exploring the underlying code. However, we strongly encourage all users to perform their analyses by running WaLSAtools directly, as this ensures the correct execution of the analysis workflow and provides a more user-friendly experience. Interactive Demonstration WaLSAtools provides an interactive interface that simplifies wave analysis. To launch the interface, simply import the WaLSAtools package and run the WaLSAtools command in a Python terminal or Jupyter notebook. The interface will guide you through the following steps: Select a category of analysis: Choose from single time series analysis or cross-correlation analysis. Choose the data type: Specify the type of data you are working with (e.g., 1D signal, 3D datacube). Pick a specific analysis method: Select the method most suitable for your data and research question. The interface will then provide information on the selected method, including its calling sequence, input parameters, and expected outputs. Here's an example of the execution of WaLSAtools in a Jupyter notebook: .dropdown-container { margin-left: 30px; margin-top: 20px; font-size: 0.9em; line-height: 2; display: flex; flex-direction: column; gap: 10px; } .dropdown-row { display: flex; align-items: center; gap: 10px; } select { width: 270px !important; height: 33px !important; padding: 5px 10px; font-size: 1em; color: #333; border: 1px solid #ccc; border-radius: 2px; background-color: #f9f9f9; appearance: none; -webkit-appearance: none; -moz-appearance: none; background-image: url('data:image/svg+xml,%3Csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"12\" height=\"12\" viewBox=\"0 0 12 12\"%3E%3Cpath d=\"M1,4 L6,9 L11,4\" fill=\"none\" stroke=\"%23000\" stroke-width=\"2.0\" /%3E%3C/svg%3E'); background-repeat: no-repeat; background-position: right 10px center; background-size: 12px 12px; cursor: pointer; } select:focus { outline: none; border-color: #4caf50; box-shadow: 0 0 5px rgba(76, 175, 80, 0.6); } select:disabled { background-color: #eaeaea; cursor: not-allowed; } .output-container { margin-left: 30px; margin-top: 5px; padding: 0; display: none; /* Hidden by default */ } .parameters-table { border-collapse: collapse; border: 1px solid #222; width: calc(100% - 30px); box-sizing: border-box; table-layout: auto; margin-top: 20px; font-size: 0.9em; } .parameters-table td { border: 1px solid #222; padding: 8px; text-align: left; } .parameters-table th { padding: 8px; text-align: left; } .code-container { font-family: monospace; position: relative; background-color: #f7f7f7; border: 1px solid #ddd; margin-left: 30px; padding: 10px; padding-left: 40px; /* For line numbers */ font-size: 14px; line-height: 1.6; display: inline-block; width: calc(100% - 30px); box-sizing: border-box; } .line-numbers { position: absolute; top: 10px; left: 10px; color: #888; text-align: right; line-height: 1.6; font-size: 14px; } .execute-btn { background-color: #4caf50; color: white; border: none; border-radius: 50%; width: 20px; height: 20px; display: flex; justify-content: center; align-items: center; font-size: 16px; font-weight: bold; cursor: pointer; position: absolute; left: -30px; /* Place the button outside the box */ top: 2px; } .execute-btn:hover { background-color: #45a049; } .index-number { position: absolute; bottom: 0px; left: -30px; color: #888; font-size: 12px; } .python-label { position: absolute; bottom: 2px; right: 6px; font-size: 12px; color: #888; } .walsa-gear-code { border-left: 4px solid rgb(189, 26, 31); background-color: rgba(255, 255, 255, 0.1); padding: 16px; border-radius: 1px; margin-bottom: 16px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); } 1 2 from WaLSAtools import WaLSAtools WaLSAtools [1] Python \u00a9 WaLSA Team ( www.WaLSA.team ) WaLSAtools v1.0.0 - Wave analysis tools Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools If you use WaLSAtools in your research, please cite: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers , 5, 21 Choose a category, data type, and analysis method from the list below, to get hints on the calling sequence and parameters: Category: Select Category Single Time Series Analysis Cross-Correlation Between Two Time Series Data Type: Select Data Type Method: Select Method Sub-method: Select Sub-method FFT Wavelet Lomb-Scargle Welch Please select appropriate options from all dropdown menus. Calling Sequence: Note: Parameters (**kwargs) Parameter Type Description const parameters = { single_series: { fft: { returnValues: 'power, frequency, significance, amplitude', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, nosignificance: { type: 'bool', description: 'If True, skip significance calculation. Default: False.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, amplitude: { type: 'bool', description: ' If True, return the amplitudes of the Fourier transform. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, wavelet: { returnValues: 'power, period, significance, coi, gws_power, gws_significance, rgws_power', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, mother: { type: 'str', description: 'The mother wavelet function to use. Default: \"morlet\".' }, GWS: { type: 'bool', description: 'If True, calculate the Global Wavelet Spectrum. Default: False.' }, RGWS: { type: 'bool', description: 'If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False.' }, dj: { type: 'float', description: 'Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025.' }, s0: { type: 'float', description: 'Initial (smallest) scale of the wavelet. Default: 2 * dt.' }, J: { type: 'int', description: 'Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj.' }, lag1: { type: 'float', description: 'Lag-1 autocorrelation. Default: 0.0.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, lombscargle: { returnValues: 'power, frequency, significance', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, dy: { type: 'array', description: 'Errors or observational uncertainties associated with the time series.' }, fit_mean: { type: 'bool', description: 'If True, include a constant offset as part of the model at each frequency. This improves accuracy, especially for incomplete phase coverage.' }, center_data: { type: 'bool', description: 'If True, pre-center the data by subtracting the weighted mean of the input data. This is especially important if fit_mean=False.' }, nterms: { type: 'int', description: 'Number of terms to use in the Fourier fit. Default: 1.' }, normalization: { type: 'str', description: 'The normalization method for the periodogram. Options: \"standard\", \"model\", \"log\", \"psd\". Default: \"standard\".' }, nosignificance: { type: 'bool', description: 'If True, skip significance calculation. Default: False.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, welch: { returnValues: 'power, frequency, significance', parameters: { signal: { type: 'array', description: 'The 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signal.' }, nperseg: { type: 'int', description: 'Length of each segment for analysis. Default: 256.' }, noverlap: { type: 'int', description: 'Number of points to overlap between segments. Default: 128.' }, window: { type: 'str', description: 'Type of window function used in the Welch method. Default: \"hann\".' }, siglevel: { type: 'float', description: 'Significance level for confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, emd: { returnValues: 'HHT_power, HHT_significance, HHT_frequency, psd_spectra, psd_significance, IMFs, IMF_significance, instantaneous_frequency', parameters: { signal: { type: 'array', description: 'The input signal (1D).' }, time: { type: 'array', description: 'The time array of the signal.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, EEMD: { type: 'bool', description: 'If True, use Ensemble Empirical Mode Decomposition (EEMD) instead of Empirical Mode Decomposition (EMD). Default: False.' }, Welch_psd: { type: 'bool', description: 'If True, calculate Welch PSD spectra instead of FFT PSD spectra (for the psd_spectra and psd_confidence_levels). Default: False.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None.' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, komega: { returnValues: 'power, wavenumber, frequency, filtered_cube, spatial_fft_map, torus_map, spatial_fft_filtered_map, temporal_fft, temporal_filter, temporal_frequencies, spatial_frequencies', parameters: { signal: { type: 'array', description: 'Input datacube, normally in the form of [x, y, t] or [t, x, y]. Note that the input datacube must have identical x and y dimensions. If not, the datacube will be cropped accordingly.' }, time: { type: 'array', description: 'Time array corresponding to the input datacube.' }, pixelsize: { type: 'float', description: 'Spatial sampling of the input datacube. If not given, it is plotted in units of \"pixel\".' }, filtering: { type: 'bool', description: 'If True, filtering is applied, and the filtered datacube (filtered_cube) is returned. Otherwise, None is returned. Default: False.' }, f1: { type: 'float', description: 'Optional lower (temporal) frequency to filter, in Hz.' }, f2: { type: 'float', description: 'Optional upper (temporal) frequency to filter, in Hz.' }, k1: { type: 'float', description: 'Optional lower (spatial) wavenumber to filter, in units of pixelsize^-1 (k = (2 * \u03c0) / wavelength).' }, k2: { type: 'float', description: 'Optional upper (spatial) wavenumber to filter, in units of pixelsize^-1.' }, spatial_torus: { type: 'bool', description: 'If True, makes the annulus used for spatial filtering have a Gaussian-shaped profile, useful for preventing aliasing. Default: True.' }, temporal_torus: { type: 'bool', description: 'If True, makes the temporal filter have a Gaussian-shaped profile, useful for preventing aliasing. Default: True.' }, no_spatial_filt: { type: 'bool', description: 'If True, ensures no spatial filtering is performed on the dataset (i.e., only temporal filtering is applied).' }, no_temporal_filt: { type: 'bool', description: 'If True, ensures no temporal filtering is performed on the dataset (i.e., only spatial filtering is applied).' }, silent: { type: 'bool', description: 'If True, suppresses the k-\u03c9 diagram plot.' }, smooth: { type: 'bool', description: 'If True, power is smoothed. Default: True.' }, mode: { type: 'int', description: 'Output power mode: 0 = log10(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude.' }, processing_maps: { type: 'bool', description: 'If True, the function returns the processing maps (spatial_fft_map, torus_map, spatial_fft_filtered_map, temporal_fft, temporal_filter, temporal_frequencies, spatial_frequencies). Otherwise, they are all returned as None. Default: False.' } } }, pod: { returnValues: 'pod_results', parameters: { signal: { type: 'array', description: '3D data cube with shape (time, x, y) or similar.' }, time: { type: 'array', description: '1D array representing the time points for each time step in the data.' }, num_modes: { type: 'int, optional', description: 'Number of top modes to compute. Default is None (all modes).' }, num_top_frequencies: { type: 'int, optional', description: 'Number of top frequencies to consider. Default is None (all frequencies).' }, top_frequencies: { type: 'list, optional', description: 'List of top frequencies to consider. Default is None.' }, num_cumulative_modes: { type: 'int, optional', description: 'Number of cumulative modes to consider. Default is None (all modes).' }, welch_nperseg: { type: 'int, optional', description: \"Number of samples per segment for Welch's method. Default is 150.\" }, welch_noverlap: { type: 'int, optional', description: \"Number of overlapping samples for Welch's method. Default is 25.\" }, welch_nfft: { type: 'int, optional', description: 'Number of points for the FFT. Default is 2^14.' }, welch_fs: { type: 'int, optional', description: 'Sampling frequency for the data. Default is 2.' }, nperm: { type: 'int, optional', description: 'Number of permutations for significance testing. Default is 1000.' }, siglevel: { type: 'float, optional', description: 'Significance level for the Welch spectrum. Default is 0.95.' }, timestep_to_reconstruct: { type: 'int, optional', description: 'Timestep of the datacube to reconstruct using the top modes. Default is 0.' }, num_modes_reconstruct: { type: 'int, optional', description: 'Number of modes to use for reconstruction. Default is None (all modes).' }, spod: { type: 'bool, optional', description: 'If True, perform Spectral Proper Orthogonal Decomposition (SPOD) analysis. Default is False.' }, spod_filter_size: { type: 'int, optional', description: 'Filter size for SPOD analysis. Default is None.' }, spod_num_modes: { type: 'int, optional', description: 'Number of SPOD modes to compute. Default is None.' }, print_results: { type: 'bool, optional', description: 'If True, print a summary of results. Default is True.' } } }, dominantfreq: { returnValues: 'power, frequency, significance', parameters: { signal: { type: 'array', description: 'Input signal array (1D or 2D).' }, time: { type: 'array', description: 'Time array corresponding to the signal.' }, method: { type: 'string', description: 'Analysis method (e.g., fft, wavelet, etc.).' }, kwargs: { type: 'object', description: 'Additional optional parameters for customization.' } } } }, cross_correlation: { wavelet: { returnValues: 'cross_power, cross_period, cross_sig, cross_coi, coherence, coh_period, coh_sig, coh_coi, phase_angle', parameters: { data1: { type: 'array', description: 'The first 1D time series signal.' }, data2: { type: 'array', description: 'The second 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signals.' }, siglevel: { type: 'float', description: 'Significance level for the confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, mother: { type: 'str', description: 'The mother wavelet function to use. Default: \"morlet\".' }, GWS: { type: 'bool', description: 'If True, calculate the Global Wavelet Spectrum. Default: False.' }, RGWS: { type: 'bool', description: 'If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False.' }, dj: { type: 'float', description: 'Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025.' }, s0: { type: 'float', description: 'Initial (smallest) scale of the wavelet. Default: 2 * dt.' }, J: { type: 'int', description: 'Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj.' }, lag1: { type: 'float', description: 'Lag-1 autocorrelation. Default: 0.0.' }, apod: { type: 'float', description: 'Extent of apodization edges (of a Tukey window). Default: 0.1.' }, pxdetrend: { type: 'int', description: 'Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2.' }, polyfit: { type: 'int', description: 'Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None.' }, meantemporal: { type: 'bool', description: 'If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False.' }, meandetrend: { type: 'bool', description: 'If True, subtract the linear trend with time for the image means (spatial detrending). Default: False.' }, recon: { type: 'bool', description: 'If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False.' }, resample_original: { type: 'bool', description: 'If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False.' }, nodetrendapod: { type: 'bool', description: 'If True, neither detrending nor apodization is performed. Default: False.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, welch: { returnValues: 'frequency, cospectrum, phase_angle, power_data1, power_data2, frequency_coherence, coherence', parameters: { data1: { type: 'array', description: 'The first 1D time series signal.' }, data2: { type: 'array', description: 'The second 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signals.' }, nperseg: { type: 'int', description: 'Length of each segment for analysis. Default: 256.' }, noverlap: { type: 'int', description: 'Number of points to overlap between segments. Default: 128.' }, window: { type: 'str', description: 'Type of window function used in the Welch method. Default: \"hann\".' }, siglevel: { type: 'float', description: 'Significance level for confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } }, fft: { returnValues: 'frequency, cospectrum, phase_angle, power_data1, power_data2, frequency_coherence, coherence', warning: 'Selecting FFT for cross-correlation automatically runs Welch instead, to improve noise handling by averaging over segments. Consider adjusting \"nperseg\" to tune resolution.', parameters: { data1: { type: 'array', description: 'The first 1D time series signal.' }, data2: { type: 'array', description: 'The second 1D time series signal.' }, time: { type: 'array', description: 'The time array corresponding to the signals.' }, nperseg: { type: 'int', description: 'Length of each segment for analysis. Default: 256.' }, noverlap: { type: 'int', description: 'Number of points to overlap between segments. Default: 128.' }, window: { type: 'str', description: 'Type of window function used in the Welch method. Default: \"hann\".' }, siglevel: { type: 'float', description: 'Significance level for confidence intervals. Default: 0.95.' }, nperm: { type: 'int', description: 'Number of permutations for significance testing. Default: 1000.' }, silent: { type: 'bool', description: 'If True, suppress print statements. Default: False.' } } } } }; const categoryDropdown = document.getElementById('category'); const datatypeDropdown = document.getElementById('datatype'); const analysisMethodDropdown = document.getElementById('analysisMethod'); const subMethodDropdown = document.getElementById('subMethod'); const subMethodLabel = document.getElementById('subMethodLabel'); const outputContainer = document.getElementById('outputContainer'); const callingSequence = document.getElementById('callingSequence'); const parameterTableBody = document.getElementById('parameterTableBody'); function resetDropdown(dropdown, placeholder = \"Select ...\") { dropdown.innerHTML = `<option value=\"\">${placeholder}</option>`; dropdown.disabled = true; } function hideOutput() { outputContainer.style.display = 'none'; } function clearOutput() { callingSequence.innerHTML = ''; parameterTableBody.innerHTML = ''; hideOutput(); } document.addEventListener('DOMContentLoaded', () => { updateOutput(); // Attach event listeners categoryDropdown.addEventListener('change', () => { const category = categoryDropdown.value; resetDropdown(datatypeDropdown, \"Select Data Type\"); resetDropdown(analysisMethodDropdown, \"Select Method\"); resetDropdown(subMethodDropdown, \"Select Sub-method\"); subMethodDropdown.style.display = 'none'; subMethodLabel.style.display = 'none'; clearOutput(); if (category) { datatypeDropdown.disabled = false; if (category === 'a') { datatypeDropdown.innerHTML += ` <option value=\"1\">1D Signal</option> <option value=\"2\">3D Datacube</option>`; } else if (category === 'b') { datatypeDropdown.innerHTML += `<option value=\"1\">1D Signal</option>`; } } updateOutput(); }); datatypeDropdown.addEventListener('change', () => { const category = categoryDropdown.value; const datatype = datatypeDropdown.value; resetDropdown(analysisMethodDropdown, \"Select Method\"); resetDropdown(subMethodDropdown, \"Select Sub-method\"); subMethodDropdown.style.display = 'none'; subMethodLabel.style.display = 'none'; clearOutput(); if (datatype) { analysisMethodDropdown.disabled = false; if (category === 'a' && datatype === '1') { analysisMethodDropdown.innerHTML += ` <option value=\"fft\">FFT</option> <option value=\"wavelet\">Wavelet</option> <option value=\"lombscargle\">Lomb-Scargle</option> <option value=\"welch\">Welch</option> <option value=\"emd\">EMD</option>`; } else if (category === 'a' && datatype === '2') { analysisMethodDropdown.innerHTML += ` <option value=\"komega\">k-omega</option> <option value=\"pod\">POD</option> <option value=\"dominantfreq\">Dominant Freq / Mean Power Spectrum</option>`; } else if (category === 'b') { analysisMethodDropdown.innerHTML += ` <option value=\"fft\">FFT</option> <option value=\"wavelet\">Wavelet</option> <option value=\"welch\">Welch</option>`; } } updateOutput(); }); analysisMethodDropdown.addEventListener('change', () => { const category = categoryDropdown.value; const datatype = datatypeDropdown.value; const analysisMethod = analysisMethodDropdown.value; resetDropdown(subMethodDropdown, \"Select Sub-method\"); subMethodDropdown.style.display = 'none'; subMethodLabel.style.display = 'none'; subMethodDropdown.disabled = true; clearOutput(); if ( category === 'a' && datatype === '2' && analysisMethod === 'dominantfreq' ) { subMethodDropdown.style.display = 'inline-block'; subMethodLabel.style.display = 'inline-block'; subMethodDropdown.disabled = false; subMethodDropdown.innerHTML = ` <option value=\"\">Select Sub-method</option> <option value=\"fft\">FFT</option> <option value=\"wavelet\">Wavelet</option> <option value=\"lombscargle\">Lomb-Scargle</option> <option value=\"welch\">Welch</option>`; } updateOutput(); }); subMethodDropdown.addEventListener('change', updateOutput); updateOutput(); }); // Update Output Container function updateOutput() { const category = categoryDropdown.value; const datatype = datatypeDropdown.value; const analysisMethod = analysisMethodDropdown.value; const subMethod = subMethodDropdown.value; const message = document.getElementById('dropdownMessage'); // Hide output and show a message if selections are incomplete if (!category || !datatype || !analysisMethod || (subMethodDropdown.style.display === 'inline-block' && !subMethod)) { message.style.display = 'block'; hideOutput(); return; } // Hide the message when all selections are made message.style.display = 'none'; // Retrieve returnValues based on category and analysisMethod let returnValues = ''; if (category === 'a') { returnValues = parameters.single_series[analysisMethod]?.returnValues || 'No return values available'; } else if (category === 'b') { returnValues = parameters.cross_correlation[analysisMethod]?.returnValues || 'No return values available'; } // Construct the command string let command1 = ''; if (category === 'a' && datatype === '1') { command1 = `${returnValues} = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method='${analysisMethod}', **kwargs)`; } else if (category === 'b') { command1 = `${returnValues} = WaLSAtools(data1=INPUT_DATA1, data2=INPUT_DATA2, time=TIME_ARRAY, method='${analysisMethod}', **kwargs)`; } else if (category === 'a' && datatype === '2') { if (analysisMethod === 'dominantfreq') { retValues = 'dominant_frequency, mean_power, frequency, power_map' command1 = `${retValues} = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, averagedpower=True, dominantfreq=True, method='${subMethod}', **kwargs)`; } else { if (analysisMethod === 'komega') { analysisMethodout = 'k-omega'; } else { analysisMethodout = analysisMethod; } command1 = `${returnValues} = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method='${analysisMethodout}', **kwargs)`; } } const command = ` <div style=\"display: flex; align-items: baseline;\"> <span style=\"color: #222; min-width: 4ch; margin: 0 !important; line-height: 1.5;\">>>> </span> <pre style=\" white-space: pre-wrap; word-wrap: break-word; color: #01016D; margin: 0 !important; line-height: 1.5; \">${command1}</pre> </div> `; // Update calling sequence and parameter table callingSequence.innerHTML = command; const warningBox = document.getElementById('warningNote'); const warningMessage = document.getElementById('warningMessage'); if (category === 'b' && analysisMethod === 'fft') { warningMessage.innerText = parameters.cross_correlation.fft.warning; warningBox.style.display = 'block'; } else { warningBox.style.display = 'none'; warningMessage.innerText = ''; } if (analysisMethod === 'dominantfreq') { updateParameterTable(subMethod); } else { updateParameterTable(analysisMethod); } outputContainer.style.display = 'block'; } function updateParameterTable(datatype) { parameterTableBody.innerHTML = ''; const paramData = parameters.single_series[datatype]?.parameters || parameters.cross_correlation[datatype]?.parameters; if (!paramData) { parameterTableBody.innerHTML = ` <tr> <td colspan=\"3\" style=\"text-align: center;\">No parameters available.</td> </tr>`; return; } Object.entries(paramData).forEach(([key, value]) => { parameterTableBody.innerHTML += ` <tr> <td>${key}</td> <td>${value.type}</td> <td>${value.description}</td> </tr>`; }); } document.addEventListener('DOMContentLoaded', () => { updateOutput(); }); Source code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from .analysis_modules.WaLSA_speclizer import WaLSA_speclizer from .analysis_modules.WaLSA_k_omega import WaLSA_k_omega from .analysis_modules.WaLSA_pod import WaLSA_pod from .analysis_modules.WaLSA_cross_spectra import WaLSA_cross_spectra from .analysis_modules.WaLSA_interactive import interactive class WaLSAtools : \"\"\" Main class to perform spectral analysis using different methods. It runs interactively if called without (or empty and acts as a function if called with parentheses and parameters. \"\"\" def __call__ ( self , signal = None , time = None , method = None , ** kwargs ): \"\"\" Main function to perform spectral analysis using different methods. Parameters: signal (array): The input signal (1D, or 3D). time (array): The time array of the signal. method (str): The method to use for spectral analysis ('fft', 'lombscargle', 'k-omega', etc.) **kwargs: Additional parameters for data preparation and analysis methods. Returns: Results of the selected analysis method. \"\"\" if signal is None and time is None and method is None : interactive () # Run interactive (help) mode if no inputs are provided return None method_map = { 'fft' : WaLSA_speclizer , 'lombscargle' : WaLSA_speclizer , 'wavelet' : WaLSA_speclizer , 'welch' : WaLSA_speclizer , 'emd' : WaLSA_speclizer , 'k-omega' : WaLSA_k_omega , 'pod' : WaLSA_pod } if method not in method_map : raise ValueError ( f \"Unknown method ' { method } '. Please choose from { list ( method_map . keys ()) } .\" ) func = method_map [ method ] if method in [ 'fft' , 'lombscargle' , 'wavelet' , 'welch' , 'emd' ] and 'data1' in kwargs and 'data2' in kwargs : return WaLSA_cross_spectra ( signal = np . ones ( 10 ), time = time , method = method , ** kwargs ) else : return func ( signal = signal , time = time , method = method , ** kwargs ) def __repr__ ( self ): \"\"\" Custom representation to allow interactive mode when 'WaLSAtools' is typed without parentheses. \"\"\" interactive () # Call the interactive (help) function return '' # Return an empty string so that no additional output is shown # Instantiate the object so that it works like a function and runs interactively WaLSAtools = WaLSAtools ()", "title": "WaLSAtools"}, {"location": "python/beginner-friendly-guide/", "text": "Getting Started with WaLSAtools \u00b6 A Beginner-Friendly Guide from Setting Up Python to using WaLSAtools \u00b6 This guide will walk you through the full setup process for running WaLSAtools , even if you are completely new to Python. We recommend using a lightweight and flexible method using pyenv , which lets you easily install and manage different versions of Python \u2014 without needing admin access. Note You do not need to have Python pre-installed. However, even if Python is already installed on your system, we still recommend the steps below to ensure compatibility and avoid conflicts. Step 1: Install Python (via pyenv ) \u00b6 Operating Systems macOS Linux (Ubuntu/Debian) Windows Install pyenv on macOS using Homebrew : brew update brew install pyenv pyenv-virtualenv openssl readline sqlite3 xz zlib ncurses tcl-tk Update your shell configuration: bash (default) zsh (macOS default since Catalina) echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bashrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bashrc echo 'eval \"$(pyenv init --path)\"' >> ~/.bashrc echo 'eval \"$(pyenv init -)\"' >> ~/.bashrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.bashrc source ~/.bashrc echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.zshrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.zshrc echo 'eval \"$(pyenv init --path)\"' >> ~/.zshrc echo 'eval \"$(pyenv init -)\"' >> ~/.zshrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.zshrc source ~/.zshrc Install a Python verion: pyenv install 3.12.8 install system dependencies: sudo apt update && sudo apt install -y make build-essential libssl-dev zlib1g-dev \\ libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncursesw5-dev \\ xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev Install pyenv using the recommended installer: curl https://pyenv.run | bash Follow the post-installation instructions printed in the terminal to activate pyenv . Update your shell configuration: bash zsh echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bashrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bashrc echo 'eval \"$(pyenv init --path)\"' >> ~/.bashrc echo 'eval \"$(pyenv init -)\"' >> ~/.bashrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.bashrc source ~/.bashrc echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.zshrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.zshrc echo 'eval \"$(pyenv init --path)\"' >> ~/.zshrc echo 'eval \"$(pyenv init -)\"' >> ~/.zshrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.zshrc source ~/.zshrc Install a Python verion: pyenv install 3.12.8 We recommend using the official pyenv port for Windows: Install pyenv-win Ensure pyenv , pyenv-win and Python executables are in your PATH Install a Python verion: pyenv install 3.12.8 Why Python 3.12.8? While other Python versions (above 3.8) may also work, Python 3.12.8 has been thoroughly tested with WaLSAtools and is our recommended version. You can install multiple Python versions if you wish and create a separate virtual environment for each. Step 2: Create a Virtual Environment \u00b6 Create a clean environment for your installed Python version (e.g., 3.12.8; hence walsa_env_3_12_8 ) for WaLSAtools: pyenv virtualenv 3 .12.8 walsa_env_3_12_8 pyenv activate walsa_env_3_12_8 If pyenv is not initialized properly Double-check your .bashrc (or .bash_profile) / .zshrc entries and reload ( source ) them. Step 3: Install WaLSAtools \u00b6 First, upgrade pip : pip install --upgrade pip Then install WaLSAtools from PyPI: pip install WaLSAtools What if pip is not installed? If you get an error like command not found: pip , you can install it with: python -m ensurepip --upgrade Step 4: Verify the Installation \u00b6 Start Python inside your terminal (within the virtual enviroment): python This will open the Python interactive prompt (you will see something like >>>). Then, at the prompt, type: from WaLSAtools import WaLSAtools WaLSAtools If installed correctly, WaLSAtools\u2019 interactive welcome menu will appear \ud83c\udf89 Alternatively, you can verify the installation inside a Jupyter notebook (preferred; see below). Jupyter notebook is highly recommended Although WaLSAtools runs from the terminal, we recommend using Jupyter notebooks . All our tutorials and worked examples are written in notebook format for easier use. Step 5: Clone the GitHub repository \u00b6 Although WaLSAtools has already been installed via pip, we strongly recommend also cloning (downloading) the WaLSAtools GitHub repository. By cloning the repository, you will gain access to: The complete source codes, Worked examples demonstrating practical analyses, The full set of documentation files used to build this website. Having the local repository allows you to explore the materials at your own pace, customize them if needed, and even contribute improvements by submitting a pull request (see the Contribution page for details). To clone the repository, simply run: git clone https://github.com/WaLSAteam/WaLSAtools.git This will create a local folder named WaLSAtools containing everything you need. Step 6: Install and Use Jupyter Notebooks in VS Code (Highly Recommended) \u00b6 We recommend using Visual Studio Code (VS Code) to work with WaLSAtools . It provides an easy, modern, and fully integrated environment to edit and run Python scripts and Jupyter notebooks \u2014 all inside one application! VS Code supports interactive notebooks (.ipynb), standard Python scripts (.py), and includes many helpful tools (such as syntax highlighting, variable explorers, and inline output). Step-by-Step Guide \u00b6 Download and install VS Code : \ud83d\udd17 https://code.visualstudio.com Install the Python Extension : Open VS Code. Click the Extensions icon (left sidebar or press Ctrl+Shift+X / Cmd+Shift+X ). Search for Python . Install the official Python extension by Microsoft . (It includes full Jupyter notebook support.) Open your Project Folder Launch VS Code. Open the folder where your notebooks or scripts are located (or to be located). (Example: If you cloned WaLSAtools GitHub repo, open the WaLSAtools/codes/python/ folder.) Create or open a notebook (.ipynb) : You can open any example notebook provided in the WaLSAtools GitHub repository. Or create a new one via: File \u2192 New File \u2192 Jupyter Notebook (name it something like example.ipynb) Select your Python environment (kernel) : When you open a notebook for the first time, VS Code may ask you to select a kernel. \ud83d\udca1 If it doesn\u2019t ask, click \u201cSelect Kernel\u201d or the Python version shown at the top right of the notebook interface to manually select it. Alternatively, you can press Ctrl+Shift+P ( Cmd+Shift+P on Mac), search for \u201cPython: Select Kernel\u201d, and manually pick it. Choose the Python interpreter corresponding to your WaLSAtools virtual environment (e.g., walsa_env_3_12_8). Test WaLSAtools Inside the Notebook : Inside a notebook's code cell, enter the following: from WaLSAtools import WaLSAtools WaLSAtools Click the Execute Cell button (on the left side of the code cell), or Click Run All at the top to execute the whole notebook. If installed correctly, you should see the interactive welcome menu for WaLSAtools \ud83c\udf89 You are All Set \u00b6 You have now installed Python, set up a clean environment, and verified WaLSAtools. Explore the Analysis Tools page and the worked examples. Still stuck? Check the Troubleshooting page or post your question in our GitHub discussion .", "title": "Beginner's Guide"}, {"location": "python/beginner-friendly-guide/#getting-started-with-walsatools", "text": "", "title": "Getting Started with WaLSAtools"}, {"location": "python/beginner-friendly-guide/#a-beginner-friendly-guide-from-setting-up-python-to-using-walsatools", "text": "This guide will walk you through the full setup process for running WaLSAtools , even if you are completely new to Python. We recommend using a lightweight and flexible method using pyenv , which lets you easily install and manage different versions of Python \u2014 without needing admin access. Note You do not need to have Python pre-installed. However, even if Python is already installed on your system, we still recommend the steps below to ensure compatibility and avoid conflicts.", "title": "A Beginner-Friendly Guide from Setting Up Python to using WaLSAtools"}, {"location": "python/beginner-friendly-guide/#step-1-install-python-via-pyenv", "text": "Operating Systems macOS Linux (Ubuntu/Debian) Windows Install pyenv on macOS using Homebrew : brew update brew install pyenv pyenv-virtualenv openssl readline sqlite3 xz zlib ncurses tcl-tk Update your shell configuration: bash (default) zsh (macOS default since Catalina) echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bashrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bashrc echo 'eval \"$(pyenv init --path)\"' >> ~/.bashrc echo 'eval \"$(pyenv init -)\"' >> ~/.bashrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.bashrc source ~/.bashrc echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.zshrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.zshrc echo 'eval \"$(pyenv init --path)\"' >> ~/.zshrc echo 'eval \"$(pyenv init -)\"' >> ~/.zshrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.zshrc source ~/.zshrc Install a Python verion: pyenv install 3.12.8 install system dependencies: sudo apt update && sudo apt install -y make build-essential libssl-dev zlib1g-dev \\ libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncursesw5-dev \\ xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev Install pyenv using the recommended installer: curl https://pyenv.run | bash Follow the post-installation instructions printed in the terminal to activate pyenv . Update your shell configuration: bash zsh echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bashrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bashrc echo 'eval \"$(pyenv init --path)\"' >> ~/.bashrc echo 'eval \"$(pyenv init -)\"' >> ~/.bashrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.bashrc source ~/.bashrc echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.zshrc echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.zshrc echo 'eval \"$(pyenv init --path)\"' >> ~/.zshrc echo 'eval \"$(pyenv init -)\"' >> ~/.zshrc echo 'eval \"$(pyenv virtualenv-init -)\"' >> ~/.zshrc source ~/.zshrc Install a Python verion: pyenv install 3.12.8 We recommend using the official pyenv port for Windows: Install pyenv-win Ensure pyenv , pyenv-win and Python executables are in your PATH Install a Python verion: pyenv install 3.12.8 Why Python 3.12.8? While other Python versions (above 3.8) may also work, Python 3.12.8 has been thoroughly tested with WaLSAtools and is our recommended version. You can install multiple Python versions if you wish and create a separate virtual environment for each.", "title": "Step 1: Install Python (via pyenv)"}, {"location": "python/beginner-friendly-guide/#step-2-create-a-virtual-environment", "text": "Create a clean environment for your installed Python version (e.g., 3.12.8; hence walsa_env_3_12_8 ) for WaLSAtools: pyenv virtualenv 3 .12.8 walsa_env_3_12_8 pyenv activate walsa_env_3_12_8 If pyenv is not initialized properly Double-check your .bashrc (or .bash_profile) / .zshrc entries and reload ( source ) them.", "title": "Step 2: Create a Virtual Environment"}, {"location": "python/beginner-friendly-guide/#step-3-install-walsatools", "text": "First, upgrade pip : pip install --upgrade pip Then install WaLSAtools from PyPI: pip install WaLSAtools What if pip is not installed? If you get an error like command not found: pip , you can install it with: python -m ensurepip --upgrade", "title": "Step 3: Install WaLSAtools"}, {"location": "python/beginner-friendly-guide/#step-4-verify-the-installation", "text": "Start Python inside your terminal (within the virtual enviroment): python This will open the Python interactive prompt (you will see something like >>>). Then, at the prompt, type: from WaLSAtools import WaLSAtools WaLSAtools If installed correctly, WaLSAtools\u2019 interactive welcome menu will appear \ud83c\udf89 Alternatively, you can verify the installation inside a Jupyter notebook (preferred; see below). Jupyter notebook is highly recommended Although WaLSAtools runs from the terminal, we recommend using Jupyter notebooks . All our tutorials and worked examples are written in notebook format for easier use.", "title": "Step 4: Verify the Installation"}, {"location": "python/beginner-friendly-guide/#step-5-clone-the-github-repository", "text": "Although WaLSAtools has already been installed via pip, we strongly recommend also cloning (downloading) the WaLSAtools GitHub repository. By cloning the repository, you will gain access to: The complete source codes, Worked examples demonstrating practical analyses, The full set of documentation files used to build this website. Having the local repository allows you to explore the materials at your own pace, customize them if needed, and even contribute improvements by submitting a pull request (see the Contribution page for details). To clone the repository, simply run: git clone https://github.com/WaLSAteam/WaLSAtools.git This will create a local folder named WaLSAtools containing everything you need.", "title": "Step 5: Clone the GitHub repository"}, {"location": "python/beginner-friendly-guide/#step-6-install-and-use-jupyter-notebooks-in-vs-code-highly-recommended", "text": "We recommend using Visual Studio Code (VS Code) to work with WaLSAtools . It provides an easy, modern, and fully integrated environment to edit and run Python scripts and Jupyter notebooks \u2014 all inside one application! VS Code supports interactive notebooks (.ipynb), standard Python scripts (.py), and includes many helpful tools (such as syntax highlighting, variable explorers, and inline output).", "title": "Step 6: Install and Use Jupyter Notebooks in VS Code (Highly Recommended)"}, {"location": "python/beginner-friendly-guide/#step-by-step-guide", "text": "Download and install VS Code : \ud83d\udd17 https://code.visualstudio.com Install the Python Extension : Open VS Code. Click the Extensions icon (left sidebar or press Ctrl+Shift+X / Cmd+Shift+X ). Search for Python . Install the official Python extension by Microsoft . (It includes full Jupyter notebook support.) Open your Project Folder Launch VS Code. Open the folder where your notebooks or scripts are located (or to be located). (Example: If you cloned WaLSAtools GitHub repo, open the WaLSAtools/codes/python/ folder.) Create or open a notebook (.ipynb) : You can open any example notebook provided in the WaLSAtools GitHub repository. Or create a new one via: File \u2192 New File \u2192 Jupyter Notebook (name it something like example.ipynb) Select your Python environment (kernel) : When you open a notebook for the first time, VS Code may ask you to select a kernel. \ud83d\udca1 If it doesn\u2019t ask, click \u201cSelect Kernel\u201d or the Python version shown at the top right of the notebook interface to manually select it. Alternatively, you can press Ctrl+Shift+P ( Cmd+Shift+P on Mac), search for \u201cPython: Select Kernel\u201d, and manually pick it. Choose the Python interpreter corresponding to your WaLSAtools virtual environment (e.g., walsa_env_3_12_8). Test WaLSAtools Inside the Notebook : Inside a notebook's code cell, enter the following: from WaLSAtools import WaLSAtools WaLSAtools Click the Execute Cell button (on the left side of the code cell), or Click Run All at the top to execute the whole notebook. If installed correctly, you should see the interactive welcome menu for WaLSAtools \ud83c\udf89", "title": "Step-by-Step Guide"}, {"location": "python/beginner-friendly-guide/#you-are-all-set", "text": "You have now installed Python, set up a clean environment, and verified WaLSAtools. Explore the Analysis Tools page and the worked examples. Still stuck? Check the Troubleshooting page or post your question in our GitHub discussion .", "title": "You are All Set"}, {"location": "python/cross-correlation-example/", "text": "Worked Example - NRMP: Cross-Correlation Analysis \u00b6 This example demonstrates the application of cross-correlation analysis to two nearly identical synthetic 1D signals. The signals share the same base frequencies and amplitudes but have slight phase differences introduced between them. This simulates a scenario where similar wave signals are observed at different locations or with a time delay. By analysing the cross-correlation between these signals, we can identify common frequencies, quantify the strength of their relationship, and determine the phase or time lag between their oscillations. This provides valuable insights into the potential connections or shared drivers influencing the signals. Analysis and Figure The figure below presents a comparative analysis of cross-correlation techniques applied to the two synthetic 1D signals. Methods used: Fast Fourier Transform (FFT) Wavelet Transform (with Morlet wavelet) WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 6 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Cross-correlation analysis of two synthetic 1D time series using FFT and wavelet techniques. (a) and (b) display the first and second time series, respectively. \u00a9 compares their FFT power spectra (blue: time series 1, red: time series 2). (d)-(f) present the FFT-derived co-spectrum, coherence spectrum, and phase differences. (g) and (h) show individual wavelet power spectra (Morlet mother wavelet). (i) and (j) depict the wavelet co-spectrum and coherence map. Cross-hatched areas in wavelet panels mark the cone of influence (COI); black contours indicate the 95% confidence level. Power is represented in log-scale in panels (g)-(i) , while colors in panel (j) map coherence levels. Phase differences in (i) and (j) are visualized as arrows (right: in-phase, up: 90-degree lead for time series 1). Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , walsa_detrend_apod #-------------------------------------------------------------------------- # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_1D.fits' ) signal_1d_data1 = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Assuming time is in the second HDU (Extension HDU 1) hdul . close () hdul = fits . open ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) signal_1d_data2 = hdul [ 0 ] . data # 1D synthetic signal data hdul . close () tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Welch Cross Spectrum using WaLSAtools frequencies_welch , cospectrum_welch , phase_angle_welch , power1_welch , power2_welch , freq_coherence_welch , coherence_welch = WaLSAtools ( data1 = signal_1d_data2 , data2 = signal_1d_data1 , time = time , method = 'welch' , nperseg = 500 ) # Wavelet Analysis using WaLSAtools - data1 wavelet_power_morlet1 , wavelet_periods_morlet1 , wavelet_significance_morlet1 , coi_morlet1 = WaLSAtools ( signal = signal_1d_data1 , time = time , method = 'wavelet' , siglevel = 0.95 , mother = 'morlet' , GWS = False , RGWS = False ) # Wavelet Analysis using WaLSAtools - data2 wavelet_power_morlet2 , wavelet_periods_morlet2 , wavelet_significance_morlet2 , coi_morlet2 = WaLSAtools ( signal = signal_1d_data2 , time = time , method = 'wavelet' , siglevel = 0.95 , mother = 'morlet' , GWS = False , RGWS = False ) # Wavelet Cross Spectrum using WaLSAtools cross_power , cross_periods , cross_sig , cross_coi , coherence , coh_periods , coh_sig , coh_coi , phase_angle = WaLSAtools ( data1 = signal_1d_data2 , data2 = signal_1d_data1 , time = time , method = 'wavelet' , nperm = 1000 , siglevel = 0.95 ) # Detrend and Apodize the timeeries for plotting (note that these are done within the analysis routines above) signal_1d_data1 = walsa_detrend_apod ( signal_1d_data1 , apod = 0.1 , pxdetrend = 2 , silent = True ) signal_1d_data2 = walsa_detrend_apod ( signal_1d_data2 , apod = 0.1 , pxdetrend = 2 , silent = True ) Welch processed. Welch processed. Detrending and apodization complete. Wavelet (morlet) processed. Detrending and apodization complete. Wavelet (morlet) processed. Wavelet cross-power spectrum calculated. Calculating wavelet cross-power significance: Progress: 100.00%Wavelet coherence calculated. Calculating wavelet coherence significance: Progress: 100.00% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator from matplotlib.colors import ListedColormap from matplotlib.ticker import AutoMinorLocator , FormatStrFormatter from mpl_toolkits.axes_grid1 import make_axes_locatable from mpl_toolkits.axes_grid1.inset_locator import inset_axes from WaLSAtools import WaLSA_save_pdf # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'Arial' , # Set Helvetica as the default sans-serif font 'font.size' : 13.5 , # Global font size 'axes.titlesize' : 13.5 , # Title font size 'axes.labelsize' : 13.5 , # Axis label font size 'xtick.labelsize' : 13.5 , # X-axis tick label font size 'ytick.labelsize' : 13.5 , # Y-axis tick label font size 'legend.fontsize' : 13.5 , # Legend font size 'figure.titlesize' : 13.5 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 500 , # Make all fonts bold 'axes.titleweight' : 500 , # Make title font bold 'axes.labelweight' : 500 # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.0 ) plt . rc ( 'lines' , linewidth = 0.8 ) pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] # Mark pre-defined frequencies # Set up the figure layout fig = plt . figure ( figsize = ( 9.5 , 10.79 )) #-------------------------------------------------------------------------- # FFT/Welch plots_width = 0.24 plots_height = 0.10 positions = [[ 0.07 , 0.872 , plots_width , plots_height ], [ 0.403 , 0.872 , plots_width , plots_height ], [ 0.750 , 0.872 , plots_width , plots_height ], [ 0.07 , 0.682 , plots_width , plots_height ], [ 0.403 , 0.682 , plots_width , plots_height ], [ 0.752 , 0.682 , plots_width , plots_height ] ] # [left, bottom, width, height] # First 1D signal plot ax1 = fig . add_axes ( positions [ 0 ]) ax1 . plot ( time , signal_1d_data1 * 10 , color = 'dodgerblue' ) ax1 . set_xlabel ( 'Time (s)' , labelpad = 5 ) ax1 . set_ylabel ( 'DN (arb. unit)' , labelpad = 8 ) ax1 . set_title ( '(a) 1st Time Series' , pad = 10 ) ax1 . set_ylim ( - 35 , 79 ) ax1 . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes ax1 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax1 . set_xticks ( np . arange ( 0 , 10 , 2 )) ax1 . set_yticks ( np . arange ( 0 , 80 , 40 )) # Custom tick sizes and thickness ax1 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax1 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax1 . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax1 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Second 1D signal plot ax2 = fig . add_axes ( positions [ 1 ]) ax2 . plot ( time , signal_1d_data2 * 10 , color = 'red' ) ax2 . set_xlabel ( 'Time (s)' , labelpad = 5 ) ax2 . set_ylabel ( 'DN (arb. unit)' , labelpad = 8 ) ax2 . set_title ( '(b) 2nd Time Series' , pad = 10 ) ax2 . set_ylim ( - 35 , 79 ) ax2 . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes ax2 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax2 . set_xticks ( np . arange ( 0 , 10 , 2 )) ax2 . set_yticks ( np . arange ( 0 , 80 , 40 )) # Custom tick sizes and thickness ax2 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax2 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax2 . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax2 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # FFT Power Spectra ax3 = fig . add_axes ( positions [ 2 ]) ax3 . plot ( frequencies_welch , 85 * power1_welch / np . max ( power1_welch ), color = 'dodgerblue' ) ax3 . plot ( frequencies_welch , 85 * power2_welch / np . max ( power2_welch ), linestyle = '-.' , color = 'red' , linewidth = 0.5 ) ax3 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax3 . set_ylabel ( 'Power (%)' , labelpad = 8 ) ax3 . set_title ( '(c) Power spectra' , pad = 10 ) ax3 . set_xlim ([ 0 , 36 ]) ax3 . set_ylim ( 0 , 40 ) # Set tick marks outside for all four axes ax3 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax3 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax3 . set_yticks ( np . arange ( 0 , 41 , 10 )) # Custom tick sizes and thickness ax3 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax3 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax3 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax3 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # FFT Cross Spectrum ax4 = fig . add_axes ( positions [ 3 ]) for freqin in pre_defined_freq : ax4 . axvline ( x = freqin , color = 'orange' , linewidth = 0.5 ) ax4 . plot ( frequencies_welch , 92 * cospectrum_welch / np . max ( cospectrum_welch ), color = 'DarkGreen' ) ax4 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax4 . set_ylabel ( 'Power (%)' , labelpad = 8 ) ax4 . set_title ( '(d) Co-spectrum' , pad = 10 ) ax4 . set_xlim ([ 0 , 36 ]) ax4 . set_ylim ( 0 , 40 ) # Set tick marks outside for all four axes ax4 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax4 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax4 . set_yticks ( np . arange ( 0 , 41 , 10 )) # Custom tick sizes and thickness ax4 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax4 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax4 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax4 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # FFT Coherence ax5 = fig . add_axes ( positions [ 4 ]) for freqin in pre_defined_freq : ax5 . axvline ( x = freqin , color = 'orange' , linewidth = 0.5 ) ax5 . plot ( freq_coherence_welch , coherence_welch , color = 'DarkGreen' ) ax5 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax5 . set_ylabel ( 'Coherence' , labelpad = 8 ) ax5 . set_title ( '(e) Coherence' , pad = 10 ) ax5 . set_xlim ([ 0 , 36 ]) ax5 . set_ylim ( 0 , 1.1 ) # Set tick marks outside for all four axes ax5 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax5 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax5 . set_yticks ( np . arange ( 0 , 1.1 , 0.2 )) ax5 . set_yticklabels ([ '0.0' , ' ' , '0.4' , ' ' , '0.8' , ' ' ]) # Custom tick sizes and thickness ax5 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax5 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax5 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax5 . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a horizontal line at coherence = 0.8 (as a threshold) ax5 . axhline ( y = 0.8 , color = 'darkred' , linewidth = 1.1 ) # FFT Phase Differences ax6 = fig . add_axes ( positions [ 5 ]) for freqin in pre_defined_freq : ax6 . axvline ( x = freqin , color = 'orange' , linewidth = 0.5 ) ax6 . plot ( frequencies_welch , phase_angle_welch , color = 'DarkGreen' ) ax6 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax6 . set_ylabel ( 'Phase (deg)' , labelpad = 4 ) ax6 . set_title ( '(f) Phase Difference' , pad = 10 ) ax6 . set_xlim ([ 0 , 36 ]) ax6 . set_ylim ( - 200 , 200 ) # Set tick marks outside for all four axes ax6 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax6 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax6 . set_yticks ( np . arange ( - 200 , 201 , 100 )) # Custom tick sizes and thickness ax6 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax6 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax6 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax6 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) #-------------------------------------------------------------------------- # Wavelet plots_width = 0.34 plots_height = 0.17 wpositions = [[ 0.07 , 0.358 , plots_width , plots_height ], [ 0.598 , 0.358 , plots_width , plots_height ], [ 0.07 , 0.053 , plots_width , plots_height ], [ 0.598 , 0.053 , plots_width , plots_height ], ] # [left, bottom, width, height] # Load the RGB values from the IDL file, corresponding to IDL's \"loadct, 20\" color table rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_20.txt' ) # Load the RGB values rgb_values = rgb_values / 255.0 idl_colormap_20 = ListedColormap ( rgb_values ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - data1 ax_inset_g = fig . add_axes ( wpositions [ 0 ]) colorbar_label = '(g) Log10 (Power)' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = wavelet_power_morlet1 power [ power <= 0 ] = np . nan # Avoid log10 of zero or negative values log_power = np . log10 ( power ) # Calculate log10 of the power t = time periods = wavelet_periods_morlet1 coi = coi_morlet1 sig_slevel = wavelet_significance_morlet1 dt = cadence # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): log_power = log_power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_log_power = np . nanmin ( log_power ) max_log_power = np . nanmax ( log_power ) levels = np . linspace ( min_log_power , max_log_power , 100 ) # Color levels for log10 scale # Plot the wavelet power spectrum using log10(power) # CS = ax_inset_g.contourf(t, periods, log_power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_g . pcolormesh ( t , periods , log_power , vmin = min_log_power , vmax = max_log_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_g . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_g . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_g . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_g . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_g . set_yscale ( 'log' , base = 10 ) ax_inset_g . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_g . invert_yaxis () # Set axis limits and labels ax_inset_g . set_xlim ([ t . min (), t . max ()]) ax_inset_g . set_ylabel ( ylabel ) ax_inset_g . set_xlabel ( xlabel ) ax_inset_g . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_g . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_g . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_g . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_g . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_g . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_g ) cax = inset_axes ( ax_inset_g , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0 , - 2 , - 4 , - 6 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { x : .0f } ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - data2 ax_inset_h = fig . add_axes ( wpositions [ 1 ]) colorbar_label = '(h) Log10 (Power)' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = wavelet_power_morlet2 power [ power <= 0 ] = np . nan # Avoid log10 of zero or negative values log_power = np . log10 ( power ) # Calculate log10 of the power t = time periods = wavelet_periods_morlet2 coi = coi_morlet2 sig_slevel = wavelet_significance_morlet2 dt = cadence # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): log_power = log_power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_log_power = np . nanmin ( log_power ) max_log_power = np . nanmax ( log_power ) levels = np . linspace ( min_log_power , max_log_power , 100 ) # Color levels for log10 scale # Plot the wavelet power spectrum using log10(power) # CS = ax_inset_h.contourf(t, periods, log_power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_h . pcolormesh ( t , periods , log_power , vmin = min_log_power , vmax = max_log_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_h . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_h . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_h . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_h . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_h . set_yscale ( 'log' , base = 10 ) ax_inset_h . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_h . invert_yaxis () # Set axis limits and labels ax_inset_h . set_xlim ([ t . min (), t . max ()]) ax_inset_h . set_ylabel ( ylabel ) ax_inset_h . set_xlabel ( xlabel ) ax_inset_h . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_h . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_h . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_h . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_h . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_h . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_h ) cax = inset_axes ( ax_inset_h , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0 , - 2 , - 4 , - 6 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { x : .0f } ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) #-------------------------------------------------------------------------- # Plot Wavelet cross power spectrum ax_inset_i = fig . add_axes ( wpositions [ 2 ]) colorbar_label = '(i) Log10 (Cross Power)' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = cross_power power [ power <= 0 ] = np . nan # Avoid log10 of zero or negative values # Rescaling to those from IDL (for comapring visualization only). # The power absolute values are different from IDL (due to different normalization), # but the relative values are the same. power = np . interp ( power , ( power . min (), power . max ()), ( 4.1e-5 , 2.14e2 )) log_power = np . log10 ( power ) # Calculate log10 of the power t = time periods = cross_periods coi = cross_coi sig_slevel = cross_sig dt = cadence phase = phase_angle # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): log_power = log_power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] phase = phase [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_log_power = np . nanmin ( log_power ) max_log_power = np . nanmax ( log_power ) levels = np . linspace ( min_log_power , max_log_power , 100 ) # Color levels for log10 scale # Plot the wavelet cross power spectrum using log10(power) # CS = ax_inset_i.contourf(t, periods, log_power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_i . pcolormesh ( t , periods , log_power , vmin = min_log_power , vmax = max_log_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_i . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_i . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_i . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_i . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_i . set_yscale ( 'log' , base = 10 ) ax_inset_i . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_i . invert_yaxis () # Set axis limits and labels ax_inset_i . set_xlim ([ t . min (), t . max ()]) ax_inset_i . set_ylabel ( ylabel ) ax_inset_i . set_xlabel ( xlabel ) ax_inset_i . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_i . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_i . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_i . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_i . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_i . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_i ) caxi = inset_axes ( ax_inset_i , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = caxi , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 5 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 2.5 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 2 , 1 , 0 , - 1 , - 2 , - 3 , - 4 ] # Specify tick positions cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { x : .0f } ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) # ------------ Add Phase Arrows ------------ arrow_density_x = 16 # Number of arrows in the x direction arrow_density_y = 10 # Number of arrows in the y direction fixed_arrow_size = 0.045 # Fixed size of all arrows # Create arrow grid (uniform spacing in t and log10(periods)) x_indices = np . linspace ( 0 , len ( t ) - 1 , arrow_density_x , dtype = int ) y_log_indices = np . linspace ( 0 , len ( periods ) - 1 , arrow_density_y , dtype = int ) # Create the meshgrid for X and Y positions of the arrows X , Y = np . meshgrid ( t [ x_indices ], periods [ y_log_indices ]) # Get actual periods from log10 positions # Extract the phase angle components (u, v) for the selected grid points uu = np . cos ( phase ) # x-component of the arrows vv = np . sin ( phase ) # y-component of the arrows u = uu [ y_log_indices [:, None ], x_indices ] v = vv [ y_log_indices [:, None ], x_indices ] # Normalize u and v to create unit vectors (we need to plot direction only, not magnitude) magnitude = np . sqrt ( u ** 2 + v ** 2 ) u_normalized = u / magnitude # Normalize to unit vector v_normalized = v / magnitude # Normalize to unit vector # Set all arrows to the same small fixed size u_fixed = fixed_arrow_size * u_normalized v_fixed = fixed_arrow_size * v_normalized # Plot the arrows on top of the contour plot ax_inset_i . quiver ( X , Y , u_fixed , v_fixed , color = 'black' , scale = 1 , # No further scaling units = 'width' , # Size of arrows fixed relative to width pivot = 'middle' , # Center the arrow at its position headwidth = 5 , # Arrowhead width headlength = 5 , # Arrowhead length headaxislength = 5 , # Length of arrowhead along the axis linewidth = 1.3 # Line thickness for arrows ) # Add reference arrow for \u03c6 = 0\u00b0 pointing to the right start_pos = ( - 0.19 , 1.0 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.09 , 1.0 ) # End position of the arrow (x2, y2) relative to data ax_inset_i . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_i . text ( start_pos [ 0 ] + 0.0 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.08 , # Offset the y position a bit above the arrowhead r '$\\varphi=0\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_i . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) # Add reference arrows for \u03c6 = 90\u00b0 pointing upwards start_pos = ( - 0.19 , 1.25 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.19 , 1.40 ) # End position of the arrow (x2, y2) relative to data ax_inset_i . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_i . text ( start_pos [ 0 ] + 0.02 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.04 , # Offset the y position a bit above the arrowhead r '$\\varphi=90\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_i . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) #-------------------------------------------------------------------------- # Plot Wavelet coherence spectrum ax_inset_j = fig . add_axes ( wpositions [ 3 ]) colorbar_label = '(j) Coherence' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = coherence t = time periods = coh_periods coi = coh_coi sig_slevel = coh_sig dt = cadence phase = phase_angle # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] phase = phase [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_power = np . nanmin ( power ) max_power = np . nanmax ( power ) levels = np . linspace ( min_power , max_power , 100 ) # Color levels for log10 scale # Plot the wavelet cross power spectrum using log10(power) # CS = ax_inset_j.contourf(t, periods, power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_j . pcolormesh ( t , periods , power , vmin = min_power , vmax = max_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_j . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_j . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_j . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_j . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_j . set_yscale ( 'log' , base = 10 ) ax_inset_j . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_j . invert_yaxis () # Set axis limits and labels ax_inset_j . set_xlim ([ t . min (), t . max ()]) ax_inset_j . set_ylabel ( ylabel ) ax_inset_j . set_xlabel ( xlabel ) ax_inset_j . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_j . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_j . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_j . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_j . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_j . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_j ) cax = inset_axes ( ax_inset_j , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0.2 , 0.4 , 0.6 , 0.8 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # ------------ Add Phase Arrows ------------ # Create arrow grid (uniform spacing in t and log10(periods)) x_indices = np . linspace ( 0 , len ( t ) - 1 , arrow_density_x , dtype = int ) y_log_indices = np . linspace ( 0 , len ( periods ) - 1 , arrow_density_y , dtype = int ) # Create the meshgrid for X and Y positions of the arrows X , Y = np . meshgrid ( t [ x_indices ], periods [ y_log_indices ]) # Get actual periods from log10 positions # Extract the phase angle components (u, v) for the selected grid points uu = np . cos ( phase ) # x-component of the arrows vv = np . sin ( phase ) # y-component of the arrows u = uu [ y_log_indices [:, None ], x_indices ] v = vv [ y_log_indices [:, None ], x_indices ] # Normalize u and v to create unit vectors (we need to plot direction only, not magnitude) magnitude = np . sqrt ( u ** 2 + v ** 2 ) u_normalized = u / magnitude # Normalize to unit vector v_normalized = v / magnitude # Normalize to unit vector # Set all arrows to the same small fixed size u_fixed = fixed_arrow_size * u_normalized v_fixed = fixed_arrow_size * v_normalized # Plot the arrows on top of the contour plot ax_inset_j . quiver ( X , Y , u_fixed , v_fixed , color = 'black' , scale = 1 , # No further scaling units = 'width' , # Size of arrows fixed relative to width pivot = 'middle' , # Center the arrow at its position headwidth = 5 , # Arrowhead width headlength = 5 , # Arrowhead length headaxislength = 5 , # Length of arrowhead along the axis linewidth = 1.3 # Line thickness for arrows ) # Plot arrows only witin significance areas # u = np.cos(phase) # x-component of the arrows # v = np.sin(phase) # y-component of the arrows # ###Masking u,v to keep only thos within significance # u_sig = u # v_sig = v # mask_sig = sig_slevel # mask_sig[mask_sig>=1] = 1 # mask_sig[mask_sig<1] = np.nan # u_sig = u_sig*mask_sig # v_sig = v_sig*mask_sig # ax_inset_j.quiver(t[::25], periods[::5], u_sig[::5, ::25], v_sig[::5, ::25], units='height', # angles='uv', pivot='mid', linewidth=0.5, edgecolor='k', # headwidth=5, headlength=5, headaxislength=2, minshaft=2, # minlength=5) # Add reference arrow for \u03c6 = 0\u00b0 pointing to the right start_pos = ( - 0.22 , 1.0 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.12 , 1.0 ) # End position of the arrow (x2, y2) relative to data ax_inset_j . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_j . text ( start_pos [ 0 ] + 0.0 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.08 , # Offset the y position a bit above the arrowhead r '$\\varphi=0\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_j . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) # Add reference arrows for \u03c6 = 90\u00b0 pointing upwards start_pos = ( - 0.22 , 1.25 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.22 , 1.40 ) # End position of the arrow (x2, y2) relative to data ax_inset_j . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_j . text ( start_pos [ 0 ] + 0.02 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.04 , # Offset the y position a bit above the arrowhead r '$\\varphi=90\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_j . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) #-------------------------------------------------------------------------- # Save the figure as a single PDF pdf_path = 'Figures/Fig6_cross-correlations_FFT_Wavelet.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig6_cross-correlations_FFT_Wavelet.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # Test how the arrows reprenest phase angles: # We should note that the phase angle (u, v) might not match exactly the same points where the arrows are being plotted. # This happens because the wavelet power spectrum and phase angle arrays have a much finer grid resolution than the arrow grid. # We cannot plot arrows at every single point in the wavelet power spectrum, so we have to downsample the phase angle array to match the arrow grid. # This downsampling can lead to slight misalignment between the arrows and the phase angle values, but they should be close enough for visual inspection. # We can test this by plotting the phase angle values directly on top of the arrows to see if they match. # For a more accurate representation (if really necessary), one solution could be to interpolate the phase angle values to match the arrow grid exactly. # As a final note, for any scientific analysis/interpretation the phase angle values should be used directly from the phase angle array, not from the arrows. fig = plt . figure ( figsize = ( 15 , 10 )) param = np . degrees ( phase ) levels = np . linspace ( np . nanmin ( param ), np . nanmax ( param ), num = 100 ) CS = plt . contourf ( t , periods , param , levels = levels , cmap = 'tab20' , extend = 'neither' ) plt . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.2 ]) plt . ylim ([ np . min ( periods ), np . max ( periods )]) plt . yscale ( 'log' , base = 10 ) plt . gca () . invert_yaxis () cbar = plt . colorbar ( CS ) # ------------ Add Phase Arrows ------------ arrow_density_x = 30 # Number of arrows in the x direction arrow_density_y = 20 # Number of arrows in the y direction fixed_arrow_size = 0.025 # Fixed size of all arrows # Create arrow grid (uniform spacing in t and log10(periods)) x_indices = np . linspace ( 0 , len ( t ) - 1 , arrow_density_x , dtype = int ) y_log_indices = np . linspace ( 0 , len ( periods ) - 1 , arrow_density_y , dtype = int ) # Create the meshgrid for X and Y positions of the arrows X , Y = np . meshgrid ( t [ x_indices ], periods [ y_log_indices ]) # Get actual periods from log10 positions # Extract the phase angle components (u, v) for the selected grid points uu = np . cos ( phase ) # x-component of the arrows vv = np . sin ( phase ) # y-component of the arrows u = uu [ y_log_indices [:, None ], x_indices ] v = vv [ y_log_indices [:, None ], x_indices ] # Normalize u and v to create unit vectors (we need to plot direction only, not magnitude) magnitude = np . sqrt ( u ** 2 + v ** 2 ) u_normalized = u / magnitude # Normalize to unit vector v_normalized = v / magnitude # Normalize to unit vector # Set all arrows to the same small fixed size u_fixed = fixed_arrow_size * u_normalized v_fixed = fixed_arrow_size * v_normalized # Plot the arrows on top of the contour plot plt . quiver ( X , Y , u_fixed , v_fixed , color = 'black' , scale = 1 , # No further scaling units = 'width' , # Size of arrows fixed relative to width pivot = 'middle' , # Center the arrow at its position headwidth = 6 , # Arrowhead width headlength = 6 , # Arrowhead length headaxislength = 6 , # Length of arrowhead along the axis linewidth = 1.5 # Line thickness for arrows ) plt . show () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 # Plot Wavelet coherence spectrum # Test: plot denser arrows within significance areas fig = plt . figure ( figsize = ( 15 , 10 )) ax_inset_j = plt . gca () # Get the current active axes colorbar_label = '(j) Coherence' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = coherence t = time periods = coh_periods coi = coh_coi sig_slevel = coh_sig dt = cadence phase = phase_angle # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] phase = phase [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_power = np . nanmin ( power ) max_power = np . nanmax ( power ) levels = np . linspace ( min_power , max_power , 100 ) # Color levels for log10 scale # Plot the wavelet cross power spectrum using log10(power) # CS = ax_inset_j.contourf(t, periods, power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_j . pcolormesh ( t , periods , power , vmin = min_power , vmax = max_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_j . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_j . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_j . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_j . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_j . set_yscale ( 'log' , base = 10 ) ax_inset_j . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_j . invert_yaxis () # Set axis limits and labels ax_inset_j . set_xlim ([ t . min (), t . max ()]) ax_inset_j . set_ylabel ( ylabel ) ax_inset_j . set_xlabel ( xlabel ) ax_inset_j . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_j . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_j . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_j . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_j . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_j . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_j ) cax = inset_axes ( ax_inset_j , width = \"100%\" , height = \"2%\" , loc = 'upper center' , borderpad =- 1.8 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 15 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0.2 , 0.4 , 0.6 , 0.8 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) u = np . cos ( phase ) # x-component of the arrows v = np . sin ( phase ) # y-component of the arrows ###Masking u,v to keep only thos within significance u_sig = u v_sig = v mask_sig = sig_slevel mask_sig [ mask_sig >= 1 ] = 1 mask_sig [ mask_sig < 1 ] = np . nan u_sig = u_sig * mask_sig v_sig = v_sig * mask_sig # ax_inset_j.contour(t, periods, mask_sig, levels=[1], colors='k',linewidths=[5]) ax_inset_j . quiver ( t [:: 25 ], periods [:: 5 ], u_sig [:: 5 , :: 25 ], v_sig [:: 5 , :: 25 ], units = 'height' , angles = 'uv' , pivot = 'tip' , linewidth = 0.1 , edgecolor = 'k' , headwidth = 4 , headlength = 1 , headaxislength = 1 , minshaft = 1 , minlength = 1 ) plt . show ()", "title": "Cross Correlations"}, {"location": "python/cross-correlation-example/#worked-example-nrmp-cross-correlation-analysis", "text": "This example demonstrates the application of cross-correlation analysis to two nearly identical synthetic 1D signals. The signals share the same base frequencies and amplitudes but have slight phase differences introduced between them. This simulates a scenario where similar wave signals are observed at different locations or with a time delay. By analysing the cross-correlation between these signals, we can identify common frequencies, quantify the strength of their relationship, and determine the phase or time lag between their oscillations. This provides valuable insights into the potential connections or shared drivers influencing the signals. Analysis and Figure The figure below presents a comparative analysis of cross-correlation techniques applied to the two synthetic 1D signals. Methods used: Fast Fourier Transform (FFT) Wavelet Transform (with Morlet wavelet) WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 6 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Cross-correlation analysis of two synthetic 1D time series using FFT and wavelet techniques. (a) and (b) display the first and second time series, respectively. \u00a9 compares their FFT power spectra (blue: time series 1, red: time series 2). (d)-(f) present the FFT-derived co-spectrum, coherence spectrum, and phase differences. (g) and (h) show individual wavelet power spectra (Morlet mother wavelet). (i) and (j) depict the wavelet co-spectrum and coherence map. Cross-hatched areas in wavelet panels mark the cone of influence (COI); black contours indicate the 95% confidence level. Power is represented in log-scale in panels (g)-(i) , while colors in panel (j) map coherence levels. Phase differences in (i) and (j) are visualized as arrows (right: in-phase, up: 90-degree lead for time series 1). Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , walsa_detrend_apod #-------------------------------------------------------------------------- # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_1D.fits' ) signal_1d_data1 = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Assuming time is in the second HDU (Extension HDU 1) hdul . close () hdul = fits . open ( data_dir + 'NRMP_signal_1D_phase_shifted.fits' ) signal_1d_data2 = hdul [ 0 ] . data # 1D synthetic signal data hdul . close () tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Welch Cross Spectrum using WaLSAtools frequencies_welch , cospectrum_welch , phase_angle_welch , power1_welch , power2_welch , freq_coherence_welch , coherence_welch = WaLSAtools ( data1 = signal_1d_data2 , data2 = signal_1d_data1 , time = time , method = 'welch' , nperseg = 500 ) # Wavelet Analysis using WaLSAtools - data1 wavelet_power_morlet1 , wavelet_periods_morlet1 , wavelet_significance_morlet1 , coi_morlet1 = WaLSAtools ( signal = signal_1d_data1 , time = time , method = 'wavelet' , siglevel = 0.95 , mother = 'morlet' , GWS = False , RGWS = False ) # Wavelet Analysis using WaLSAtools - data2 wavelet_power_morlet2 , wavelet_periods_morlet2 , wavelet_significance_morlet2 , coi_morlet2 = WaLSAtools ( signal = signal_1d_data2 , time = time , method = 'wavelet' , siglevel = 0.95 , mother = 'morlet' , GWS = False , RGWS = False ) # Wavelet Cross Spectrum using WaLSAtools cross_power , cross_periods , cross_sig , cross_coi , coherence , coh_periods , coh_sig , coh_coi , phase_angle = WaLSAtools ( data1 = signal_1d_data2 , data2 = signal_1d_data1 , time = time , method = 'wavelet' , nperm = 1000 , siglevel = 0.95 ) # Detrend and Apodize the timeeries for plotting (note that these are done within the analysis routines above) signal_1d_data1 = walsa_detrend_apod ( signal_1d_data1 , apod = 0.1 , pxdetrend = 2 , silent = True ) signal_1d_data2 = walsa_detrend_apod ( signal_1d_data2 , apod = 0.1 , pxdetrend = 2 , silent = True ) Welch processed. Welch processed. Detrending and apodization complete. Wavelet (morlet) processed. Detrending and apodization complete. Wavelet (morlet) processed. Wavelet cross-power spectrum calculated. Calculating wavelet cross-power significance: Progress: 100.00%Wavelet coherence calculated. Calculating wavelet coherence significance: Progress: 100.00% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator from matplotlib.colors import ListedColormap from matplotlib.ticker import AutoMinorLocator , FormatStrFormatter from mpl_toolkits.axes_grid1 import make_axes_locatable from mpl_toolkits.axes_grid1.inset_locator import inset_axes from WaLSAtools import WaLSA_save_pdf # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'Arial' , # Set Helvetica as the default sans-serif font 'font.size' : 13.5 , # Global font size 'axes.titlesize' : 13.5 , # Title font size 'axes.labelsize' : 13.5 , # Axis label font size 'xtick.labelsize' : 13.5 , # X-axis tick label font size 'ytick.labelsize' : 13.5 , # Y-axis tick label font size 'legend.fontsize' : 13.5 , # Legend font size 'figure.titlesize' : 13.5 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 500 , # Make all fonts bold 'axes.titleweight' : 500 , # Make title font bold 'axes.labelweight' : 500 # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.0 ) plt . rc ( 'lines' , linewidth = 0.8 ) pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] # Mark pre-defined frequencies # Set up the figure layout fig = plt . figure ( figsize = ( 9.5 , 10.79 )) #-------------------------------------------------------------------------- # FFT/Welch plots_width = 0.24 plots_height = 0.10 positions = [[ 0.07 , 0.872 , plots_width , plots_height ], [ 0.403 , 0.872 , plots_width , plots_height ], [ 0.750 , 0.872 , plots_width , plots_height ], [ 0.07 , 0.682 , plots_width , plots_height ], [ 0.403 , 0.682 , plots_width , plots_height ], [ 0.752 , 0.682 , plots_width , plots_height ] ] # [left, bottom, width, height] # First 1D signal plot ax1 = fig . add_axes ( positions [ 0 ]) ax1 . plot ( time , signal_1d_data1 * 10 , color = 'dodgerblue' ) ax1 . set_xlabel ( 'Time (s)' , labelpad = 5 ) ax1 . set_ylabel ( 'DN (arb. unit)' , labelpad = 8 ) ax1 . set_title ( '(a) 1st Time Series' , pad = 10 ) ax1 . set_ylim ( - 35 , 79 ) ax1 . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes ax1 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax1 . set_xticks ( np . arange ( 0 , 10 , 2 )) ax1 . set_yticks ( np . arange ( 0 , 80 , 40 )) # Custom tick sizes and thickness ax1 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax1 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax1 . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax1 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Second 1D signal plot ax2 = fig . add_axes ( positions [ 1 ]) ax2 . plot ( time , signal_1d_data2 * 10 , color = 'red' ) ax2 . set_xlabel ( 'Time (s)' , labelpad = 5 ) ax2 . set_ylabel ( 'DN (arb. unit)' , labelpad = 8 ) ax2 . set_title ( '(b) 2nd Time Series' , pad = 10 ) ax2 . set_ylim ( - 35 , 79 ) ax2 . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes ax2 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax2 . set_xticks ( np . arange ( 0 , 10 , 2 )) ax2 . set_yticks ( np . arange ( 0 , 80 , 40 )) # Custom tick sizes and thickness ax2 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax2 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax2 . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax2 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # FFT Power Spectra ax3 = fig . add_axes ( positions [ 2 ]) ax3 . plot ( frequencies_welch , 85 * power1_welch / np . max ( power1_welch ), color = 'dodgerblue' ) ax3 . plot ( frequencies_welch , 85 * power2_welch / np . max ( power2_welch ), linestyle = '-.' , color = 'red' , linewidth = 0.5 ) ax3 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax3 . set_ylabel ( 'Power (%)' , labelpad = 8 ) ax3 . set_title ( '(c) Power spectra' , pad = 10 ) ax3 . set_xlim ([ 0 , 36 ]) ax3 . set_ylim ( 0 , 40 ) # Set tick marks outside for all four axes ax3 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax3 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax3 . set_yticks ( np . arange ( 0 , 41 , 10 )) # Custom tick sizes and thickness ax3 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax3 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax3 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax3 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # FFT Cross Spectrum ax4 = fig . add_axes ( positions [ 3 ]) for freqin in pre_defined_freq : ax4 . axvline ( x = freqin , color = 'orange' , linewidth = 0.5 ) ax4 . plot ( frequencies_welch , 92 * cospectrum_welch / np . max ( cospectrum_welch ), color = 'DarkGreen' ) ax4 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax4 . set_ylabel ( 'Power (%)' , labelpad = 8 ) ax4 . set_title ( '(d) Co-spectrum' , pad = 10 ) ax4 . set_xlim ([ 0 , 36 ]) ax4 . set_ylim ( 0 , 40 ) # Set tick marks outside for all four axes ax4 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax4 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax4 . set_yticks ( np . arange ( 0 , 41 , 10 )) # Custom tick sizes and thickness ax4 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax4 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax4 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax4 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # FFT Coherence ax5 = fig . add_axes ( positions [ 4 ]) for freqin in pre_defined_freq : ax5 . axvline ( x = freqin , color = 'orange' , linewidth = 0.5 ) ax5 . plot ( freq_coherence_welch , coherence_welch , color = 'DarkGreen' ) ax5 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax5 . set_ylabel ( 'Coherence' , labelpad = 8 ) ax5 . set_title ( '(e) Coherence' , pad = 10 ) ax5 . set_xlim ([ 0 , 36 ]) ax5 . set_ylim ( 0 , 1.1 ) # Set tick marks outside for all four axes ax5 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax5 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax5 . set_yticks ( np . arange ( 0 , 1.1 , 0.2 )) ax5 . set_yticklabels ([ '0.0' , ' ' , '0.4' , ' ' , '0.8' , ' ' ]) # Custom tick sizes and thickness ax5 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax5 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax5 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax5 . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a horizontal line at coherence = 0.8 (as a threshold) ax5 . axhline ( y = 0.8 , color = 'darkred' , linewidth = 1.1 ) # FFT Phase Differences ax6 = fig . add_axes ( positions [ 5 ]) for freqin in pre_defined_freq : ax6 . axvline ( x = freqin , color = 'orange' , linewidth = 0.5 ) ax6 . plot ( frequencies_welch , phase_angle_welch , color = 'DarkGreen' ) ax6 . set_xlabel ( 'Frequency (Hz)' , labelpad = 5 ) ax6 . set_ylabel ( 'Phase (deg)' , labelpad = 4 ) ax6 . set_title ( '(f) Phase Difference' , pad = 10 ) ax6 . set_xlim ([ 0 , 36 ]) ax6 . set_ylim ( - 200 , 200 ) # Set tick marks outside for all four axes ax6 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals ax6 . set_xticks ( np . arange ( 0 , 36 , 10 )) ax6 . set_yticks ( np . arange ( - 200 , 201 , 100 )) # Custom tick sizes and thickness ax6 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.3 ) # Major ticks ax6 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.3 ) # Minor ticks # Set minor ticks ax6 . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) ax6 . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) #-------------------------------------------------------------------------- # Wavelet plots_width = 0.34 plots_height = 0.17 wpositions = [[ 0.07 , 0.358 , plots_width , plots_height ], [ 0.598 , 0.358 , plots_width , plots_height ], [ 0.07 , 0.053 , plots_width , plots_height ], [ 0.598 , 0.053 , plots_width , plots_height ], ] # [left, bottom, width, height] # Load the RGB values from the IDL file, corresponding to IDL's \"loadct, 20\" color table rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_20.txt' ) # Load the RGB values rgb_values = rgb_values / 255.0 idl_colormap_20 = ListedColormap ( rgb_values ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - data1 ax_inset_g = fig . add_axes ( wpositions [ 0 ]) colorbar_label = '(g) Log10 (Power)' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = wavelet_power_morlet1 power [ power <= 0 ] = np . nan # Avoid log10 of zero or negative values log_power = np . log10 ( power ) # Calculate log10 of the power t = time periods = wavelet_periods_morlet1 coi = coi_morlet1 sig_slevel = wavelet_significance_morlet1 dt = cadence # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): log_power = log_power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_log_power = np . nanmin ( log_power ) max_log_power = np . nanmax ( log_power ) levels = np . linspace ( min_log_power , max_log_power , 100 ) # Color levels for log10 scale # Plot the wavelet power spectrum using log10(power) # CS = ax_inset_g.contourf(t, periods, log_power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_g . pcolormesh ( t , periods , log_power , vmin = min_log_power , vmax = max_log_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_g . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_g . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_g . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_g . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_g . set_yscale ( 'log' , base = 10 ) ax_inset_g . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_g . invert_yaxis () # Set axis limits and labels ax_inset_g . set_xlim ([ t . min (), t . max ()]) ax_inset_g . set_ylabel ( ylabel ) ax_inset_g . set_xlabel ( xlabel ) ax_inset_g . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_g . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_g . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_g . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_g . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_g . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_g ) cax = inset_axes ( ax_inset_g , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0 , - 2 , - 4 , - 6 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { x : .0f } ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - data2 ax_inset_h = fig . add_axes ( wpositions [ 1 ]) colorbar_label = '(h) Log10 (Power)' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = wavelet_power_morlet2 power [ power <= 0 ] = np . nan # Avoid log10 of zero or negative values log_power = np . log10 ( power ) # Calculate log10 of the power t = time periods = wavelet_periods_morlet2 coi = coi_morlet2 sig_slevel = wavelet_significance_morlet2 dt = cadence # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): log_power = log_power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_log_power = np . nanmin ( log_power ) max_log_power = np . nanmax ( log_power ) levels = np . linspace ( min_log_power , max_log_power , 100 ) # Color levels for log10 scale # Plot the wavelet power spectrum using log10(power) # CS = ax_inset_h.contourf(t, periods, log_power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_h . pcolormesh ( t , periods , log_power , vmin = min_log_power , vmax = max_log_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_h . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_h . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_h . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_h . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_h . set_yscale ( 'log' , base = 10 ) ax_inset_h . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_h . invert_yaxis () # Set axis limits and labels ax_inset_h . set_xlim ([ t . min (), t . max ()]) ax_inset_h . set_ylabel ( ylabel ) ax_inset_h . set_xlabel ( xlabel ) ax_inset_h . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_h . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_h . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_h . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_h . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_h . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_h ) cax = inset_axes ( ax_inset_h , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0 , - 2 , - 4 , - 6 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { x : .0f } ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) #-------------------------------------------------------------------------- # Plot Wavelet cross power spectrum ax_inset_i = fig . add_axes ( wpositions [ 2 ]) colorbar_label = '(i) Log10 (Cross Power)' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = cross_power power [ power <= 0 ] = np . nan # Avoid log10 of zero or negative values # Rescaling to those from IDL (for comapring visualization only). # The power absolute values are different from IDL (due to different normalization), # but the relative values are the same. power = np . interp ( power , ( power . min (), power . max ()), ( 4.1e-5 , 2.14e2 )) log_power = np . log10 ( power ) # Calculate log10 of the power t = time periods = cross_periods coi = cross_coi sig_slevel = cross_sig dt = cadence phase = phase_angle # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): log_power = log_power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] phase = phase [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_log_power = np . nanmin ( log_power ) max_log_power = np . nanmax ( log_power ) levels = np . linspace ( min_log_power , max_log_power , 100 ) # Color levels for log10 scale # Plot the wavelet cross power spectrum using log10(power) # CS = ax_inset_i.contourf(t, periods, log_power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_i . pcolormesh ( t , periods , log_power , vmin = min_log_power , vmax = max_log_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_i . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_i . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_i . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_i . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_i . set_yscale ( 'log' , base = 10 ) ax_inset_i . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_i . invert_yaxis () # Set axis limits and labels ax_inset_i . set_xlim ([ t . min (), t . max ()]) ax_inset_i . set_ylabel ( ylabel ) ax_inset_i . set_xlabel ( xlabel ) ax_inset_i . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_i . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_i . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_i . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_i . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_i . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_i ) caxi = inset_axes ( ax_inset_i , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = caxi , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 5 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 2.5 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 2 , 1 , 0 , - 1 , - 2 , - 3 , - 4 ] # Specify tick positions cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { x : .0f } ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) # ------------ Add Phase Arrows ------------ arrow_density_x = 16 # Number of arrows in the x direction arrow_density_y = 10 # Number of arrows in the y direction fixed_arrow_size = 0.045 # Fixed size of all arrows # Create arrow grid (uniform spacing in t and log10(periods)) x_indices = np . linspace ( 0 , len ( t ) - 1 , arrow_density_x , dtype = int ) y_log_indices = np . linspace ( 0 , len ( periods ) - 1 , arrow_density_y , dtype = int ) # Create the meshgrid for X and Y positions of the arrows X , Y = np . meshgrid ( t [ x_indices ], periods [ y_log_indices ]) # Get actual periods from log10 positions # Extract the phase angle components (u, v) for the selected grid points uu = np . cos ( phase ) # x-component of the arrows vv = np . sin ( phase ) # y-component of the arrows u = uu [ y_log_indices [:, None ], x_indices ] v = vv [ y_log_indices [:, None ], x_indices ] # Normalize u and v to create unit vectors (we need to plot direction only, not magnitude) magnitude = np . sqrt ( u ** 2 + v ** 2 ) u_normalized = u / magnitude # Normalize to unit vector v_normalized = v / magnitude # Normalize to unit vector # Set all arrows to the same small fixed size u_fixed = fixed_arrow_size * u_normalized v_fixed = fixed_arrow_size * v_normalized # Plot the arrows on top of the contour plot ax_inset_i . quiver ( X , Y , u_fixed , v_fixed , color = 'black' , scale = 1 , # No further scaling units = 'width' , # Size of arrows fixed relative to width pivot = 'middle' , # Center the arrow at its position headwidth = 5 , # Arrowhead width headlength = 5 , # Arrowhead length headaxislength = 5 , # Length of arrowhead along the axis linewidth = 1.3 # Line thickness for arrows ) # Add reference arrow for \u03c6 = 0\u00b0 pointing to the right start_pos = ( - 0.19 , 1.0 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.09 , 1.0 ) # End position of the arrow (x2, y2) relative to data ax_inset_i . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_i . text ( start_pos [ 0 ] + 0.0 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.08 , # Offset the y position a bit above the arrowhead r '$\\varphi=0\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_i . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) # Add reference arrows for \u03c6 = 90\u00b0 pointing upwards start_pos = ( - 0.19 , 1.25 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.19 , 1.40 ) # End position of the arrow (x2, y2) relative to data ax_inset_i . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_i . text ( start_pos [ 0 ] + 0.02 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.04 , # Offset the y position a bit above the arrowhead r '$\\varphi=90\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_i . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) #-------------------------------------------------------------------------- # Plot Wavelet coherence spectrum ax_inset_j = fig . add_axes ( wpositions [ 3 ]) colorbar_label = '(j) Coherence' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = coherence t = time periods = coh_periods coi = coh_coi sig_slevel = coh_sig dt = cadence phase = phase_angle # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] phase = phase [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_power = np . nanmin ( power ) max_power = np . nanmax ( power ) levels = np . linspace ( min_power , max_power , 100 ) # Color levels for log10 scale # Plot the wavelet cross power spectrum using log10(power) # CS = ax_inset_j.contourf(t, periods, power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_j . pcolormesh ( t , periods , power , vmin = min_power , vmax = max_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_j . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_j . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_j . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_j . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_j . set_yscale ( 'log' , base = 10 ) ax_inset_j . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_j . invert_yaxis () # Set axis limits and labels ax_inset_j . set_xlim ([ t . min (), t . max ()]) ax_inset_j . set_ylabel ( ylabel ) ax_inset_j . set_xlabel ( xlabel ) ax_inset_j . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_j . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_j . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_j . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_j . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_j . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_j ) cax = inset_axes ( ax_inset_j , width = \"100%\" , height = \"6%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0.2 , 0.4 , 0.6 , 0.8 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # ------------ Add Phase Arrows ------------ # Create arrow grid (uniform spacing in t and log10(periods)) x_indices = np . linspace ( 0 , len ( t ) - 1 , arrow_density_x , dtype = int ) y_log_indices = np . linspace ( 0 , len ( periods ) - 1 , arrow_density_y , dtype = int ) # Create the meshgrid for X and Y positions of the arrows X , Y = np . meshgrid ( t [ x_indices ], periods [ y_log_indices ]) # Get actual periods from log10 positions # Extract the phase angle components (u, v) for the selected grid points uu = np . cos ( phase ) # x-component of the arrows vv = np . sin ( phase ) # y-component of the arrows u = uu [ y_log_indices [:, None ], x_indices ] v = vv [ y_log_indices [:, None ], x_indices ] # Normalize u and v to create unit vectors (we need to plot direction only, not magnitude) magnitude = np . sqrt ( u ** 2 + v ** 2 ) u_normalized = u / magnitude # Normalize to unit vector v_normalized = v / magnitude # Normalize to unit vector # Set all arrows to the same small fixed size u_fixed = fixed_arrow_size * u_normalized v_fixed = fixed_arrow_size * v_normalized # Plot the arrows on top of the contour plot ax_inset_j . quiver ( X , Y , u_fixed , v_fixed , color = 'black' , scale = 1 , # No further scaling units = 'width' , # Size of arrows fixed relative to width pivot = 'middle' , # Center the arrow at its position headwidth = 5 , # Arrowhead width headlength = 5 , # Arrowhead length headaxislength = 5 , # Length of arrowhead along the axis linewidth = 1.3 # Line thickness for arrows ) # Plot arrows only witin significance areas # u = np.cos(phase) # x-component of the arrows # v = np.sin(phase) # y-component of the arrows # ###Masking u,v to keep only thos within significance # u_sig = u # v_sig = v # mask_sig = sig_slevel # mask_sig[mask_sig>=1] = 1 # mask_sig[mask_sig<1] = np.nan # u_sig = u_sig*mask_sig # v_sig = v_sig*mask_sig # ax_inset_j.quiver(t[::25], periods[::5], u_sig[::5, ::25], v_sig[::5, ::25], units='height', # angles='uv', pivot='mid', linewidth=0.5, edgecolor='k', # headwidth=5, headlength=5, headaxislength=2, minshaft=2, # minlength=5) # Add reference arrow for \u03c6 = 0\u00b0 pointing to the right start_pos = ( - 0.22 , 1.0 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.12 , 1.0 ) # End position of the arrow (x2, y2) relative to data ax_inset_j . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_j . text ( start_pos [ 0 ] + 0.0 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.08 , # Offset the y position a bit above the arrowhead r '$\\varphi=0\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_j . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) # Add reference arrows for \u03c6 = 90\u00b0 pointing upwards start_pos = ( - 0.22 , 1.25 ) # Start position of the arrow (x1, y1) relative to data end_pos = ( - 0.22 , 1.40 ) # End position of the arrow (x2, y2) relative to data ax_inset_j . annotate ( '' , # No text, just the arrow xy = end_pos , # Position of the arrowhead xytext = start_pos , # Start of the arrow (where the line starts) xycoords = 'axes fraction' , # Fraction of the plot (use axes fraction if outside the plot) arrowprops = dict ( arrowstyle = '-|>' , # Full, filled arrowhead color = 'black' , # Arrow color linewidth = 1.3 , # Thickness of the arrow line mutation_scale = 12 , # Controls the size of the arrowhead ) ) ax_inset_j . text ( start_pos [ 0 ] + 0.02 , # Offset the x position a bit to the right of the arrowhead start_pos [ 1 ] + 0.04 , # Offset the y position a bit above the arrowhead r '$\\varphi=90\\degree$' , # LaTeX for phi (\u03c6) and degrees (\u00b0) transform = ax_inset_j . transAxes , # Relative to the plot's axes fontsize = 14 , fontweight = 'bold' ) #-------------------------------------------------------------------------- # Save the figure as a single PDF pdf_path = 'Figures/Fig6_cross-correlations_FFT_Wavelet.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig6_cross-correlations_FFT_Wavelet.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # Test how the arrows reprenest phase angles: # We should note that the phase angle (u, v) might not match exactly the same points where the arrows are being plotted. # This happens because the wavelet power spectrum and phase angle arrays have a much finer grid resolution than the arrow grid. # We cannot plot arrows at every single point in the wavelet power spectrum, so we have to downsample the phase angle array to match the arrow grid. # This downsampling can lead to slight misalignment between the arrows and the phase angle values, but they should be close enough for visual inspection. # We can test this by plotting the phase angle values directly on top of the arrows to see if they match. # For a more accurate representation (if really necessary), one solution could be to interpolate the phase angle values to match the arrow grid exactly. # As a final note, for any scientific analysis/interpretation the phase angle values should be used directly from the phase angle array, not from the arrows. fig = plt . figure ( figsize = ( 15 , 10 )) param = np . degrees ( phase ) levels = np . linspace ( np . nanmin ( param ), np . nanmax ( param ), num = 100 ) CS = plt . contourf ( t , periods , param , levels = levels , cmap = 'tab20' , extend = 'neither' ) plt . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.2 ]) plt . ylim ([ np . min ( periods ), np . max ( periods )]) plt . yscale ( 'log' , base = 10 ) plt . gca () . invert_yaxis () cbar = plt . colorbar ( CS ) # ------------ Add Phase Arrows ------------ arrow_density_x = 30 # Number of arrows in the x direction arrow_density_y = 20 # Number of arrows in the y direction fixed_arrow_size = 0.025 # Fixed size of all arrows # Create arrow grid (uniform spacing in t and log10(periods)) x_indices = np . linspace ( 0 , len ( t ) - 1 , arrow_density_x , dtype = int ) y_log_indices = np . linspace ( 0 , len ( periods ) - 1 , arrow_density_y , dtype = int ) # Create the meshgrid for X and Y positions of the arrows X , Y = np . meshgrid ( t [ x_indices ], periods [ y_log_indices ]) # Get actual periods from log10 positions # Extract the phase angle components (u, v) for the selected grid points uu = np . cos ( phase ) # x-component of the arrows vv = np . sin ( phase ) # y-component of the arrows u = uu [ y_log_indices [:, None ], x_indices ] v = vv [ y_log_indices [:, None ], x_indices ] # Normalize u and v to create unit vectors (we need to plot direction only, not magnitude) magnitude = np . sqrt ( u ** 2 + v ** 2 ) u_normalized = u / magnitude # Normalize to unit vector v_normalized = v / magnitude # Normalize to unit vector # Set all arrows to the same small fixed size u_fixed = fixed_arrow_size * u_normalized v_fixed = fixed_arrow_size * v_normalized # Plot the arrows on top of the contour plot plt . quiver ( X , Y , u_fixed , v_fixed , color = 'black' , scale = 1 , # No further scaling units = 'width' , # Size of arrows fixed relative to width pivot = 'middle' , # Center the arrow at its position headwidth = 6 , # Arrowhead width headlength = 6 , # Arrowhead length headaxislength = 6 , # Length of arrowhead along the axis linewidth = 1.5 # Line thickness for arrows ) plt . show () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 # Plot Wavelet coherence spectrum # Test: plot denser arrows within significance areas fig = plt . figure ( figsize = ( 15 , 10 )) ax_inset_j = plt . gca () # Get the current active axes colorbar_label = '(j) Coherence' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) # Apply log10 transformation to the power and avoid negative or zero values power = coherence t = time periods = coh_periods coi = coh_coi sig_slevel = coh_sig dt = cadence phase = phase_angle # Optional: Remove large periods outside the cone of influence (if enabled) removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] phase = phase [: cutoff_index , :] # Define levels for log10 color scaling (adjust to reflect log10 range) min_power = np . nanmin ( power ) max_power = np . nanmax ( power ) levels = np . linspace ( min_power , max_power , 100 ) # Color levels for log10 scale # Plot the wavelet cross power spectrum using log10(power) # CS = ax_inset_j.contourf(t, periods, power, levels=levels, cmap=cmap, extend='neither') CS = ax_inset_j . pcolormesh ( t , periods , power , vmin = min_power , vmax = max_power , cmap = cmap , shading = 'auto' ) # 95% significance contour (significance levels remain the same) ax_inset_j . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) # Cone-of-influence (COI) ax_inset_j . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_j . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_j . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_j . set_yscale ( 'log' , base = 10 ) ax_inset_j . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_j . invert_yaxis () # Set axis limits and labels ax_inset_j . set_xlim ([ t . min (), t . max ()]) ax_inset_j . set_ylabel ( ylabel ) ax_inset_j . set_xlabel ( xlabel ) ax_inset_j . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_j . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_j . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_j . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_j . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_j . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_j ) cax = inset_axes ( ax_inset_j , width = \"100%\" , height = \"2%\" , loc = 'upper center' , borderpad =- 1.8 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 15 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 1.0 , direction = 'out' , top = True , bottom = False ) # Set custom tick locations for colorbar custom_ticks = [ 0.2 , 0.4 , 0.6 , 0.8 ] # Specify tick positions (must be within log10(power) range) cbar . set_ticks ( custom_ticks ) cbar . ax . xaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) # Set minor ticks on the colorbar cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) u = np . cos ( phase ) # x-component of the arrows v = np . sin ( phase ) # y-component of the arrows ###Masking u,v to keep only thos within significance u_sig = u v_sig = v mask_sig = sig_slevel mask_sig [ mask_sig >= 1 ] = 1 mask_sig [ mask_sig < 1 ] = np . nan u_sig = u_sig * mask_sig v_sig = v_sig * mask_sig # ax_inset_j.contour(t, periods, mask_sig, levels=[1], colors='k',linewidths=[5]) ax_inset_j . quiver ( t [:: 25 ], periods [:: 5 ], u_sig [:: 5 , :: 25 ], v_sig [:: 5 , :: 25 ], units = 'height' , angles = 'uv' , pivot = 'tip' , linewidth = 0.1 , edgecolor = 'k' , headwidth = 4 , headlength = 1 , headaxislength = 1 , minshaft = 1 , minlength = 1 ) plt . show ()", "title": "Worked Example - NRMP: Cross-Correlation Analysis"}, {"location": "python/dominant-frequency-example/", "text": "Worked Example - NRMP: Dominant Frequency \u00b6 This example demonstrates the application of dominant frequency analysis to a synthetic spatio-temporal dataset. The dataset comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing the dominant frequencies at each spatial location, we can gain insights into the spatial distribution of oscillatory behaviour and identify potential wave modes. Analysis and Figure The figure below shows the dominant frequency maps calculated using different spectral analysis methods. The maps reveal the spatial distribution of the most prominent oscillation frequencies in the dataset. Methods used: Fast Fourier Transform (FFT) Refined Global Wavelet Spectrum (RGWS) with Morlet wavelet Refined Global Wavelet Spectrum (RGWS) with Paul wavelet WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Dominant frequency maps and mean power spectra. Top row: Dominant frequency maps derived using FFT (left), Morlet-based RGWS (middle), and Paul-based RGWS (right). Bottom panel: Normalized mean power spectra for FFT (blue), Morlet-based RGWS (red), and Paul-based RGWS (black). Important Notes on Interpreting the Dominant Frequencies The dominant frequency at each pixel corresponds to the frequency with the highest spectral power. While a linear detrending and Tukey apodization (with 0.1 tapering fraction) have been applied to reduce long-term trends and edge effects , the lowest frequency bin may still appear dominant \u2014 especially in regions without strong higher-frequency oscillations. This is a common outcome in time series with broad, low-frequency variability, where power is not concentrated at narrow peaks, or limited by frequency resolution. However, this does not necessarily reflect meaningful or coherent low-frequency wave activity . In the figure, white regions indicate pixels where the dominant frequency falls into the lowest frequency bin , which is explicitly mapped to white in the color table (see line 23 of the plotting routine). These are only visible in the FFT and Morlet-based RGWS maps. The Paul-based RGWS map, on the other hand, does not show white regions . This is because, for this method, the dominant frequencies tend to fall slightly above the lowest bin (around 100-120\u202fmHz ), even though the method includes lower frequencies. This behavior reflects the fundamental differences among the analysis techniques used: \ud83d\udccc FFT (Fast Fourier Transform) \u25cd Provides relatively high frequency resolution at all frequencies, with fixed, global basis functions. \u25cd Sensitive to any persistent oscillatory signal , but often returns low-frequency peaks if stronger high-frequency signals are absent. \u25cd In the averaged power spectrum, the dominant peak lies at 100\u202fmHz \u2014 the lowest available frequency bin. \ud83d\udccc Morlet-based RGWS \u25cd Uses the Morlet wavelet , which offers good frequency resolution but less precise time localization , particularly well-suited to capturing persistent oscillations with quasi-stationary frequencies. \u25cd As with all RGWS methods, the frequency resolution is non-uniform , leading to narrower and more pronounced peaks at lower frequencies , and broader, smoother features at higher frequencies in the power spectrum. \u25cd This causes the spectrum to mirror FFT\u2019s tendency to favor the lowest bin as dominant when no strong high-frequency signals are present, but with less detail in the dominant frequency map , compared to FFT, due to smoothing at high frequencies. \ud83d\udccc Paul-based RGWS \u25cd Employs the Paul wavelet , which has excellent time localization but poorer frequency resolution , particularly at low frequencies. This causes the lowest frequency bin to appear more diffuse, with power spread across a broader range, making sharp low-frequency peaks less distinguishable. \u25cd It responds strongly to short-lived or localized features in the data, but tends to underrepresent broad, slowly varying components . As a result, power in the lowest frequency bin is often weakened or distributed , making it less likely to be selected as dominant. \u25cd Consequently, the mean power spectrum peaks around 120\u202fmHz , and white regions do not appear in the dominant frequency map, since the 100\u202fmHz bin is rarely the strongest in this method. These differences emphasize that dominant frequency maps depend strongly on the method used , and should always be interpreted in tandem with the full power spectra (see bottom panel of Figure 4) and with awareness of each method's strengths and limitations. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf , WaLSA_histo_opt #-------------------------------------------------------------------------- # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic signal data time = hdul [ 1 ] . data # Time array hdul . close () cadence = 0.5 # cadence in seconds # FFT Analysis using WaLSAtools FFT_dominant_frequency , FFT_averaged_power , FFT_frequencies , FFT_pm = WaLSAtools ( signal = signal_3d , time = time , method = 'fft' , format = 'txy' , averagedpower = True , dominantfreq = True ) # Normalize FFT averaged power to its maximum value FFT_averaged_power_normalized = 100 * FFT_averaged_power / np . max ( FFT_averaged_power ) # RGWS-Morlet Analysis using WaLSAtools Morlet_dominant_frequency , Morlet_averaged_power , Morlet_frequencies , Morlet_pm = WaLSAtools ( signal = signal_3d , time = time , method = 'wavelet' , mother = 'morlet' , RGWS = True , siglevel = 0.95 , format = 'txy' , averagedpower = True , dominantfreq = True ) # Normalize RGWS-Morlet averaged power to its maximum value Morlet_averaged_power_normalized = 100 * Morlet_averaged_power / np . max ( Morlet_averaged_power ) # RGWS-Paul Analysis using WaLSAtools Paul_dominant_frequency , Paul_averaged_power , Paul_frequencies , Paul_pm = WaLSAtools ( signal = signal_3d , time = time , method = 'wavelet' , mother = 'paul' , RGWS = True , siglevel = 0.95 , format = 'txy' , averagedpower = True , dominantfreq = True ) # Normalize RGWS-Paul averaged power to its maximum value Paul_averaged_power_normalized = 100 * Paul_averaged_power / np . max ( Paul_averaged_power ) Processing FFT for a 3D cube with format 'txy' and shape (200, 130, 130). Calculating Dominant frequencies and/or averaged power spectrum (FFT) .... Progress: 100.00% Analysis completed. Processing Wavelet for a 3D cube with format 'txy' and shape (200, 130, 130). Calculating Dominant frequencies and/or averaged power spectrum (Wavelet) .... Progress: 100.00% Analysis completed. Processing Wavelet for a 3D cube with format 'txy' and shape (200, 130, 130). Calculating Dominant frequencies and/or averaged power spectrum (Wavelet) .... Progress: 100.00% Analysis completed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 import matplotlib.pyplot as plt import numpy as np from matplotlib.ticker import AutoMinorLocator from matplotlib.colors import ListedColormap from mpl_toolkits.axes_grid1 import make_axes_locatable from mpl_toolkits.axes_grid1.inset_locator import inset_axes # Set up the figure layout fig = plt . figure ( figsize = ( 12.8 , 10 )) # Top row: 3 squared images positions_top = [ [ 0.079 , 0.484 , 0.234 , 0.4 ], # Left image [ 0.415 , 0.484 , 0.234 , 0.4 ], # Center image [ 0.755 , 0.484 , 0.234 , 0.4 ] # Right image ] # Define visualization parameters xticks_labels = [ '0' , ' ' , '40' , ' ' , '80' , ' ' , '120' ] # Load the RGB values from the IDL file and create the color map rgb_values = np . loadtxt ( 'Color_Tables/idl_walsa_powercolor_1.txt' ) rgb_values [ 0 ,:] = [ 255.0 , 255.0 , 255.0 ] rgb_values [ 255 ,:] = [ 0. , 0. , 0. ] rgb_values = rgb_values / 255.0 idl_colormap = ListedColormap ( rgb_values ) # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'Arial' , # Set Helvetica as the default sans-serif font 'font.size' : 19 , # Global font size 'axes.titlesize' : 20 , # Title font size 'axes.labelsize' : 18 , # Axis label font size 'xtick.labelsize' : 17 , # X-axis tick label font size 'ytick.labelsize' : 17 , # Y-axis tick label font size 'legend.fontsize' : 15 , # Legend font size 'figure.titlesize' : 19 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 'medium' , # Make all fonts bold 'axes.titleweight' : 'medium' , # Make title font bold 'axes.labelweight' : 'medium' # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.3 ) plt . rc ( 'lines' , linewidth = 1.7 ) # Plot the three snapshots in the top row for i in range ( 3 ): if i == 0 : im = FFT_dominant_frequency * 1000 # Convert to mHz colorbar_label = 'FFT \\n Dominant Frequency (mHz)' elif i == 1 : im = Morlet_dominant_frequency * 1000 # Convert to mHz colorbar_label = 'RGWS - Morlet \\n Dominant Frequency (mHz)' else : im = Paul_dominant_frequency * 1000 # Convert to mHz colorbar_label = 'RGWS - Paul \\n Dominant Frequency (mHz)' ax = fig . add_axes ( positions_top [ i ]) # Create each subplot in specified position DF = ax . imshow ( WaLSA_histo_opt ( im ), cmap = idl_colormap , aspect = 'equal' , origin = 'lower' , vmin = im . min (), vmax = im . max ()) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.4 ) # Major ticks ax . tick_params ( axis = 'x' , which = 'major' , pad = 8 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.4 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax . set_xlabel ( '(pixel)' ) ax . set_ylabel ( '(pixel)' , labelpad = 12 ) # Create an inset color bar axis above the plot divider = make_axes_locatable ( ax ) cax = inset_axes ( ax , width = \"100%\" , height = \"7.5%\" , loc = 'upper center' , borderpad =- 2.1 ) cbar = plt . colorbar ( DF , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 16 , linespacing = 2 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 7 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 4 , width = 1.2 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) # Define the range of the color bar and set major ticks at intervals of 100 tick_min = np . floor ( DF . get_clim ()[ 0 ]) tick_max = np . ceil ( DF . get_clim ()[ 1 ]) major_ticks = np . arange ( np . ceil ( tick_min / 100 ) * 100 , tick_max + 1 , 100 ) cbar . set_ticks ( major_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Bottom row: 1D signal plot filling the entire row ax1d = fig . add_axes ([ 0.08 , 0.08 , 0.906 , 0.291 ]) # [left, bottom, width, height] ax1d . plot ( FFT_frequencies * 1000 , FFT_averaged_power_normalized , color = 'DodgerBlue' , label = 'FFT' ) ax1d . plot ( Morlet_frequencies * 1000 , Morlet_averaged_power_normalized , color = 'Red' , label = 'RGWS (Morlet)' ) ax1d . plot ( Paul_frequencies * 1000 , Paul_averaged_power_normalized , color = 'Black' , label = 'RGWS (Paul)' ) ax1d . set_title ( 'Mean Power Spectra' , pad = 21 ) ax1d . set_xlabel ( 'Frequency (mHz)' , labelpad = 5 ) ax1d . set_ylabel ( 'Normalised Power' , labelpad = 12 ) ax1d . set_xlim ([ 20 , 640 ]) ax1d . set_ylim ( 0 , 115 ) # Set tick marks outside for all four axes ax1d . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals xtick_positions = range ( 50 , 650 , 50 ) # Major tick marks every 50 xlabel_positions = range ( 100 , 700 , 100 ) # Labels every 100 ax1d . set_xticks ( xtick_positions ) labels = [ str ( pos ) if pos in xlabel_positions else '' for pos in xtick_positions ] ax1d . set_xticklabels ( labels ) ax1d . set_yticks ( np . arange ( 0 , 115 , 20 )) # Custom tick sizes and thickness ax1d . tick_params ( axis = 'both' , which = 'major' , length = 10 , width = 1.4 , pad = 5 ) # Major ticks ax1d . tick_params ( axis = 'x' , which = 'major' , pad = 8 ) # Major ticks ax1d . tick_params ( axis = 'both' , which = 'minor' , length = 6 , width = 1.4 ) # Minor ticks # Set minor ticks ax1d . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax1d . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add custom labels manually to the plot .... to align the labels to the right handles , labels = ax1d . get_legend_handles_labels () # Define the vertical offset for each legend item offset = 0.17 for i , ( handle , label ) in enumerate ( zip ( handles , labels )): # Add the colored line ax1d . plot ( [ 0.935 , 0.98 ], # x coordinates (start and end of the line) [ 0.85 - offset * i , 0.85 - offset * i ], # y coordinates (constant to make it horizontal) transform = ax1d . transAxes , color = handle . get_color (), # Use the color from the original handle linestyle = handle . get_linestyle (), # Use the linestyle from the original handle linewidth = handle . get_linewidth (), # Use the linewidth from the original handle ) # Add the label text ax1d . text ( 0.925 , 0.85 - offset * i , label , transform = ax1d . transAxes , ha = 'right' , va = 'center' , fontsize = 17 , ) #-------------------------------------------------------------------------- # Save the figure as a single PDF pdf_path = 'Figures/Fig4_dominant_frequency_mean_power_spectra.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig4_dominant_frequency_mean_power_spectra.pdf'", "title": "Dominant Frequency"}, {"location": "python/dominant-frequency-example/#worked-example-nrmp-dominant-frequency", "text": "This example demonstrates the application of dominant frequency analysis to a synthetic spatio-temporal dataset. The dataset comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing the dominant frequencies at each spatial location, we can gain insights into the spatial distribution of oscillatory behaviour and identify potential wave modes. Analysis and Figure The figure below shows the dominant frequency maps calculated using different spectral analysis methods. The maps reveal the spatial distribution of the most prominent oscillation frequencies in the dataset. Methods used: Fast Fourier Transform (FFT) Refined Global Wavelet Spectrum (RGWS) with Morlet wavelet Refined Global Wavelet Spectrum (RGWS) with Paul wavelet WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Dominant frequency maps and mean power spectra. Top row: Dominant frequency maps derived using FFT (left), Morlet-based RGWS (middle), and Paul-based RGWS (right). Bottom panel: Normalized mean power spectra for FFT (blue), Morlet-based RGWS (red), and Paul-based RGWS (black). Important Notes on Interpreting the Dominant Frequencies The dominant frequency at each pixel corresponds to the frequency with the highest spectral power. While a linear detrending and Tukey apodization (with 0.1 tapering fraction) have been applied to reduce long-term trends and edge effects , the lowest frequency bin may still appear dominant \u2014 especially in regions without strong higher-frequency oscillations. This is a common outcome in time series with broad, low-frequency variability, where power is not concentrated at narrow peaks, or limited by frequency resolution. However, this does not necessarily reflect meaningful or coherent low-frequency wave activity . In the figure, white regions indicate pixels where the dominant frequency falls into the lowest frequency bin , which is explicitly mapped to white in the color table (see line 23 of the plotting routine). These are only visible in the FFT and Morlet-based RGWS maps. The Paul-based RGWS map, on the other hand, does not show white regions . This is because, for this method, the dominant frequencies tend to fall slightly above the lowest bin (around 100-120\u202fmHz ), even though the method includes lower frequencies. This behavior reflects the fundamental differences among the analysis techniques used: \ud83d\udccc FFT (Fast Fourier Transform) \u25cd Provides relatively high frequency resolution at all frequencies, with fixed, global basis functions. \u25cd Sensitive to any persistent oscillatory signal , but often returns low-frequency peaks if stronger high-frequency signals are absent. \u25cd In the averaged power spectrum, the dominant peak lies at 100\u202fmHz \u2014 the lowest available frequency bin. \ud83d\udccc Morlet-based RGWS \u25cd Uses the Morlet wavelet , which offers good frequency resolution but less precise time localization , particularly well-suited to capturing persistent oscillations with quasi-stationary frequencies. \u25cd As with all RGWS methods, the frequency resolution is non-uniform , leading to narrower and more pronounced peaks at lower frequencies , and broader, smoother features at higher frequencies in the power spectrum. \u25cd This causes the spectrum to mirror FFT\u2019s tendency to favor the lowest bin as dominant when no strong high-frequency signals are present, but with less detail in the dominant frequency map , compared to FFT, due to smoothing at high frequencies. \ud83d\udccc Paul-based RGWS \u25cd Employs the Paul wavelet , which has excellent time localization but poorer frequency resolution , particularly at low frequencies. This causes the lowest frequency bin to appear more diffuse, with power spread across a broader range, making sharp low-frequency peaks less distinguishable. \u25cd It responds strongly to short-lived or localized features in the data, but tends to underrepresent broad, slowly varying components . As a result, power in the lowest frequency bin is often weakened or distributed , making it less likely to be selected as dominant. \u25cd Consequently, the mean power spectrum peaks around 120\u202fmHz , and white regions do not appear in the dominant frequency map, since the 100\u202fmHz bin is rarely the strongest in this method. These differences emphasize that dominant frequency maps depend strongly on the method used , and should always be interpreted in tandem with the full power spectra (see bottom panel of Figure 4) and with awareness of each method's strengths and limitations. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf , WaLSA_histo_opt #-------------------------------------------------------------------------- # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic signal data time = hdul [ 1 ] . data # Time array hdul . close () cadence = 0.5 # cadence in seconds # FFT Analysis using WaLSAtools FFT_dominant_frequency , FFT_averaged_power , FFT_frequencies , FFT_pm = WaLSAtools ( signal = signal_3d , time = time , method = 'fft' , format = 'txy' , averagedpower = True , dominantfreq = True ) # Normalize FFT averaged power to its maximum value FFT_averaged_power_normalized = 100 * FFT_averaged_power / np . max ( FFT_averaged_power ) # RGWS-Morlet Analysis using WaLSAtools Morlet_dominant_frequency , Morlet_averaged_power , Morlet_frequencies , Morlet_pm = WaLSAtools ( signal = signal_3d , time = time , method = 'wavelet' , mother = 'morlet' , RGWS = True , siglevel = 0.95 , format = 'txy' , averagedpower = True , dominantfreq = True ) # Normalize RGWS-Morlet averaged power to its maximum value Morlet_averaged_power_normalized = 100 * Morlet_averaged_power / np . max ( Morlet_averaged_power ) # RGWS-Paul Analysis using WaLSAtools Paul_dominant_frequency , Paul_averaged_power , Paul_frequencies , Paul_pm = WaLSAtools ( signal = signal_3d , time = time , method = 'wavelet' , mother = 'paul' , RGWS = True , siglevel = 0.95 , format = 'txy' , averagedpower = True , dominantfreq = True ) # Normalize RGWS-Paul averaged power to its maximum value Paul_averaged_power_normalized = 100 * Paul_averaged_power / np . max ( Paul_averaged_power ) Processing FFT for a 3D cube with format 'txy' and shape (200, 130, 130). Calculating Dominant frequencies and/or averaged power spectrum (FFT) .... Progress: 100.00% Analysis completed. Processing Wavelet for a 3D cube with format 'txy' and shape (200, 130, 130). Calculating Dominant frequencies and/or averaged power spectrum (Wavelet) .... Progress: 100.00% Analysis completed. Processing Wavelet for a 3D cube with format 'txy' and shape (200, 130, 130). Calculating Dominant frequencies and/or averaged power spectrum (Wavelet) .... Progress: 100.00% Analysis completed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 import matplotlib.pyplot as plt import numpy as np from matplotlib.ticker import AutoMinorLocator from matplotlib.colors import ListedColormap from mpl_toolkits.axes_grid1 import make_axes_locatable from mpl_toolkits.axes_grid1.inset_locator import inset_axes # Set up the figure layout fig = plt . figure ( figsize = ( 12.8 , 10 )) # Top row: 3 squared images positions_top = [ [ 0.079 , 0.484 , 0.234 , 0.4 ], # Left image [ 0.415 , 0.484 , 0.234 , 0.4 ], # Center image [ 0.755 , 0.484 , 0.234 , 0.4 ] # Right image ] # Define visualization parameters xticks_labels = [ '0' , ' ' , '40' , ' ' , '80' , ' ' , '120' ] # Load the RGB values from the IDL file and create the color map rgb_values = np . loadtxt ( 'Color_Tables/idl_walsa_powercolor_1.txt' ) rgb_values [ 0 ,:] = [ 255.0 , 255.0 , 255.0 ] rgb_values [ 255 ,:] = [ 0. , 0. , 0. ] rgb_values = rgb_values / 255.0 idl_colormap = ListedColormap ( rgb_values ) # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'Arial' , # Set Helvetica as the default sans-serif font 'font.size' : 19 , # Global font size 'axes.titlesize' : 20 , # Title font size 'axes.labelsize' : 18 , # Axis label font size 'xtick.labelsize' : 17 , # X-axis tick label font size 'ytick.labelsize' : 17 , # Y-axis tick label font size 'legend.fontsize' : 15 , # Legend font size 'figure.titlesize' : 19 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 'medium' , # Make all fonts bold 'axes.titleweight' : 'medium' , # Make title font bold 'axes.labelweight' : 'medium' # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.3 ) plt . rc ( 'lines' , linewidth = 1.7 ) # Plot the three snapshots in the top row for i in range ( 3 ): if i == 0 : im = FFT_dominant_frequency * 1000 # Convert to mHz colorbar_label = 'FFT \\n Dominant Frequency (mHz)' elif i == 1 : im = Morlet_dominant_frequency * 1000 # Convert to mHz colorbar_label = 'RGWS - Morlet \\n Dominant Frequency (mHz)' else : im = Paul_dominant_frequency * 1000 # Convert to mHz colorbar_label = 'RGWS - Paul \\n Dominant Frequency (mHz)' ax = fig . add_axes ( positions_top [ i ]) # Create each subplot in specified position DF = ax . imshow ( WaLSA_histo_opt ( im ), cmap = idl_colormap , aspect = 'equal' , origin = 'lower' , vmin = im . min (), vmax = im . max ()) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.4 ) # Major ticks ax . tick_params ( axis = 'x' , which = 'major' , pad = 8 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.4 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax . set_xlabel ( '(pixel)' ) ax . set_ylabel ( '(pixel)' , labelpad = 12 ) # Create an inset color bar axis above the plot divider = make_axes_locatable ( ax ) cax = inset_axes ( ax , width = \"100%\" , height = \"7.5%\" , loc = 'upper center' , borderpad =- 2.1 ) cbar = plt . colorbar ( DF , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 16 , linespacing = 2 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 7 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 4 , width = 1.2 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 10 )) # Define the range of the color bar and set major ticks at intervals of 100 tick_min = np . floor ( DF . get_clim ()[ 0 ]) tick_max = np . ceil ( DF . get_clim ()[ 1 ]) major_ticks = np . arange ( np . ceil ( tick_min / 100 ) * 100 , tick_max + 1 , 100 ) cbar . set_ticks ( major_ticks ) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Bottom row: 1D signal plot filling the entire row ax1d = fig . add_axes ([ 0.08 , 0.08 , 0.906 , 0.291 ]) # [left, bottom, width, height] ax1d . plot ( FFT_frequencies * 1000 , FFT_averaged_power_normalized , color = 'DodgerBlue' , label = 'FFT' ) ax1d . plot ( Morlet_frequencies * 1000 , Morlet_averaged_power_normalized , color = 'Red' , label = 'RGWS (Morlet)' ) ax1d . plot ( Paul_frequencies * 1000 , Paul_averaged_power_normalized , color = 'Black' , label = 'RGWS (Paul)' ) ax1d . set_title ( 'Mean Power Spectra' , pad = 21 ) ax1d . set_xlabel ( 'Frequency (mHz)' , labelpad = 5 ) ax1d . set_ylabel ( 'Normalised Power' , labelpad = 12 ) ax1d . set_xlim ([ 20 , 640 ]) ax1d . set_ylim ( 0 , 115 ) # Set tick marks outside for all four axes ax1d . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals xtick_positions = range ( 50 , 650 , 50 ) # Major tick marks every 50 xlabel_positions = range ( 100 , 700 , 100 ) # Labels every 100 ax1d . set_xticks ( xtick_positions ) labels = [ str ( pos ) if pos in xlabel_positions else '' for pos in xtick_positions ] ax1d . set_xticklabels ( labels ) ax1d . set_yticks ( np . arange ( 0 , 115 , 20 )) # Custom tick sizes and thickness ax1d . tick_params ( axis = 'both' , which = 'major' , length = 10 , width = 1.4 , pad = 5 ) # Major ticks ax1d . tick_params ( axis = 'x' , which = 'major' , pad = 8 ) # Major ticks ax1d . tick_params ( axis = 'both' , which = 'minor' , length = 6 , width = 1.4 ) # Minor ticks # Set minor ticks ax1d . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax1d . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add custom labels manually to the plot .... to align the labels to the right handles , labels = ax1d . get_legend_handles_labels () # Define the vertical offset for each legend item offset = 0.17 for i , ( handle , label ) in enumerate ( zip ( handles , labels )): # Add the colored line ax1d . plot ( [ 0.935 , 0.98 ], # x coordinates (start and end of the line) [ 0.85 - offset * i , 0.85 - offset * i ], # y coordinates (constant to make it horizontal) transform = ax1d . transAxes , color = handle . get_color (), # Use the color from the original handle linestyle = handle . get_linestyle (), # Use the linestyle from the original handle linewidth = handle . get_linewidth (), # Use the linewidth from the original handle ) # Add the label text ax1d . text ( 0.925 , 0.85 - offset * i , label , transform = ax1d . transAxes , ha = 'right' , va = 'center' , fontsize = 17 , ) #-------------------------------------------------------------------------- # Save the figure as a single PDF pdf_path = 'Figures/Fig4_dominant_frequency_mean_power_spectra.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig4_dominant_frequency_mean_power_spectra.pdf'", "title": "Worked Example - NRMP: Dominant Frequency"}, {"location": "python/eemd-example/", "text": "Worked Example - NRMP: Ensemble Empirical Mode Decomposition (EEMD) \u00b6 This example demonstrates the application of Ensemble Empirical Mode Decomposition (EEMD) to a synthetic 1D signal. EEMD is an extension of EMD that addresses the issue of mode mixing by adding noise to the signal and performing multiple EMD decompositions. This ensemble approach improves the accuracy and robustness of the analysis, especially for noisy signals. Analysis and Figure The figure below shows the results of applying EEMD to the synthetic 1D signal. Methods used: Ensemble Empirical Mode Decomposition (EEMD) Hilbert Transform (to calculate instantaneous frequencies) Fast Fourier Transform (FFT) (to analyze the frequency content of the IMFs) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S3 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: EEMD analysis of the synthetic 1D signal. (a) IMFs extracted from the synthetic signal using EEMD. IMF 1 is marked with the grey background as non-significant (at 5%), based on a significance test. (b) Instantaneous frequencies of each IMF in Hz, revealing time-varying frequency content. \u00a9 HHT marginal spectrum (solid line) and its 95% confidence level (dashed line). (d) FFT power spectra of individual IMFs, with dashed lines indicating 95% confidence levels. The dotted vertical lines mark the oscillation frequencies of the synthetic signal. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from astropy.io import fits # type: ignore from WaLSAtools import WaLSAtools , WaLSA_save_pdf # type: ignore # Load the synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_1D.fits' ) signal = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Time array in the second HDU (Extension HDU 1) hdul . close () # EMD & HHT Calculations using WaLSAtools HHT_power_spectrum , HHT_significance_level , HHT_freq_bins , psd_spectra_fft , confidence_levels_fft , imfs , IMF_significance_levels , instantaneous_frequencies = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True ) Detrending and apodization complete. EEMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator import matplotlib.gridspec as gridspec def custom_round ( freq ): if freq < 1 : return round ( freq , 1 ) else : return round ( freq ) # Setting global parameters plt . rcParams . update ({ 'font.size' : 12 , # Global font size 'axes.titlesize' : 11 , # Title font size 'axes.labelsize' : 11 , # Axis label font size 'xtick.labelsize' : 10 , # X-axis tick label font size 'ytick.labelsize' : 10 , # Y-axis tick label font size 'legend.fontsize' : 12 , # Legend font size 'figure.titlesize' : 12.5 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) significance_threshold = 0.05 plt . rc ( 'axes' , linewidth = 1.0 ) plt . rc ( 'lines' , linewidth = 1.3 ) # Color cycle for consistency across plots colors = plt . cm . tab10 ( np . linspace ( 0 , 1 , len ( imfs ))) # Create a multi-panel plot with custom grid layout fig = plt . figure ( figsize = ( 8. , 9.2 ), constrained_layout = True ) gs = gridspec . GridSpec ( len ( imfs ) + 2 , 2 , height_ratios = [ 1 ] * len ( imfs ) + [ 0.3 , 2 ], figure = fig ) # Plot each IMF and its instantaneous frequency side by side for i , ( imf , freq ) in enumerate ( zip ( imfs , instantaneous_frequencies )): ax_imf = fig . add_subplot ( gs [ i , 0 ]) ax_if = fig . add_subplot ( gs [ i , 1 ]) if IMF_significance_levels [ i ] > significance_threshold : ax_imf . set_facecolor ( 'lightgray' ) ax_imf . plot ( time , imf , label = f 'IMF { i + 1 } ' , color = colors [ i ]) ax_imf . set_ylabel ( f 'IMF { i + 1 } ' ) ax_imf . yaxis . set_label_coords ( - 0.16 , 0.5 ) # Align y-axis labels ax_imf . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_imf . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax_imf . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_imf . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_imf . set_xticklabels ([]) # Hide x labels for all but the last IMF plot if i == 0 : ax_imf . set_title ( '(a) IMFs' ) ax_imf . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_imf . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_imf . set_xlabel ( 'Time (s)' ) if IMF_significance_levels [ i ] > significance_threshold : ax_if . set_facecolor ( 'lightgray' ) if len ( freq ) < len ( time ): freq = np . append ( freq , freq [ - 1 ]) # Extend freq to match the length of time ax_if . plot ( time , freq , label = f 'IF { i + 1 } ' , color = colors [ i ]) ax_if . set_ylabel ( f 'IF { i + 1 } (Hz)' ) ax_if . yaxis . set_label_coords ( - 0.1 , 0.5 ) # Align y-axis labels ax_if . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_if . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_if . set_xticklabels ([]) # Hide x labels for all but the last IF plot if i == 0 : ax_if . set_title ( '(b) Instantaneous Frequencies' ) ax_if . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_if . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_if . set_xlabel ( 'Time (s)' ) # Plot the HHT marginal spectrum and FFT spectra in the last row # Panel (c): HHT Marginal Spectrum ax_hht = fig . add_subplot ( gs [ - 1 , 0 ]) # freq_bins = np.linspace(0, 50, len(HHT_power_spectrum)) # Assuming a maximum frequency of 50 Hz for illustration ax_hht . plot ( HHT_freq_bins , HHT_power_spectrum , color = 'black' ) ax_hht . plot ( HHT_freq_bins , HHT_significance_level , linestyle = '--' , color = 'green' ) ax_hht . set_title ( '(c) HHT Marginal Spectrum' ) ax_hht . set_xlabel ( 'Frequency (Hz)' ) ax_hht . set_ylabel ( 'Power' ) ax_hht . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_hht . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_hht . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_hht . set_xlim ( 0 , 36 ) ax_hht . set_ylim ( bottom = 0 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Panel (d): FFT Spectra of IMFs ax_fft = fig . add_subplot ( gs [ - 1 , 1 ]) for i , ( xf , psd ) in enumerate ( psd_spectra_fft ): ax_fft . plot ( xf , psd , label = f 'IMF { i + 1 } ' , color = colors [ i ]) for i , confidence_level in enumerate ( confidence_levels_fft ): ax_fft . plot ( xf , confidence_level , linestyle = '--' , color = colors [ i ]) ax_fft . set_title ( '(d) FFT Spectra of IMFs' ) ax_fft . set_xlabel ( 'Frequency (Hz)' ) ax_fft . set_ylabel ( 'Power' ) ax_fft . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_fft . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_fft . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_fft . set_xlim ( 0 , 36 ) ax_fft . set_ylim ( 0 , 1.5 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Save the figure as a PDF pdf_path = 'Figures/FigS3_EEMD_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS3_EEMD_analysis.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Further tests # Plot frequency distributions for each IMF plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( instantaneous_frequencies ))) for i , freqs in enumerate ( instantaneous_frequencies ): counts , bins = np . histogram ( freqs , bins = 'auto' , density = True ) counts = counts / counts . max () # Normalize to maximum value plt . hist ( bins [: - 1 ], bins , weights = counts , alpha = 0.7 , color = colors [ i ], label = f 'IMF { i + 1 } ' , histtype = 'stepfilled' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'Normalized Density' ) plt . title ( 'Normalized Frequency Distributions of IMFs' ) plt . legend () plt . xlim ( 0 , 36 ) plt . tight_layout () plt . show () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Further tests # EMD & HHT Calculations using WaLSAtools - Welch PSD Spectra _ , _ , _ , psd_spectra_welch , confidence_levels_welch , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True , Welch_psd = True ) plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( psd_spectra_welch ))) for i , ( f , psd ) in enumerate ( psd_spectra_welch ): plt . plot ( f , psd , color = colors [ i ], label = f 'IMF { i + 1 } ' ) plt . plot ( f , confidence_levels_welch [ i ], color = colors [ i ], linestyle = '--' , label = f '95% Confidence Level IMF { i + 1 } ' ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'PSD' ) plt . title ( 'Welch PSD Spectra of IMFs with 95% Confidence Levels' ) plt . legend () plt . show () Detrending and apodization complete. EEMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Further tests # FFT Spectra of individual significant IMFs (i.e., excluding the non-significant IMFs) - using EEMD _ , _ , _ , psd_spectra_welch , confidence_levels_welch , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True , significant_imfs = True ) plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( psd_spectra_welch ))) for i , ( f , psd ) in enumerate ( psd_spectra_welch ): plt . plot ( f , psd , color = colors [ i ], label = f 'IMF { i + 1 } ' ) plt . plot ( f , confidence_levels_welch [ i ], color = colors [ i ], linestyle = '--' , label = f '95% Confidence Level IMF { i + 1 } ' ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'PSD' ) plt . title ( 'Welch PSD Spectra of IMFs with 95% Confidence Levels' ) plt . legend () plt . ylim ( 0 , 1.5 ) plt . show () Detrending and apodization complete. EEMD processed.", "title": "EEMD"}, {"location": "python/eemd-example/#worked-example-nrmp-ensemble-empirical-mode-decomposition-eemd", "text": "This example demonstrates the application of Ensemble Empirical Mode Decomposition (EEMD) to a synthetic 1D signal. EEMD is an extension of EMD that addresses the issue of mode mixing by adding noise to the signal and performing multiple EMD decompositions. This ensemble approach improves the accuracy and robustness of the analysis, especially for noisy signals. Analysis and Figure The figure below shows the results of applying EEMD to the synthetic 1D signal. Methods used: Ensemble Empirical Mode Decomposition (EEMD) Hilbert Transform (to calculate instantaneous frequencies) Fast Fourier Transform (FFT) (to analyze the frequency content of the IMFs) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S3 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: EEMD analysis of the synthetic 1D signal. (a) IMFs extracted from the synthetic signal using EEMD. IMF 1 is marked with the grey background as non-significant (at 5%), based on a significance test. (b) Instantaneous frequencies of each IMF in Hz, revealing time-varying frequency content. \u00a9 HHT marginal spectrum (solid line) and its 95% confidence level (dashed line). (d) FFT power spectra of individual IMFs, with dashed lines indicating 95% confidence levels. The dotted vertical lines mark the oscillation frequencies of the synthetic signal. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 from astropy.io import fits # type: ignore from WaLSAtools import WaLSAtools , WaLSA_save_pdf # type: ignore # Load the synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_1D.fits' ) signal = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Time array in the second HDU (Extension HDU 1) hdul . close () # EMD & HHT Calculations using WaLSAtools HHT_power_spectrum , HHT_significance_level , HHT_freq_bins , psd_spectra_fft , confidence_levels_fft , imfs , IMF_significance_levels , instantaneous_frequencies = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True ) Detrending and apodization complete. EEMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator import matplotlib.gridspec as gridspec def custom_round ( freq ): if freq < 1 : return round ( freq , 1 ) else : return round ( freq ) # Setting global parameters plt . rcParams . update ({ 'font.size' : 12 , # Global font size 'axes.titlesize' : 11 , # Title font size 'axes.labelsize' : 11 , # Axis label font size 'xtick.labelsize' : 10 , # X-axis tick label font size 'ytick.labelsize' : 10 , # Y-axis tick label font size 'legend.fontsize' : 12 , # Legend font size 'figure.titlesize' : 12.5 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) significance_threshold = 0.05 plt . rc ( 'axes' , linewidth = 1.0 ) plt . rc ( 'lines' , linewidth = 1.3 ) # Color cycle for consistency across plots colors = plt . cm . tab10 ( np . linspace ( 0 , 1 , len ( imfs ))) # Create a multi-panel plot with custom grid layout fig = plt . figure ( figsize = ( 8. , 9.2 ), constrained_layout = True ) gs = gridspec . GridSpec ( len ( imfs ) + 2 , 2 , height_ratios = [ 1 ] * len ( imfs ) + [ 0.3 , 2 ], figure = fig ) # Plot each IMF and its instantaneous frequency side by side for i , ( imf , freq ) in enumerate ( zip ( imfs , instantaneous_frequencies )): ax_imf = fig . add_subplot ( gs [ i , 0 ]) ax_if = fig . add_subplot ( gs [ i , 1 ]) if IMF_significance_levels [ i ] > significance_threshold : ax_imf . set_facecolor ( 'lightgray' ) ax_imf . plot ( time , imf , label = f 'IMF { i + 1 } ' , color = colors [ i ]) ax_imf . set_ylabel ( f 'IMF { i + 1 } ' ) ax_imf . yaxis . set_label_coords ( - 0.16 , 0.5 ) # Align y-axis labels ax_imf . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_imf . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax_imf . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_imf . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_imf . set_xticklabels ([]) # Hide x labels for all but the last IMF plot if i == 0 : ax_imf . set_title ( '(a) IMFs' ) ax_imf . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_imf . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_imf . set_xlabel ( 'Time (s)' ) if IMF_significance_levels [ i ] > significance_threshold : ax_if . set_facecolor ( 'lightgray' ) if len ( freq ) < len ( time ): freq = np . append ( freq , freq [ - 1 ]) # Extend freq to match the length of time ax_if . plot ( time , freq , label = f 'IF { i + 1 } ' , color = colors [ i ]) ax_if . set_ylabel ( f 'IF { i + 1 } (Hz)' ) ax_if . yaxis . set_label_coords ( - 0.1 , 0.5 ) # Align y-axis labels ax_if . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_if . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_if . set_xticklabels ([]) # Hide x labels for all but the last IF plot if i == 0 : ax_if . set_title ( '(b) Instantaneous Frequencies' ) ax_if . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_if . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_if . set_xlabel ( 'Time (s)' ) # Plot the HHT marginal spectrum and FFT spectra in the last row # Panel (c): HHT Marginal Spectrum ax_hht = fig . add_subplot ( gs [ - 1 , 0 ]) # freq_bins = np.linspace(0, 50, len(HHT_power_spectrum)) # Assuming a maximum frequency of 50 Hz for illustration ax_hht . plot ( HHT_freq_bins , HHT_power_spectrum , color = 'black' ) ax_hht . plot ( HHT_freq_bins , HHT_significance_level , linestyle = '--' , color = 'green' ) ax_hht . set_title ( '(c) HHT Marginal Spectrum' ) ax_hht . set_xlabel ( 'Frequency (Hz)' ) ax_hht . set_ylabel ( 'Power' ) ax_hht . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_hht . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_hht . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_hht . set_xlim ( 0 , 36 ) ax_hht . set_ylim ( bottom = 0 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Panel (d): FFT Spectra of IMFs ax_fft = fig . add_subplot ( gs [ - 1 , 1 ]) for i , ( xf , psd ) in enumerate ( psd_spectra_fft ): ax_fft . plot ( xf , psd , label = f 'IMF { i + 1 } ' , color = colors [ i ]) for i , confidence_level in enumerate ( confidence_levels_fft ): ax_fft . plot ( xf , confidence_level , linestyle = '--' , color = colors [ i ]) ax_fft . set_title ( '(d) FFT Spectra of IMFs' ) ax_fft . set_xlabel ( 'Frequency (Hz)' ) ax_fft . set_ylabel ( 'Power' ) ax_fft . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_fft . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_fft . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_fft . set_xlim ( 0 , 36 ) ax_fft . set_ylim ( 0 , 1.5 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Save the figure as a PDF pdf_path = 'Figures/FigS3_EEMD_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS3_EEMD_analysis.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Further tests # Plot frequency distributions for each IMF plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( instantaneous_frequencies ))) for i , freqs in enumerate ( instantaneous_frequencies ): counts , bins = np . histogram ( freqs , bins = 'auto' , density = True ) counts = counts / counts . max () # Normalize to maximum value plt . hist ( bins [: - 1 ], bins , weights = counts , alpha = 0.7 , color = colors [ i ], label = f 'IMF { i + 1 } ' , histtype = 'stepfilled' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'Normalized Density' ) plt . title ( 'Normalized Frequency Distributions of IMFs' ) plt . legend () plt . xlim ( 0 , 36 ) plt . tight_layout () plt . show () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Further tests # EMD & HHT Calculations using WaLSAtools - Welch PSD Spectra _ , _ , _ , psd_spectra_welch , confidence_levels_welch , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True , Welch_psd = True ) plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( psd_spectra_welch ))) for i , ( f , psd ) in enumerate ( psd_spectra_welch ): plt . plot ( f , psd , color = colors [ i ], label = f 'IMF { i + 1 } ' ) plt . plot ( f , confidence_levels_welch [ i ], color = colors [ i ], linestyle = '--' , label = f '95% Confidence Level IMF { i + 1 } ' ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'PSD' ) plt . title ( 'Welch PSD Spectra of IMFs with 95% Confidence Levels' ) plt . legend () plt . show () Detrending and apodization complete. EEMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Further tests # FFT Spectra of individual significant IMFs (i.e., excluding the non-significant IMFs) - using EEMD _ , _ , _ , psd_spectra_welch , confidence_levels_welch , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True , significant_imfs = True ) plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( psd_spectra_welch ))) for i , ( f , psd ) in enumerate ( psd_spectra_welch ): plt . plot ( f , psd , color = colors [ i ], label = f 'IMF { i + 1 } ' ) plt . plot ( f , confidence_levels_welch [ i ], color = colors [ i ], linestyle = '--' , label = f '95% Confidence Level IMF { i + 1 } ' ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'PSD' ) plt . title ( 'Welch PSD Spectra of IMFs with 95% Confidence Levels' ) plt . legend () plt . ylim ( 0 , 1.5 ) plt . show () Detrending and apodization complete. EEMD processed.", "title": "Worked Example - NRMP: Ensemble Empirical Mode Decomposition (EEMD)"}, {"location": "python/emd-example/", "text": "Worked Example - NRMP: Empirical Mode Decomposition (EMD) \u00b6 This example demonstrates the application of Empirical Mode Decomposition (EMD) to a synthetic 1D signal. EMD is a data-driven technique that decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. Analysis and Figure The figure below shows the results of applying EMD to the synthetic 1D signal. Methods used: Empirical Mode Decomposition (EMD) Hilbert Transform (to calculate instantaneous frequencies) Fast Fourier Transform (FFT) (to analyze the frequency content of the IMFs) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S2 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: EMD analysis of the synthetic 1D signal. (a) IMFs extracted from the synthetic signal using EMD. IMFs 4, 5, and 6 are marked with the grey background as non-significant (at 5%) based on a significance test. (b) Instantaneous frequencies of each IMF. \u00a9 HHT marginal spectrum. (d) FFT power spectra of individual IMFs. The dashed lines in both panels \u00a9 and (d) indicate the 95% confidence levels. Note that the powers in panels \u00a9 and (d) are shown in arbitrary units. The dotted vertical lines mark the oscillation frequencies of the synthetic signal. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from astropy.io import fits # type: ignore from WaLSAtools import WaLSAtools , WaLSA_save_pdf # type: ignore # Load the synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_1D.fits' ) signal = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Time array in the second HDU (Extension HDU 1) hdul . close () sampling_rate = 100 # Hz duration = 10 # seconds # EMD & HHT Calculations using WaLSAtools HHT_power_spectrum , HHT_significance_level , HHT_freq_bins , psd_spectra_fft , confidence_levels_fft , imfs , IMF_significance_levels , instantaneous_frequencies = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 ) Detrending and apodization complete. EMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator import matplotlib.gridspec as gridspec def custom_round ( freq ): if freq < 1 : return round ( freq , 1 ) else : return round ( freq ) # Setting global parameters plt . rcParams . update ({ 'font.size' : 12 , # Global font size 'axes.titlesize' : 11 , # Title font size 'axes.labelsize' : 11 , # Axis label font size 'xtick.labelsize' : 10 , # X-axis tick label font size 'ytick.labelsize' : 10 , # Y-axis tick label font size 'legend.fontsize' : 12 , # Legend font size 'figure.titlesize' : 12.5 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) significance_threshold = 0.05 plt . rc ( 'axes' , linewidth = 1.0 ) plt . rc ( 'lines' , linewidth = 1.3 ) # Color cycle for consistency across plots colors = plt . cm . tab10 ( np . linspace ( 0 , 1 , len ( imfs ))) # Create a multi-panel plot with custom grid layout fig = plt . figure ( figsize = ( 8. , 9.2 ), constrained_layout = True ) gs = gridspec . GridSpec ( len ( imfs ) + 2 , 2 , height_ratios = [ 1 ] * len ( imfs ) + [ 0.3 , 2 ], figure = fig ) # Plot each IMF and its instantaneous frequency side by side for i , ( imf , freq ) in enumerate ( zip ( imfs , instantaneous_frequencies )): ax_imf = fig . add_subplot ( gs [ i , 0 ]) ax_if = fig . add_subplot ( gs [ i , 1 ]) if IMF_significance_levels [ i ] > significance_threshold : ax_imf . set_facecolor ( 'lightgray' ) ax_imf . plot ( time , imf , label = f 'IMF { i + 1 } ' , color = colors [ i ]) ax_imf . set_ylabel ( f 'IMF { i + 1 } ' ) ax_imf . yaxis . set_label_coords ( - 0.16 , 0.5 ) # Align y-axis labels ax_imf . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_imf . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax_imf . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_imf . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_imf . set_xticklabels ([]) # Hide x labels for all but the last IMF plot if i == 0 : ax_imf . set_title ( '(a) IMFs' ) ax_imf . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_imf . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_imf . set_xlabel ( 'Time (s)' ) if IMF_significance_levels [ i ] > significance_threshold : ax_if . set_facecolor ( 'lightgray' ) if len ( freq ) < len ( time ): freq = np . append ( freq , freq [ - 1 ]) # Extend freq to match the length of time ax_if . plot ( time , freq , label = f 'IF { i + 1 } ' , color = colors [ i ]) ax_if . set_ylabel ( f 'IF { i + 1 } (Hz)' ) ax_if . yaxis . set_label_coords ( - 0.1 , 0.5 ) # Align y-axis labels ax_if . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_if . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_if . set_xticklabels ([]) # Hide x labels for all but the last IF plot if i == 0 : ax_if . set_title ( '(b) Instantaneous Frequencies' ) ax_if . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_if . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_if . set_xlabel ( 'Time (s)' ) # Plot the HHT marginal spectrum and FFT spectra in the last row # Panel (c): HHT Marginal Spectrum ax_hht = fig . add_subplot ( gs [ - 1 , 0 ]) # freq_bins = np.linspace(0, 50, len(HHT_power_spectrum)) # Assuming a maximum frequency of 50 Hz for illustration ax_hht . plot ( HHT_freq_bins , HHT_power_spectrum , color = 'black' ) ax_hht . plot ( HHT_freq_bins , HHT_significance_level , linestyle = '--' , color = 'green' ) ax_hht . set_title ( '(c) HHT Marginal Spectrum' ) ax_hht . set_xlabel ( 'Frequency (Hz)' ) ax_hht . set_ylabel ( 'Power' ) ax_hht . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_hht . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_hht . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_hht . set_xlim ( 0 , 36 ) ax_hht . set_ylim ( bottom = 0 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Panel (d): FFT Spectra of IMFs ax_fft = fig . add_subplot ( gs [ - 1 , 1 ]) for i , ( xf , psd ) in enumerate ( psd_spectra_fft ): ax_fft . plot ( xf , psd , label = f 'IMF { i + 1 } ' , color = colors [ i ]) for i , confidence_level in enumerate ( confidence_levels_fft ): ax_fft . plot ( xf , confidence_level , linestyle = '--' , color = colors [ i ]) ax_fft . set_title ( '(d) FFT Spectra of IMFs' ) ax_fft . set_xlabel ( 'Frequency (Hz)' ) ax_fft . set_ylabel ( 'Power' ) ax_fft . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_fft . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_fft . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_fft . set_xlim ( 0 , 36 ) ax_fft . set_ylim ( 0 , 2.5 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Save the figure as a PDF pdf_path = 'Figures/FigS2_EMD_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS2_EMD_analysis.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Further tests # Plot frequency distributions for each IMF plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( instantaneous_frequencies ))) for i , freqs in enumerate ( instantaneous_frequencies ): counts , bins = np . histogram ( freqs , bins = 'auto' , density = True ) counts = counts / counts . max () # Normalize to maximum value plt . hist ( bins [: - 1 ], bins , weights = counts , alpha = 0.7 , color = colors [ i ], label = f 'IMF { i + 1 } ' , histtype = 'stepfilled' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'Normalized Density' ) plt . title ( 'Normalized Frequency Distributions of IMFs' ) plt . legend () plt . xlim ( 0 , 36 ) plt . tight_layout () plt . show () # Further tests # EMD & HHT Calculations using WaLSAtools - Welch PSD Spectra _ , _ , _ , psd_spectra_welch , confidence_levels_welch , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , Welch_psd = True ) plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( psd_spectra_welch ))) for i , ( f , psd ) in enumerate ( psd_spectra_welch ): plt . plot ( f , psd , color = colors [ i ], label = f 'IMF { i + 1 } ' ) plt . plot ( f , confidence_levels_welch [ i ], color = colors [ i ], linestyle = '--' , label = f '95% Confidence Level IMF { i + 1 } ' ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'PSD' ) plt . title ( 'Welch PSD Spectra of IMFs with 95% Confidence Levels' ) plt . legend () plt . show () Detrending and apodization complete. EMD processed.", "title": "EMD"}, {"location": "python/emd-example/#worked-example-nrmp-empirical-mode-decomposition-emd", "text": "This example demonstrates the application of Empirical Mode Decomposition (EMD) to a synthetic 1D signal. EMD is a data-driven technique that decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. Analysis and Figure The figure below shows the results of applying EMD to the synthetic 1D signal. Methods used: Empirical Mode Decomposition (EMD) Hilbert Transform (to calculate instantaneous frequencies) Fast Fourier Transform (FFT) (to analyze the frequency content of the IMFs) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S2 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: EMD analysis of the synthetic 1D signal. (a) IMFs extracted from the synthetic signal using EMD. IMFs 4, 5, and 6 are marked with the grey background as non-significant (at 5%) based on a significance test. (b) Instantaneous frequencies of each IMF. \u00a9 HHT marginal spectrum. (d) FFT power spectra of individual IMFs. The dashed lines in both panels \u00a9 and (d) indicate the 95% confidence levels. Note that the powers in panels \u00a9 and (d) are shown in arbitrary units. The dotted vertical lines mark the oscillation frequencies of the synthetic signal. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from astropy.io import fits # type: ignore from WaLSAtools import WaLSAtools , WaLSA_save_pdf # type: ignore # Load the synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_1D.fits' ) signal = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Time array in the second HDU (Extension HDU 1) hdul . close () sampling_rate = 100 # Hz duration = 10 # seconds # EMD & HHT Calculations using WaLSAtools HHT_power_spectrum , HHT_significance_level , HHT_freq_bins , psd_spectra_fft , confidence_levels_fft , imfs , IMF_significance_levels , instantaneous_frequencies = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 ) Detrending and apodization complete. EMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator import matplotlib.gridspec as gridspec def custom_round ( freq ): if freq < 1 : return round ( freq , 1 ) else : return round ( freq ) # Setting global parameters plt . rcParams . update ({ 'font.size' : 12 , # Global font size 'axes.titlesize' : 11 , # Title font size 'axes.labelsize' : 11 , # Axis label font size 'xtick.labelsize' : 10 , # X-axis tick label font size 'ytick.labelsize' : 10 , # Y-axis tick label font size 'legend.fontsize' : 12 , # Legend font size 'figure.titlesize' : 12.5 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) significance_threshold = 0.05 plt . rc ( 'axes' , linewidth = 1.0 ) plt . rc ( 'lines' , linewidth = 1.3 ) # Color cycle for consistency across plots colors = plt . cm . tab10 ( np . linspace ( 0 , 1 , len ( imfs ))) # Create a multi-panel plot with custom grid layout fig = plt . figure ( figsize = ( 8. , 9.2 ), constrained_layout = True ) gs = gridspec . GridSpec ( len ( imfs ) + 2 , 2 , height_ratios = [ 1 ] * len ( imfs ) + [ 0.3 , 2 ], figure = fig ) # Plot each IMF and its instantaneous frequency side by side for i , ( imf , freq ) in enumerate ( zip ( imfs , instantaneous_frequencies )): ax_imf = fig . add_subplot ( gs [ i , 0 ]) ax_if = fig . add_subplot ( gs [ i , 1 ]) if IMF_significance_levels [ i ] > significance_threshold : ax_imf . set_facecolor ( 'lightgray' ) ax_imf . plot ( time , imf , label = f 'IMF { i + 1 } ' , color = colors [ i ]) ax_imf . set_ylabel ( f 'IMF { i + 1 } ' ) ax_imf . yaxis . set_label_coords ( - 0.16 , 0.5 ) # Align y-axis labels ax_imf . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_imf . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax_imf . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_imf . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_imf . set_xticklabels ([]) # Hide x labels for all but the last IMF plot if i == 0 : ax_imf . set_title ( '(a) IMFs' ) ax_imf . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_imf . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_imf . set_xlabel ( 'Time (s)' ) if IMF_significance_levels [ i ] > significance_threshold : ax_if . set_facecolor ( 'lightgray' ) if len ( freq ) < len ( time ): freq = np . append ( freq , freq [ - 1 ]) # Extend freq to match the length of time ax_if . plot ( time , freq , label = f 'IF { i + 1 } ' , color = colors [ i ]) ax_if . set_ylabel ( f 'IF { i + 1 } (Hz)' ) ax_if . yaxis . set_label_coords ( - 0.1 , 0.5 ) # Align y-axis labels ax_if . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_if . tick_params ( axis = 'both' , which = 'major' , direction = 'in' , length = 6 , width = 1.0 ) ax_if . tick_params ( axis = 'both' , which = 'minor' , direction = 'in' , length = 3 , width = 1.0 ) if i < len ( imfs ) - 1 : ax_if . set_xticklabels ([]) # Hide x labels for all but the last IF plot if i == 0 : ax_if . set_title ( '(b) Instantaneous Frequencies' ) ax_if . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_if . set_xlim ( 0 , 10 ) if i == len ( imfs ) - 1 : ax_if . set_xlabel ( 'Time (s)' ) # Plot the HHT marginal spectrum and FFT spectra in the last row # Panel (c): HHT Marginal Spectrum ax_hht = fig . add_subplot ( gs [ - 1 , 0 ]) # freq_bins = np.linspace(0, 50, len(HHT_power_spectrum)) # Assuming a maximum frequency of 50 Hz for illustration ax_hht . plot ( HHT_freq_bins , HHT_power_spectrum , color = 'black' ) ax_hht . plot ( HHT_freq_bins , HHT_significance_level , linestyle = '--' , color = 'green' ) ax_hht . set_title ( '(c) HHT Marginal Spectrum' ) ax_hht . set_xlabel ( 'Frequency (Hz)' ) ax_hht . set_ylabel ( 'Power' ) ax_hht . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_hht . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_hht . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_hht . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_hht . set_xlim ( 0 , 36 ) ax_hht . set_ylim ( bottom = 0 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Panel (d): FFT Spectra of IMFs ax_fft = fig . add_subplot ( gs [ - 1 , 1 ]) for i , ( xf , psd ) in enumerate ( psd_spectra_fft ): ax_fft . plot ( xf , psd , label = f 'IMF { i + 1 } ' , color = colors [ i ]) for i , confidence_level in enumerate ( confidence_levels_fft ): ax_fft . plot ( xf , confidence_level , linestyle = '--' , color = colors [ i ]) ax_fft . set_title ( '(d) FFT Spectra of IMFs' ) ax_fft . set_xlabel ( 'Frequency (Hz)' ) ax_fft . set_ylabel ( 'Power' ) ax_fft . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_fft . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 6 , width = 1.0 ) ax_fft . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 3 , width = 1.0 ) ax_fft . tick_params ( axis = 'x' , which = 'both' , top = False ) # Turn off upper x-axis ticks ax_fft . set_xlim ( 0 , 36 ) ax_fft . set_ylim ( 0 , 2.5 ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : rounded_freq = custom_round ( freq ) plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) # Save the figure as a PDF pdf_path = 'Figures/FigS2_EMD_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS2_EMD_analysis.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Further tests # Plot frequency distributions for each IMF plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( instantaneous_frequencies ))) for i , freqs in enumerate ( instantaneous_frequencies ): counts , bins = np . histogram ( freqs , bins = 'auto' , density = True ) counts = counts / counts . max () # Normalize to maximum value plt . hist ( bins [: - 1 ], bins , weights = counts , alpha = 0.7 , color = colors [ i ], label = f 'IMF { i + 1 } ' , histtype = 'stepfilled' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'Normalized Density' ) plt . title ( 'Normalized Frequency Distributions of IMFs' ) plt . legend () plt . xlim ( 0 , 36 ) plt . tight_layout () plt . show () # Further tests # EMD & HHT Calculations using WaLSAtools - Welch PSD Spectra _ , _ , _ , psd_spectra_welch , confidence_levels_welch , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , Welch_psd = True ) plt . figure ( figsize = ( 12 , 8 )) colors = plt . cm . tab20 ( np . linspace ( 0 , 1 , len ( psd_spectra_welch ))) for i , ( f , psd ) in enumerate ( psd_spectra_welch ): plt . plot ( f , psd , color = colors [ i ], label = f 'IMF { i + 1 } ' ) plt . plot ( f , confidence_levels_welch [ i ], color = colors [ i ], linestyle = '--' , label = f '95% Confidence Level IMF { i + 1 } ' ) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] for freq in pre_defined_freq : plt . axvline ( x = freq , color = 'gray' , linestyle = ':' ) plt . xlabel ( 'Frequency (Hz)' ) plt . ylabel ( 'PSD' ) plt . title ( 'Welch PSD Spectra of IMFs with 95% Confidence Levels' ) plt . legend () plt . show () Detrending and apodization complete. EMD processed.", "title": "Worked Example - NRMP: Empirical Mode Decomposition (EMD)"}, {"location": "python/installation/", "text": "Installation \u00b6 Install WaLSAtools \u00b6 This page provides a direct and simple installation guide for WaLSAtools . For a complete beginner-friendly setup from scratch, see the Beginner's Guide . Prerequisites \u00b6 Before installing WaLSAtools, ensure you have the following: Python 3.8 or later installed. \ud83d\udc49 You can download the latest version of Python from https://www.python.org/downloads/ if needed. pip (Python package installer) available. \ud83d\udc49 You can check by running: pip --version If you do not have pip, follow the official installation guide . Recommended Python version We have tested WaLSAtools most extensively with Python 3.12.8 . Virtual Environment (Recommended): To avoid conflicts with existing packages (especially due to major changes in packages like NumPy 2.0+), we strongly recommend installing WaLSAtools inside a fresh virtual environment. This keeps WaLSAtools and its dependencies isolated from your system-wide Python or other projects. If you are new to virtual environments, you can refer to our Beginner's Guide for a full setup tutorial. Installation via pip (Recommended) \u00b6 To install the latest stable release from PyPI (Python Package Index), simply run: pip install WaLSAtools This will automatically download and install WaLSAtools and its required dependencies into your environment. Tip: Upgrade pip first Before installing any package, it is good practice to upgrade pip: pip install --upgrade pip Installation from Source (Optional) \u00b6 If you prefer installing the development version directly from GitHub: Clone (or Download) the WaLSAtools GitHub repository: git clone https://github.com/WaLSAteam/WaLSAtools.git Navigate to the Python codes directory: cd WaLSAtools/codes/python/ Install using pip: pip install . Alternatively, you can use the traditional setup: python setup.py install This method ensures you have access to the latest updates and examples. Cloning the GitHub repository Even if you install WaLSAtools via PyPI, we strongly recommend also cloning the WaLSAtools GitHub repository. This gives you full access to the source code, worked examples, and documentation files, and ensures you can easily explore, customize, or contribute to the project. Verifying the Installation \u00b6 After installation, verify that WaLSAtools is properly installed. You can check inside the terminal by launching Python and typing: from WaLSAtools import WaLSAtools WaLSAtools If installed correctly, WaLSAtools\u2019 interactive welcome menu will appear \ud83c\udf89 Need Help? \u00b6 If you encounter any issues during installation, first check our Troubleshooting and/or Beginner's Guide pages. If you still need help, browse the topics in our GitHub discussion \u2014 and feel free to post your question if your issue has not yet been addressed.", "title": "Installation"}, {"location": "python/installation/#installation", "text": "", "title": "Installation"}, {"location": "python/installation/#install-walsatools", "text": "This page provides a direct and simple installation guide for WaLSAtools . For a complete beginner-friendly setup from scratch, see the Beginner's Guide .", "title": "Install WaLSAtools"}, {"location": "python/installation/#prerequisites", "text": "Before installing WaLSAtools, ensure you have the following: Python 3.8 or later installed. \ud83d\udc49 You can download the latest version of Python from https://www.python.org/downloads/ if needed. pip (Python package installer) available. \ud83d\udc49 You can check by running: pip --version If you do not have pip, follow the official installation guide . Recommended Python version We have tested WaLSAtools most extensively with Python 3.12.8 . Virtual Environment (Recommended): To avoid conflicts with existing packages (especially due to major changes in packages like NumPy 2.0+), we strongly recommend installing WaLSAtools inside a fresh virtual environment. This keeps WaLSAtools and its dependencies isolated from your system-wide Python or other projects. If you are new to virtual environments, you can refer to our Beginner's Guide for a full setup tutorial.", "title": "Prerequisites"}, {"location": "python/installation/#installation-via-pip-recommended", "text": "To install the latest stable release from PyPI (Python Package Index), simply run: pip install WaLSAtools This will automatically download and install WaLSAtools and its required dependencies into your environment. Tip: Upgrade pip first Before installing any package, it is good practice to upgrade pip: pip install --upgrade pip", "title": "Installation via pip (Recommended)"}, {"location": "python/installation/#installation-from-source-optional", "text": "If you prefer installing the development version directly from GitHub: Clone (or Download) the WaLSAtools GitHub repository: git clone https://github.com/WaLSAteam/WaLSAtools.git Navigate to the Python codes directory: cd WaLSAtools/codes/python/ Install using pip: pip install . Alternatively, you can use the traditional setup: python setup.py install This method ensures you have access to the latest updates and examples. Cloning the GitHub repository Even if you install WaLSAtools via PyPI, we strongly recommend also cloning the WaLSAtools GitHub repository. This gives you full access to the source code, worked examples, and documentation files, and ensures you can easily explore, customize, or contribute to the project.", "title": "Installation from Source (Optional)"}, {"location": "python/installation/#verifying-the-installation", "text": "After installation, verify that WaLSAtools is properly installed. You can check inside the terminal by launching Python and typing: from WaLSAtools import WaLSAtools WaLSAtools If installed correctly, WaLSAtools\u2019 interactive welcome menu will appear \ud83c\udf89", "title": "Verifying the Installation"}, {"location": "python/installation/#need-help", "text": "If you encounter any issues during installation, first check our Troubleshooting and/or Beginner's Guide pages. If you still need help, browse the topics in our GitHub discussion \u2014 and feel free to post your question if your issue has not yet been addressed.", "title": "Need Help?"}, {"location": "python/introduction/", "text": "Introduction \u00b6 Overview \u00b6 WaLSAtools is an open-source library for analysing a wide variety of wave phenomena in time series data \u2013 including 1D signals, images, and multi-dimensional datasets. It provides tools to extract meaningful insights from complex datasets and is applicable across diverse fields, including astrophysics, engineering, life, physical and environmental sciences, and biomedical studies, among others. The library is continuously expanding with new features and functionalities, ensuring it remains a valuable resource for wave analysis. The core of WaLSAtools is built upon Python . This ensures accessibility and ease of use for a broad audience. We are actively developing versions in other popular languages to further enhance accessibility, enabling researchers from various backgrounds to leverage the power of WaLSAtools for their wave analysis needs. Currently, WaLSAtools is partially implemented in IDL , with plans to expand its functionality and extend to other programming languages in the future. WaLSAtools provides a suite of both fundamental and advanced tools, but it remains the user's responsibility to choose the method that best fits the nature of their dataset and the scientific questions being addressed. Selecting the appropriate analysis method is essential for ensuring reliable and scientifically valid results. The use of unsuitable or overly simplified techniques \u2013 without consideration of the data's properties or the research goals \u2013 can lead to incomplete or incorrect conclusions, and potentially to misinterpretation. This principle is central to our accompanying Primer , which emphasises the importance of methodological awareness in wave analysis across all disciplines. Developed by the WaLSA Team , WaLSAtools was initially inspired by the intricate wave dynamics observed in the Sun's atmosphere. However, its applications extend far beyond solar physics, offering a versatile toolkit for anyone working with oscillatory signals. WaLSAtools promotes reproducibility and transparency in wave analysis. Its robust implementations of validated techniques ensure consistent and trustworthy results, empowering researchers to delve deeper into the complexities of their data. Through its interactive interface, WaLSAtools guides users through the analysis process, providing the necessary information and tools to perform various types of wave analysis with ease. This repository is associated with a primer article titled Wave analysis tools in Nature Reviews Methods Primers (NRMP; Free access to view-only Primer and its Supplementary Information ), showcasing its capabilities through detailed analyses of synthetic datasets. The Analysis Tools/Examples/Worked examples - NRMP contain reproducible codes for generating all figures presented in the NRMP article, serving as a practical guide for applying WaLSAtools to real-world analyses. To switch between Python and IDL documentation, click the current programming language name at the top of the page. Key Features \u00b6 Wide Range of Wave Analysis Techniques: From foundational methods like FFT and wavelet analysis to advanced techniques such as EMD, k-\u03c9, and POD analysis. Cross-Disciplinary Applicability: Suitable for signal processing, oscillation studies, and multi-dimensional analysis in various fields. Interactive Interfaces: Simplified workflows through interactive menus for both Python and IDL . Open Science Principles: Promotes reproducibility and transparency in data analysis. Contributions are welcome to improve the codes, methods, or documentation. Analysis Methods \u00b6 WaLSAtools offers a variety of spectral analysis techniques, each tailored to specific types of data and research questions. These methods are broadly categorised into: Single Time Series Analysis: Includes methods for analysing individual time series, such as: 1D Signals: Fast Fourier Transform (FFT), Lomb-Scargle, Wavelet Transform, Welch, Hilbert-Huang Transform (HHT) and Empirical Mode Decomposition (EMD) 3D Cubes: k-\u03c9 Analysis, Dominant Frequency, Mean Power Spectrum, and Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis: Includes methods for analysing correlations between two time series, resulting in cross-spectrum, coherence, and phase relationships. All time series are pre-processed to mitigate unwanted effects, such as long-term trends and edge effects, prior to spectral analysis. This includes detrending and apodization. Detailed Descriptions of Analysis Methods \u00b6 The choice of the most appropriate wave analysis technique depends not only on the nature of the data but also on the specific research goals and the desired insights. WaLSAtools offers a variety of methods, each with its own strengths and limitations, allowing researchers to tailor their analysis to their specific needs. This section provides detailed descriptions of the individual methods available in WaLSAtools , empowering users to make informed decisions about the most suitable techniques for their research. Single time series analysis: 1D signal \u00b6 One Dimensional (1D) Signal WaLSAtools provides a variety of methods for analysing 1D signals (time series). Each method uses a different approach to decompose the signal into its constituent frequencies, making them suitable for various scenarios. Selecting the appropriate technique depends on the specific characteristics of the data and the research goals. FFT Lomb-Scargle Wavelet EMD/HHT Welch The Fast Fourier Transform (FFT; Cooley and Tukey 1965 ) is an efficient algorithm that computes the discrete Fourier transform (DFT; Fourier 1824 ) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. The FFT is widely used in many fields due to its computational efficiency. This makes it significantly faster than directly computing the DFT, especially for large datasets. The FFT algorithm estimates the frequency spectrum by decomposing the signal into a set of sinusoidal oscillations at distinct frequencies, each with its own amplitude and phase. Advantages: Computationally efficient, especially for large datasets. Provides a clear and easily interpretable frequency spectrum. Well-suited for analysing stationary signals with evenly spaced samples. Limitations: Assumes the signal is stationary (frequency content does not change over time). Requires evenly spaced data points. Can be sensitive to edge effects in finite signals. FFT is often the prime choice of method for spectral analysis, unless the science case and/or data properties require the use of other techniques. The Lomb\u2013Scargle periodogram is a method of estimating a frequency spectrum, based on a least-squares fit of sinusoids to data samples, irrespective of whether the sampling is regularly or irregularly spaced in time. Advantages: Can handle irregularly sampled data without the need for interpolation. Provides accurate frequency estimates even with missing data points. Limitations: Can be computationally expensive for very large datasets. May not be as efficient as FFT for evenly spaced data. Lomb\u2013Scargle should be the method of choice when the data points are unequally spaced in time (e.g., when there are gaps or missing data points). Note: While interpolation can sometimes be used to fill gaps in data and enable the use of other methods like FFT, selecting an appropriate interpolation method and mitigating potential artifacts can be challenging. A wavelet transform is a time-frequency representation of a signal. It allows a signal to be decomposed into its constituent wavelets, which are localised in both time and frequency. The Wavelet Transform is a powerful tool for analysing time series data that exhibit non-stationary behaviors, meaning their frequency content changes over time. Unlike the Fourier Transform, which provides a global frequency spectrum, the Wavelet Transform allows for localised analysis in both time and frequency, revealing how different frequencies contribute to the signal at different times. Key Concepts: Mother Wavelet: The Wavelet Transform uses a function called a \"mother wavelet\" to analyse the signal. Different mother wavelets have different shapes and properties, making them suitable for different types of signals and analysis goals. The choice of mother wavelet is crucial for optimal results. Scales: The Wavelet Transform analyses the signal at different scales, which correspond to different frequency ranges. This multi-resolution analysis allows for the detection of both short-lived, high-frequency features and long-lasting, low-frequency trends. Cone of Influence (COI): The COI is a region in the time-frequency plane where edge effects can influence the results of the Wavelet Transform. It is important to be aware of the COI when interpreting the results. WaLSAtools provides a versatile implementation of the Wavelet Transform, allowing users to choose from various mother wavelets and customize the analysis parameters. In addition to the standard 2D time-frequency spectrum, it offers two types of 1D spectra: Global Wavelet Spectrum (GWS): Obtained by averaging the wavelet power over time. Refined Global Wavelet Spectrum (RGWS): A novel approach that excludes the COI and regions below a given confidence level from the time-integral of wavelet power, providing a more robust representation of the significant frequency components. Advantages: Suitable for analysing non-stationary signals. Provides both time and frequency localisation. Offers a multi-resolution view of the signal. Limitations: The choice of mother wavelet can influence the results. Frequency resolution is limited, especially at higher frequencies. Edge effects can influence the analysis near the boundaries of the time series. Wavelet transform is particularly suitable for studying transient oscillations, weak signals, or quasi-periodic signatures. Empirical Mode Decomposition (EMD) is a data-driven technique for analysing nonlinear and non-stationary signals. It decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. The Hilbert-Huang Transform (HHT) combines EMD with the Hilbert Transform to calculate the instantaneous frequency and amplitude of each IMF. This provides a detailed view of how the signal's frequency content evolves over time. WaLSAtools Implementation: WaLSAtools provides implementations of both EMD and HHT, allowing users to: Decompose signals into IMFs using EMD. Calculate instantaneous frequencies and amplitudes using HHT. Visualise the results with time-frequency plots and marginal spectra. Advantages: Suitable for analysing nonlinear and non-stationary signals. Adaptively extracts IMFs based on the signal's local characteristics. Provides time-varying frequency and amplitude information. Limitations: Can be sensitive to noise and parameter choices. Mode mixing can occur, where a single IMF contains components from different oscillatory modes. Requires careful selection of stopping criteria and spline fitting parameters. Key Considerations: Ensemble EMD (EEMD): WaLSAtools also includes EEMD, an ensemble-based approach that reduces the impact of noise and improves mode separation. Significance Testing: It is essential to assess the statistical significance of the extracted IMFs to distinguish genuine oscillations from noise-induced artifacts. Parameter Selection: Carefully choose the EMD and HHT parameters based on the specific characteristics of the data and the research goals. EMD and HHT are valuable tools for analysing complex signals that exhibit non-stationary and nonlinear behaviors, providing insights into the time-varying dynamics of oscillatory phenomena. Welch's method is a technique for estimating the power spectral density (PSD) of a signal. It is particularly useful when dealing with noisy data or signals that have time-varying frequency content. How it works: The signal is divided into overlapping segments. Each segment is windowed (e.g., using a Hann or Hamming window) to reduce spectral leakage. The periodogram (a basic estimate of the PSD) is computed for each segment. The periodograms are averaged to obtain a smoother and more robust estimate of the PSD. Advantages: Reduces noise in the PSD estimate. Can handle signals with time-varying frequency content. Provides a more robust estimate of the PSD compared to a single periodogram. Limitations: Reduces frequency resolution due to the use of shorter segments. The choice of window function and segment length can affect the results. Welch's method is a valuable tool for analysing signals where noise reduction is a priority or when the frequency content of the signal changes over time. Info Power Spectral Density (PSD): The analysis methods compute wave amplitudes at different frequencies, resulting in a frequency spectrum. The Power Spectral Density (PSD) can further be calculated, which represents the power (amplitude squared) per unit frequency. This normalisation allows for meaningful comparisons between different signals, regardless of their frequency resolution. Additionally, WaLSAtools outputs single-sided PSDs, where the power at negative frequencies is folded into the positive frequencies, divided by two since the folding effectively doubles the PSD values. Confidence Levels: WaLSAtools can estimate the statistical significance of the computed power using a randomisation test. This helps distinguish between genuine signals and those arising from noise or spurious effects. For example, a 95% confidence level indicates that the detected power is significant with a 5% probability of being due to random fluctuations. Single time series analysis: 3D Datacube \u00b6 Three Dimensional (3D) Datacube Analysing the distribution of oscillation power over a spatial extent is often crucial to identify wave modes and understand their behaviour. WaLSAtools offers several methods for analysing 3D datacubes (time series of 2D images), each providing unique insights into the spatio-temporal characteristics of waves. k-\u03c9 Mean Power Dominant Frequency POD k-\u03c9 analysis is a powerful technique for investigating wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both spatial (wavenumber, k) and temporal (frequency, \u03c9) domains. The resulting k-\u03c9 diagram reveals the relationship between spatial and temporal scales of oscillations, providing insights into wave dispersion relations and identifying different wave modes. WaLSAtools provides a comprehensive k-\u03c9 analysis tool that allows for: Generating k-\u03c9 diagrams from 3D datacubes. Filtering of the data in k-space and/or \u03c9-space. Reconstructing filtered datacubes to isolate specific wave modes or features. Fourier filtering is a key component of k-\u03c9 analysis, enabling the isolation of wave signatures with specific wavenumber and frequency characteristics. This is particularly useful for identifying weak wave modes that might be masked by stronger signals or background trends. Advantages: Reveals wave dispersion relations. Enables isolation of specific wave modes through filtering. Provides insights into the spatio-temporal characteristics of waves. Limitations: Assumes the wave field is statistically homogeneous and stationary. Can be sensitive to edge effects and noise. For a detailed description of the Fourier filtering technique, refer to the step-by-step guide of the original (QUEEFF) code integrated into WaLSAtools . The mean power spectrum provides a global view of the oscillatory behaviour within a region of interest. It is calculated by averaging the power spectra of individual pixels across the spatial domain. WaLSAtools allows for calculating the mean power spectrum using various 1D analysis methods (FFT, Lomb-Scargle, Wavelet, HHT, Welch, etc.). Advantages: Highlights the dominant (mean) oscillatory modes in a region. Provides a baseline for filtering out global contributions. Can be used to compare oscillatory behaviour across different regions or datasets. Limitations: May not capture localised or subtle variations in oscillatory behaviour. The dominant frequency is the frequency with the highest power in a spectrum. WaLSAtools can calculate the dominant frequency for each pixel in a 3D datacube, generating a map that visualises the spatial distribution of dominant frequencies. Advantages: Provides a visual representation of the dominant oscillatory modes in a region. Can reveal spatial patterns and correlations with other physical properties. Limitations: Can be biased in signals with multiple strong spectral peaks. May not capture the full complexity of oscillatory behaviour. Proper Orthogonal Decomposition (POD) is a powerful data-driven technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. WaLSAtools provides a POD analysis tool that: Calculates the POD modes and their corresponding eigenvalues. Reconstructs the original data using a reduced number of modes. Visualises the spatial patterns and temporal evolution of the dominant modes. Advantages: Effectively reduces the dimensionality of complex datasets. Identifies coherent spatial patterns and their temporal behaviour. Can be used for feature extraction and pattern recognition. Limitations: Assumes the data is statistically stationary. May not capture highly localised or transient phenomena. Cross-correlation Analysis \u00b6 Cross-Correlation Analysis Investigating the relationships between two time series is essential for understanding the interplay of different phenomena across various scientific disciplines. WaLSAtools provides a comprehensive suite of tools for cross-correlation analysis, enabling researchers to: Uncover shared frequencies and correlated power between two signals. Quantify the strength of the relationship between two time series at different frequencies. Determine the relative timing (phase or time lag) between oscillations. These tools are valuable for uncovering hidden connections, tracking wave propagation, and exploring the underlying drivers of oscillatory behaviour in diverse fields. Cross-Spectrum Coherence Phase Difference The cross-spectrum, also known as the cross-power spectrum, is a complex-valued function that describes the correlation between two time series in the frequency domain. It is calculated by multiplying the frequency representation of one signal by the complex conjugate of the frequency representation of the other one. The magnitude of the cross-spectrum, often called the co-spectrum, represents the shared power between the two signals at each frequency. High values in the co-spectrum indicate strong correlations between the oscillations at those frequencies. Applications: Identifying common frequencies and shared power between two signals. Detecting potential connections or shared influences affecting the signals. Limitations: May not reveal correlations if the individual power spectra lack prominent peaks. Can be sensitive to noise and potential biases in the data. Coherence is a normalised measure of the linear correlation between two time series at each frequency. It ranges from 0 (no correlation) to 1 (perfect correlation). High coherence values indicate that the oscillations in the two time series are strongly related at that frequency, even if their individual power spectra do not exhibit strong peaks. Applications: Uncovering hidden relationships between signals. Tracing wave propagation across different locations or systems. Investigating connections between oscillations in different physical parameters or measurements. Limitations: Only measures linear relationships between signals. Can be sensitive to noise and potential biases in the data. Phase difference, or phase lag, measures the relative timing of oscillations in two time series. It is calculated from the phase angle of the complex cross-spectrum and indicates whether the oscillations are in phase, or if one signal leads or lags the other. Applications: Determining the direction and speed of wave propagation. Exploring potential cause-and-effect connections between phenomena. Investigating the degree of synchronization between oscillating systems. Limitations: Can be challenging to interpret in complex systems with multiple interacting oscillations. Sensitive to noise and potential biases in the data. Note The co-spectrum, coherence, and phase lag are one-dimensional for 1D power spectra (FFT, Lomb-Scargle, HHT, GWS, RGWS, Welch) and two-dimensional for the 2D Wavelet spectrum. Info Check out the documentation on the Analysis Tools to learn how to run WaLSAtools and more about all inputs, parameters, and outputs. Under Development \u00b6 WaLSAtools is constantly evolving with new features and improvements. Here are some of the ongoing developments: Expanding Language Support: Further development in IDL (for full consistency between the Python and IDL versions), with potential expansion to MATLAB and other programming languages. Enhancing Existing Methods: Improving the Dominant Frequency method to handle cases with multiple strong power peaks and provide uncertainty estimations. Adding New Methods: Implementing new analysis techniques, such as Adaptive Local Iterative Filtering (ALIF) and Synchrosqueezing Transform (SST). We welcome contributions from the community to help us expand and improve WaLSAtools . If you are interested in contributing, please see the Contribution Guidelines .", "title": "Introduction"}, {"location": "python/introduction/#introduction", "text": "", "title": "Introduction"}, {"location": "python/introduction/#overview", "text": "WaLSAtools is an open-source library for analysing a wide variety of wave phenomena in time series data \u2013 including 1D signals, images, and multi-dimensional datasets. It provides tools to extract meaningful insights from complex datasets and is applicable across diverse fields, including astrophysics, engineering, life, physical and environmental sciences, and biomedical studies, among others. The library is continuously expanding with new features and functionalities, ensuring it remains a valuable resource for wave analysis. The core of WaLSAtools is built upon Python . This ensures accessibility and ease of use for a broad audience. We are actively developing versions in other popular languages to further enhance accessibility, enabling researchers from various backgrounds to leverage the power of WaLSAtools for their wave analysis needs. Currently, WaLSAtools is partially implemented in IDL , with plans to expand its functionality and extend to other programming languages in the future. WaLSAtools provides a suite of both fundamental and advanced tools, but it remains the user's responsibility to choose the method that best fits the nature of their dataset and the scientific questions being addressed. Selecting the appropriate analysis method is essential for ensuring reliable and scientifically valid results. The use of unsuitable or overly simplified techniques \u2013 without consideration of the data's properties or the research goals \u2013 can lead to incomplete or incorrect conclusions, and potentially to misinterpretation. This principle is central to our accompanying Primer , which emphasises the importance of methodological awareness in wave analysis across all disciplines. Developed by the WaLSA Team , WaLSAtools was initially inspired by the intricate wave dynamics observed in the Sun's atmosphere. However, its applications extend far beyond solar physics, offering a versatile toolkit for anyone working with oscillatory signals. WaLSAtools promotes reproducibility and transparency in wave analysis. Its robust implementations of validated techniques ensure consistent and trustworthy results, empowering researchers to delve deeper into the complexities of their data. Through its interactive interface, WaLSAtools guides users through the analysis process, providing the necessary information and tools to perform various types of wave analysis with ease. This repository is associated with a primer article titled Wave analysis tools in Nature Reviews Methods Primers (NRMP; Free access to view-only Primer and its Supplementary Information ), showcasing its capabilities through detailed analyses of synthetic datasets. The Analysis Tools/Examples/Worked examples - NRMP contain reproducible codes for generating all figures presented in the NRMP article, serving as a practical guide for applying WaLSAtools to real-world analyses. To switch between Python and IDL documentation, click the current programming language name at the top of the page.", "title": "Overview"}, {"location": "python/introduction/#key-features", "text": "Wide Range of Wave Analysis Techniques: From foundational methods like FFT and wavelet analysis to advanced techniques such as EMD, k-\u03c9, and POD analysis. Cross-Disciplinary Applicability: Suitable for signal processing, oscillation studies, and multi-dimensional analysis in various fields. Interactive Interfaces: Simplified workflows through interactive menus for both Python and IDL . Open Science Principles: Promotes reproducibility and transparency in data analysis. Contributions are welcome to improve the codes, methods, or documentation.", "title": "Key Features"}, {"location": "python/introduction/#analysis-methods", "text": "WaLSAtools offers a variety of spectral analysis techniques, each tailored to specific types of data and research questions. These methods are broadly categorised into: Single Time Series Analysis: Includes methods for analysing individual time series, such as: 1D Signals: Fast Fourier Transform (FFT), Lomb-Scargle, Wavelet Transform, Welch, Hilbert-Huang Transform (HHT) and Empirical Mode Decomposition (EMD) 3D Cubes: k-\u03c9 Analysis, Dominant Frequency, Mean Power Spectrum, and Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis: Includes methods for analysing correlations between two time series, resulting in cross-spectrum, coherence, and phase relationships. All time series are pre-processed to mitigate unwanted effects, such as long-term trends and edge effects, prior to spectral analysis. This includes detrending and apodization.", "title": "Analysis Methods"}, {"location": "python/introduction/#detailed-descriptions-of-analysis-methods", "text": "The choice of the most appropriate wave analysis technique depends not only on the nature of the data but also on the specific research goals and the desired insights. WaLSAtools offers a variety of methods, each with its own strengths and limitations, allowing researchers to tailor their analysis to their specific needs. This section provides detailed descriptions of the individual methods available in WaLSAtools , empowering users to make informed decisions about the most suitable techniques for their research.", "title": "Detailed Descriptions of Analysis Methods"}, {"location": "python/introduction/#single-time-series-analysis-1d-signal", "text": "One Dimensional (1D) Signal WaLSAtools provides a variety of methods for analysing 1D signals (time series). Each method uses a different approach to decompose the signal into its constituent frequencies, making them suitable for various scenarios. Selecting the appropriate technique depends on the specific characteristics of the data and the research goals. FFT Lomb-Scargle Wavelet EMD/HHT Welch The Fast Fourier Transform (FFT; Cooley and Tukey 1965 ) is an efficient algorithm that computes the discrete Fourier transform (DFT; Fourier 1824 ) of a sequence, or its inverse. Fourier analysis converts a signal from its original domain (often time or space) to a representation in the frequency domain and vice versa. The DFT is obtained by decomposing a sequence of values into components of different frequencies. The FFT is widely used in many fields due to its computational efficiency. This makes it significantly faster than directly computing the DFT, especially for large datasets. The FFT algorithm estimates the frequency spectrum by decomposing the signal into a set of sinusoidal oscillations at distinct frequencies, each with its own amplitude and phase. Advantages: Computationally efficient, especially for large datasets. Provides a clear and easily interpretable frequency spectrum. Well-suited for analysing stationary signals with evenly spaced samples. Limitations: Assumes the signal is stationary (frequency content does not change over time). Requires evenly spaced data points. Can be sensitive to edge effects in finite signals. FFT is often the prime choice of method for spectral analysis, unless the science case and/or data properties require the use of other techniques. The Lomb\u2013Scargle periodogram is a method of estimating a frequency spectrum, based on a least-squares fit of sinusoids to data samples, irrespective of whether the sampling is regularly or irregularly spaced in time. Advantages: Can handle irregularly sampled data without the need for interpolation. Provides accurate frequency estimates even with missing data points. Limitations: Can be computationally expensive for very large datasets. May not be as efficient as FFT for evenly spaced data. Lomb\u2013Scargle should be the method of choice when the data points are unequally spaced in time (e.g., when there are gaps or missing data points). Note: While interpolation can sometimes be used to fill gaps in data and enable the use of other methods like FFT, selecting an appropriate interpolation method and mitigating potential artifacts can be challenging. A wavelet transform is a time-frequency representation of a signal. It allows a signal to be decomposed into its constituent wavelets, which are localised in both time and frequency. The Wavelet Transform is a powerful tool for analysing time series data that exhibit non-stationary behaviors, meaning their frequency content changes over time. Unlike the Fourier Transform, which provides a global frequency spectrum, the Wavelet Transform allows for localised analysis in both time and frequency, revealing how different frequencies contribute to the signal at different times. Key Concepts: Mother Wavelet: The Wavelet Transform uses a function called a \"mother wavelet\" to analyse the signal. Different mother wavelets have different shapes and properties, making them suitable for different types of signals and analysis goals. The choice of mother wavelet is crucial for optimal results. Scales: The Wavelet Transform analyses the signal at different scales, which correspond to different frequency ranges. This multi-resolution analysis allows for the detection of both short-lived, high-frequency features and long-lasting, low-frequency trends. Cone of Influence (COI): The COI is a region in the time-frequency plane where edge effects can influence the results of the Wavelet Transform. It is important to be aware of the COI when interpreting the results. WaLSAtools provides a versatile implementation of the Wavelet Transform, allowing users to choose from various mother wavelets and customize the analysis parameters. In addition to the standard 2D time-frequency spectrum, it offers two types of 1D spectra: Global Wavelet Spectrum (GWS): Obtained by averaging the wavelet power over time. Refined Global Wavelet Spectrum (RGWS): A novel approach that excludes the COI and regions below a given confidence level from the time-integral of wavelet power, providing a more robust representation of the significant frequency components. Advantages: Suitable for analysing non-stationary signals. Provides both time and frequency localisation. Offers a multi-resolution view of the signal. Limitations: The choice of mother wavelet can influence the results. Frequency resolution is limited, especially at higher frequencies. Edge effects can influence the analysis near the boundaries of the time series. Wavelet transform is particularly suitable for studying transient oscillations, weak signals, or quasi-periodic signatures. Empirical Mode Decomposition (EMD) is a data-driven technique for analysing nonlinear and non-stationary signals. It decomposes a signal into a set of Intrinsic Mode Functions (IMFs), each representing a distinct oscillatory mode with its own time-varying amplitude and frequency. The Hilbert-Huang Transform (HHT) combines EMD with the Hilbert Transform to calculate the instantaneous frequency and amplitude of each IMF. This provides a detailed view of how the signal's frequency content evolves over time. WaLSAtools Implementation: WaLSAtools provides implementations of both EMD and HHT, allowing users to: Decompose signals into IMFs using EMD. Calculate instantaneous frequencies and amplitudes using HHT. Visualise the results with time-frequency plots and marginal spectra. Advantages: Suitable for analysing nonlinear and non-stationary signals. Adaptively extracts IMFs based on the signal's local characteristics. Provides time-varying frequency and amplitude information. Limitations: Can be sensitive to noise and parameter choices. Mode mixing can occur, where a single IMF contains components from different oscillatory modes. Requires careful selection of stopping criteria and spline fitting parameters. Key Considerations: Ensemble EMD (EEMD): WaLSAtools also includes EEMD, an ensemble-based approach that reduces the impact of noise and improves mode separation. Significance Testing: It is essential to assess the statistical significance of the extracted IMFs to distinguish genuine oscillations from noise-induced artifacts. Parameter Selection: Carefully choose the EMD and HHT parameters based on the specific characteristics of the data and the research goals. EMD and HHT are valuable tools for analysing complex signals that exhibit non-stationary and nonlinear behaviors, providing insights into the time-varying dynamics of oscillatory phenomena. Welch's method is a technique for estimating the power spectral density (PSD) of a signal. It is particularly useful when dealing with noisy data or signals that have time-varying frequency content. How it works: The signal is divided into overlapping segments. Each segment is windowed (e.g., using a Hann or Hamming window) to reduce spectral leakage. The periodogram (a basic estimate of the PSD) is computed for each segment. The periodograms are averaged to obtain a smoother and more robust estimate of the PSD. Advantages: Reduces noise in the PSD estimate. Can handle signals with time-varying frequency content. Provides a more robust estimate of the PSD compared to a single periodogram. Limitations: Reduces frequency resolution due to the use of shorter segments. The choice of window function and segment length can affect the results. Welch's method is a valuable tool for analysing signals where noise reduction is a priority or when the frequency content of the signal changes over time. Info Power Spectral Density (PSD): The analysis methods compute wave amplitudes at different frequencies, resulting in a frequency spectrum. The Power Spectral Density (PSD) can further be calculated, which represents the power (amplitude squared) per unit frequency. This normalisation allows for meaningful comparisons between different signals, regardless of their frequency resolution. Additionally, WaLSAtools outputs single-sided PSDs, where the power at negative frequencies is folded into the positive frequencies, divided by two since the folding effectively doubles the PSD values. Confidence Levels: WaLSAtools can estimate the statistical significance of the computed power using a randomisation test. This helps distinguish between genuine signals and those arising from noise or spurious effects. For example, a 95% confidence level indicates that the detected power is significant with a 5% probability of being due to random fluctuations.", "title": "Single time series analysis: 1D signal"}, {"location": "python/introduction/#single-time-series-analysis-3d-datacube", "text": "Three Dimensional (3D) Datacube Analysing the distribution of oscillation power over a spatial extent is often crucial to identify wave modes and understand their behaviour. WaLSAtools offers several methods for analysing 3D datacubes (time series of 2D images), each providing unique insights into the spatio-temporal characteristics of waves. k-\u03c9 Mean Power Dominant Frequency POD k-\u03c9 analysis is a powerful technique for investigating wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both spatial (wavenumber, k) and temporal (frequency, \u03c9) domains. The resulting k-\u03c9 diagram reveals the relationship between spatial and temporal scales of oscillations, providing insights into wave dispersion relations and identifying different wave modes. WaLSAtools provides a comprehensive k-\u03c9 analysis tool that allows for: Generating k-\u03c9 diagrams from 3D datacubes. Filtering of the data in k-space and/or \u03c9-space. Reconstructing filtered datacubes to isolate specific wave modes or features. Fourier filtering is a key component of k-\u03c9 analysis, enabling the isolation of wave signatures with specific wavenumber and frequency characteristics. This is particularly useful for identifying weak wave modes that might be masked by stronger signals or background trends. Advantages: Reveals wave dispersion relations. Enables isolation of specific wave modes through filtering. Provides insights into the spatio-temporal characteristics of waves. Limitations: Assumes the wave field is statistically homogeneous and stationary. Can be sensitive to edge effects and noise. For a detailed description of the Fourier filtering technique, refer to the step-by-step guide of the original (QUEEFF) code integrated into WaLSAtools . The mean power spectrum provides a global view of the oscillatory behaviour within a region of interest. It is calculated by averaging the power spectra of individual pixels across the spatial domain. WaLSAtools allows for calculating the mean power spectrum using various 1D analysis methods (FFT, Lomb-Scargle, Wavelet, HHT, Welch, etc.). Advantages: Highlights the dominant (mean) oscillatory modes in a region. Provides a baseline for filtering out global contributions. Can be used to compare oscillatory behaviour across different regions or datasets. Limitations: May not capture localised or subtle variations in oscillatory behaviour. The dominant frequency is the frequency with the highest power in a spectrum. WaLSAtools can calculate the dominant frequency for each pixel in a 3D datacube, generating a map that visualises the spatial distribution of dominant frequencies. Advantages: Provides a visual representation of the dominant oscillatory modes in a region. Can reveal spatial patterns and correlations with other physical properties. Limitations: Can be biased in signals with multiple strong spectral peaks. May not capture the full complexity of oscillatory behaviour. Proper Orthogonal Decomposition (POD) is a powerful data-driven technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. WaLSAtools provides a POD analysis tool that: Calculates the POD modes and their corresponding eigenvalues. Reconstructs the original data using a reduced number of modes. Visualises the spatial patterns and temporal evolution of the dominant modes. Advantages: Effectively reduces the dimensionality of complex datasets. Identifies coherent spatial patterns and their temporal behaviour. Can be used for feature extraction and pattern recognition. Limitations: Assumes the data is statistically stationary. May not capture highly localised or transient phenomena.", "title": "Single time series analysis: 3D Datacube"}, {"location": "python/introduction/#cross-correlation-analysis", "text": "Cross-Correlation Analysis Investigating the relationships between two time series is essential for understanding the interplay of different phenomena across various scientific disciplines. WaLSAtools provides a comprehensive suite of tools for cross-correlation analysis, enabling researchers to: Uncover shared frequencies and correlated power between two signals. Quantify the strength of the relationship between two time series at different frequencies. Determine the relative timing (phase or time lag) between oscillations. These tools are valuable for uncovering hidden connections, tracking wave propagation, and exploring the underlying drivers of oscillatory behaviour in diverse fields. Cross-Spectrum Coherence Phase Difference The cross-spectrum, also known as the cross-power spectrum, is a complex-valued function that describes the correlation between two time series in the frequency domain. It is calculated by multiplying the frequency representation of one signal by the complex conjugate of the frequency representation of the other one. The magnitude of the cross-spectrum, often called the co-spectrum, represents the shared power between the two signals at each frequency. High values in the co-spectrum indicate strong correlations between the oscillations at those frequencies. Applications: Identifying common frequencies and shared power between two signals. Detecting potential connections or shared influences affecting the signals. Limitations: May not reveal correlations if the individual power spectra lack prominent peaks. Can be sensitive to noise and potential biases in the data. Coherence is a normalised measure of the linear correlation between two time series at each frequency. It ranges from 0 (no correlation) to 1 (perfect correlation). High coherence values indicate that the oscillations in the two time series are strongly related at that frequency, even if their individual power spectra do not exhibit strong peaks. Applications: Uncovering hidden relationships between signals. Tracing wave propagation across different locations or systems. Investigating connections between oscillations in different physical parameters or measurements. Limitations: Only measures linear relationships between signals. Can be sensitive to noise and potential biases in the data. Phase difference, or phase lag, measures the relative timing of oscillations in two time series. It is calculated from the phase angle of the complex cross-spectrum and indicates whether the oscillations are in phase, or if one signal leads or lags the other. Applications: Determining the direction and speed of wave propagation. Exploring potential cause-and-effect connections between phenomena. Investigating the degree of synchronization between oscillating systems. Limitations: Can be challenging to interpret in complex systems with multiple interacting oscillations. Sensitive to noise and potential biases in the data. Note The co-spectrum, coherence, and phase lag are one-dimensional for 1D power spectra (FFT, Lomb-Scargle, HHT, GWS, RGWS, Welch) and two-dimensional for the 2D Wavelet spectrum. Info Check out the documentation on the Analysis Tools to learn how to run WaLSAtools and more about all inputs, parameters, and outputs.", "title": "Cross-correlation Analysis"}, {"location": "python/introduction/#under-development", "text": "WaLSAtools is constantly evolving with new features and improvements. Here are some of the ongoing developments: Expanding Language Support: Further development in IDL (for full consistency between the Python and IDL versions), with potential expansion to MATLAB and other programming languages. Enhancing Existing Methods: Improving the Dominant Frequency method to handle cases with multiple strong power peaks and provide uncertainty estimations. Adding New Methods: Implementing new analysis techniques, such as Adaptive Local Iterative Filtering (ALIF) and Synchrosqueezing Transform (SST). We welcome contributions from the community to help us expand and improve WaLSAtools . If you are interested in contributing, please see the Contribution Guidelines .", "title": "Under Development"}, {"location": "python/k-omega-example/", "text": "Worked Example - NRMP: k-\u03c9 Analysis and Filtering \u00b6 This example demonstrates the application of k-\u03c9 analysis and filtering to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset in the k-\u03c9 domain, we can gain insights into the relationship between spatial and temporal scales of oscillations, identify different wave modes, and isolate specific wave features through filtering. Analysis and Figure The figure below provides a comprehensive illustration of k-\u03c9 analysis and filtering applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis Fourier filtering in the wavenumber and frequency domains WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Illustration of k-\u03c9 analysis and filtering applied to a synthetic spatio-temporal dataset. (a) The k-\u03c9 power diagram, with dashed lines outlining the targeted filtering region. (b) A six-frame sequence from the filtered datacube, showcasing the spatial and temporal evolution of the isolated wave features. \u00a9-(e) Step-by-step visualization of the spatial filtering process: \u00a9 The time-averaged spatial power spectrum of the original dataset. (d) The spatial filter mask. (e) The result of applying the mask to the spatial Fourier transform. (f) The spatially-averaged temporal power spectrum, with the temporal filter masks (dashed lines) and the preserved oscillatory power (solid red curves). Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic signal data time = hdul [ 1 ] . data # Time Array hdul . close () cadence = 0.5 # cadence in seconds # frequency and wavenumber ranges for filtering f1 = 0.470 f2 = 0.530 k1 = 0.047 k2 = 0.250 # k-omega Analysis using WaLSAtools power , wavenumber , frequencies , filtered_cube , spatial_fft_map , torus_map , spatial_fft_filtered_map , temporal_fft , temporal_filter , temporal_frequencies , spatial_frequencies = WaLSAtools ( signal = signal_3d , time = time , method = 'k-omega' , filtering = True , processing_maps = True , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , ) Processing k-\u03c9 analysis for a 3D cube with format 'txy' and shape (200, 130, 130). Input datacube size (t,x,y): (200, 130, 130) Spatially, the important values are: 2-pixel size = 2.00 (pixel) Nyquist wavenumber = 3.14 (pixel\u207b\u00b9) Temporally, the important values are: 2-element duration (Nyquist period) = 1.00 (s) Time series duration = 65.00 (s) Nyquist frequency = 1.00 (Hz) Constructing a k-\u03c9 diagram of the input datacube.......... Start filtering (in k-\u03c9 space) ...... The preserved wavenumbers are [0.047, 0.250] (pixel\u207b\u00b9) The preserved spatial sizes are [25.133, 133.685] (pixel) The preserved frequencies are [0.470, 0.530] (Hz) The preserved periods are [1, 2] (s) Making a 3D Fourier transform of the input datacube .......... Filtered datacube generated. 1 2 3 4 5 6 7 8 9 10 11 12 # Save the results # To be used in Figure 5 of the Nature Reviews Methods Primers paper. np . savez ( 'Saved_Parameters/k_omega_analysis.npz' , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 from matplotlib.colors import Normalize import matplotlib.pyplot as plt from matplotlib.ticker import LogLocator import numpy as np from matplotlib.colors import ListedColormap import matplotlib.pyplot as plt import matplotlib.patches as patches from matplotlib.colors import Normalize from matplotlib.ticker import AutoMinorLocator from WaLSAtools import WaLSA_save_pdf , WaLSA_histo_opt , WaLSA_plot_k_omega # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'DejaVu Sans' , # Set Helvetica as the default sans-serif font 'font.size' : 15 , # Global font size 'axes.titlesize' : 15 , # Title font size 'axes.labelsize' : 12.5 , # Axis label font size 'xtick.labelsize' : 12.5 , # X-axis tick label font size 'ytick.labelsize' : 12.5 , # Y-axis tick label font size 'legend.fontsize' : 12.5 , # Legend font size 'figure.titlesize' : 14 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 500 , # Make all fonts bold 'axes.titleweight' : 500 , # Make title font bold 'axes.labelweight' : 500 # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.4 ) plt . rc ( 'lines' , linewidth = 1.5 ) # Set up the figure layout fig = plt . figure ( figsize = ( 9.11 , 9.05 )) #-------------------------------------------------------------------------- # k-omega plot ax1d = fig . add_axes ([ 0.09 , 0.65 , 0.56 , 0.282 ]) # [left, bottom, width, height] ax1d = WaLSA_plot_k_omega ( kopower = power , kopower_xscale = wavenumber , kopower_yscale = frequencies * 1000. , xlog = False , ylog = False , xrange = ( 0 , 0.3 ), figsize = ( 8 , 4 ), cbartab = 0.18 , xtitle = 'Wavenumber (pixel\u207b\u00b9)' , ytitle = 'Frequency (mHz)' , colorbar_label = 'Log\u2081\u2080(Oscillation Power)' , ax = ax1d , f1 = 0.472 * 1000 , f2 = 0.530 * 1000 , k1 = 0.047 , k2 = 0.25 ) # Add label fig . text ( 0.008 , 0.963 , '(a)' , color = 'black' ) #-------------------------------------------------------------------------- # Plot the fist 6 frames of the filtered cube in a 3x2 grid fpositions = [ [ 0.737 , 0.867 , 0.11 , 0.108 ], [ 0.861 , 0.867 , 0.11 , 0.108 ], # Top row [ 0.737 , 0.741 , 0.11 , 0.108 ], [ 0.861 , 0.741 , 0.11 , 0.108 ], # Middle row [ 0.737 , 0.615 , 0.11 , 0.108 ], [ 0.861 , 0.615 , 0.11 , 0.108 ] # Bottom row ] rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_1.txt' ) / 255.0 idl_colormap_1 = ListedColormap ( rgb_values ) custom_cmap = plt . get_cmap ( idl_colormap_1 ) for i in range ( 6 ): im = filtered_cube [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = custom_cmap , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 16 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 13 ) ax . text ( 18 , 103 , str ( i + 1 ), fontsize = 12.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add a box around the six frames rectangle = patches . Rectangle ( ( 0.677 , 0.591 ), 0.313 , 0.3985 , zorder = 10 , linewidth = 1.5 , edgecolor = 'DodgerBlue' , facecolor = 'none' , linestyle = ':' ) fig . add_artist ( rectangle ) # Add label fig . text ( 0.687 , 0.963 , '(b)' , color = 'black' ) #-------------------------------------------------------------------------- # Plot the processing steps: Spatial FFT, Spatial FFT filter, and Filtered spatial FFT positions = [[ 0.078 , 0.31 , 0.215 , 0.215 ], [ 0.425 , 0.31 , 0.215 , 0.215 ], [ 0.767 , 0.31 , 0.215 , 0.215 ]] import matplotlib.pyplot as plt import numpy as np from matplotlib.colors import Normalize from matplotlib import cm # Load custom colormap rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_0.txt' ) / 255.0 cmap_torus_map = ListedColormap ( rgb_values ) rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_5.txt' ) / 255.0 cmap_spatial_fft = ListedColormap ( rgb_values ) reversed_colors = cmap_spatial_fft ( np . linspace ( 1 , 0 , 256 )) cmap_reversed = ListedColormap ( reversed_colors ) # Plot (c) Spatial FFT # Extract data and convert to magnitude if it's complex spatial_fft_map_data = spatial_fft_map [ 'data' ] if np . iscomplexobj ( spatial_fft_map_data ): # Check if the data is complex spatial_fft_map_data = np . abs ( spatial_fft_map_data ) # Use the magnitude for visualization ax1 = fig . add_axes ( positions [ 0 ]) im1 = ax1 . imshow ( spatial_fft_map_data , cmap = cmap_spatial_fft , aspect = 'equal' , extent = [ np . min ( spatial_frequencies ), np . max ( spatial_frequencies ), np . min ( spatial_frequencies ), np . max ( spatial_frequencies )], norm = Normalize ( vmin = np . nanmin ( spatial_fft_map_data ) + 1 , vmax = np . nanmax ( spatial_fft_map_data ) - 1 ) ) ax1 . set_xlabel ( 'Wavenumber (k\u2093; pixel\u207b\u00b9)' ) ax1 . set_ylabel ( 'Wavenumber (k\u1d67; pixel\u207b\u00b9)' ) ax1 . minorticks_on () ax1 . xaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax1 . yaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax1 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax1 . xaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax1 . yaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax1 . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) ax1 . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) ax1 . xaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax1 . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) # Crosshair ax1 . axhline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax1 . axvline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax1 . set_xlim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) ax1 . set_ylim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) # Annotation ax1 . text ( 0 , 3.7 , '(c) Spatial FFT' , ha = 'center' , color = 'black' ) # Plot (d) Spatial FFT Filter # Extract data and convert to magnitude if it's complex torus_map_data = torus_map [ 'data' ] if np . iscomplexobj ( torus_map_data ): # Check if the data is complex torus_map_data = np . abs ( torus_map_data ) # Use the magnitude for visualization ax2 = fig . add_axes ( positions [ 1 ]) im2 = ax2 . imshow ( torus_map_data , cmap = cmap_torus_map , aspect = 'equal' , extent = [ np . min ( spatial_frequencies ), np . max ( spatial_frequencies ), np . min ( spatial_frequencies ), np . max ( spatial_frequencies )], norm = Normalize ( vmin = 0 , vmax = 1 ) ) ax2 . set_xlabel ( 'Wavenumber (k\u2093; pixel\u207b\u00b9)' ) ax2 . set_ylabel ( 'Wavenumber (k\u1d67; pixel\u207b\u00b9)' ) ax2 . minorticks_on () ax2 . xaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax2 . yaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax2 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax2 . xaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax2 . yaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax2 . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) ax2 . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) ax2 . xaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax2 . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) # Crosshair ax2 . axhline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax2 . axvline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax2 . set_xlim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) ax2 . set_ylim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) # Annotation ax2 . text ( 0 , 3.7 , '(d) Spatial FFT filter' , ha = 'center' , color = 'black' ) # Plot (e) Filtered Spatial FFT # Extract data and convert to magnitude if it's complex spatial_fft_filtered_map_data = spatial_fft_filtered_map [ 'data' ] if np . iscomplexobj ( spatial_fft_filtered_map_data ): # Check if the data is complex spatial_fft_filtered_map_data = np . abs ( spatial_fft_filtered_map_data ) # Use the magnitude for visualization ax3 = fig . add_axes ( positions [ 2 ]) im3 = ax3 . imshow ( spatial_fft_filtered_map_data , cmap = cmap_reversed , aspect = 'equal' , extent = [ np . min ( spatial_frequencies ), np . max ( spatial_frequencies ), np . min ( spatial_frequencies ), np . max ( spatial_frequencies )], norm = Normalize ( vmin = np . nanmin ( spatial_fft_filtered_map_data ) + 1 , vmax = np . nanmax ( spatial_fft_filtered_map_data ) - 1 ) ) ax3 . set_xlabel ( 'Wavenumber (k\u2093; pixel\u207b\u00b9)' ) ax3 . set_ylabel ( 'Wavenumber (k\u1d67; pixel\u207b\u00b9)' ) ax3 . minorticks_on () ax3 . xaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax3 . yaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax3 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax3 . xaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax3 . yaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax3 . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) ax3 . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) ax3 . xaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax3 . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) # Crosshair ax3 . axhline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax3 . axvline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax3 . set_xlim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) ax3 . set_ylim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) # Annotation ax3 . text ( 0 , 3.7 , '(e) Filtered spatial FFT' , ha = 'center' , color = 'black' ); #-------------------------------------------------------------------------- # Plot the temporal FFT, temporal filter, and filtered FFT ax4 = fig . add_axes ([ 0.088 , 0.062 , 0.889 , 0.153 ]) # Position for the plot normalised_temporal_fft = temporal_fft / ( 3.3 * 10 ** 6 ) # Plot temporal FFT (main line with logarithmic y-axis) ax4 . plot ( temporal_frequencies * 1000 , np . abs ( normalised_temporal_fft ), label = 'FFT Power' , color = 'black' , linewidth = 0.5 ) ax4 . set_yscale ( 'log' ) # Logarithmic y-axis # Add vertical line at x=0 ax4 . axvline ( 0 , color = 'black' , linewidth = 1.5 , linestyle = '--' ) # Plot temporal filter temporal_fft_plot_ymin = 10 ** np . nanmin ( np . log10 ( normalised_temporal_fft )) temporal_fft_plot_ymax = 10 ** np . nanmax ( np . log10 ( normalised_temporal_fft )) temporal_fft_plot_ymin = 10 **- 3 temporal_fft_plot_ymax = 10 ** 2 real_temporal_filter = np . real ( temporal_filter ) # Extract the real part ax4 . plot ( temporal_frequencies * 1000 , np . maximum ( real_temporal_filter , temporal_fft_plot_ymin ), label = 'Temporal Filter' , color = 'blue' , linewidth = 1.5 , linestyle = '--' ) # Plot filtered FFT ax4 . plot ( temporal_frequencies * 1000 , np . maximum ( np . abs ( np . real ( normalised_temporal_fft ) * real_temporal_filter ), temporal_fft_plot_ymin ), label = 'Filtered FFT' , color = 'red' , linewidth = 1.3 ) # Configure ticks and labels ax4 . set_xlabel ( 'Frequency (mHz)' ) ax4 . set_ylabel ( 'Power (arb. units)' ) ax4 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax4 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.1 ) ax4 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) ax4 . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Set custom ticks ax4 . xaxis . set_major_locator ( plt . MultipleLocator ( 250 )) ax4 . xaxis . set_minor_locator ( plt . MultipleLocator ( 50 )) ax4 . set_yticks ([ 10 **- 3 , 10 **- 2 , 10 **- 1 , 10 ** 0 , 10 ** 1 , 10 ** 2 ], minor = False ) ax4 . set_yticklabels ([ '' , '10\u207b\u00b2' , '' , '10\u2070' , '' , '10\u00b2' ]) ax4 . yaxis . set_minor_locator ( LogLocator ( base = 10.0 , subs = np . arange ( 1.0 , 10.0 ) * 0.1 , numticks = 10 )) # Set plot limits ax4 . set_xlim ([ - 999 , 1000 ]) ax4 . set_ylim ([ temporal_fft_plot_ymin , temporal_fft_plot_ymax ]) # Add label ax4 . text ( - 980 , 15 , '(f)' , color = 'black' ) #-------------------------------------------------------------------------- # Adjust overall layout # fig.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.0, hspace=0.0) # Save the figure as a PDF pdf_path = 'Figures/FigS4_k-omega_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS4_k-omega_analysis.pdf'", "title": "k-&#969; analysis"}, {"location": "python/k-omega-example/#worked-example-nrmp-k-analysis-and-filtering", "text": "This example demonstrates the application of k-\u03c9 analysis and filtering to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset in the k-\u03c9 domain, we can gain insights into the relationship between spatial and temporal scales of oscillations, identify different wave modes, and isolate specific wave features through filtering. Analysis and Figure The figure below provides a comprehensive illustration of k-\u03c9 analysis and filtering applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis Fourier filtering in the wavenumber and frequency domains WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S4 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Illustration of k-\u03c9 analysis and filtering applied to a synthetic spatio-temporal dataset. (a) The k-\u03c9 power diagram, with dashed lines outlining the targeted filtering region. (b) A six-frame sequence from the filtered datacube, showcasing the spatial and temporal evolution of the isolated wave features. \u00a9-(e) Step-by-step visualization of the spatial filtering process: \u00a9 The time-averaged spatial power spectrum of the original dataset. (d) The spatial filter mask. (e) The result of applying the mask to the spatial Fourier transform. (f) The spatially-averaged temporal power spectrum, with the temporal filter masks (dashed lines) and the preserved oscillatory power (solid red curves). Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic signal data time = hdul [ 1 ] . data # Time Array hdul . close () cadence = 0.5 # cadence in seconds # frequency and wavenumber ranges for filtering f1 = 0.470 f2 = 0.530 k1 = 0.047 k2 = 0.250 # k-omega Analysis using WaLSAtools power , wavenumber , frequencies , filtered_cube , spatial_fft_map , torus_map , spatial_fft_filtered_map , temporal_fft , temporal_filter , temporal_frequencies , spatial_frequencies = WaLSAtools ( signal = signal_3d , time = time , method = 'k-omega' , filtering = True , processing_maps = True , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 , ) Processing k-\u03c9 analysis for a 3D cube with format 'txy' and shape (200, 130, 130). Input datacube size (t,x,y): (200, 130, 130) Spatially, the important values are: 2-pixel size = 2.00 (pixel) Nyquist wavenumber = 3.14 (pixel\u207b\u00b9) Temporally, the important values are: 2-element duration (Nyquist period) = 1.00 (s) Time series duration = 65.00 (s) Nyquist frequency = 1.00 (Hz) Constructing a k-\u03c9 diagram of the input datacube.......... Start filtering (in k-\u03c9 space) ...... The preserved wavenumbers are [0.047, 0.250] (pixel\u207b\u00b9) The preserved spatial sizes are [25.133, 133.685] (pixel) The preserved frequencies are [0.470, 0.530] (Hz) The preserved periods are [1, 2] (s) Making a 3D Fourier transform of the input datacube .......... Filtered datacube generated. 1 2 3 4 5 6 7 8 9 10 11 12 # Save the results # To be used in Figure 5 of the Nature Reviews Methods Primers paper. np . savez ( 'Saved_Parameters/k_omega_analysis.npz' , power = power , wavenumber = wavenumber , frequencies = frequencies , filtered_cube = filtered_cube , f1 = f1 , f2 = f2 , k1 = k1 , k2 = k2 ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 from matplotlib.colors import Normalize import matplotlib.pyplot as plt from matplotlib.ticker import LogLocator import numpy as np from matplotlib.colors import ListedColormap import matplotlib.pyplot as plt import matplotlib.patches as patches from matplotlib.colors import Normalize from matplotlib.ticker import AutoMinorLocator from WaLSAtools import WaLSA_save_pdf , WaLSA_histo_opt , WaLSA_plot_k_omega # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'DejaVu Sans' , # Set Helvetica as the default sans-serif font 'font.size' : 15 , # Global font size 'axes.titlesize' : 15 , # Title font size 'axes.labelsize' : 12.5 , # Axis label font size 'xtick.labelsize' : 12.5 , # X-axis tick label font size 'ytick.labelsize' : 12.5 , # Y-axis tick label font size 'legend.fontsize' : 12.5 , # Legend font size 'figure.titlesize' : 14 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 500 , # Make all fonts bold 'axes.titleweight' : 500 , # Make title font bold 'axes.labelweight' : 500 # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.4 ) plt . rc ( 'lines' , linewidth = 1.5 ) # Set up the figure layout fig = plt . figure ( figsize = ( 9.11 , 9.05 )) #-------------------------------------------------------------------------- # k-omega plot ax1d = fig . add_axes ([ 0.09 , 0.65 , 0.56 , 0.282 ]) # [left, bottom, width, height] ax1d = WaLSA_plot_k_omega ( kopower = power , kopower_xscale = wavenumber , kopower_yscale = frequencies * 1000. , xlog = False , ylog = False , xrange = ( 0 , 0.3 ), figsize = ( 8 , 4 ), cbartab = 0.18 , xtitle = 'Wavenumber (pixel\u207b\u00b9)' , ytitle = 'Frequency (mHz)' , colorbar_label = 'Log\u2081\u2080(Oscillation Power)' , ax = ax1d , f1 = 0.472 * 1000 , f2 = 0.530 * 1000 , k1 = 0.047 , k2 = 0.25 ) # Add label fig . text ( 0.008 , 0.963 , '(a)' , color = 'black' ) #-------------------------------------------------------------------------- # Plot the fist 6 frames of the filtered cube in a 3x2 grid fpositions = [ [ 0.737 , 0.867 , 0.11 , 0.108 ], [ 0.861 , 0.867 , 0.11 , 0.108 ], # Top row [ 0.737 , 0.741 , 0.11 , 0.108 ], [ 0.861 , 0.741 , 0.11 , 0.108 ], # Middle row [ 0.737 , 0.615 , 0.11 , 0.108 ], [ 0.861 , 0.615 , 0.11 , 0.108 ] # Bottom row ] rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_1.txt' ) / 255.0 idl_colormap_1 = ListedColormap ( rgb_values ) custom_cmap = plt . get_cmap ( idl_colormap_1 ) for i in range ( 6 ): im = filtered_cube [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = custom_cmap , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 16 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 13 ) ax . text ( 18 , 103 , str ( i + 1 ), fontsize = 12.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add a box around the six frames rectangle = patches . Rectangle ( ( 0.677 , 0.591 ), 0.313 , 0.3985 , zorder = 10 , linewidth = 1.5 , edgecolor = 'DodgerBlue' , facecolor = 'none' , linestyle = ':' ) fig . add_artist ( rectangle ) # Add label fig . text ( 0.687 , 0.963 , '(b)' , color = 'black' ) #-------------------------------------------------------------------------- # Plot the processing steps: Spatial FFT, Spatial FFT filter, and Filtered spatial FFT positions = [[ 0.078 , 0.31 , 0.215 , 0.215 ], [ 0.425 , 0.31 , 0.215 , 0.215 ], [ 0.767 , 0.31 , 0.215 , 0.215 ]] import matplotlib.pyplot as plt import numpy as np from matplotlib.colors import Normalize from matplotlib import cm # Load custom colormap rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_0.txt' ) / 255.0 cmap_torus_map = ListedColormap ( rgb_values ) rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_5.txt' ) / 255.0 cmap_spatial_fft = ListedColormap ( rgb_values ) reversed_colors = cmap_spatial_fft ( np . linspace ( 1 , 0 , 256 )) cmap_reversed = ListedColormap ( reversed_colors ) # Plot (c) Spatial FFT # Extract data and convert to magnitude if it's complex spatial_fft_map_data = spatial_fft_map [ 'data' ] if np . iscomplexobj ( spatial_fft_map_data ): # Check if the data is complex spatial_fft_map_data = np . abs ( spatial_fft_map_data ) # Use the magnitude for visualization ax1 = fig . add_axes ( positions [ 0 ]) im1 = ax1 . imshow ( spatial_fft_map_data , cmap = cmap_spatial_fft , aspect = 'equal' , extent = [ np . min ( spatial_frequencies ), np . max ( spatial_frequencies ), np . min ( spatial_frequencies ), np . max ( spatial_frequencies )], norm = Normalize ( vmin = np . nanmin ( spatial_fft_map_data ) + 1 , vmax = np . nanmax ( spatial_fft_map_data ) - 1 ) ) ax1 . set_xlabel ( 'Wavenumber (k\u2093; pixel\u207b\u00b9)' ) ax1 . set_ylabel ( 'Wavenumber (k\u1d67; pixel\u207b\u00b9)' ) ax1 . minorticks_on () ax1 . xaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax1 . yaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax1 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax1 . xaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax1 . yaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax1 . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) ax1 . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) ax1 . xaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax1 . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) # Crosshair ax1 . axhline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax1 . axvline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax1 . set_xlim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) ax1 . set_ylim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) # Annotation ax1 . text ( 0 , 3.7 , '(c) Spatial FFT' , ha = 'center' , color = 'black' ) # Plot (d) Spatial FFT Filter # Extract data and convert to magnitude if it's complex torus_map_data = torus_map [ 'data' ] if np . iscomplexobj ( torus_map_data ): # Check if the data is complex torus_map_data = np . abs ( torus_map_data ) # Use the magnitude for visualization ax2 = fig . add_axes ( positions [ 1 ]) im2 = ax2 . imshow ( torus_map_data , cmap = cmap_torus_map , aspect = 'equal' , extent = [ np . min ( spatial_frequencies ), np . max ( spatial_frequencies ), np . min ( spatial_frequencies ), np . max ( spatial_frequencies )], norm = Normalize ( vmin = 0 , vmax = 1 ) ) ax2 . set_xlabel ( 'Wavenumber (k\u2093; pixel\u207b\u00b9)' ) ax2 . set_ylabel ( 'Wavenumber (k\u1d67; pixel\u207b\u00b9)' ) ax2 . minorticks_on () ax2 . xaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax2 . yaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax2 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax2 . xaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax2 . yaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax2 . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) ax2 . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) ax2 . xaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax2 . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) # Crosshair ax2 . axhline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax2 . axvline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax2 . set_xlim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) ax2 . set_ylim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) # Annotation ax2 . text ( 0 , 3.7 , '(d) Spatial FFT filter' , ha = 'center' , color = 'black' ) # Plot (e) Filtered Spatial FFT # Extract data and convert to magnitude if it's complex spatial_fft_filtered_map_data = spatial_fft_filtered_map [ 'data' ] if np . iscomplexobj ( spatial_fft_filtered_map_data ): # Check if the data is complex spatial_fft_filtered_map_data = np . abs ( spatial_fft_filtered_map_data ) # Use the magnitude for visualization ax3 = fig . add_axes ( positions [ 2 ]) im3 = ax3 . imshow ( spatial_fft_filtered_map_data , cmap = cmap_reversed , aspect = 'equal' , extent = [ np . min ( spatial_frequencies ), np . max ( spatial_frequencies ), np . min ( spatial_frequencies ), np . max ( spatial_frequencies )], norm = Normalize ( vmin = np . nanmin ( spatial_fft_filtered_map_data ) + 1 , vmax = np . nanmax ( spatial_fft_filtered_map_data ) - 1 ) ) ax3 . set_xlabel ( 'Wavenumber (k\u2093; pixel\u207b\u00b9)' ) ax3 . set_ylabel ( 'Wavenumber (k\u1d67; pixel\u207b\u00b9)' ) ax3 . minorticks_on () ax3 . xaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax3 . yaxis . set_minor_locator ( plt . MultipleLocator ( 3 )) ax3 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax3 . xaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax3 . yaxis . set_major_locator ( plt . MultipleLocator ( 1 )) ax3 . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) ax3 . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) ax3 . xaxis . set_minor_locator ( AutoMinorLocator ( 3 )) ax3 . yaxis . set_minor_locator ( AutoMinorLocator ( 3 )) # Crosshair ax3 . axhline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax3 . axvline ( 0 , color = 'white' , linewidth = 1 , linestyle = ( 0 , ( 5 , 10 ))) ax3 . set_xlim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) ax3 . set_ylim ( np . min ( spatial_frequencies ), np . max ( spatial_frequencies )) # Annotation ax3 . text ( 0 , 3.7 , '(e) Filtered spatial FFT' , ha = 'center' , color = 'black' ); #-------------------------------------------------------------------------- # Plot the temporal FFT, temporal filter, and filtered FFT ax4 = fig . add_axes ([ 0.088 , 0.062 , 0.889 , 0.153 ]) # Position for the plot normalised_temporal_fft = temporal_fft / ( 3.3 * 10 ** 6 ) # Plot temporal FFT (main line with logarithmic y-axis) ax4 . plot ( temporal_frequencies * 1000 , np . abs ( normalised_temporal_fft ), label = 'FFT Power' , color = 'black' , linewidth = 0.5 ) ax4 . set_yscale ( 'log' ) # Logarithmic y-axis # Add vertical line at x=0 ax4 . axvline ( 0 , color = 'black' , linewidth = 1.5 , linestyle = '--' ) # Plot temporal filter temporal_fft_plot_ymin = 10 ** np . nanmin ( np . log10 ( normalised_temporal_fft )) temporal_fft_plot_ymax = 10 ** np . nanmax ( np . log10 ( normalised_temporal_fft )) temporal_fft_plot_ymin = 10 **- 3 temporal_fft_plot_ymax = 10 ** 2 real_temporal_filter = np . real ( temporal_filter ) # Extract the real part ax4 . plot ( temporal_frequencies * 1000 , np . maximum ( real_temporal_filter , temporal_fft_plot_ymin ), label = 'Temporal Filter' , color = 'blue' , linewidth = 1.5 , linestyle = '--' ) # Plot filtered FFT ax4 . plot ( temporal_frequencies * 1000 , np . maximum ( np . abs ( np . real ( normalised_temporal_fft ) * real_temporal_filter ), temporal_fft_plot_ymin ), label = 'Filtered FFT' , color = 'red' , linewidth = 1.3 ) # Configure ticks and labels ax4 . set_xlabel ( 'Frequency (mHz)' ) ax4 . set_ylabel ( 'Power (arb. units)' ) ax4 . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax4 . tick_params ( axis = 'both' , which = 'major' , length = 6 , width = 1.1 ) ax4 . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) ax4 . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Set custom ticks ax4 . xaxis . set_major_locator ( plt . MultipleLocator ( 250 )) ax4 . xaxis . set_minor_locator ( plt . MultipleLocator ( 50 )) ax4 . set_yticks ([ 10 **- 3 , 10 **- 2 , 10 **- 1 , 10 ** 0 , 10 ** 1 , 10 ** 2 ], minor = False ) ax4 . set_yticklabels ([ '' , '10\u207b\u00b2' , '' , '10\u2070' , '' , '10\u00b2' ]) ax4 . yaxis . set_minor_locator ( LogLocator ( base = 10.0 , subs = np . arange ( 1.0 , 10.0 ) * 0.1 , numticks = 10 )) # Set plot limits ax4 . set_xlim ([ - 999 , 1000 ]) ax4 . set_ylim ([ temporal_fft_plot_ymin , temporal_fft_plot_ymax ]) # Add label ax4 . text ( - 980 , 15 , '(f)' , color = 'black' ) #-------------------------------------------------------------------------- # Adjust overall layout # fig.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.0, hspace=0.0) # Save the figure as a PDF pdf_path = 'Figures/FigS4_k-omega_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS4_k-omega_analysis.pdf'", "title": "Worked Example - NRMP: k-\u03c9 Analysis and Filtering"}, {"location": "python/k-omega-pod-example/", "text": "Worked Example - NRMP: k-\u03c9 and POD Analysis \u00b6 This example demonstrates the application of k-\u03c9 filtering and Proper Orthogonal Decomposition (POD) to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset with k-\u03c9 and POD, we can identify and isolate specific wave modes, revealing their spatial structures and temporal dynamics. k-\u03c9 Analysis \u00b6 k-\u03c9 analysis is a technique used to study wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both the spatial domain (wavenumber, k) and the temporal domain (frequency, \u03c9). The resulting k-\u03c9 diagram shows how wave power is distributed across different spatial and temporal scales, providing insights into wave dispersion relations and the characteristics of different wave modes. In this example, we apply k-\u03c9 analysis to the synthetic spatio-temporal dataset to identify and isolate a specific wave mode with a frequency of 500 mHz and wavenumbers between 0.05 and 0.25 pixel -1 . We then use Fourier filtering to extract this wave mode from the dataset, revealing its spatial structure and temporal evolution. Proper Orthogonal Decomposition (POD) \u00b6 Proper Orthogonal Decomposition (POD) is a powerful technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. In this example, we apply POD to the synthetic spatio-temporal dataset to identify the dominant spatial modes of oscillation. We then apply frequency filtering to the temporal coefficients of these modes to isolate the 500 mHz wave mode. This allows us to compare the results of k-\u03c9 filtering and POD-based filtering, highlighting their respective strengths and limitations. Analysis and Figure The figure below shows a comparison of k-\u03c9 filtering and POD analysis applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis with Fourier filtering Proper Orthogonal Decomposition (POD) with frequency filtering WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 5 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Comparison of k-\u03c9 filtering and POD analysis. (a) k-\u03c9 power diagram of the synthetic spatio-temporal dataset with a targeted filtering region (dashed lines). (b) First six spatial modes from POD analysis (each 130\u00d7130 pixels 2 ). \u00a9 First six frames of the k-\u03c9 filtered datacube centred at 500 mHz (\u00b130 mHz) and wavenumbers 0.05\u22120.25 pixel -1 . (d) First six frames of the frequency-filtered POD reconstruction at 500 mHz using the first 22 POD modes (99% of total variance). All images and spatial modes are plotted with their own minimum and maximum values to highlight detailed structures within them. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import numpy as np from astropy.io import fits # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic signal data hdul . close () cadence = 0.5 # cadence in seconds # Load k-omega parameters calculated and saved in FIGS4__komega_analysis.ipynb ko_data = np . load ( 'Saved_Parameters/k_omega_analysis.npz' ) power = ko_data [ 'power' ] wavenumber = ko_data [ 'wavenumber' ] frequencies = ko_data [ 'frequencies' ] filtered_cube = ko_data [ 'filtered_cube' ] f1 = ko_data [ 'f1' ] f2 = ko_data [ 'f2' ] k1 = ko_data [ 'k1' ] k2 = ko_data [ 'k2' ] # Load POD parameters calculated and saved in FIGS5_FIGS6_FIGS7__POD.ipynb pod_modes = fits . getdata ( 'Saved_Parameters/pod_first_6_spatial_modes.fits' ) frequency_filtered_modes = fits . getdata ( 'Saved_Parameters/POD_first_6_frequency_filtered_spatial_modes_at_500mHz.fits' ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator from WaLSAtools import WaLSA_save_pdf , WaLSA_histo_opt , WaLSA_plot_k_omega #------------------------------------------------------------------------------------ def calculate_grid_positions ( left = 0.05 , bottom = 0.05 , h_distance = 0.02 , v_distance = 0.02 , nrows = 3 , ncols = 2 , width = None , height = None , right = None , top = None ): \"\"\" Calculate positions for a grid of subplots. Parameters: - left (float): x position of the entire grid block (0 to 1) - bottom (float): y position of the entire grid block (0 to 1) - h_distance (float): horizontal distance between plots (0 to 1) - v_distance (float): vertical distance between plots (0 to 1) - nrows (int): number of rows in the grid - ncols (int): number of columns in the grid - width (float): total width of the grid block (optional, overrides right) - height (float): total height of the grid block (optional, overrides top) - right (float): x position of the right edge of the grid block (optional) - top (float): y position of the top edge of the grid block (optional) Returns: - List of positions for each subplot in [left, bottom, width, height] format. \"\"\" # If width is not provided, calculate it using 'right' or fallback to previous logic if width is None : if right is not None : width = right - left else : width = 1 - left - h_distance * ( ncols - 1 ) # Default calculation # If height is not provided, calculate it using 'top' or fallback to previous logic if height is None : if top is not None : height = top - bottom else : height = 1 - bottom - v_distance * ( nrows - 1 ) # Default calculation if width <= 0 or height <= 0 : raise ValueError ( \"Both 'width' and 'height' must be positive values.\" ) # Calculate the available width and height for subplots (account for distances) total_width = width - h_distance * ( ncols - 1 ) # Total available width for subplots total_height = height - v_distance * ( nrows - 1 ) # Total available height for subplots # Calculate the width and height for each image (keep aspect ratio 1:1) subplot_width = total_width / ncols subplot_height = total_height / nrows subplot_size = min ( subplot_width , subplot_height ) # Ensure aspect ratio is 1:1 # Calculate positions for each subplot positions = [] for row in range ( nrows ): for col in range ( ncols ): x = left + col * ( subplot_size + h_distance ) y = bottom + ( nrows - 1 - row ) * ( subplot_size + v_distance ) # from bottom to top positions . append ([ x , y , subplot_size , subplot_size ]) return positions #-------------------------------------------------------------------------------------- # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'DejaVu Sans' , # Set Helvetica as the default sans-serif font 'font.size' : 15 , # Global font size 'axes.titlesize' : 15 , # Title font size 'axes.labelsize' : 12.5 , # Axis label font size 'xtick.labelsize' : 12.5 , # X-axis tick label font size 'ytick.labelsize' : 12.5 , # Y-axis tick label font size 'legend.fontsize' : 12.5 , # Legend font size 'figure.titlesize' : 14 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 500 , # Make all fonts bold 'axes.titleweight' : 500 , # Make title font bold 'axes.labelweight' : 500 # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.4 ) plt . rc ( 'lines' , linewidth = 1.5 ) # Set up the figure layout fig = plt . figure ( figsize = ( 9.11 , 9.31 )) #-------------------------------------------------------------------------- # k-omega plot ax1d = fig . add_axes ([ 0.085 , 0.529 , 0.405 , 0.436 ]) # [left, bottom, width, height] ax1d = WaLSA_plot_k_omega ( kopower = power , kopower_xscale = wavenumber , kopower_yscale = frequencies * 1000. , xlog = False , ylog = False , xrange = ( 0 , 0.3 ), figsize = ( 8 , 4 ), cbartab = 0.22 , xtitle = 'Wavenumber (pixel\u207b\u00b9)' , ytitle = 'Frequency (mHz)' , colorbar_label = 'Log\u2081\u2080(Oscillation Power)' , ax = ax1d , f1 = f1 * 1000 , f2 = f2 * 1000 , k1 = k1 , k2 = k2 , colorbar_location = 'top' ) # Add label fig . text ( 0.27 , 0.982 , '(a) k\u2212\u03c9 diagram and filtering' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Plot the fist 6 POD modes in a 3x2 grid left = 0.67 # Left position of the entire grid block bottom = 0.474 # Bottom position of the entire grid block h_distance = 0.024 # Horizontal distance between plots v_distance = 0.022 # Vertical distance between plots # Generate 3x2 grid positions fpositions = calculate_grid_positions ( left , bottom , h_distance , v_distance , nrows = 3 , ncols = 2 , right = 0.987 ) for i in range ( 6 ): im = pod_modes [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 19 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 16 ) ax . text ( 18 , 103 , 'P' + str ( i + 1 ), fontsize = 12.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add label fig . text ( 0.80 , 0.9820 , '(b) POD spatial modes' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Plot the fist 6 k-omega filtered images in a 1x6 grid left = 0. # Left position of the entire grid block bottom = 0.23 # Bottom position of the entire grid block h_distance = 0.02 # Horizontal distance between plots v_distance = 0.02 # Vertical distance between plots # Generate 3x2 grid positions fpositions = calculate_grid_positions ( left , bottom , h_distance , v_distance , nrows = 1 , ncols = 6 , width = 1.0 ) for i in range ( 6 ): im = filtered_cube [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 19 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 16 ) ax . text ( 18 , 103 , str ( i + 1 ), fontsize = 13.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add label fig . text ( 0.50 , 0.40 , '(c) k\u2212\u03c9 filtered images' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Plot the fist 6 POD frequency\u2212filtered spatial images in a 1x6 grid left = 0. # Left position of the entire grid block bottom = 0. # Bottom position of the entire grid block h_distance = 0.02 # Horizontal distance between plots v_distance = 0.02 # Vertical distance between plots # Generate 3x2 grid positions fpositions = calculate_grid_positions ( left , bottom , h_distance , v_distance , nrows = 1 , ncols = 6 , width = 1.0 ) for i in range ( 6 ): im = frequency_filtered_modes [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 19 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 16 ) ax . text ( 18 , 103 , str ( i + 1 ), fontsize = 13.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add label fig . text ( 0.50 , 0.17 , '(d) POD frequency\u2212filtered spatial images' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Save the figure as a PDF pdf_path = 'Figures/Fig5_k-omega_and_pod_analyses.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig5_k-omega_and_pod_analyses.pdf'", "title": "k-&#969; and POD"}, {"location": "python/k-omega-pod-example/#worked-example-nrmp-k-and-pod-analysis", "text": "This example demonstrates the application of k-\u03c9 filtering and Proper Orthogonal Decomposition (POD) to a synthetic spatio-temporal dataset. The dataset consists of a time series of 2D images, representing the evolution of wave patterns over both space and time. By analysing this dataset with k-\u03c9 and POD, we can identify and isolate specific wave modes, revealing their spatial structures and temporal dynamics.", "title": "Worked Example - NRMP: k-\u03c9 and POD Analysis"}, {"location": "python/k-omega-pod-example/#k-analysis", "text": "k-\u03c9 analysis is a technique used to study wave phenomena in spatio-temporal datasets. It involves calculating the power spectrum of the data in both the spatial domain (wavenumber, k) and the temporal domain (frequency, \u03c9). The resulting k-\u03c9 diagram shows how wave power is distributed across different spatial and temporal scales, providing insights into wave dispersion relations and the characteristics of different wave modes. In this example, we apply k-\u03c9 analysis to the synthetic spatio-temporal dataset to identify and isolate a specific wave mode with a frequency of 500 mHz and wavenumbers between 0.05 and 0.25 pixel -1 . We then use Fourier filtering to extract this wave mode from the dataset, revealing its spatial structure and temporal evolution.", "title": "k-\u03c9 Analysis"}, {"location": "python/k-omega-pod-example/#proper-orthogonal-decomposition-pod", "text": "Proper Orthogonal Decomposition (POD) is a powerful technique for analysing multi-dimensional data. It identifies dominant spatial patterns, or modes, that capture the most significant variations in the data. POD is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. In this example, we apply POD to the synthetic spatio-temporal dataset to identify the dominant spatial modes of oscillation. We then apply frequency filtering to the temporal coefficients of these modes to isolate the 500 mHz wave mode. This allows us to compare the results of k-\u03c9 filtering and POD-based filtering, highlighting their respective strengths and limitations. Analysis and Figure The figure below shows a comparison of k-\u03c9 filtering and POD analysis applied to the synthetic spatio-temporal dataset. Methods used: k-\u03c9 analysis with Fourier filtering Proper Orthogonal Decomposition (POD) with frequency filtering WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 5 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Comparison of k-\u03c9 filtering and POD analysis. (a) k-\u03c9 power diagram of the synthetic spatio-temporal dataset with a targeted filtering region (dashed lines). (b) First six spatial modes from POD analysis (each 130\u00d7130 pixels 2 ). \u00a9 First six frames of the k-\u03c9 filtered datacube centred at 500 mHz (\u00b130 mHz) and wavenumbers 0.05\u22120.25 pixel -1 . (d) First six frames of the frequency-filtered POD reconstruction at 500 mHz using the first 22 POD modes (99% of total variance). All images and spatial modes are plotted with their own minimum and maximum values to highlight detailed structures within them. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import numpy as np from astropy.io import fits # Load synthetic data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic signal data hdul . close () cadence = 0.5 # cadence in seconds # Load k-omega parameters calculated and saved in FIGS4__komega_analysis.ipynb ko_data = np . load ( 'Saved_Parameters/k_omega_analysis.npz' ) power = ko_data [ 'power' ] wavenumber = ko_data [ 'wavenumber' ] frequencies = ko_data [ 'frequencies' ] filtered_cube = ko_data [ 'filtered_cube' ] f1 = ko_data [ 'f1' ] f2 = ko_data [ 'f2' ] k1 = ko_data [ 'k1' ] k2 = ko_data [ 'k2' ] # Load POD parameters calculated and saved in FIGS5_FIGS6_FIGS7__POD.ipynb pod_modes = fits . getdata ( 'Saved_Parameters/pod_first_6_spatial_modes.fits' ) frequency_filtered_modes = fits . getdata ( 'Saved_Parameters/POD_first_6_frequency_filtered_spatial_modes_at_500mHz.fits' ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 import numpy as np import matplotlib.pyplot as plt from matplotlib.ticker import AutoMinorLocator from WaLSAtools import WaLSA_save_pdf , WaLSA_histo_opt , WaLSA_plot_k_omega #------------------------------------------------------------------------------------ def calculate_grid_positions ( left = 0.05 , bottom = 0.05 , h_distance = 0.02 , v_distance = 0.02 , nrows = 3 , ncols = 2 , width = None , height = None , right = None , top = None ): \"\"\" Calculate positions for a grid of subplots. Parameters: - left (float): x position of the entire grid block (0 to 1) - bottom (float): y position of the entire grid block (0 to 1) - h_distance (float): horizontal distance between plots (0 to 1) - v_distance (float): vertical distance between plots (0 to 1) - nrows (int): number of rows in the grid - ncols (int): number of columns in the grid - width (float): total width of the grid block (optional, overrides right) - height (float): total height of the grid block (optional, overrides top) - right (float): x position of the right edge of the grid block (optional) - top (float): y position of the top edge of the grid block (optional) Returns: - List of positions for each subplot in [left, bottom, width, height] format. \"\"\" # If width is not provided, calculate it using 'right' or fallback to previous logic if width is None : if right is not None : width = right - left else : width = 1 - left - h_distance * ( ncols - 1 ) # Default calculation # If height is not provided, calculate it using 'top' or fallback to previous logic if height is None : if top is not None : height = top - bottom else : height = 1 - bottom - v_distance * ( nrows - 1 ) # Default calculation if width <= 0 or height <= 0 : raise ValueError ( \"Both 'width' and 'height' must be positive values.\" ) # Calculate the available width and height for subplots (account for distances) total_width = width - h_distance * ( ncols - 1 ) # Total available width for subplots total_height = height - v_distance * ( nrows - 1 ) # Total available height for subplots # Calculate the width and height for each image (keep aspect ratio 1:1) subplot_width = total_width / ncols subplot_height = total_height / nrows subplot_size = min ( subplot_width , subplot_height ) # Ensure aspect ratio is 1:1 # Calculate positions for each subplot positions = [] for row in range ( nrows ): for col in range ( ncols ): x = left + col * ( subplot_size + h_distance ) y = bottom + ( nrows - 1 - row ) * ( subplot_size + v_distance ) # from bottom to top positions . append ([ x , y , subplot_size , subplot_size ]) return positions #-------------------------------------------------------------------------------------- # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'DejaVu Sans' , # Set Helvetica as the default sans-serif font 'font.size' : 15 , # Global font size 'axes.titlesize' : 15 , # Title font size 'axes.labelsize' : 12.5 , # Axis label font size 'xtick.labelsize' : 12.5 , # X-axis tick label font size 'ytick.labelsize' : 12.5 , # Y-axis tick label font size 'legend.fontsize' : 12.5 , # Legend font size 'figure.titlesize' : 14 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 500 , # Make all fonts bold 'axes.titleweight' : 500 , # Make title font bold 'axes.labelweight' : 500 # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.4 ) plt . rc ( 'lines' , linewidth = 1.5 ) # Set up the figure layout fig = plt . figure ( figsize = ( 9.11 , 9.31 )) #-------------------------------------------------------------------------- # k-omega plot ax1d = fig . add_axes ([ 0.085 , 0.529 , 0.405 , 0.436 ]) # [left, bottom, width, height] ax1d = WaLSA_plot_k_omega ( kopower = power , kopower_xscale = wavenumber , kopower_yscale = frequencies * 1000. , xlog = False , ylog = False , xrange = ( 0 , 0.3 ), figsize = ( 8 , 4 ), cbartab = 0.22 , xtitle = 'Wavenumber (pixel\u207b\u00b9)' , ytitle = 'Frequency (mHz)' , colorbar_label = 'Log\u2081\u2080(Oscillation Power)' , ax = ax1d , f1 = f1 * 1000 , f2 = f2 * 1000 , k1 = k1 , k2 = k2 , colorbar_location = 'top' ) # Add label fig . text ( 0.27 , 0.982 , '(a) k\u2212\u03c9 diagram and filtering' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Plot the fist 6 POD modes in a 3x2 grid left = 0.67 # Left position of the entire grid block bottom = 0.474 # Bottom position of the entire grid block h_distance = 0.024 # Horizontal distance between plots v_distance = 0.022 # Vertical distance between plots # Generate 3x2 grid positions fpositions = calculate_grid_positions ( left , bottom , h_distance , v_distance , nrows = 3 , ncols = 2 , right = 0.987 ) for i in range ( 6 ): im = pod_modes [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 19 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 16 ) ax . text ( 18 , 103 , 'P' + str ( i + 1 ), fontsize = 12.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add label fig . text ( 0.80 , 0.9820 , '(b) POD spatial modes' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Plot the fist 6 k-omega filtered images in a 1x6 grid left = 0. # Left position of the entire grid block bottom = 0.23 # Bottom position of the entire grid block h_distance = 0.02 # Horizontal distance between plots v_distance = 0.02 # Vertical distance between plots # Generate 3x2 grid positions fpositions = calculate_grid_positions ( left , bottom , h_distance , v_distance , nrows = 1 , ncols = 6 , width = 1.0 ) for i in range ( 6 ): im = filtered_cube [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 19 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 16 ) ax . text ( 18 , 103 , str ( i + 1 ), fontsize = 13.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add label fig . text ( 0.50 , 0.40 , '(c) k\u2212\u03c9 filtered images' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Plot the fist 6 POD frequency\u2212filtered spatial images in a 1x6 grid left = 0. # Left position of the entire grid block bottom = 0. # Bottom position of the entire grid block h_distance = 0.02 # Horizontal distance between plots v_distance = 0.02 # Vertical distance between plots # Generate 3x2 grid positions fpositions = calculate_grid_positions ( left , bottom , h_distance , v_distance , nrows = 1 , ncols = 6 , width = 1.0 ) for i in range ( 6 ): im = frequency_filtered_modes [ i , :, :] ax = fig . add_axes ( fpositions [ i ]) # Create each subplot in specified position ax . imshow ( WaLSA_histo_opt ( im ), cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) # Configure axis ticks and labels ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . set_xticks ( np . arange ( 0 , 130 , 20 )) ax . set_yticks ( np . arange ( 0 , 130 , 20 )) ax . tick_params ( axis = 'both' , which = 'major' , length = 5 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 3 , width = 1.1 ) # Minor ticks ax . xaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . yaxis . set_minor_locator ( AutoMinorLocator ( 2 )) ax . set_xticklabels ([]) ax . set_yticklabels ([]) # Plot specific markers and labels ax . plot ( 18 , 110 , 'o' , color = 'black' , markersize = 19 ) ax . plot ( 18 , 110 , 'o' , color = 'white' , markersize = 16 ) ax . text ( 18 , 103 , str ( i + 1 ), fontsize = 13.5 , ha = 'center' , color = 'black' , fontweight = 500 ) # Add label fig . text ( 0.50 , 0.17 , '(d) POD frequency\u2212filtered spatial images' , color = 'black' , ha = 'center' ) #-------------------------------------------------------------------------- # Save the figure as a PDF pdf_path = 'Figures/Fig5_k-omega_and_pod_analyses.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig5_k-omega_and_pod_analyses.pdf'", "title": "Proper Orthogonal Decomposition (POD)"}, {"location": "python/nrmp-synthetic-data/", "text": "Worked Example - NRMP: Synthetic Datasets \u00b6 This page provides detailed information about the synthetic datasets used in the worked examples presented in the Nature Reviews Methods Primers article. These datasets were carefully crafted to evaluate the performance of various wave analysis techniques in a controlled environment. They comprise a 1D time series and a spatio-temporal datacube, each containing a variety of oscillatory signals with known parameters. Synthetic 1D Time Series \u00b6 The synthetic 1D time series is constructed by combining five sinusoidal waves with distinct frequencies (5, 12, 15, 18, and 25 Hz) and amplitudes. To introduce realistic variability, the amplitudes of these waves are modulated with an envelope function. Additional features, such as a short-lived transient oscillation, a weak high-frequency signal, and a quasi-periodic signature, are also incorporated. Non-linearity is introduced through a mathematical transformation, and random noise is added to simulate measurement imperfections. A second, nearly identical time series is also generated with adjusted phases for some of the wave components. This simulates observing the signal at a different location or time, enabling the evaluation of cross-correlation techniques. Synthetic Spatio-Temporal Datacube \u00b6 The synthetic spatio-temporal datacube comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. The datacube contains 50 concentric circular regions, each with ten sinusoidal waves of distinct frequencies, amplitudes, and phases. Additional complexities, such as a transient cubic polynomial signal, simulated transverse motion, a fluting-like instability, a quasi-periodic signal, and noise, are also incorporated. Detailed Parameters \u00b6 The tables below provide detailed parameter specifications for the synthetic datasets. [Image of Supplementary Table S1 from NRMP article] Table Caption: Parameters for the synthetic 1D time series. [Image of Supplementary Table S2 from NRMP article] Table Caption: Parameters for the synthetic spatio-temporal datacube. These synthetic datasets serve as valuable benchmarks for assessing the capabilities and limitations of different wave analysis techniques. By comparing the analysis results against the known ground truth, researchers can gain insights into the appropriate use cases for each method and improve the reliability of their interpretations when analysing real-world data.", "title": "Worked Example - NRMP: Synthetic Datasets"}, {"location": "python/nrmp-synthetic-data/#worked-example-nrmp-synthetic-datasets", "text": "This page provides detailed information about the synthetic datasets used in the worked examples presented in the Nature Reviews Methods Primers article. These datasets were carefully crafted to evaluate the performance of various wave analysis techniques in a controlled environment. They comprise a 1D time series and a spatio-temporal datacube, each containing a variety of oscillatory signals with known parameters.", "title": "Worked Example - NRMP: Synthetic Datasets"}, {"location": "python/nrmp-synthetic-data/#synthetic-1d-time-series", "text": "The synthetic 1D time series is constructed by combining five sinusoidal waves with distinct frequencies (5, 12, 15, 18, and 25 Hz) and amplitudes. To introduce realistic variability, the amplitudes of these waves are modulated with an envelope function. Additional features, such as a short-lived transient oscillation, a weak high-frequency signal, and a quasi-periodic signature, are also incorporated. Non-linearity is introduced through a mathematical transformation, and random noise is added to simulate measurement imperfections. A second, nearly identical time series is also generated with adjusted phases for some of the wave components. This simulates observing the signal at a different location or time, enabling the evaluation of cross-correlation techniques.", "title": "Synthetic 1D Time Series"}, {"location": "python/nrmp-synthetic-data/#synthetic-spatio-temporal-datacube", "text": "The synthetic spatio-temporal datacube comprises a time series of 2D images, representing the evolution of wave patterns over both space and time. The datacube contains 50 concentric circular regions, each with ten sinusoidal waves of distinct frequencies, amplitudes, and phases. Additional complexities, such as a transient cubic polynomial signal, simulated transverse motion, a fluting-like instability, a quasi-periodic signal, and noise, are also incorporated.", "title": "Synthetic Spatio-Temporal Datacube"}, {"location": "python/nrmp-synthetic-data/#detailed-parameters", "text": "The tables below provide detailed parameter specifications for the synthetic datasets. [Image of Supplementary Table S1 from NRMP article] Table Caption: Parameters for the synthetic 1D time series. [Image of Supplementary Table S2 from NRMP article] Table Caption: Parameters for the synthetic spatio-temporal datacube. These synthetic datasets serve as valuable benchmarks for assessing the capabilities and limitations of different wave analysis techniques. By comparing the analysis results against the known ground truth, researchers can gain insights into the appropriate use cases for each method and improve the reliability of their interpretations when analysing real-world data.", "title": "Detailed Parameters"}, {"location": "python/pod-eigenvalues-example/", "text": "Worked Example - NRMP: POD Eigenvalues and Explained Variance \u00b6 This example delves deeper into the analysis of Proper Orthogonal Decomposition (POD) results, focusing on the eigenvalues and explained variance. By examining the eigenvalues and their corresponding spatial modes, we can gain a better understanding of the dominant patterns and their contributions to the overall variability in the data. Analysis and Figure The figure below summarizes the POD analysis results, including the normalized eigenvalues, combined power spectrum, and cumulative explained variance. Methods used: Proper Orthogonal Decomposition (POD) Power spectrum analysis Variance analysis WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S6 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: POD mode analysis. Top left: Normalized squared singular values (eigenvalues) of the first ten POD modes, demonstrating their relative contributions to the total variance. Top middle: Combined power spectrum of the first ten POD modes, revealing the dominant frequencies captured by these ten modes. The vertical dotted lines mark the ten base frequencies used to construct the synthetic data; the red dashed line identifies the 95% confidence level (estimated from 1000 bootstrap resamples). Top right: Cumulative explained variance as a function of the number of POD modes included, with vertical lines indicating the cumulative variance captured by 2 (blue), 10 (green), and 22 (red) modes. Bottom left: Reconstructed image (130\u00d7130 pixels 2 ) of the first frame of the time series using the first 22 modes. Bottom middle: Original image (130\u00d7130 pixels 2 ; first frame) of the datacube. Bottom right: Scatter plot of the reconstructed and original image. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , num_modes = 10 , num_top_frequencies = 10 , num_cumulative_modes = 50 , timestep_to_reconstruct = 1 , num_modes_reconstruct = 22 ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.7], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.39], [0.35, 0.32], [0.4, 0.25], [0.45, 0.24], [0.55, 0.18]] Total variance contribution of the first 10 modes: 96.01% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (50,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (ndarray, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (NoneType, Shape: None): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (NoneType, Shape: None): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 3 4 5 6 7 input_data = pod_results [ 'input_data' ] eigenvalue_contribution = pod_results [ 'eigenvalue_contribution' ] combined_welch_psd = pod_results [ 'combined_welch_psd' ] frequencies = pod_results [ 'frequencies' ] combined_welch_significance = pod_results [ 'combined_welch_significance' ] cumulative_eigenvalues = pod_results [ 'cumulative_eigenvalues' ] reconstructed = pod_results [ 'reconstructed' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import AutoMinorLocator import matplotlib.ticker as ticker from matplotlib.ticker import MaxNLocator # Setting global parameters for the plots plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 16 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 14 , # X-axis tick label font size 'ytick.labelsize' : 14 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 17 , # Figure title font size 'axes.grid' : False , # Turn off grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) fig = plt . figure ( figsize = ( 15 , 10 )) # Create subplots with GridSpec gs1 = gridspec . GridSpec ( 2 , 3 , figure = fig , wspace = 0.45 , hspace = 0.4 ) # Plot normalized eigenvalues ax_ev = plt . subplot ( gs1 [ 0 , 0 ]) ax_ev . set_title ( f 'Normalized Eigenvalues' ) mode_nums = np . arange ( 1 , 11 ) ax_ev . plot ( mode_nums , 100 * eigenvalue_contribution [ 0 : 10 ], 'k-o' ) ax_ev . set_xlabel ( 'Modes' ) ax_ev . set_ylabel ( 'Eigenvalues (%)' ) ax_ev . grid ( True ) ax_ev . xaxis . set_major_locator ( ticker . MultipleLocator ( 1 )) ax_ev . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_ev . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_ev . spines . values (): spine . set_linewidth ( 1.5 ) # Plot combined power spectrum ax_freq = plt . subplot ( gs1 [ 0 , 1 ]) pre_defined_freq = [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ] for freq in pre_defined_freq : ax_freq . axvline ( x = freq , color = 'green' , linestyle = ':' , linewidth = 1.5 ) ax_freq . plot ( frequencies * 1000. , combined_welch_psd / np . max ( combined_welch_psd ), 'k' ) ax_freq . plot ( frequencies * 1000. , combined_welch_significance , 'r--' , label = '95% Significance Threshold' ) ax_freq . set_title ( f 'Combined Power Spectrum' ) ax_freq . set_xlabel ( 'Frequency (mHz)' ) ax_freq . set_ylabel ( 'Normalized Power' ) ax_freq . grid ( False ) ax_freq . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_freq . spines . values (): spine . set_linewidth ( 1.5 ) ax_freq . set_xlim ( 0 , 1000 ) ax_freq . text ( 0.95 , 0.95 , '10 modes' , transform = ax_freq . transAxes , fontsize = 15 , verticalalignment = 'top' , horizontalalignment = 'right' ) # Plot cumulative eigenvalues ax_freq = plt . subplot ( gs1 [ 0 , 2 ]) ax_freq . plot ( cumulative_eigenvalues , 'k-o' ) ax_freq . set_title ( f 'Cumulative Eigenvalues' ) ax_freq . set_xlabel ( 'Number of modes' ) ax_freq . set_ylabel ( 'Eigenvalues (%)' ) ax_freq . grid ( False ) ax_freq . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_freq . spines . values (): spine . set_linewidth ( 1.5 ) ax_freq . set_xlim ( 1 , 30 ) ax_freq . set_ylim ( 0 , 110 ) # Identify indices where 90% and 95% is reached thresholds = [ 84 , 96 , 99 ] colors = [ 'blue' , 'green' , 'red' ] for threshold , color in zip ( thresholds , colors ): index = next ( i for i , v in enumerate ( cumulative_eigenvalues ) if v >= threshold ) ax_freq . axvline ( x = index , color = color , linestyle = '--' , label = f ' { threshold } % at mode { index } ' ) # Plot reconstructed image for frame number 1 (using the first 22 modes) im_recon = plt . subplot ( gs1 [ 1 , 0 ]) im_recon . set_title ( 'Reconst. (22 modes)' ) img = im_recon . imshow ( reconstructed , cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) im_recon . set_xticks ([]) # Remove x ticks im_recon . set_yticks ([]) # Remove y ticks for spine in im_recon . spines . values (): spine . set_linewidth ( 1.5 ) im_recon . set_position ([ 0.05 , 0.12 , 0.32 , 0.32 ]) # Adjust these values (left, bottom, width, height) # Create a new axis for the colorbar and set its position cax = fig . add_axes ([ 0.103 , 0.093 , 0.2135 , 0.015 ]) # Adjust these values (left, bottom, width, height) colorbar = plt . colorbar ( img , cax = cax , orientation = 'horizontal' ) colorbar . outline . set_linewidth ( 1.5 ) # Plot input image (mean subtracted) for frame number 1 im_input = plt . subplot ( gs1 [ 1 , 1 ]) im_input . set_title ( 'Input Image' ) img2 = im_input . imshow ( input_data [ 1 , :, :], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) im_input . set_xticks ([]) # Remove x ticks im_input . set_yticks ([]) # Remove y ticks for spine in im_input . spines . values (): spine . set_linewidth ( 1.5 ) im_input . set_position ([ 0.34 , 0.12 , 0.32 , 0.32 ]) # Adjust these values (left, bottom, width, height) # Create a new axis for the colorbar and set its position cax2 = fig . add_axes ([ 0.3935 , 0.093 , 0.2135 , 0.015 ]) # Adjust these values (left, bottom, width, height) colorbar = plt . colorbar ( img2 , cax = cax2 , orientation = 'horizontal' ) colorbar . outline . set_linewidth ( 1.5 ) # Add scatter plot ax_scatter = plt . subplot ( gs1 [ 1 , 2 ]) ax_scatter . set_title ( 'Scatter Plot' ) ax_scatter . scatter ( reconstructed , input_data [ 1 , :, :]) ax_scatter . set_xlabel ( 'Reconstructed' ) ax_scatter . set_ylabel ( 'Input' ) ax_scatter . grid ( True ) ax_scatter . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax_scatter . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax_scatter . xaxis . set_major_locator ( MaxNLocator ( nbins = 4 )) ax_scatter . yaxis . set_major_locator ( MaxNLocator ( nbins = 4 )) ax_scatter . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_scatter . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_scatter . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_scatter . spines . values (): spine . set_linewidth ( 1.5 ) ax_scatter . set_xlim ( - 180 , 580 ) ax_scatter . set_ylim ( - 180 , 580 ) # Save the figure as a PDF pdf_path = 'Figures/FigS6_POD_eigenvalues_powerspectrum.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS6_POD_egenvalues_powerspectrum.pdf'", "title": "POD eigenvalues"}, {"location": "python/pod-eigenvalues-example/#worked-example-nrmp-pod-eigenvalues-and-explained-variance", "text": "This example delves deeper into the analysis of Proper Orthogonal Decomposition (POD) results, focusing on the eigenvalues and explained variance. By examining the eigenvalues and their corresponding spatial modes, we can gain a better understanding of the dominant patterns and their contributions to the overall variability in the data. Analysis and Figure The figure below summarizes the POD analysis results, including the normalized eigenvalues, combined power spectrum, and cumulative explained variance. Methods used: Proper Orthogonal Decomposition (POD) Power spectrum analysis Variance analysis WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S6 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: POD mode analysis. Top left: Normalized squared singular values (eigenvalues) of the first ten POD modes, demonstrating their relative contributions to the total variance. Top middle: Combined power spectrum of the first ten POD modes, revealing the dominant frequencies captured by these ten modes. The vertical dotted lines mark the ten base frequencies used to construct the synthetic data; the red dashed line identifies the 95% confidence level (estimated from 1000 bootstrap resamples). Top right: Cumulative explained variance as a function of the number of POD modes included, with vertical lines indicating the cumulative variance captured by 2 (blue), 10 (green), and 22 (red) modes. Bottom left: Reconstructed image (130\u00d7130 pixels 2 ) of the first frame of the time series using the first 22 modes. Bottom middle: Original image (130\u00d7130 pixels 2 ; first frame) of the datacube. Bottom right: Scatter plot of the reconstructed and original image. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , num_modes = 10 , num_top_frequencies = 10 , num_cumulative_modes = 50 , timestep_to_reconstruct = 1 , num_modes_reconstruct = 22 ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.7], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.39], [0.35, 0.32], [0.4, 0.25], [0.45, 0.24], [0.55, 0.18]] Total variance contribution of the first 10 modes: 96.01% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (50,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (ndarray, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (NoneType, Shape: None): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (NoneType, Shape: None): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 3 4 5 6 7 input_data = pod_results [ 'input_data' ] eigenvalue_contribution = pod_results [ 'eigenvalue_contribution' ] combined_welch_psd = pod_results [ 'combined_welch_psd' ] frequencies = pod_results [ 'frequencies' ] combined_welch_significance = pod_results [ 'combined_welch_significance' ] cumulative_eigenvalues = pod_results [ 'cumulative_eigenvalues' ] reconstructed = pod_results [ 'reconstructed' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import AutoMinorLocator import matplotlib.ticker as ticker from matplotlib.ticker import MaxNLocator # Setting global parameters for the plots plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 16 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 14 , # X-axis tick label font size 'ytick.labelsize' : 14 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 17 , # Figure title font size 'axes.grid' : False , # Turn off grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) fig = plt . figure ( figsize = ( 15 , 10 )) # Create subplots with GridSpec gs1 = gridspec . GridSpec ( 2 , 3 , figure = fig , wspace = 0.45 , hspace = 0.4 ) # Plot normalized eigenvalues ax_ev = plt . subplot ( gs1 [ 0 , 0 ]) ax_ev . set_title ( f 'Normalized Eigenvalues' ) mode_nums = np . arange ( 1 , 11 ) ax_ev . plot ( mode_nums , 100 * eigenvalue_contribution [ 0 : 10 ], 'k-o' ) ax_ev . set_xlabel ( 'Modes' ) ax_ev . set_ylabel ( 'Eigenvalues (%)' ) ax_ev . grid ( True ) ax_ev . xaxis . set_major_locator ( ticker . MultipleLocator ( 1 )) ax_ev . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_ev . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_ev . spines . values (): spine . set_linewidth ( 1.5 ) # Plot combined power spectrum ax_freq = plt . subplot ( gs1 [ 0 , 1 ]) pre_defined_freq = [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ] for freq in pre_defined_freq : ax_freq . axvline ( x = freq , color = 'green' , linestyle = ':' , linewidth = 1.5 ) ax_freq . plot ( frequencies * 1000. , combined_welch_psd / np . max ( combined_welch_psd ), 'k' ) ax_freq . plot ( frequencies * 1000. , combined_welch_significance , 'r--' , label = '95% Significance Threshold' ) ax_freq . set_title ( f 'Combined Power Spectrum' ) ax_freq . set_xlabel ( 'Frequency (mHz)' ) ax_freq . set_ylabel ( 'Normalized Power' ) ax_freq . grid ( False ) ax_freq . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_freq . spines . values (): spine . set_linewidth ( 1.5 ) ax_freq . set_xlim ( 0 , 1000 ) ax_freq . text ( 0.95 , 0.95 , '10 modes' , transform = ax_freq . transAxes , fontsize = 15 , verticalalignment = 'top' , horizontalalignment = 'right' ) # Plot cumulative eigenvalues ax_freq = plt . subplot ( gs1 [ 0 , 2 ]) ax_freq . plot ( cumulative_eigenvalues , 'k-o' ) ax_freq . set_title ( f 'Cumulative Eigenvalues' ) ax_freq . set_xlabel ( 'Number of modes' ) ax_freq . set_ylabel ( 'Eigenvalues (%)' ) ax_freq . grid ( False ) ax_freq . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_freq . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_freq . spines . values (): spine . set_linewidth ( 1.5 ) ax_freq . set_xlim ( 1 , 30 ) ax_freq . set_ylim ( 0 , 110 ) # Identify indices where 90% and 95% is reached thresholds = [ 84 , 96 , 99 ] colors = [ 'blue' , 'green' , 'red' ] for threshold , color in zip ( thresholds , colors ): index = next ( i for i , v in enumerate ( cumulative_eigenvalues ) if v >= threshold ) ax_freq . axvline ( x = index , color = color , linestyle = '--' , label = f ' { threshold } % at mode { index } ' ) # Plot reconstructed image for frame number 1 (using the first 22 modes) im_recon = plt . subplot ( gs1 [ 1 , 0 ]) im_recon . set_title ( 'Reconst. (22 modes)' ) img = im_recon . imshow ( reconstructed , cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) im_recon . set_xticks ([]) # Remove x ticks im_recon . set_yticks ([]) # Remove y ticks for spine in im_recon . spines . values (): spine . set_linewidth ( 1.5 ) im_recon . set_position ([ 0.05 , 0.12 , 0.32 , 0.32 ]) # Adjust these values (left, bottom, width, height) # Create a new axis for the colorbar and set its position cax = fig . add_axes ([ 0.103 , 0.093 , 0.2135 , 0.015 ]) # Adjust these values (left, bottom, width, height) colorbar = plt . colorbar ( img , cax = cax , orientation = 'horizontal' ) colorbar . outline . set_linewidth ( 1.5 ) # Plot input image (mean subtracted) for frame number 1 im_input = plt . subplot ( gs1 [ 1 , 1 ]) im_input . set_title ( 'Input Image' ) img2 = im_input . imshow ( input_data [ 1 , :, :], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) im_input . set_xticks ([]) # Remove x ticks im_input . set_yticks ([]) # Remove y ticks for spine in im_input . spines . values (): spine . set_linewidth ( 1.5 ) im_input . set_position ([ 0.34 , 0.12 , 0.32 , 0.32 ]) # Adjust these values (left, bottom, width, height) # Create a new axis for the colorbar and set its position cax2 = fig . add_axes ([ 0.3935 , 0.093 , 0.2135 , 0.015 ]) # Adjust these values (left, bottom, width, height) colorbar = plt . colorbar ( img2 , cax = cax2 , orientation = 'horizontal' ) colorbar . outline . set_linewidth ( 1.5 ) # Add scatter plot ax_scatter = plt . subplot ( gs1 [ 1 , 2 ]) ax_scatter . set_title ( 'Scatter Plot' ) ax_scatter . scatter ( reconstructed , input_data [ 1 , :, :]) ax_scatter . set_xlabel ( 'Reconstructed' ) ax_scatter . set_ylabel ( 'Input' ) ax_scatter . grid ( True ) ax_scatter . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax_scatter . yaxis . set_minor_locator ( AutoMinorLocator ( 4 )) ax_scatter . xaxis . set_major_locator ( MaxNLocator ( nbins = 4 )) ax_scatter . yaxis . set_major_locator ( MaxNLocator ( nbins = 4 )) ax_scatter . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_scatter . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_scatter . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_scatter . spines . values (): spine . set_linewidth ( 1.5 ) ax_scatter . set_xlim ( - 180 , 580 ) ax_scatter . set_ylim ( - 180 , 580 ) # Save the figure as a PDF pdf_path = 'Figures/FigS6_POD_eigenvalues_powerspectrum.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS6_POD_egenvalues_powerspectrum.pdf'", "title": "Worked Example - NRMP: POD Eigenvalues and Explained Variance"}, {"location": "python/pod-example/", "text": "Worked Example - NRMP: Proper Orthogonal Decomposition (POD) Analysis \u00b6 This example demonstrates the application of Proper Orthogonal Decomposition (POD) to a synthetic spatio-temporal dataset. POD is a powerful technique for analysing multi-dimensional data, identifying dominant spatial patterns (modes) that capture the most significant variations in the data. It is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. Analysis and Figure The figure below shows the results of applying POD to the synthetic spatio-temporal dataset. Methods used: Proper Orthogonal Decomposition (POD) Welch's method (to analyze the frequency content of the temporal coefficients) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S5 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: POD analysis results. The first six spatial modes (130\u00d7130 pixels 2 each), along with their temporal coefficients and Welch power spectra of the temporal coefficients. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , num_modes = 10 ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.7], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.39], [0.35, 0.32], [0.4, 0.25], [0.45, 0.24], [0.55, 0.18]] Total variance contribution of the first 10 modes: 96.01% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (10,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (ndarray, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (NoneType, Shape: None): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (NoneType, Shape: None): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 spatial_modes = pod_results [ 'spatial_mode' ] temporal_coefficients = pod_results [ 'temporal_coefficient' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import AutoMinorLocator from scipy.signal import welch # Setting global parameters plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 18 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 20 , # Figure title font size 'axes.grid' : False , # Turn off grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) fig = plt . figure ( figsize = ( 15 , 19 )) # Create a figure with specified size # Create subplots with GridSpec gs1 = gridspec . GridSpec ( 9 , 3 , height_ratios = [ 1 , 0.5 , - 0.04 , 0.5 , 0.2 , 1 , 0.5 , - 0.04 , 0.5 ], figure = fig , hspace = 0.5 , wspace = 0.3 ) # Plot each column of p as an image in a subplot for m in range ( 3 ): # First set of 3 modes ax_img = plt . subplot ( gs1 [ 0 , m ]) ax_img . set_title ( f 'POD Mode ($P_ { m + 1 } $)' ) img = ax_img . imshow ( spatial_modes [ m , :, :], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) ax_line = plt . subplot ( gs1 [ 1 , m ]) ax_line . plot ( time , temporal_coefficients [ m , :], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 0 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_line . grid ( False ) # Turn off grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) ax_welch = plt . subplot ( gs1 [ 3 , m ]) f , px = welch ( temporal_coefficients [ m , :] - np . mean ( temporal_coefficients [ m , :]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 0 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_welch . grid ( False ) # Turn off grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Create a separate GridSpec for the spacing between the two sets gs_space = gridspec . GridSpec ( 1 , 1 , top = 0.98 , bottom = 0.95 , hspace = 0.5 , wspace = 0.5 , figure = fig ) for m in range ( 3 , 6 ): # Second set of 3 modes row = m - 3 col = m % 3 ax_img = plt . subplot ( gs1 [ 5 , col ]) ax_img . set_title ( f 'POD Mode ($P_ { m + 1 } $)' ) img = ax_img . imshow ( spatial_modes [ m , :, :], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) ax_line = plt . subplot ( gs1 [ 6 , col ]) ax_line . plot ( time , temporal_coefficients [ m , :], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 3 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_line . grid ( False ) # Turn off grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) ax_welch = plt . subplot ( gs1 [ 8 , col ]) f , px = welch ( temporal_coefficients [ m , :] - np . mean ( temporal_coefficients [ m , :]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 3 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_welch . grid ( False ) # Turn off grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Save the figure as a PDF pdf_path = 'Figures/FigS5_POD_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) # Show the plot plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS5_POD_analysis.pdf'", "title": "POD analysis"}, {"location": "python/pod-example/#worked-example-nrmp-proper-orthogonal-decomposition-pod-analysis", "text": "This example demonstrates the application of Proper Orthogonal Decomposition (POD) to a synthetic spatio-temporal dataset. POD is a powerful technique for analysing multi-dimensional data, identifying dominant spatial patterns (modes) that capture the most significant variations in the data. It is particularly useful for reducing the dimensionality of complex datasets and extracting coherent structures. Analysis and Figure The figure below shows the results of applying POD to the synthetic spatio-temporal dataset. Methods used: Proper Orthogonal Decomposition (POD) Welch's method (to analyze the frequency content of the temporal coefficients) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S5 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: POD analysis results. The first six spatial modes (130\u00d7130 pixels 2 each), along with their temporal coefficients and Welch power spectra of the temporal coefficients. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , num_modes = 10 ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.7], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.39], [0.35, 0.32], [0.4, 0.25], [0.45, 0.24], [0.55, 0.18]] Total variance contribution of the first 10 modes: 96.01% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (10,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (ndarray, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (NoneType, Shape: None): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (NoneType, Shape: None): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 spatial_modes = pod_results [ 'spatial_mode' ] temporal_coefficients = pod_results [ 'temporal_coefficient' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import AutoMinorLocator from scipy.signal import welch # Setting global parameters plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 18 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 20 , # Figure title font size 'axes.grid' : False , # Turn off grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) fig = plt . figure ( figsize = ( 15 , 19 )) # Create a figure with specified size # Create subplots with GridSpec gs1 = gridspec . GridSpec ( 9 , 3 , height_ratios = [ 1 , 0.5 , - 0.04 , 0.5 , 0.2 , 1 , 0.5 , - 0.04 , 0.5 ], figure = fig , hspace = 0.5 , wspace = 0.3 ) # Plot each column of p as an image in a subplot for m in range ( 3 ): # First set of 3 modes ax_img = plt . subplot ( gs1 [ 0 , m ]) ax_img . set_title ( f 'POD Mode ($P_ { m + 1 } $)' ) img = ax_img . imshow ( spatial_modes [ m , :, :], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) ax_line = plt . subplot ( gs1 [ 1 , m ]) ax_line . plot ( time , temporal_coefficients [ m , :], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 0 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_line . grid ( False ) # Turn off grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) ax_welch = plt . subplot ( gs1 [ 3 , m ]) f , px = welch ( temporal_coefficients [ m , :] - np . mean ( temporal_coefficients [ m , :]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 0 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_welch . grid ( False ) # Turn off grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Create a separate GridSpec for the spacing between the two sets gs_space = gridspec . GridSpec ( 1 , 1 , top = 0.98 , bottom = 0.95 , hspace = 0.5 , wspace = 0.5 , figure = fig ) for m in range ( 3 , 6 ): # Second set of 3 modes row = m - 3 col = m % 3 ax_img = plt . subplot ( gs1 [ 5 , col ]) ax_img . set_title ( f 'POD Mode ($P_ { m + 1 } $)' ) img = ax_img . imshow ( spatial_modes [ m , :, :], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) ax_line = plt . subplot ( gs1 [ 6 , col ]) ax_line . plot ( time , temporal_coefficients [ m , :], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 3 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_line . grid ( False ) # Turn off grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) ax_welch = plt . subplot ( gs1 [ 8 , col ]) f , px = welch ( temporal_coefficients [ m , :] - np . mean ( temporal_coefficients [ m , :]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 3 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . tick_params ( axis = 'y' , labelsize = 8 ) # Adjust y tick label size ax_welch . grid ( False ) # Turn off grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Save the figure as a PDF pdf_path = 'Figures/FigS5_POD_analysis.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) # Show the plot plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS5_POD_analysis.pdf'", "title": "Worked Example - NRMP: Proper Orthogonal Decomposition (POD) Analysis"}, {"location": "python/pod-filtering-example/", "text": "Worked Example - NRMP: POD with Frequency Filtering \u00b6 This example demonstrates the application of frequency filtering to the temporal coefficients of POD modes. By isolating specific frequencies in the temporal evolution of each mode, we can extract spatial patterns associated with those frequencies, revealing more detailed information about the wave behaviour. Analysis and Figure The figure below shows the frequency-filtered spatial modes for the ten dominant frequencies in the synthetic spatio-temporal dataset. Methods used: Proper Orthogonal Decomposition (POD) Frequency filtering of temporal coefficients WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S7 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Frequency-filtered spatial modes for the ten dominant frequencies. The spatial patterns associated with each frequency are shown for the first three time steps of the series, with each image covering 130\u00d7130 pixels 2 . Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , num_modes = 10 , num_top_frequencies = 10 , top_frequencies = [ 0.10 , 0.15 , 0.20 , 0.25 , 0.30 , 0.35 , 0.40 , 0.45 , 0.50 , 0.55 ], # in Hz num_cumulative_modes = 50 , timestep_to_reconstruct = 1 , num_modes_reconstruct = 22 ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.7], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.39], [0.35, 0.32], [0.4, 0.25], [0.45, 0.24], [0.55, 0.18]] Total variance contribution of the first 10 modes: 96.01% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (50,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (list, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (NoneType, Shape: None): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (NoneType, Shape: None): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 frequency_filtered_modes = pod_results [ 'frequency_filtered_modes' ] frequency_filtered_modes_frequencies = pod_results [ 'frequency_filtered_modes_frequencies' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec # Setting global parameters for the plot plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 16 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 17 , # Figure title font size 'axes.grid' : False , # Turn off grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) figure = plt . figure ( figsize = ( 16. , 20. )) # Set figure size gs1 = gridspec . GridSpec ( 9 , 5 , figure = figure , height_ratios = [ 0.15 , 1 , 1 , 0.15 , 1 , 1 , 0.15 , 1 , 1 ]) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 0 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.41 , 0 , 'Frame number: 1' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) frame_index = 0 for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 1 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 2 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 3 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.41 , 0 , 'Frame number: 2' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) frame_index = 1 for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 4 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 5 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 6 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.41 , 0 , 'Frame number: 3' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) frame_index = 2 for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 7 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 8 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) # Save the figure as a PDF pdf_path = 'Figures/FigS7_POD_frequency_filtered_spatial_modes.pdf' WaLSA_save_pdf ( figure , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS7_POD_frequency_filtered_spatial_modes.pdf' 1 2 3 4 5 6 7 8 9 10 # Save the first six frames of the frequency-filtered POD reconstruction at 0.5 Hz (500 mHz), as a FITS file. # To be used in Figure 5 of the Nature Reviews Methods Primers paper num_images = 6 freq_index = np . where ( np . isclose ( frequency_filtered_modes_frequencies , 0.5 ))[ 0 ] data_cube = np . zeros (( num_images , signal_3d . shape [ 1 ], signal_3d . shape [ 2 ])) for i in range ( num_images ): data_cube [ i , :, :] = frequency_filtered_modes [ i , :, :, freq_index ] hdu_var = fits . PrimaryHDU ( data_cube ) hdu_var . writeto ( 'Saved_Parameters/POD_first_6_frequency_filtered_spatial_modes_at_500mHz.fits' , overwrite = True ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # Create a set of images for the frequency-filtered POD reconstruction at all time steps # To be used in the Supplementary Video 2 # Setting global parameters plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 16 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 17 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) for frame_index in range ( 0 , 200 ): figure = plt . figure ( figsize = ( 16. , 6.6 )) gs1 = gridspec . GridSpec ( 5 , 5 , figure = figure , height_ratios = [ 0.1 , 0.1 , 1 , 0.1 , 1 ]) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 0 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.405 , 0 , f 'Frame number: { frame_index + 1 } ' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 2 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 4 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar . ax . tick_params ( labelsize = 14 ) plt . savefig ( f 'Video_Snapshots/POD_spectral_images__video_S2/im_ { frame_index : 03d } .jpg' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0.2 ) plt . close () print ( \"Images saved successfully.\" ) Images saved successfully.", "title": "POD filtering"}, {"location": "python/pod-filtering-example/#worked-example-nrmp-pod-with-frequency-filtering", "text": "This example demonstrates the application of frequency filtering to the temporal coefficients of POD modes. By isolating specific frequencies in the temporal evolution of each mode, we can extract spatial patterns associated with those frequencies, revealing more detailed information about the wave behaviour. Analysis and Figure The figure below shows the frequency-filtered spatial modes for the ten dominant frequencies in the synthetic spatio-temporal dataset. Methods used: Proper Orthogonal Decomposition (POD) Frequency filtering of temporal coefficients WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S7 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Frequency-filtered spatial modes for the ten dominant frequencies. The spatial patterns associated with each frequency are shown for the first three time steps of the series, with each image covering 130\u00d7130 pixels 2 . Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , num_modes = 10 , num_top_frequencies = 10 , top_frequencies = [ 0.10 , 0.15 , 0.20 , 0.25 , 0.30 , 0.35 , 0.40 , 0.45 , 0.50 , 0.55 ], # in Hz num_cumulative_modes = 50 , timestep_to_reconstruct = 1 , num_modes_reconstruct = 22 ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.7], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.39], [0.35, 0.32], [0.4, 0.25], [0.45, 0.24], [0.55, 0.18]] Total variance contribution of the first 10 modes: 96.01% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (50,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (list, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (NoneType, Shape: None): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (NoneType, Shape: None): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 frequency_filtered_modes = pod_results [ 'frequency_filtered_modes' ] frequency_filtered_modes_frequencies = pod_results [ 'frequency_filtered_modes_frequencies' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec # Setting global parameters for the plot plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 16 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 17 , # Figure title font size 'axes.grid' : False , # Turn off grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) figure = plt . figure ( figsize = ( 16. , 20. )) # Set figure size gs1 = gridspec . GridSpec ( 9 , 5 , figure = figure , height_ratios = [ 0.15 , 1 , 1 , 0.15 , 1 , 1 , 0.15 , 1 , 1 ]) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 0 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.41 , 0 , 'Frame number: 1' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) frame_index = 0 for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 1 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 2 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 3 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.41 , 0 , 'Frame number: 2' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) frame_index = 1 for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 4 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 5 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 6 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.41 , 0 , 'Frame number: 3' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) frame_index = 2 for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 7 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 8 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar = plt . colorbar ( img , orientation = 'vertical' , shrink = 0.86 ) cbar . ax . tick_params ( labelsize = 14 ) # Save the figure as a PDF pdf_path = 'Figures/FigS7_POD_frequency_filtered_spatial_modes.pdf' WaLSA_save_pdf ( figure , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FigS7_POD_frequency_filtered_spatial_modes.pdf' 1 2 3 4 5 6 7 8 9 10 # Save the first six frames of the frequency-filtered POD reconstruction at 0.5 Hz (500 mHz), as a FITS file. # To be used in Figure 5 of the Nature Reviews Methods Primers paper num_images = 6 freq_index = np . where ( np . isclose ( frequency_filtered_modes_frequencies , 0.5 ))[ 0 ] data_cube = np . zeros (( num_images , signal_3d . shape [ 1 ], signal_3d . shape [ 2 ])) for i in range ( num_images ): data_cube [ i , :, :] = frequency_filtered_modes [ i , :, :, freq_index ] hdu_var = fits . PrimaryHDU ( data_cube ) hdu_var . writeto ( 'Saved_Parameters/POD_first_6_frequency_filtered_spatial_modes_at_500mHz.fits' , overwrite = True ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # Create a set of images for the frequency-filtered POD reconstruction at all time steps # To be used in the Supplementary Video 2 # Setting global parameters plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 16 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 17 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) for frame_index in range ( 0 , 200 ): figure = plt . figure ( figsize = ( 16. , 6.6 )) gs1 = gridspec . GridSpec ( 5 , 5 , figure = figure , height_ratios = [ 0.1 , 0.1 , 1 , 0.1 , 1 ]) # Add a horizontal line and title (frame number) line_ax1 = plt . subplot ( gs1 [ 0 , :]) line_ax1 . plot ([ 0.01 , 1 ], [ 0 , 0 ], clip_on = False , color = 'black' , linewidth = 2 ) plt . text ( 0.405 , 0 , f 'Frame number: { frame_index + 1 } ' , fontsize = 18 , fontweight = 'bold' , verticalalignment = 'center' , bbox = dict ( facecolor = 'white' , edgecolor = 'none' )) line_ax1 . axis ( 'off' ) line_ax1 . set_xticks ([]) # Remove x ticks line_ax1 . set_yticks ([]) # Remove y ticks line_ax1 . set_xlim ( 0 , 1 ) for i in range ( 0 , 5 ): ax_img = plt . subplot ( gs1 [ 2 , i ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, i ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ i ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar . ax . tick_params ( labelsize = 14 ) for j in range ( 5 , 10 ): ax_img = plt . subplot ( gs1 [ 4 , j - 5 ]) img = plt . imshow ( frequency_filtered_modes [ frame_index , :, :, j ], cmap = 'jet' , aspect = 'equal' , origin = 'lower' ) ax_img . set_title ( f 'f = { ( int ( np . round ( frequency_filtered_modes_frequencies [ j ] * 1000 ))) } mHz' ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks cbar . ax . tick_params ( labelsize = 14 ) plt . savefig ( f 'Video_Snapshots/POD_spectral_images__video_S2/im_ { frame_index : 03d } .jpg' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0.2 ) plt . close () print ( \"Images saved successfully.\" ) Images saved successfully.", "title": "Worked Example - NRMP: POD with Frequency Filtering"}, {"location": "python/power-spectra-example/", "text": "Worked Example - NRMP: Power Spectra \u00b6 This example demonstrates the application of various spectral analysis techniques to a synthetic 1D signal constructed with predefined frequencies and amplitudes. The signal includes a range of oscillatory components with different characteristics, including: Dominant oscillations: Five dominant frequencies (5, 12, 15, 18, and 25 Hz) with varying amplitudes. Transient oscillation: A short-lived oscillation with a frequency of 2 Hz. Weak oscillation: A low-amplitude oscillation with a frequency of 33 Hz. Quasi-periodic oscillation: An oscillation with a frequency of 10 Hz and a time-varying amplitude. Noise: Random noise added to the signal. By analysing this synthetic signal with different methods, we can evaluate their ability to accurately identify and characterise these diverse oscillatory components. This provides valuable insights into the strengths and limitations of each technique, guiding the selection of appropriate methods for analysing real-world data. For a comprehensive discussion of the analysis and results, please refer to the associated article in Nature Reviews Methods Primers . Analysis and Figure The figure below presents a comparative analysis of various wave analysis methods applied to the synthetic 1D signal. The signal was pre-processed by detrending (to remove any linear trends) and apodized (to reduce edge effects) using a Tukey window. Methods used: Fast Fourier Transform (FFT) Lomb-Scargle Periodogram Welch's Method Wavelet Transform (with Morlet, Paul, and Mexican Hat wavelets) Global Wavelet Spectrum (GWS) Refined Global Wavelet Spectrum (RGWS) Hilbert-Huang Transform (HHT) with Empirical Mode Decomposition (EMD) and Ensemble EMD (EEMD) WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 3 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Performance of diverse analysis methods on a synthetic 1D time series. (a) The detrended and apodized signal. (b) The unevenly sampled signal. (c) The FFT power spectrum. (d) The Lomb-Scargle periodogram. (e) The global wavelet spectrum (GWS) for the Morlet, Mexican Hat, and Paul wavelets. (f) The refined global wavelet spectrum (RGWS) for the Morlet, Mexican Hat, and Paul wavelets. (g) The HHT spectrum using EMD. (h) The FFT power spectra of the individual IMFs extracted by EMD. (i) The HHT spectrum using EEMD. (j) The FFT power spectra of the individual IMFs extracted by EEMD. (k) The Welch power spectrum. (l)-(n) The wavelet power spectra for the Morlet, Mexican Hat, and Paul wavelets, respectively. All powers are normalized to their maximum value and shown in percentages, with panels (c) , (d) , (h) , and (j) zoomed in on a smaller power range for better visibility of smaller peaks. The 95% confidence levels are indicated by dot-dashed curves for 1D power spectra and solid black contours for wavelet spectra. Vertical lines above each 1D spectrum mark the frequency resolution. Green vertical (or horizontal) lines on the frequency axes indicate the predefined frequencies used to construct the synthetic signal. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , walsa_detrend_apod import warnings #-------------------------------------------------------------------------- warnings . filterwarnings ( 'ignore' , category = RuntimeWarning ) # Load the synthetic signal from the FITS file data_dir = 'Synthetic_Data/' file_path = data_dir + 'NRMP_signal_1D.fits' hdul = fits . open ( file_path ) signal = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Time array saved in the second HDU (Extension HDU 1) hdul . close () # Sampling rate and duration of the data sampling_rate = 100 # Hz duration = 10 # seconds #-------------------------------------------------------------------------- # Create unevenly sampled data by removing gaps from the signal # Define gaps' sizes and start indices gap_sizes = [ 17 , 42 , 95 , 46 ] # Sizes of gaps gap_starts = [ 150 , 200 , 500 , 800 ] # Start indices for gaps # Create initial set of indices n_points = len ( signal ) indices = np . arange ( n_points ) # Remove gaps for gap_start , gap_size in zip ( gap_starts , gap_sizes ): indices = indices [( indices < gap_start ) | ( indices >= gap_start + gap_size )] # Reduce both time and signal arrays according to final indices t_uneven = time [ indices ] signal_uneven = signal [ indices ] # Sort time and signal to maintain ascending order (although should already be in order) sorted_indices = np . argsort ( t_uneven ) t_uneven = t_uneven [ sorted_indices ] signal_uneven = signal_uneven [ sorted_indices ] #-------------------------------------------------------------------------- # FFT Analysis using WaLSAtools fft_power , fft_freqs , fft_significance = WaLSAtools ( signal = signal , time = time , method = 'fft' , siglevel = 0.95 , apod = 0.1 ) # Normalize FFT power to its maximum value fft_power_normalized = 100 * fft_power / np . max ( fft_power ) fft_significance_normalized = 100 * fft_significance / np . max ( fft_power ) #-------------------------------------------------------------------------- # Lomb-Scargle Analysis using WaLSAtools ls_power , ls_freqs , ls_significance = WaLSAtools ( signal = signal , time = time , method = 'lombscargle' , siglevel = 0.95 , apod = 0.1 ) # Normalize Lomb-Scargle power to its maximum value ls_power_normalized = 100 * ls_power / np . max ( ls_power ) ls_significance_normalized = 100 * ls_significance / np . max ( ls_power ) #-------------------------------------------------------------------------- # Wavelet Analysis using WaLSAtools - Morlet wavelet_power_morlet , wavelet_periods_morlet , wavelet_significance_morlet , coi_morlet , ( global_power_morlet , global_conf_morlet ), ( rgws_morlet_periods , rgws_morlet_power ) = WaLSAtools ( signal = signal , time = time , method = 'wavelet' , siglevel = 0.95 , apod = 0.1 , mother = 'morlet' , GWS = True , RGWS = True ) #-------------------------------------------------------------------------- # Wavelet Analysis using WaLSAtools - DOG (Mexican Hat) wavelet_power_dog , wavelet_periods_dog , wavelet_significance_dog , coi_dog , ( global_power_dog , global_conf_dog ), ( rgws_dog_periods , rgws_dog_power ) = WaLSAtools ( signal = signal , time = time , method = 'wavelet' , siglevel = 0.95 , apod = 0.1 , mother = 'dog' , GWS = True , RGWS = True ) #-------------------------------------------------------------------------- # Wavelet Analysis using WaLSAtools - Paul wavelet_power_paul , wavelet_periods_paul , wavelet_significance_paul , coi_paul , ( global_power_paul , global_conf_paul ), ( rgws_paul_periods , rgws_paul_power ) = WaLSAtools ( signal = signal , time = time , method = 'wavelet' , siglevel = 0.95 , apod = 0.1 , mother = 'paul' , GWS = True , RGWS = True ) #-------------------------------------------------------------------------- # Welch Power Spectral Density Analysis using WaLSAtools welch_psd , welch_freqs , welch_significance = WaLSAtools ( signal = signal , time = time , method = 'welch' , siglevel = 0.95 , nperseg = 200 , noverlap = 20 ) # Normalize Welch PSD to its maximum value welch_psd_normalized = 100 * welch_psd / np . max ( welch_psd ) welch_significance_normalized = 100 * welch_significance / np . max ( welch_psd ) #-------------------------------------------------------------------------- # EMD & HHT Calculations using WaLSAtools HHT_power_spectrum_EMD , HHT_significance_level_EMD , HHT_freq_bins_EMD , psd_spectra_fft_EMD , confidence_levels_fft_EMD , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 ) # Normalize power spectra to their maximum values HHT_power_spectrum_EMD_normalized = 100 * HHT_power_spectrum_EMD / np . max ( HHT_power_spectrum_EMD ) HHT_significance_level_EMD_normalized = 100 * HHT_significance_level_EMD / np . max ( HHT_power_spectrum_EMD ) #-------------------------------------------------------------------------- # EEMD & HHT Calculations using WaLSAtools HHT_power_spectrum_EEMD , HHT_significance_level_EEMD , HHT_freq_bins_EEMD , psd_spectra_fft_EEMD , confidence_levels_fft_EEMD , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True ) # Normalize power spectra to their maximum values HHT_power_spectrum_EEMD_normalized = 100 * HHT_power_spectrum_EEMD / np . max ( HHT_power_spectrum_EEMD ) HHT_significance_level_EEMD_normalized = 100 * HHT_significance_level_EEMD / np . max ( HHT_power_spectrum_EEMD ) Detrending and apodization complete. FFT processed. Detrending and apodization complete. Lomb-Scargle processed. Detrending and apodization complete. Wavelet (morlet) processed. Detrending and apodization complete. Wavelet (dog) processed. Detrending and apodization complete. Wavelet (paul) processed. Welch processed. Detrending and apodization complete. EMD processed. Detrending and apodization complete. EEMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 from mpl_toolkits.axes_grid1.inset_locator import inset_axes import matplotlib.pyplot as plt from matplotlib import gridspec from matplotlib.patches import Polygon from matplotlib.ticker import AutoMinorLocator , FormatStrFormatter from matplotlib.legend_handler import HandlerTuple from mpl_toolkits.axes_grid1 import make_axes_locatable from WaLSAtools import WaLSA_save_pdf from matplotlib.colors import ListedColormap #-------------------------------------------------------------------------- pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] # Mark pre-defined frequencies # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'Arial' , # Set Helvetica as the default sans-serif font 'font.size' : 19 , # Global font size 'axes.titlesize' : 19 , # Title font size 'axes.labelsize' : 17 , # Axis label font size 'xtick.labelsize' : 17 , # X-axis tick label font size 'ytick.labelsize' : 17 , # Y-axis tick label font size 'legend.fontsize' : 15 , # Legend font size 'figure.titlesize' : 19 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 'medium' , # Make all fonts bold 'axes.titleweight' : 'medium' , # Make title font bold 'axes.labelweight' : 'medium' # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.3 ) plt . rc ( 'lines' , linewidth = 1.1 ) # Create a figure and a gridspec with customized layout fig = plt . figure ( figsize = ( 16 , 15 )) gs = gridspec . GridSpec ( 5 , 3 , height_ratios = [ 1 , 1 , 1 , 1 , 1 ], width_ratios = [ 1 , 1 , 1 ], figure = fig , wspace = 0.4 , hspace = 0.8 ) # Add the light gray background manually using Polygons # Fill for first two columns (all rows) polygon_coords_1 = [[ 0.0 , 0.0 ], [ 0.64 , 0.0 ], [ 0.64 , 1.0 ], [ 0.0 , 1.0 ]] # Define the coordinates for the first region background_poly_1 = Polygon ( polygon_coords_1 , closed = True , facecolor = ( 0.91 , 0.91 , 0.91 ), edgecolor = None , zorder =- 1 ) fig . add_artist ( background_poly_1 ) # Fill for bottom part of third column (for plot k) polygon_coords_2 = [[ 0.64 , 0.0 ], [ 1.0 , 0.0 ], [ 1.0 , 0.2 ], [ 0.64 , 0.2 ]] # Define the coordinates for the second region background_poly_2 = Polygon ( polygon_coords_2 , closed = True , facecolor = ( 0.91 , 0.91 , 0.91 ), edgecolor = None , zorder =- 1 ) fig . add_artist ( background_poly_2 ) # Assign plots to their respective positions axs = [ fig . add_subplot ( gs [ 0 , 0 ]), # (a) fig . add_subplot ( gs [ 1 , 0 ]), # (b) fig . add_subplot ( gs [ 2 , 0 ]), # (e) fig . add_subplot ( gs [ 3 , 0 ]), # (g) fig . add_subplot ( gs [ 4 , 0 ]), # (i) fig . add_subplot ( gs [ 0 , 1 ]), # (c) fig . add_subplot ( gs [ 1 , 1 ]), # (d) fig . add_subplot ( gs [ 2 , 1 ]), # (f) fig . add_subplot ( gs [ 3 , 1 ]), # (h) fig . add_subplot ( gs [ 4 , 1 ]), # (j) fig . add_subplot ( gs [ 4 , 2 ]), # (k) ] # Create individual axes for the subplots l, m, and n using fig.add_axes() # The list elements [left, bottom, width, height] are fractions of the figure size ax_inset_l = fig . add_axes ([ 0.725 , 0.785 , 0.21 , 0.14 ]) ax_inset_m = fig . add_axes ([ 0.725 , 0.522 , 0.21 , 0.14 ]) ax_inset_n = fig . add_axes ([ 0.725 , 0.255 , 0.21 , 0.14 ]) # Set background color for all plots except (l), (m), and (n) for ax in axs : if ax not in [ ax_inset_l , ax_inset_m , ax_inset_n ]: ax . set_facecolor (( 0.91 , 0.91 , 0.91 )) # Light gray background #-------------------------------------------------------------------------- # Plot the signal apod_signal = walsa_detrend_apod ( signal , apod = 0.1 , pxdetrend = 2 , silent = True ) # axs[0].plot(time, apod_signal * 10, color='#3071A7') axs [ 0 ] . plot ( time , apod_signal * 10 , color = 'DodgerBlue' ) axs [ 0 ] . set_title ( '(a) Detrended & apodized synthetic signal' , pad = 12 , fontsize = 18 ) axs [ 0 ] . set_xlabel ( 'Time (s)' ) axs [ 0 ] . set_ylabel ( 'DN (arb. unit)' ) axs [ 0 ] . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes axs [ 0 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals axs [ 0 ] . set_xticks ( np . arange ( 0 , 10 , 2 )) axs [ 0 ] . set_yticks ( np . arange ( 0 , 80.01 , 40 )) # Custom tick sizes and thickness axs [ 0 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) # Major ticks axs [ 0 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) # Minor ticks # Set minor ticks axs [ 0 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) axs [ 0 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) #-------------------------------------------------------------------------- # Plot the unevenly sampled signal apod_signal_uneven = walsa_detrend_apod ( signal_uneven , apod = 0.1 , silent = True ) segment_start_idx = 0 for i in range ( 1 , len ( t_uneven )): if t_uneven [ i ] - t_uneven [ i - 1 ] > np . mean ( np . diff ( t_uneven )): axs [ 1 ] . plot ( t_uneven [ segment_start_idx : i ], apod_signal_uneven [ segment_start_idx : i ] * 10 , color = 'DodgerBlue' ) segment_start_idx = i axs [ 1 ] . plot ( t_uneven [ segment_start_idx :], apod_signal_uneven [ segment_start_idx :] * 10 , color = 'DodgerBlue' ) axs [ 1 ] . set_title ( '(b) The synthetic signal with gaps' , pad = 12 ) axs [ 1 ] . set_xlabel ( 'Time (s)' ) axs [ 1 ] . set_ylabel ( 'DN (arb. unit)' ) axs [ 1 ] . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes axs [ 1 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals axs [ 1 ] . set_xticks ( np . arange ( 0 , 10 , 2 )) axs [ 1 ] . set_yticks ( np . arange ( 0 , 80.01 , 40 )) # Custom tick sizes and thickness axs [ 1 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) # Major ticks axs [ 1 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) # Minor ticks # Set minor ticks axs [ 1 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) axs [ 1 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) #-------------------------------------------------------------------------- # Plot FFT power spectrum (normalized) for freqin in pre_defined_freq : axs [ 5 ] . axvline ( x = freqin , color = '#239023' , linewidth = 0.5 ) axs [ 5 ] . plot ( fft_freqs , fft_power_normalized , color = 'red' ) axs [ 5 ] . set_title ( '(c) FFT' , pad = 12 ) axs [ 5 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 5 ] . set_ylabel ( 'Power (%)' ) axs [ 5 ] . set_xlim ([ 0 , 36 ]) axs [ 5 ] . set_ylim ([ 0 , 12 ]) # Plot the significance level as a line significance_plot , = axs [ 5 ] . plot ( fft_freqs , fft_significance_normalized , linestyle = '-.' , color = 'black' , label = '95 % c onfidence level' , linewidth = 0.7 ) axs [ 5 ] . legend ( [( significance_plot ,)], # Use a tuple for the line element [ '95 % c onfidence level ' ], # Text label handler_map = { tuple : HandlerTuple ( ndivide = None )}, # Custom handler to place the line on the right loc = 'upper right' , # Adjust position as needed bbox_to_anchor = ( 1.0 , 0.92 ), # Adjust the (x, y) position of the legend frameon = False , # No frame for the legend handletextpad =- 12.85 # Adjust this value to move the line closer/farther from the text ) # Set tick marks outside for all four axes axs [ 5 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals axs [ 5 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) # X-axis tick interval every 4 units axs [ 5 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) # Y-axis tick interval every 2 units # Custom tick sizes and thickness axs [ 5 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) # Major ticks axs [ 5 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) # Minor ticks # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) axs [ 5 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 5 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Vertical lines at all FFT frequencies (to illustrate frequency resolution) for freq in fft_freqs : axs [ 5 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 5 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot Lomb-Scargle power spectrum (normalized) for freqin in pre_defined_freq : axs [ 6 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 6 ] . plot ( ls_freqs , ls_power_normalized , color = 'red' ) axs [ 6 ] . set_title ( '(d) Lomb-Scargle' , pad = 12 ) axs [ 6 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 6 ] . set_ylabel ( 'Power (%)' ) axs [ 6 ] . set_xlim ([ 0 , 36 ]) axs [ 6 ] . set_ylim ([ 0 , 12 ]) # Plot the significance level as a line axs [ 6 ] . plot ( ls_freqs , ls_significance_normalized , linestyle = '-.' , color = 'black' , linewidth = 0.5 ) # Set tick marks outside for all four axes axs [ 6 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 6 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 6 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) axs [ 6 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 6 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 6 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 6 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in ls_freqs : axs [ 6 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 6 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Load the RGB values from the IDL file, corresponding to IDL's \"loadct, 20\" color table rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_20_modified.txt' ) # Normalize the RGB values to [0, 1] (matplotlib expects RGB values in this range) rgb_values = rgb_values / 255.0 idl_colormap_20 = ListedColormap ( rgb_values ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - Morlet colorbar_label = '(l) Power (%) | Morlet Wavelet' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) power = wavelet_power_morlet power [ power < 0 ] = 0 power = 100 * power / np . nanmax ( power ) t = time periods = wavelet_periods_morlet coi = coi_morlet sig_slevel = wavelet_significance_morlet dt = 1 / sampling_rate removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels from 0 to 100 for consistent color scaling levels = np . linspace ( 0 , 100 , 100 ) # Set levels directly from 0 to 100 # Plot the wavelet power spectrum CS = ax_inset_l . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # 95% significance contour ax_inset_l . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 0.6 ]) # Cone-of-influence ax_inset_l . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_l . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_l . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_l . set_yscale ( 'log' , base = 10 ) ax_inset_l . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_l . invert_yaxis () # Set axis limits and labels ax_inset_l . set_xlim ([ t . min (), t . max ()]) ax_inset_l . set_ylabel ( ylabel ) ax_inset_l . set_xlabel ( xlabel ) ax_inset_l . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_l . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_l . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_l . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_l . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_l . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_l ) cax = inset_axes ( ax_inset_l , width = \"100%\" , height = \"5%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 0.8 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . set_ticks ([ 0 , 20 , 40 , 60 , 80 , 100 ]) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add horizontal lines for pre-defined frequencies for freqin in pre_defined_freq : ax_inset_l . axhline ( y = 1 / freqin , color = '#32CD32' , linewidth = 0.7 ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - DOG (Mexican Hat) colorbar_label = '(m) Power (%) | Mexican-Hat Wavelet' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) power = wavelet_power_dog power [ power < 0 ] = 0 power = 100 * power / np . nanmax ( power ) t = time periods = wavelet_periods_dog coi = coi_dog sig_slevel = wavelet_significance_dog dt = 1 / sampling_rate removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels from 0 to 100 for consistent color scaling levels = np . linspace ( 0 , 100 , 100 ) # Set levels directly from 0 to 100 # Plot the wavelet power spectrum CS = ax_inset_m . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # 95% significance contour ax_inset_m . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 0.6 ]) # Cone-of-influence ax_inset_m . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_m . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ max_period ], [ max_period ], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_m . set_ylim ([ np . min ( periods ), max_period ]) ax_inset_m . set_yscale ( 'log' , base = 10 ) ax_inset_m . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_m . invert_yaxis () # Set axis limits and labels ax_inset_m . set_xlim ([ t . min (), t . max ()]) ax_inset_m . set_ylabel ( ylabel ) ax_inset_m . set_xlabel ( xlabel ) ax_inset_m . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_m . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_m . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_m . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_m . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_m . twinx () # Set limits for the frequency axis based on the `max_period` used for the period axis min_frequency = 1 / max_period max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_m ) cax = inset_axes ( ax_inset_m , width = \"100%\" , height = \"5%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 0.8 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . set_ticks ([ 0 , 20 , 40 , 60 , 80 , 100 ]) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) for freqin in pre_defined_freq : ax_inset_m . axhline ( y = 1 / freqin , color = '#32CD32' , linewidth = 0.7 ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - Paul colorbar_label = '(n) Power (%) | Paul Wavelet' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) power = wavelet_power_paul power [ power < 0 ] = 0 power = 100 * power / np . nanmax ( power ) t = time periods = wavelet_periods_paul coi = coi_paul sig_slevel = wavelet_significance_paul dt = 1 / sampling_rate removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels from 0 to 100 for consistent color scaling levels = np . linspace ( 0 , 100 , 100 ) # Set levels directly from 0 to 100 # Plot the wavelet power spectrum CS = ax_inset_n . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # 95% significance contour ax_inset_n . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 0.6 ]) # Plot cone-of-influence (CoI) ax_inset_n . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_n . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ max_period ], [ max_period ], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_n . set_ylim ([ np . min ( periods ), max_period ]) ax_inset_n . set_yscale ( 'log' , base = 10 ) ax_inset_n . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_n . invert_yaxis () # Set axis limits and labels ax_inset_n . set_xlim ([ t . min (), t . max ()]) ax_inset_n . set_ylabel ( ylabel ) ax_inset_n . set_xlabel ( xlabel ) ax_inset_n . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_n . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_n . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_n . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_n . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_n . twinx () # Set limits for the frequency axis based on the `max_period` used for the period axis min_frequency = 1 / max_period max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_n ) cax = inset_axes ( ax_inset_n , width = \"100%\" , height = \"5%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 0.8 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . set_ticks ([ 0 , 20 , 40 , 60 , 80 , 100 ]) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) for freqin in pre_defined_freq : ax_inset_n . axhline ( y = 1 / freqin , color = '#32CD32' , linewidth = 0.7 ) #-------------------------------------------------------------------------- # Plot Global Wavelet Spectra (GWS) for freqin in pre_defined_freq : axs [ 2 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 2 ] . plot ( 1 / wavelet_periods_morlet , 100 * global_power_morlet / np . max ( global_power_morlet ), 'g-' , label = 'Morlet' ) axs [ 2 ] . plot ( 1 / wavelet_periods_dog , 100 * global_power_dog / np . max ( global_power_dog ), 'r-' , label = 'Mexican Hat' ) axs [ 2 ] . plot ( 1 / wavelet_periods_paul , 100 * global_power_paul / np . max ( global_power_paul ), 'b-' , label = 'Paul' ) axs [ 2 ] . plot ( 1 / wavelet_periods_morlet , 100 * global_conf_morlet / np . max ( global_power_morlet ), 'g-.' ) axs [ 2 ] . plot ( 1 / wavelet_periods_dog , 100 * global_conf_dog / np . max ( global_power_dog ), 'r-.' ) axs [ 2 ] . plot ( 1 / wavelet_periods_paul , 100 * global_conf_paul / np . max ( global_power_paul ), 'b-.' ) axs [ 2 ] . set_title ( '(e) GWS' , pad = 12 ) axs [ 2 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 2 ] . set_ylabel ( 'Power (%)' ) axs [ 2 ] . set_xlim ([ 0 , 36 ]) axs [ 2 ] . set_ylim ([ 0 , 119 ]) # axs[2].legend( # loc='upper right', bbox_to_anchor=(1.0, 0.92), frameon=False, # handletextpad=-6.5 # ) # Add custom labels manually to the plot .... to align the labels to the right handles , labels = axs [ 2 ] . get_legend_handles_labels () # Define the vertical offset for each legend item offset = 0.15 for i , ( handle , label ) in enumerate ( zip ( handles , labels )): # Add the colored line axs [ 2 ] . plot ( [ 0.9 , 0.97 ], # x coordinates (start and end of the line) [ 0.78 - offset * i , 0.78 - offset * i ], # y coordinates (constant to make it horizontal) transform = axs [ 2 ] . transAxes , color = handle . get_color (), # Use the color from the original handle linestyle = handle . get_linestyle (), # Use the linestyle from the original handle linewidth = handle . get_linewidth (), # Use the linewidth from the original handle ) # Add the label text axs [ 2 ] . text ( 0.885 , 0.78 - offset * i , # Adjust x and y positions as needed label , transform = axs [ 2 ] . transAxes , ha = 'right' , va = 'center' , fontsize = 15 , # Align the text to the right ) # Set tick marks outside for all four axes axs [ 2 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 2 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 2 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 2 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 2 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 2 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 2 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in 1 / wavelet_periods_morlet : axs [ 2 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 2 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot Refined Global Wavelet Spectra (RGWS) for freqin in pre_defined_freq : axs [ 7 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 7 ] . plot ( 1 / rgws_morlet_periods , 100 * rgws_morlet_power / np . max ( rgws_morlet_power ), 'g-' ) axs [ 7 ] . plot ( 1 / rgws_dog_periods , 100 * rgws_dog_power / np . max ( rgws_dog_power ), 'r-' ) axs [ 7 ] . plot ( 1 / rgws_paul_periods , 100 * rgws_paul_power / np . max ( rgws_paul_power ), 'b-' ) axs [ 7 ] . set_title ( '(f) RGWS' , pad = 12 ) axs [ 7 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 7 ] . set_ylabel ( 'Power (%)' ) axs [ 7 ] . set_xlim ([ 0 , 36 ]) axs [ 7 ] . set_ylim ([ 0 , 119 ]) # Set tick marks outside for all four axes axs [ 7 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 7 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 7 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 7 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 7 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 7 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 7 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in 1 / rgws_morlet_periods : axs [ 7 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 7 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot Welch power spectrum (normalized) for freqin in pre_defined_freq : axs [ 10 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 10 ] . plot ( welch_freqs , welch_psd_normalized , color = 'red' ) axs [ 10 ] . set_title ( '(k) Welch' , pad = 12 ) axs [ 10 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 10 ] . set_ylabel ( 'Power (%)' ) axs [ 10 ] . set_xlim ([ 0 , 36 ]) axs [ 10 ] . set_ylim ([ 0 , 119 ]) # Plot the significance level as a line axs [ 10 ] . plot ( welch_freqs , welch_significance_normalized , linestyle = '-.' , color = 'black' ) # Set tick marks outside for all four axes axs [ 10 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 10 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 10 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 10 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 10 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 10 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 10 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in welch_freqs : axs [ 10 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 10 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot HHT Marginal Spectrum (from EMD) for freqin in pre_defined_freq : axs [ 3 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 3 ] . plot ( HHT_freq_bins_EMD , HHT_power_spectrum_EMD_normalized , color = 'red' ) axs [ 3 ] . plot ( HHT_freq_bins_EMD , HHT_significance_level_EMD_normalized , linestyle = '-.' , color = 'black' ) axs [ 3 ] . set_title ( '(g) HHT (EMD + Hilbert)' , pad = 12 ) axs [ 3 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 3 ] . set_ylabel ( 'Power (%)' ) axs [ 3 ] . set_xlim ( 0 , 36 ) axs [ 3 ] . set_ylim ( 0 , 119 ) # Set tick marks outside for all four axes axs [ 3 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 3 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 3 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 3 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 3 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 3 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 3 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in HHT_freq_bins_EMD : axs [ 3 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 3 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot FFT Spectra of IMFs (from EMD) colors = [ 'dodgerblue' , 'orange' , 'darkgreen' , 'red' , 'gray' , 'orchid' , 'limegreen' , 'cyan' , 'blue' , 'magenta' ] for freqin in pre_defined_freq : axs [ 8 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) for i , (( xf , psd ), confidence_level ) in enumerate ( zip ( psd_spectra_fft_EMD , confidence_levels_fft_EMD )): if i == 0 : psd0 = psd psd_normalized = 100 * psd / np . max ( psd0 ) confidence_level_normalized = 100 * confidence_level / np . max ( psd0 ) axs [ 8 ] . plot ( xf , psd_normalized , label = f 'IMF { i + 1 } ' , color = colors [ i ]) axs [ 8 ] . plot ( xf , confidence_level_normalized , linestyle = '--' , color = colors [ i ]) axs [ 8 ] . set_title ( '(h) FFT of IMFs (EMD)' , pad = 12 ) axs [ 8 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 8 ] . set_ylabel ( 'Power (%)' ) axs [ 8 ] . set_xlim ( 0 , 36 ) axs [ 8 ] . set_ylim ( 0 , 12 ) # Set tick marks outside for all four axes axs [ 8 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 8 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 8 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) axs [ 8 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 8 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 8 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 8 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in xf : axs [ 8 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 8 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot HHT Marginal Spectrum (from EEMD) for freqin in pre_defined_freq : axs [ 4 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 4 ] . plot ( HHT_freq_bins_EEMD , HHT_power_spectrum_EEMD_normalized , color = 'red' ) axs [ 4 ] . plot ( HHT_freq_bins_EEMD , HHT_significance_level_EEMD_normalized , linestyle = '-.' , color = 'black' ) axs [ 4 ] . set_title ( '(i) HHT (EEMD + Hilbert)' , pad = 12 ) axs [ 4 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 4 ] . set_ylabel ( 'Power (%)' ) axs [ 4 ] . set_xlim ( 0 , 36 ) axs [ 4 ] . set_ylim ( 0 , 119 ) # Set tick marks outside for all four axes axs [ 4 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 4 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 4 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 4 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 4 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 4 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 4 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in HHT_freq_bins_EEMD : axs [ 4 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 4 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot FFT Spectra of IMFs (from EEMD) for freqin in pre_defined_freq : axs [ 9 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) for i , (( xf , psd ), confidence_level ) in enumerate ( zip ( psd_spectra_fft_EEMD , confidence_levels_fft_EEMD )): if i == 0 : psd0 = psd psd_normalized = 100 * psd / np . max ( psd0 ) confidence_level_normalized = 100 * confidence_level / np . max ( psd0 ) axs [ 9 ] . plot ( xf , psd_normalized , label = f 'IMF { i + 1 } ' , color = colors [ i ]) axs [ 9 ] . plot ( xf , confidence_level_normalized , linestyle = '--' , color = colors [ i ]) axs [ 9 ] . set_title ( '(j) FFT of IMFs (EEMD)' , pad = 12 ) axs [ 9 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 9 ] . set_ylabel ( 'Power (%)' ) axs [ 9 ] . set_xlim ( 0 , 36 ) axs [ 9 ] . set_ylim ( 0 , 12 ) # Set tick marks outside for all four axes axs [ 9 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 9 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 9 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) axs [ 9 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 9 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 9 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 9 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in xf : axs [ 9 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 9 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Adjust overall layout fig . subplots_adjust ( left = 0.05 , right = 0.95 , top = 0.95 , bottom = 0.05 , wspace = 0.0 , hspace = 0.0 ) # Save the figure as a single PDF pdf_path = 'Figures/Fig3_power_spectra_1D_signal.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig3_power_spectra_1D_signal.pdf'", "title": "Power Spectra"}, {"location": "python/power-spectra-example/#worked-example-nrmp-power-spectra", "text": "This example demonstrates the application of various spectral analysis techniques to a synthetic 1D signal constructed with predefined frequencies and amplitudes. The signal includes a range of oscillatory components with different characteristics, including: Dominant oscillations: Five dominant frequencies (5, 12, 15, 18, and 25 Hz) with varying amplitudes. Transient oscillation: A short-lived oscillation with a frequency of 2 Hz. Weak oscillation: A low-amplitude oscillation with a frequency of 33 Hz. Quasi-periodic oscillation: An oscillation with a frequency of 10 Hz and a time-varying amplitude. Noise: Random noise added to the signal. By analysing this synthetic signal with different methods, we can evaluate their ability to accurately identify and characterise these diverse oscillatory components. This provides valuable insights into the strengths and limitations of each technique, guiding the selection of appropriate methods for analysing real-world data. For a comprehensive discussion of the analysis and results, please refer to the associated article in Nature Reviews Methods Primers . Analysis and Figure The figure below presents a comparative analysis of various wave analysis methods applied to the synthetic 1D signal. The signal was pre-processed by detrending (to remove any linear trends) and apodized (to reduce edge effects) using a Tukey window. Methods used: Fast Fourier Transform (FFT) Lomb-Scargle Periodogram Welch's Method Wavelet Transform (with Morlet, Paul, and Mexican Hat wavelets) Global Wavelet Spectrum (GWS) Refined Global Wavelet Spectrum (RGWS) Hilbert-Huang Transform (HHT) with Empirical Mode Decomposition (EMD) and Ensemble EMD (EEMD) WaLSAtools version: 1.0 These particular analyses generate the figure below (Figure 3 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: Performance of diverse analysis methods on a synthetic 1D time series. (a) The detrended and apodized signal. (b) The unevenly sampled signal. (c) The FFT power spectrum. (d) The Lomb-Scargle periodogram. (e) The global wavelet spectrum (GWS) for the Morlet, Mexican Hat, and Paul wavelets. (f) The refined global wavelet spectrum (RGWS) for the Morlet, Mexican Hat, and Paul wavelets. (g) The HHT spectrum using EMD. (h) The FFT power spectra of the individual IMFs extracted by EMD. (i) The HHT spectrum using EEMD. (j) The FFT power spectra of the individual IMFs extracted by EEMD. (k) The Welch power spectrum. (l)-(n) The wavelet power spectra for the Morlet, Mexican Hat, and Paul wavelets, respectively. All powers are normalized to their maximum value and shown in percentages, with panels (c) , (d) , (h) , and (j) zoomed in on a smaller power range for better visibility of smaller peaks. The 95% confidence levels are indicated by dot-dashed curves for 1D power spectra and solid black contours for wavelet spectra. Vertical lines above each 1D spectrum mark the frequency resolution. Green vertical (or horizontal) lines on the frequency axes indicate the predefined frequencies used to construct the synthetic signal. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , walsa_detrend_apod import warnings #-------------------------------------------------------------------------- warnings . filterwarnings ( 'ignore' , category = RuntimeWarning ) # Load the synthetic signal from the FITS file data_dir = 'Synthetic_Data/' file_path = data_dir + 'NRMP_signal_1D.fits' hdul = fits . open ( file_path ) signal = hdul [ 0 ] . data # 1D synthetic signal data time = hdul [ 1 ] . data # Time array saved in the second HDU (Extension HDU 1) hdul . close () # Sampling rate and duration of the data sampling_rate = 100 # Hz duration = 10 # seconds #-------------------------------------------------------------------------- # Create unevenly sampled data by removing gaps from the signal # Define gaps' sizes and start indices gap_sizes = [ 17 , 42 , 95 , 46 ] # Sizes of gaps gap_starts = [ 150 , 200 , 500 , 800 ] # Start indices for gaps # Create initial set of indices n_points = len ( signal ) indices = np . arange ( n_points ) # Remove gaps for gap_start , gap_size in zip ( gap_starts , gap_sizes ): indices = indices [( indices < gap_start ) | ( indices >= gap_start + gap_size )] # Reduce both time and signal arrays according to final indices t_uneven = time [ indices ] signal_uneven = signal [ indices ] # Sort time and signal to maintain ascending order (although should already be in order) sorted_indices = np . argsort ( t_uneven ) t_uneven = t_uneven [ sorted_indices ] signal_uneven = signal_uneven [ sorted_indices ] #-------------------------------------------------------------------------- # FFT Analysis using WaLSAtools fft_power , fft_freqs , fft_significance = WaLSAtools ( signal = signal , time = time , method = 'fft' , siglevel = 0.95 , apod = 0.1 ) # Normalize FFT power to its maximum value fft_power_normalized = 100 * fft_power / np . max ( fft_power ) fft_significance_normalized = 100 * fft_significance / np . max ( fft_power ) #-------------------------------------------------------------------------- # Lomb-Scargle Analysis using WaLSAtools ls_power , ls_freqs , ls_significance = WaLSAtools ( signal = signal , time = time , method = 'lombscargle' , siglevel = 0.95 , apod = 0.1 ) # Normalize Lomb-Scargle power to its maximum value ls_power_normalized = 100 * ls_power / np . max ( ls_power ) ls_significance_normalized = 100 * ls_significance / np . max ( ls_power ) #-------------------------------------------------------------------------- # Wavelet Analysis using WaLSAtools - Morlet wavelet_power_morlet , wavelet_periods_morlet , wavelet_significance_morlet , coi_morlet , ( global_power_morlet , global_conf_morlet ), ( rgws_morlet_periods , rgws_morlet_power ) = WaLSAtools ( signal = signal , time = time , method = 'wavelet' , siglevel = 0.95 , apod = 0.1 , mother = 'morlet' , GWS = True , RGWS = True ) #-------------------------------------------------------------------------- # Wavelet Analysis using WaLSAtools - DOG (Mexican Hat) wavelet_power_dog , wavelet_periods_dog , wavelet_significance_dog , coi_dog , ( global_power_dog , global_conf_dog ), ( rgws_dog_periods , rgws_dog_power ) = WaLSAtools ( signal = signal , time = time , method = 'wavelet' , siglevel = 0.95 , apod = 0.1 , mother = 'dog' , GWS = True , RGWS = True ) #-------------------------------------------------------------------------- # Wavelet Analysis using WaLSAtools - Paul wavelet_power_paul , wavelet_periods_paul , wavelet_significance_paul , coi_paul , ( global_power_paul , global_conf_paul ), ( rgws_paul_periods , rgws_paul_power ) = WaLSAtools ( signal = signal , time = time , method = 'wavelet' , siglevel = 0.95 , apod = 0.1 , mother = 'paul' , GWS = True , RGWS = True ) #-------------------------------------------------------------------------- # Welch Power Spectral Density Analysis using WaLSAtools welch_psd , welch_freqs , welch_significance = WaLSAtools ( signal = signal , time = time , method = 'welch' , siglevel = 0.95 , nperseg = 200 , noverlap = 20 ) # Normalize Welch PSD to its maximum value welch_psd_normalized = 100 * welch_psd / np . max ( welch_psd ) welch_significance_normalized = 100 * welch_significance / np . max ( welch_psd ) #-------------------------------------------------------------------------- # EMD & HHT Calculations using WaLSAtools HHT_power_spectrum_EMD , HHT_significance_level_EMD , HHT_freq_bins_EMD , psd_spectra_fft_EMD , confidence_levels_fft_EMD , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 ) # Normalize power spectra to their maximum values HHT_power_spectrum_EMD_normalized = 100 * HHT_power_spectrum_EMD / np . max ( HHT_power_spectrum_EMD ) HHT_significance_level_EMD_normalized = 100 * HHT_significance_level_EMD / np . max ( HHT_power_spectrum_EMD ) #-------------------------------------------------------------------------- # EEMD & HHT Calculations using WaLSAtools HHT_power_spectrum_EEMD , HHT_significance_level_EEMD , HHT_freq_bins_EEMD , psd_spectra_fft_EEMD , confidence_levels_fft_EEMD , _ , _ , _ = WaLSAtools ( signal = signal , time = time , method = 'emd' , siglevel = 0.95 , EEMD = True ) # Normalize power spectra to their maximum values HHT_power_spectrum_EEMD_normalized = 100 * HHT_power_spectrum_EEMD / np . max ( HHT_power_spectrum_EEMD ) HHT_significance_level_EEMD_normalized = 100 * HHT_significance_level_EEMD / np . max ( HHT_power_spectrum_EEMD ) Detrending and apodization complete. FFT processed. Detrending and apodization complete. Lomb-Scargle processed. Detrending and apodization complete. Wavelet (morlet) processed. Detrending and apodization complete. Wavelet (dog) processed. Detrending and apodization complete. Wavelet (paul) processed. Welch processed. Detrending and apodization complete. EMD processed. Detrending and apodization complete. EEMD processed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 from mpl_toolkits.axes_grid1.inset_locator import inset_axes import matplotlib.pyplot as plt from matplotlib import gridspec from matplotlib.patches import Polygon from matplotlib.ticker import AutoMinorLocator , FormatStrFormatter from matplotlib.legend_handler import HandlerTuple from mpl_toolkits.axes_grid1 import make_axes_locatable from WaLSAtools import WaLSA_save_pdf from matplotlib.colors import ListedColormap #-------------------------------------------------------------------------- pre_defined_freq = [ 2 , 5 , 10 , 12 , 15 , 18 , 25 , 33 ] # Mark pre-defined frequencies # Setting global parameters plt . rcParams . update ({ 'font.family' : 'sans-serif' , # Use sans-serif fonts 'font.sans-serif' : 'Arial' , # Set Helvetica as the default sans-serif font 'font.size' : 19 , # Global font size 'axes.titlesize' : 19 , # Title font size 'axes.labelsize' : 17 , # Axis label font size 'xtick.labelsize' : 17 , # X-axis tick label font size 'ytick.labelsize' : 17 , # Y-axis tick label font size 'legend.fontsize' : 15 , # Legend font size 'figure.titlesize' : 19 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style 'font.weight' : 'medium' , # Make all fonts bold 'axes.titleweight' : 'medium' , # Make title font bold 'axes.labelweight' : 'medium' # Make axis labels bold }) plt . rc ( 'axes' , linewidth = 1.3 ) plt . rc ( 'lines' , linewidth = 1.1 ) # Create a figure and a gridspec with customized layout fig = plt . figure ( figsize = ( 16 , 15 )) gs = gridspec . GridSpec ( 5 , 3 , height_ratios = [ 1 , 1 , 1 , 1 , 1 ], width_ratios = [ 1 , 1 , 1 ], figure = fig , wspace = 0.4 , hspace = 0.8 ) # Add the light gray background manually using Polygons # Fill for first two columns (all rows) polygon_coords_1 = [[ 0.0 , 0.0 ], [ 0.64 , 0.0 ], [ 0.64 , 1.0 ], [ 0.0 , 1.0 ]] # Define the coordinates for the first region background_poly_1 = Polygon ( polygon_coords_1 , closed = True , facecolor = ( 0.91 , 0.91 , 0.91 ), edgecolor = None , zorder =- 1 ) fig . add_artist ( background_poly_1 ) # Fill for bottom part of third column (for plot k) polygon_coords_2 = [[ 0.64 , 0.0 ], [ 1.0 , 0.0 ], [ 1.0 , 0.2 ], [ 0.64 , 0.2 ]] # Define the coordinates for the second region background_poly_2 = Polygon ( polygon_coords_2 , closed = True , facecolor = ( 0.91 , 0.91 , 0.91 ), edgecolor = None , zorder =- 1 ) fig . add_artist ( background_poly_2 ) # Assign plots to their respective positions axs = [ fig . add_subplot ( gs [ 0 , 0 ]), # (a) fig . add_subplot ( gs [ 1 , 0 ]), # (b) fig . add_subplot ( gs [ 2 , 0 ]), # (e) fig . add_subplot ( gs [ 3 , 0 ]), # (g) fig . add_subplot ( gs [ 4 , 0 ]), # (i) fig . add_subplot ( gs [ 0 , 1 ]), # (c) fig . add_subplot ( gs [ 1 , 1 ]), # (d) fig . add_subplot ( gs [ 2 , 1 ]), # (f) fig . add_subplot ( gs [ 3 , 1 ]), # (h) fig . add_subplot ( gs [ 4 , 1 ]), # (j) fig . add_subplot ( gs [ 4 , 2 ]), # (k) ] # Create individual axes for the subplots l, m, and n using fig.add_axes() # The list elements [left, bottom, width, height] are fractions of the figure size ax_inset_l = fig . add_axes ([ 0.725 , 0.785 , 0.21 , 0.14 ]) ax_inset_m = fig . add_axes ([ 0.725 , 0.522 , 0.21 , 0.14 ]) ax_inset_n = fig . add_axes ([ 0.725 , 0.255 , 0.21 , 0.14 ]) # Set background color for all plots except (l), (m), and (n) for ax in axs : if ax not in [ ax_inset_l , ax_inset_m , ax_inset_n ]: ax . set_facecolor (( 0.91 , 0.91 , 0.91 )) # Light gray background #-------------------------------------------------------------------------- # Plot the signal apod_signal = walsa_detrend_apod ( signal , apod = 0.1 , pxdetrend = 2 , silent = True ) # axs[0].plot(time, apod_signal * 10, color='#3071A7') axs [ 0 ] . plot ( time , apod_signal * 10 , color = 'DodgerBlue' ) axs [ 0 ] . set_title ( '(a) Detrended & apodized synthetic signal' , pad = 12 , fontsize = 18 ) axs [ 0 ] . set_xlabel ( 'Time (s)' ) axs [ 0 ] . set_ylabel ( 'DN (arb. unit)' ) axs [ 0 ] . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes axs [ 0 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals axs [ 0 ] . set_xticks ( np . arange ( 0 , 10 , 2 )) axs [ 0 ] . set_yticks ( np . arange ( 0 , 80.01 , 40 )) # Custom tick sizes and thickness axs [ 0 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) # Major ticks axs [ 0 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) # Minor ticks # Set minor ticks axs [ 0 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) axs [ 0 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) #-------------------------------------------------------------------------- # Plot the unevenly sampled signal apod_signal_uneven = walsa_detrend_apod ( signal_uneven , apod = 0.1 , silent = True ) segment_start_idx = 0 for i in range ( 1 , len ( t_uneven )): if t_uneven [ i ] - t_uneven [ i - 1 ] > np . mean ( np . diff ( t_uneven )): axs [ 1 ] . plot ( t_uneven [ segment_start_idx : i ], apod_signal_uneven [ segment_start_idx : i ] * 10 , color = 'DodgerBlue' ) segment_start_idx = i axs [ 1 ] . plot ( t_uneven [ segment_start_idx :], apod_signal_uneven [ segment_start_idx :] * 10 , color = 'DodgerBlue' ) axs [ 1 ] . set_title ( '(b) The synthetic signal with gaps' , pad = 12 ) axs [ 1 ] . set_xlabel ( 'Time (s)' ) axs [ 1 ] . set_ylabel ( 'DN (arb. unit)' ) axs [ 1 ] . set_xlim ([ 0 , 10 ]) # Set tick marks outside for all four axes axs [ 1 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals axs [ 1 ] . set_xticks ( np . arange ( 0 , 10 , 2 )) axs [ 1 ] . set_yticks ( np . arange ( 0 , 80.01 , 40 )) # Custom tick sizes and thickness axs [ 1 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) # Major ticks axs [ 1 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) # Minor ticks # Set minor ticks axs [ 1 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) axs [ 1 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) #-------------------------------------------------------------------------- # Plot FFT power spectrum (normalized) for freqin in pre_defined_freq : axs [ 5 ] . axvline ( x = freqin , color = '#239023' , linewidth = 0.5 ) axs [ 5 ] . plot ( fft_freqs , fft_power_normalized , color = 'red' ) axs [ 5 ] . set_title ( '(c) FFT' , pad = 12 ) axs [ 5 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 5 ] . set_ylabel ( 'Power (%)' ) axs [ 5 ] . set_xlim ([ 0 , 36 ]) axs [ 5 ] . set_ylim ([ 0 , 12 ]) # Plot the significance level as a line significance_plot , = axs [ 5 ] . plot ( fft_freqs , fft_significance_normalized , linestyle = '-.' , color = 'black' , label = '95 % c onfidence level' , linewidth = 0.7 ) axs [ 5 ] . legend ( [( significance_plot ,)], # Use a tuple for the line element [ '95 % c onfidence level ' ], # Text label handler_map = { tuple : HandlerTuple ( ndivide = None )}, # Custom handler to place the line on the right loc = 'upper right' , # Adjust position as needed bbox_to_anchor = ( 1.0 , 0.92 ), # Adjust the (x, y) position of the legend frameon = False , # No frame for the legend handletextpad =- 12.85 # Adjust this value to move the line closer/farther from the text ) # Set tick marks outside for all four axes axs [ 5 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) # Custom tick intervals axs [ 5 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) # X-axis tick interval every 4 units axs [ 5 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) # Y-axis tick interval every 2 units # Custom tick sizes and thickness axs [ 5 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) # Major ticks axs [ 5 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) # Minor ticks # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) axs [ 5 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 5 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Vertical lines at all FFT frequencies (to illustrate frequency resolution) for freq in fft_freqs : axs [ 5 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 5 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot Lomb-Scargle power spectrum (normalized) for freqin in pre_defined_freq : axs [ 6 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 6 ] . plot ( ls_freqs , ls_power_normalized , color = 'red' ) axs [ 6 ] . set_title ( '(d) Lomb-Scargle' , pad = 12 ) axs [ 6 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 6 ] . set_ylabel ( 'Power (%)' ) axs [ 6 ] . set_xlim ([ 0 , 36 ]) axs [ 6 ] . set_ylim ([ 0 , 12 ]) # Plot the significance level as a line axs [ 6 ] . plot ( ls_freqs , ls_significance_normalized , linestyle = '-.' , color = 'black' , linewidth = 0.5 ) # Set tick marks outside for all four axes axs [ 6 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 6 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 6 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) axs [ 6 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 6 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 6 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 6 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in ls_freqs : axs [ 6 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 6 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Load the RGB values from the IDL file, corresponding to IDL's \"loadct, 20\" color table rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_20_modified.txt' ) # Normalize the RGB values to [0, 1] (matplotlib expects RGB values in this range) rgb_values = rgb_values / 255.0 idl_colormap_20 = ListedColormap ( rgb_values ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - Morlet colorbar_label = '(l) Power (%) | Morlet Wavelet' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) power = wavelet_power_morlet power [ power < 0 ] = 0 power = 100 * power / np . nanmax ( power ) t = time periods = wavelet_periods_morlet coi = coi_morlet sig_slevel = wavelet_significance_morlet dt = 1 / sampling_rate removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels from 0 to 100 for consistent color scaling levels = np . linspace ( 0 , 100 , 100 ) # Set levels directly from 0 to 100 # Plot the wavelet power spectrum CS = ax_inset_l . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # 95% significance contour ax_inset_l . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 0.6 ]) # Cone-of-influence ax_inset_l . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_l . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ np . max ( periods )], [ np . max ( periods )], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_l . set_ylim ([ np . min ( periods ), np . max ( periods )]) ax_inset_l . set_yscale ( 'log' , base = 10 ) ax_inset_l . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_l . invert_yaxis () # Set axis limits and labels ax_inset_l . set_xlim ([ t . min (), t . max ()]) ax_inset_l . set_ylabel ( ylabel ) ax_inset_l . set_xlabel ( xlabel ) ax_inset_l . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_l . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_l . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_l . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_l . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_l . twinx () min_frequency = 1 / np . max ( periods ) max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_l ) cax = inset_axes ( ax_inset_l , width = \"100%\" , height = \"5%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 0.8 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . set_ticks ([ 0 , 20 , 40 , 60 , 80 , 100 ]) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add horizontal lines for pre-defined frequencies for freqin in pre_defined_freq : ax_inset_l . axhline ( y = 1 / freqin , color = '#32CD32' , linewidth = 0.7 ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - DOG (Mexican Hat) colorbar_label = '(m) Power (%) | Mexican-Hat Wavelet' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) power = wavelet_power_dog power [ power < 0 ] = 0 power = 100 * power / np . nanmax ( power ) t = time periods = wavelet_periods_dog coi = coi_dog sig_slevel = wavelet_significance_dog dt = 1 / sampling_rate removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels from 0 to 100 for consistent color scaling levels = np . linspace ( 0 , 100 , 100 ) # Set levels directly from 0 to 100 # Plot the wavelet power spectrum CS = ax_inset_m . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # 95% significance contour ax_inset_m . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 0.6 ]) # Cone-of-influence ax_inset_m . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_m . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ max_period ], [ max_period ], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_m . set_ylim ([ np . min ( periods ), max_period ]) ax_inset_m . set_yscale ( 'log' , base = 10 ) ax_inset_m . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_m . invert_yaxis () # Set axis limits and labels ax_inset_m . set_xlim ([ t . min (), t . max ()]) ax_inset_m . set_ylabel ( ylabel ) ax_inset_m . set_xlabel ( xlabel ) ax_inset_m . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_m . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_m . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_m . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_m . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_m . twinx () # Set limits for the frequency axis based on the `max_period` used for the period axis min_frequency = 1 / max_period max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_m ) cax = inset_axes ( ax_inset_m , width = \"100%\" , height = \"5%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 0.8 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . set_ticks ([ 0 , 20 , 40 , 60 , 80 , 100 ]) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) for freqin in pre_defined_freq : ax_inset_m . axhline ( y = 1 / freqin , color = '#32CD32' , linewidth = 0.7 ) #-------------------------------------------------------------------------- # Plot Wavelet power spectrum - Paul colorbar_label = '(n) Power (%) | Paul Wavelet' ylabel = 'Period (s)' xlabel = 'Time (s)' cmap = plt . get_cmap ( idl_colormap_20 ) power = wavelet_power_paul power [ power < 0 ] = 0 power = 100 * power / np . nanmax ( power ) t = time periods = wavelet_periods_paul coi = coi_paul sig_slevel = wavelet_significance_paul dt = 1 / sampling_rate removespace = True if removespace : max_period = np . max ( coi ) cutoff_index = np . argmax ( periods > max_period ) # Ensure cutoff_index is within bounds if cutoff_index > 0 and cutoff_index <= len ( periods ): power = power [: cutoff_index , :] periods = periods [: cutoff_index ] sig_slevel = sig_slevel [: cutoff_index , :] # Define levels from 0 to 100 for consistent color scaling levels = np . linspace ( 0 , 100 , 100 ) # Set levels directly from 0 to 100 # Plot the wavelet power spectrum CS = ax_inset_n . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # 95% significance contour ax_inset_n . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 0.6 ]) # Plot cone-of-influence (CoI) ax_inset_n . plot ( t , coi , '-k' , lw = 1.15 ) ax_inset_n . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ max_period ], [ max_period ], [ 1e-9 ]]), color = 'none' , edgecolor = 'k' , alpha = 1 , hatch = 'xx' ) # Log scale for periods ax_inset_n . set_ylim ([ np . min ( periods ), max_period ]) ax_inset_n . set_yscale ( 'log' , base = 10 ) ax_inset_n . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.1f ' )) ax_inset_n . invert_yaxis () # Set axis limits and labels ax_inset_n . set_xlim ([ t . min (), t . max ()]) ax_inset_n . set_ylabel ( ylabel ) ax_inset_n . set_xlabel ( xlabel ) ax_inset_n . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , length = 8 , width = 1.5 , top = True , right = True ) # Custom tick intervals ax_inset_n . set_xticks ( np . arange ( 0 , 10 , 2 )) # Custom tick sizes and thickness ax_inset_n . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 , right = True ) # Major ticks ax_inset_n . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Set the number of minor ticks (e.g., 4 minor ticks between major ticks) ax_inset_n . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) # Add a secondary y-axis for frequency in Hz ax_freq = ax_inset_n . twinx () # Set limits for the frequency axis based on the `max_period` used for the period axis min_frequency = 1 / max_period max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( FormatStrFormatter ( ' %.0f ' )) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' ) ax_freq . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) ax_freq . tick_params ( axis = 'both' , which = 'minor' , top = True , right = True , length = 4 , width = 1.5 ) # Create an inset color bar axis above the plot with a slightly reduced width divider = make_axes_locatable ( ax_inset_n ) cax = inset_axes ( ax_inset_n , width = \"100%\" , height = \"5%\" , loc = 'upper center' , borderpad =- 1.4 ) cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , labelpad = 8 ) cbar . ax . tick_params ( direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust tick marks for the color bar cbar . ax . tick_params ( axis = 'x' , which = 'major' , length = 6 , width = 1.2 , direction = 'out' , top = True , labeltop = True , bottom = False ) cbar . ax . tick_params ( axis = 'x' , which = 'minor' , length = 3 , width = 0.8 , direction = 'out' , top = True , bottom = False ) # Set colorbar ticks and labels cbar . set_ticks ([ 0 , 20 , 40 , 60 , 80 , 100 ]) cbar . ax . xaxis . set_major_formatter ( plt . FuncFormatter ( lambda x , _ : f ' { int ( x ) } ' )) # Set minor ticks cbar . ax . xaxis . set_minor_locator ( AutoMinorLocator ( 4 )) for freqin in pre_defined_freq : ax_inset_n . axhline ( y = 1 / freqin , color = '#32CD32' , linewidth = 0.7 ) #-------------------------------------------------------------------------- # Plot Global Wavelet Spectra (GWS) for freqin in pre_defined_freq : axs [ 2 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 2 ] . plot ( 1 / wavelet_periods_morlet , 100 * global_power_morlet / np . max ( global_power_morlet ), 'g-' , label = 'Morlet' ) axs [ 2 ] . plot ( 1 / wavelet_periods_dog , 100 * global_power_dog / np . max ( global_power_dog ), 'r-' , label = 'Mexican Hat' ) axs [ 2 ] . plot ( 1 / wavelet_periods_paul , 100 * global_power_paul / np . max ( global_power_paul ), 'b-' , label = 'Paul' ) axs [ 2 ] . plot ( 1 / wavelet_periods_morlet , 100 * global_conf_morlet / np . max ( global_power_morlet ), 'g-.' ) axs [ 2 ] . plot ( 1 / wavelet_periods_dog , 100 * global_conf_dog / np . max ( global_power_dog ), 'r-.' ) axs [ 2 ] . plot ( 1 / wavelet_periods_paul , 100 * global_conf_paul / np . max ( global_power_paul ), 'b-.' ) axs [ 2 ] . set_title ( '(e) GWS' , pad = 12 ) axs [ 2 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 2 ] . set_ylabel ( 'Power (%)' ) axs [ 2 ] . set_xlim ([ 0 , 36 ]) axs [ 2 ] . set_ylim ([ 0 , 119 ]) # axs[2].legend( # loc='upper right', bbox_to_anchor=(1.0, 0.92), frameon=False, # handletextpad=-6.5 # ) # Add custom labels manually to the plot .... to align the labels to the right handles , labels = axs [ 2 ] . get_legend_handles_labels () # Define the vertical offset for each legend item offset = 0.15 for i , ( handle , label ) in enumerate ( zip ( handles , labels )): # Add the colored line axs [ 2 ] . plot ( [ 0.9 , 0.97 ], # x coordinates (start and end of the line) [ 0.78 - offset * i , 0.78 - offset * i ], # y coordinates (constant to make it horizontal) transform = axs [ 2 ] . transAxes , color = handle . get_color (), # Use the color from the original handle linestyle = handle . get_linestyle (), # Use the linestyle from the original handle linewidth = handle . get_linewidth (), # Use the linewidth from the original handle ) # Add the label text axs [ 2 ] . text ( 0.885 , 0.78 - offset * i , # Adjust x and y positions as needed label , transform = axs [ 2 ] . transAxes , ha = 'right' , va = 'center' , fontsize = 15 , # Align the text to the right ) # Set tick marks outside for all four axes axs [ 2 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 2 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 2 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 2 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 2 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 2 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 2 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in 1 / wavelet_periods_morlet : axs [ 2 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 2 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot Refined Global Wavelet Spectra (RGWS) for freqin in pre_defined_freq : axs [ 7 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 7 ] . plot ( 1 / rgws_morlet_periods , 100 * rgws_morlet_power / np . max ( rgws_morlet_power ), 'g-' ) axs [ 7 ] . plot ( 1 / rgws_dog_periods , 100 * rgws_dog_power / np . max ( rgws_dog_power ), 'r-' ) axs [ 7 ] . plot ( 1 / rgws_paul_periods , 100 * rgws_paul_power / np . max ( rgws_paul_power ), 'b-' ) axs [ 7 ] . set_title ( '(f) RGWS' , pad = 12 ) axs [ 7 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 7 ] . set_ylabel ( 'Power (%)' ) axs [ 7 ] . set_xlim ([ 0 , 36 ]) axs [ 7 ] . set_ylim ([ 0 , 119 ]) # Set tick marks outside for all four axes axs [ 7 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 7 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 7 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 7 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 7 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 7 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 7 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in 1 / rgws_morlet_periods : axs [ 7 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 7 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot Welch power spectrum (normalized) for freqin in pre_defined_freq : axs [ 10 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 10 ] . plot ( welch_freqs , welch_psd_normalized , color = 'red' ) axs [ 10 ] . set_title ( '(k) Welch' , pad = 12 ) axs [ 10 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 10 ] . set_ylabel ( 'Power (%)' ) axs [ 10 ] . set_xlim ([ 0 , 36 ]) axs [ 10 ] . set_ylim ([ 0 , 119 ]) # Plot the significance level as a line axs [ 10 ] . plot ( welch_freqs , welch_significance_normalized , linestyle = '-.' , color = 'black' ) # Set tick marks outside for all four axes axs [ 10 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 10 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 10 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 10 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 10 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 10 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 10 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in welch_freqs : axs [ 10 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 10 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot HHT Marginal Spectrum (from EMD) for freqin in pre_defined_freq : axs [ 3 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 3 ] . plot ( HHT_freq_bins_EMD , HHT_power_spectrum_EMD_normalized , color = 'red' ) axs [ 3 ] . plot ( HHT_freq_bins_EMD , HHT_significance_level_EMD_normalized , linestyle = '-.' , color = 'black' ) axs [ 3 ] . set_title ( '(g) HHT (EMD + Hilbert)' , pad = 12 ) axs [ 3 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 3 ] . set_ylabel ( 'Power (%)' ) axs [ 3 ] . set_xlim ( 0 , 36 ) axs [ 3 ] . set_ylim ( 0 , 119 ) # Set tick marks outside for all four axes axs [ 3 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 3 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 3 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 3 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 3 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 3 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 3 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in HHT_freq_bins_EMD : axs [ 3 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 3 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot FFT Spectra of IMFs (from EMD) colors = [ 'dodgerblue' , 'orange' , 'darkgreen' , 'red' , 'gray' , 'orchid' , 'limegreen' , 'cyan' , 'blue' , 'magenta' ] for freqin in pre_defined_freq : axs [ 8 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) for i , (( xf , psd ), confidence_level ) in enumerate ( zip ( psd_spectra_fft_EMD , confidence_levels_fft_EMD )): if i == 0 : psd0 = psd psd_normalized = 100 * psd / np . max ( psd0 ) confidence_level_normalized = 100 * confidence_level / np . max ( psd0 ) axs [ 8 ] . plot ( xf , psd_normalized , label = f 'IMF { i + 1 } ' , color = colors [ i ]) axs [ 8 ] . plot ( xf , confidence_level_normalized , linestyle = '--' , color = colors [ i ]) axs [ 8 ] . set_title ( '(h) FFT of IMFs (EMD)' , pad = 12 ) axs [ 8 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 8 ] . set_ylabel ( 'Power (%)' ) axs [ 8 ] . set_xlim ( 0 , 36 ) axs [ 8 ] . set_ylim ( 0 , 12 ) # Set tick marks outside for all four axes axs [ 8 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 8 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 8 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) axs [ 8 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 8 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 8 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 8 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in xf : axs [ 8 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 8 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot HHT Marginal Spectrum (from EEMD) for freqin in pre_defined_freq : axs [ 4 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) axs [ 4 ] . plot ( HHT_freq_bins_EEMD , HHT_power_spectrum_EEMD_normalized , color = 'red' ) axs [ 4 ] . plot ( HHT_freq_bins_EEMD , HHT_significance_level_EEMD_normalized , linestyle = '-.' , color = 'black' ) axs [ 4 ] . set_title ( '(i) HHT (EEMD + Hilbert)' , pad = 12 ) axs [ 4 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 4 ] . set_ylabel ( 'Power (%)' ) axs [ 4 ] . set_xlim ( 0 , 36 ) axs [ 4 ] . set_ylim ( 0 , 119 ) # Set tick marks outside for all four axes axs [ 4 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 4 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 4 ] . set_yticks ( np . arange ( 0 , 119 , 30 )) axs [ 4 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 4 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 4 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 4 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in HHT_freq_bins_EEMD : axs [ 4 ] . vlines ( freq , ymin = 105 , ymax = 119 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 4 ] . hlines ( 105 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Plot FFT Spectra of IMFs (from EEMD) for freqin in pre_defined_freq : axs [ 9 ] . axvline ( x = freqin , color = '#32CD32' , linewidth = 0.7 ) for i , (( xf , psd ), confidence_level ) in enumerate ( zip ( psd_spectra_fft_EEMD , confidence_levels_fft_EEMD )): if i == 0 : psd0 = psd psd_normalized = 100 * psd / np . max ( psd0 ) confidence_level_normalized = 100 * confidence_level / np . max ( psd0 ) axs [ 9 ] . plot ( xf , psd_normalized , label = f 'IMF { i + 1 } ' , color = colors [ i ]) axs [ 9 ] . plot ( xf , confidence_level_normalized , linestyle = '--' , color = colors [ i ]) axs [ 9 ] . set_title ( '(j) FFT of IMFs (EEMD)' , pad = 12 ) axs [ 9 ] . set_xlabel ( 'Frequency (Hz)' ) axs [ 9 ] . set_ylabel ( 'Power (%)' ) axs [ 9 ] . set_xlim ( 0 , 36 ) axs [ 9 ] . set_ylim ( 0 , 12 ) # Set tick marks outside for all four axes axs [ 9 ] . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) axs [ 9 ] . set_xticks ( np . arange ( 0 , 36 , 5 )) axs [ 9 ] . set_yticks ( np . arange ( 0 , 12 , 5 )) axs [ 9 ] . tick_params ( axis = 'both' , which = 'major' , length = 8 , width = 1.5 ) axs [ 9 ] . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.5 ) axs [ 9 ] . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) axs [ 9 ] . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) for freq in xf : axs [ 9 ] . vlines ( freq , ymin = 10.5 , ymax = 12 , color = ( 0.10 , 0.10 , 0.10 ), linewidth = 0.4 ) axs [ 9 ] . hlines ( 10.5 , xmin = 0 , xmax = 36 , color = 'black' , linewidth = 0.4 ) #-------------------------------------------------------------------------- # Adjust overall layout fig . subplots_adjust ( left = 0.05 , right = 0.95 , top = 0.95 , bottom = 0.05 , wspace = 0.0 , hspace = 0.0 ) # Save the figure as a single PDF pdf_path = 'Figures/Fig3_power_spectra_1D_signal.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/Fig3_power_spectra_1D_signal.pdf'", "title": "Worked Example - NRMP: Power Spectra"}, {"location": "python/routines/", "text": "Under the Hood \u00b6 We strongly recommend everyone to follow the procedure as instructed here when using WaLSAtools \u2014 a user-friendly tool \u2014 which gives you all information you need to do your analysis. However, for experts who want to make themselves familiar with the techniques and codes under the hood, inspect them and modify/develop/improve them, some of the main codes are also provided below. Please note that all codes and their dependencies are available in the GitHub repository . Analysis Modules \u00b6 WaLSAtools is built upon a collection of analysis modules, each designed for a specific aspect of wave analysis. These modules are combined and accessed through the main WaLSAtools interface, providing a streamlined and user-friendly experience. Here's a brief overview of the core analysis modules: WaLSA_speclizer.py This module provides a collection of spectral analysis techniques, including FFT, Lomb-Scargle, Wavelet, Welch, and EMD/HHT. WaLSA_speclizer.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from astropy.timeseries import LombScargle # type: ignore from tqdm import tqdm # type: ignore from .WaLSA_detrend_apod import WaLSA_detrend_apod # type: ignore from .WaLSA_confidence import WaLSA_confidence # type: ignore from .WaLSA_wavelet import cwt , significance # type: ignore from scipy.signal import welch # type: ignore # -------------------------------------- Main Function ---------------------------------------- def WaLSA_speclizer ( signal = None , time = None , method = None , dominantfreq = False , averagedpower = False , ** kwargs ): \"\"\" Main function to prepare data and call the specific spectral analysis method. Parameters: signal (array): The input signal (1D or 3D). time (array): The time array of the signal. method (str): The method to use for spectral analysis ('fft', 'lombscargle', etc.) **kwargs: Additional parameters for data preparation and analysis methods. Returns: Power spectrum, frequencies, and significance (if applicable). \"\"\" if not dominantfreq or not averagedpower : if method == 'fft' : return getpowerFFT ( signal , time = time , ** kwargs ) elif method == 'lombscargle' : return getpowerLS ( signal , time = time , ** kwargs ) elif method == 'wavelet' : return getpowerWavelet ( signal , time = time , ** kwargs ) elif method == 'welch' : return welch_psd ( signal , time = time , ** kwargs ) elif method == 'emd' : return getEMD_HHT ( signal , time = time , ** kwargs ) else : raise ValueError ( f \"Unknown method: { method } \" ) else : return get_dominant_averaged ( signal , time = time , method = method , ** kwargs ) # -------------------------------------- FFT ---------------------------------------- def getpowerFFT ( signal , time , ** kwargs ): \"\"\" Perform FFT analysis on the given signal. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. nosignificance (bool): If True, skip significance calculation. Default: False. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. amplitude (bool): If True, return the amplitudes of the Fourier transform. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: Power spectrum, frequencies, significance, amplitudes \"\"\" # Define default values for the optional parameters defaults = { 'siglevel' : 0.95 , 'significance' : None , 'nperm' : 1000 , 'nosignificance' : False , 'apod' : 0.1 , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'nodetrendapod' : False , 'amplitude' : False , 'silent' : False } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } params [ 'siglevel' ] = 1 - params [ 'siglevel' ] # different convention tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) else : apocube = signal nt = len ( apocube ) # Length of the time series (1D) # Calculate the frequencies frequencies = 1. / ( cadence * 2 ) * np . arange ( nt // 2 + 1 ) / ( nt // 2 ) frequencies = frequencies [ 1 :] powermap = np . zeros ( len ( frequencies )) signal = apocube spec = np . fft . fft ( signal ) power = 2 * np . abs ( spec [ 1 : len ( frequencies ) + 1 ]) ** 2 powermap [:] = power / frequencies [ 0 ] if params [ 'amplitude' ]: amplitudes = np . zeros (( len ( signal ), len ( frequencies )), dtype = np . complex_ ) amplitudes = spec [ 1 : len ( frequencies ) + 1 ] else : amplitudes = None # Calculate significance if requested if not params [ 'nosignificance' ]: ps_perm = np . zeros (( len ( frequencies ), params [ 'nperm' ])) for ip in range ( params [ 'nperm' ]): perm_signal = np . random . permutation ( signal ) # Permuting the original signal apocube = WaLSA_detrend_apod ( perm_signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) perm_spec = np . fft . fft ( perm_signal ) perm_power = 2 * np . abs ( perm_spec [ 1 : len ( frequencies ) + 1 ]) ** 2 ps_perm [:, ip ] = perm_power # Correct call to WaLSA_confidence significance = WaLSA_confidence ( ps_perm , siglevel = params [ 'siglevel' ], nf = len ( frequencies )) significance = significance / frequencies [ 0 ] else : significance = None if not params [ 'silent' ]: print ( \"FFT processed.\" ) return powermap , frequencies , significance , amplitudes # -------------------------------------- Lomb-Scargle ---------------------------------------- def getpowerLS ( signal , time , ** kwargs ): \"\"\" Perform Lomb-Scargle analysis on the given signal. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. dy (array): Errors or observational uncertainties associated with the time series. fit_mean (bool): If True, include a constant offset as part of the model at each frequency. This improves accuracy, especially for incomplete phase coverage. center_data (bool): If True, pre-center the data by subtracting the weighted mean of the input data. This is especially important if fit_mean=False. nterms (int): Number of terms to use in the Fourier fit. Default: 1. normalization (str): The normalization method for the periodogram. Options: 'standard', 'model', 'log', 'psd'. Default: 'standard'. nosignificance (bool): If True, skip significance calculation. Default: False. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False.. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: Power spectrum, frequencies, and significance (if applicable). \"\"\" # Define default values for the optional parameters defaults = { 'siglevel' : 0.05 , 'nperm' : 1000 , 'nosignificance' : False , 'apod' : 0.1 , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'silent' : False , # Ensure 'silent' is included in defaults 'nodetrendapod' : False , 'dy' : None , # Error or sequence of observational errors associated with times t 'fit_mean' : False , # If True include a constant offset as part of the model at each frequency. This can lead to more accurate results, especially in the case of incomplete phase coverage 'center_data' : True , # If True pre-center the data by subtracting the weighted mean of the input data. This is especially important if fit_mean = False 'nterms' : 1 , # Number of terms to use in the Fourier fit 'normalization' : 'standard' # The normalization to use for the periodogram. Options are 'standard', 'model', 'log', 'psd' } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } params [ 'siglevel' ] = 1 - params [ 'siglevel' ] # different convention tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) else : apocube = signal frequencies , power = LombScargle ( time , apocube , dy = params [ 'dy' ], fit_mean = params [ 'fit_mean' ], center_data = params [ 'center_data' ], nterms = params [ 'nterms' ], normalization = params [ 'normalization' ]) . autopower () # Calculate significance if needed if not params [ 'nosignificance' ]: ps_perm = np . zeros (( len ( frequencies ), params [ 'nperm' ])) for ip in range ( params [ 'nperm' ]): perm_signal = np . random . permutation ( signal ) # Permuting the original signal apocubep = WaLSA_detrend_apod ( perm_signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) frequencies , perm_power = LombScargle ( time , apocubep , dy = params [ 'dy' ], fit_mean = params [ 'fit_mean' ], center_data = params [ 'center_data' ], nterms = params [ 'nterms' ], normalization = params [ 'normalization' ]) . autopower () ps_perm [:, ip ] = perm_power significance = WaLSA_confidence ( ps_perm , siglevel = params [ 'siglevel' ], nf = len ( frequencies )) else : significance = None if not params [ 'silent' ]: print ( \"Lomb-Scargle processed.\" ) return power , frequencies , significance # -------------------------------------- Wavelet ---------------------------------------- def getpowerWavelet ( signal , time , ** kwargs ): \"\"\" Perform wavelet analysis using the pycwt package. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. mother (str): The mother wavelet function to use. Default: 'morlet'. GWS (bool): If True, calculate the Global Wavelet Spectrum. Default: False. RGWS (bool): If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False. dj (float): Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025. s0 (float): Initial (smallest) scale of the wavelet. Default: 2 * dt. J (int): Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj. lag1 (float): Lag-1 autocorrelation. Default: 0.0. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: power: The wavelet power spectrum. periods: Corresponding periods. sig_slevel: The significance levels. coi: The cone of influence. Optionally, if global_power=True: global_power: Global wavelet power spectrum. global_conf: Confidence levels for the global wavelet spectrum. Optionally, if RGWS=True: rgws_periods: Periods for the refined global wavelet spectrum. rgws_power: Refined global wavelet power spectrum. \"\"\" # Define default values for the optional parameters similar to IDL defaults = { 'siglevel' : 0.95 , 'mother' : 'morlet' , # Morlet wavelet as the mother function 'dj' : 0.025 , # Scale spacing 's0' : - 1 , # Initial scale 'J' : - 1 , # Number of scales 'lag1' : 0.0 , # Lag-1 autocorrelation 'apod' : 0.1 , # Tukey window apodization 'silent' : False , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'GWS' : False , # If True, calculate global wavelet spectrum 'RGWS' : False , # If True, calculate refined global wavelet spectrum (excluding COI) 'nperm' : 1000 , # Number of permutations for significance calculation 'nodetrendapod' : False } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) else : apocube = signal n = len ( apocube ) dt = cadence # Standardize the signal before the wavelet transform std_signal = apocube . std () norm_signal = apocube / std_signal # Determine the initial scale s0 if not provided if params [ 's0' ] == - 1 : params [ 's0' ] = 2 * dt # Determine the number of scales J if not provided if params [ 'J' ] == - 1 : params [ 'J' ] = int (( np . log ( float ( n ) * dt / params [ 's0' ]) / np . log ( 2 )) / params [ 'dj' ]) # Perform wavelet transform W , scales , frequencies , coi , _ , _ = cwt ( norm_signal , dt , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], wavelet = params [ 'mother' ] ) power = np . abs ( W ) ** 2 # Wavelet power spectrum periods = 1 / frequencies # Convert frequencies to periods # Calculate the significance levels signif , _ = significance ( 1.0 , # Normalized variance dt , scales , 0 , # Ignored for now, used for background noise (e.g., red noise) params [ 'lag1' ], significance_level = params [ 'siglevel' ], wavelet = params [ 'mother' ] ) # Calculate the significance level for each power value sig_matrix = np . ones ([ len ( scales ), n ]) * signif [:, None ] sig_slevel = power / sig_matrix # Calculate global power if requested if params [ 'GWS' ]: global_power = np . mean ( power , axis = 1 ) # Average along the time axis dof = n - scales # the -scale corrects for padding at edges global_conf , _ = significance ( norm_signal , # time series data dt , # time step between values scales , # scale vector 1 , # sigtest = 1 for \"time-average\" test 0.0 , significance_level = params [ 'siglevel' ], dof = dof , wavelet = params [ 'mother' ] ) else : global_power = None global_conf = None # Calculate refined global wavelet spectrum (RGWS) if requested if params [ 'RGWS' ]: isig = sig_slevel < 1.0 power [ isig ] = np . nan ipower = np . full_like ( power , np . nan ) for i in range ( len ( coi )): pcol = power [:, i ] valid_idx = periods < coi [ i ] ipower [ valid_idx , i ] = pcol [ valid_idx ] rgws_power = np . nansum ( ipower , axis = 1 ) else : rgws_power = None if not params [ 'silent' ]: print ( \"Wavelet (\" + params [ 'mother' ] + \") processed.\" ) return power , periods , sig_slevel , coi , global_power , global_conf , rgws_power # -------------------------------------- Welch ---------------------------------------- def welch_psd ( signal , time , ** kwargs ): \"\"\" Calculate Welch Power Spectral Density (PSD) and significance levels. Parameters: signal (array): The 1D time series signal. time (array): The time array corresponding to the signal. nperseg (int, optional): Length of each segment for analysis. Default: 256. noverlap (int, optional): Number of points to overlap between segments. Default: 128. window (str, optional): Type of window function used in the Welch method. Default: 'hann'. siglevel (float, optional): Significance level for confidence intervals. Default: 0.95. nperm (int, optional): Number of permutations for significance testing. Default: 1000. silent (bool, optional): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: frequencies: Frequencies at which the PSD is estimated. psd: Power Spectral Density values. significance: Significance levels for the PSD. \"\"\" # Define default values for the optional parameters similar to FFT defaults = { 'siglevel' : 0.95 , 'nperm' : 1000 , # Number of permutations for significance calculation 'window' : 'hann' , # Window type for Welch method 'nperseg' : 256 , # Length of each segment 'silent' : False , 'noverlap' : 128 # Number of points to overlap between segments } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Calculate Welch PSD frequencies , psd = welch ( signal , fs = 1.0 / cadence , window = params [ 'window' ], nperseg = params [ 'nperseg' ], noverlap = params [ 'noverlap' ]) # Calculate significance levels using permutation ps_perm = np . zeros (( len ( frequencies ), params [ 'nperm' ])) for ip in range ( params [ 'nperm' ]): perm_signal = np . random . permutation ( signal ) # Permuting the original signal _ , perm_psd = welch ( perm_signal , fs = 1.0 / cadence , window = params [ 'window' ], nperseg = params [ 'nperseg' ], noverlap = params [ 'noverlap' ]) ps_perm [:, ip ] = perm_psd # Calculate significance level for Welch PSD significance = np . percentile ( ps_perm , params [ 'siglevel' ] * 100 , axis = 1 ) if not params [ 'silent' ]: print ( \"Welch processed.\" ) return psd , frequencies , significance # -------------------------------------- EMD / EEMD ---------------------------------------- import numpy as np # type: ignore from .PyEMD import EMD , EEMD # type: ignore from scipy.stats import norm # type: ignore from scipy.signal import hilbert , welch # type: ignore from scipy.signal import find_peaks # type: ignore from scipy.fft import fft , fftfreq # type: ignore # Function to apply EMD and return Intrinsic Mode Functions (IMFs) def apply_emd ( signal , time ): emd = EMD () emd . FIXE_H = 5 imfs = emd . emd ( signal , time ) # max_imfs=7, emd.FIXE_H = 10 return imfs # Function to apply EEMD and return Intrinsic Mode Functions (IMFs) def apply_eemd ( signal , time , noise_std = 0.2 , num_realizations = 1000 ): eemd = EEMD () eemd . FIXE_H = 5 eemd . noise_seed ( 12345 ) eemd . noise_width = noise_std eemd . ensemble_size = num_realizations imfs = eemd . eemd ( signal , time ) return imfs # Function to generate white noise IMFs for significance testing def generate_white_noise_imfs ( signal_length , time , num_realizations , use_eemd = None , noise_std = 0.2 ): white_noise_imfs = [] if use_eemd : eemd = EEMD () eemd . FIXE_H = 5 eemd . noise_seed ( 12345 ) eemd . noise_width = noise_std eemd . ensemble_size = num_realizations for _ in range ( num_realizations ): white_noise = np . random . normal ( size = signal_length ) imfs = eemd . eemd ( white_noise , time ) white_noise_imfs . append ( imfs ) else : emd = EMD () emd . FIXE_H = 5 for _ in range ( num_realizations ): white_noise = np . random . normal ( size = signal_length ) imfs = emd . emd ( white_noise , time ) white_noise_imfs . append ( imfs ) return white_noise_imfs # Function to calculate the energy of each IMF def calculate_imf_energy ( imfs ): return [ np . sum ( imf ** 2 ) for imf in imfs ] # Function to determine the significance of the IMFs def test_imf_significance ( imfs , white_noise_imfs ): imf_energies = calculate_imf_energy ( imfs ) num_imfs = len ( imfs ) white_noise_energies = [ calculate_imf_energy ( imf_set ) for imf_set in white_noise_imfs ] significance_levels = [] for i in range ( num_imfs ): # Collect the i-th IMF energy from each white noise realization white_noise_energy_dist = [ imf_energies [ i ] for imf_energies in white_noise_energies if i < len ( imf_energies )] mean_energy = np . mean ( white_noise_energy_dist ) std_energy = np . std ( white_noise_energy_dist ) z_score = ( imf_energies [ i ] - mean_energy ) / std_energy significance_level = 1 - norm . cdf ( z_score ) significance_levels . append ( significance_level ) return significance_levels # Function to compute instantaneous frequency of IMFs using Hilbert transform def compute_instantaneous_frequency ( imfs , time ): instantaneous_frequencies = [] for imf in imfs : analytic_signal = hilbert ( imf ) instantaneous_phase = np . unwrap ( np . angle ( analytic_signal )) instantaneous_frequency = np . diff ( instantaneous_phase ) / ( 2.0 * np . pi * np . diff ( time )) instantaneous_frequency = np . abs ( instantaneous_frequency ) # Ensure frequencies are positive instantaneous_frequencies . append ( instantaneous_frequency ) return instantaneous_frequencies # Function to compute HHT power spectrum def compute_hht_power_spectrum ( imfs , instantaneous_frequencies , freq_bins ): power_spectrum = np . zeros_like ( freq_bins ) for i in range ( len ( imfs )): amplitude = np . abs ( hilbert ( imfs [ i ])) power = amplitude ** 2 for j in range ( len ( instantaneous_frequencies [ i ])): freq_idx = np . searchsorted ( freq_bins , instantaneous_frequencies [ i ][ j ]) if freq_idx < len ( freq_bins ): power_spectrum [ freq_idx ] += power [ j ] return power_spectrum # Function to compute significance level for HHT power spectrum def compute_significance_level ( white_noise_imfs , freq_bins , time ): all_power_spectra = [] for imfs in white_noise_imfs : instantaneous_frequencies = compute_instantaneous_frequency ( imfs , time ) power_spectrum = compute_hht_power_spectrum ( imfs , instantaneous_frequencies , freq_bins ) all_power_spectra . append ( power_spectrum ) # Compute the 95th percentile power spectrum as the significance level significance_level = np . percentile ( all_power_spectra , 95 , axis = 0 ) return significance_level ## Custom rounding function def custom_round ( freq ): if freq < 1 : return round ( freq , 1 ) else : return round ( freq ) def smooth_power_spectrum ( power_spectrum , window_size = 5 ): return np . convolve ( power_spectrum , np . ones ( window_size ) / window_size , mode = 'same' ) # Function to identify and print significant peaks def identify_significant_peaks ( freq_bins , power_spectrum , significance_level ): peaks , _ = find_peaks ( power_spectrum , height = significance_level ) significant_frequencies = freq_bins [ peaks ] rounded_frequencies = [ custom_round ( freq ) for freq in significant_frequencies ] rounded_frequencies_two = [ round ( freq , 1 ) for freq in significant_frequencies ] print ( \"Significant Frequencies (Hz):\" , rounded_frequencies_two ) print ( \"Significant Frequencies (Hz):\" , rounded_frequencies ) return significant_frequencies # Function to generate randomized signals def generate_randomized_signals ( signal , num_realizations ): randomized_signals = [] for _ in range ( num_realizations ): randomized_signal = np . random . permutation ( signal ) randomized_signals . append ( randomized_signal ) return randomized_signals # Function to calculate the FFT power spectrum for each IMF def calculate_fft_psd_spectra ( imfs , time ): psd_spectra = [] for imf in imfs : N = len ( imf ) T = time [ 1 ] - time [ 0 ] # Assuming uniform sampling yf = fft ( imf ) xf = fftfreq ( N , T )[: N // 2 ] psd = ( 2.0 / N ) * ( np . abs ( yf [: N // 2 ]) ** 2 ) / ( N * T ) psd_spectra . append (( xf , psd )) return psd_spectra # Function to calculate the FFT power spectrum for randomized signals def calculate_fft_psd_spectra_randomized ( imfs , time , num_realizations ): all_psd_spectra = [] for imf in imfs : randomized_signals = generate_randomized_signals ( imf , num_realizations ) for signal in randomized_signals : N = len ( signal ) T = time [ 1 ] - time [ 0 ] # Assuming uniform sampling yf = fft ( signal ) psd = ( 2.0 / N ) * ( np . abs ( yf [: N // 2 ]) ** 2 ) / ( N * T ) all_psd_spectra . append ( psd ) return np . array ( all_psd_spectra ) # Function to calculate the 95th percentile confidence level def calculate_confidence_level ( imfs , time , num_realizations ): confidence_levels = [] for imf in imfs : all_psd_spectra = calculate_fft_psd_spectra_randomized ([ imf ], time , num_realizations ) confidence_level = np . percentile ( all_psd_spectra , 95 , axis = 0 ) confidence_levels . append ( confidence_level ) return confidence_levels # Function to calculate the Welch PSD for each IMF def calculate_welch_psd_spectra ( imfs , fs ): psd_spectra = [] for imf in imfs : f , psd = welch ( imf , fs = fs ) psd_spectra . append (( f , psd )) return psd_spectra # Function to calculate the Welch PSD for randomized signals def calculate_welch_psd_spectra_randomized ( imfs , fs , num_realizations ): all_psd_spectra = [] for imf in imfs : randomized_signals = generate_randomized_signals ( imf , num_realizations ) for signal in randomized_signals : f , psd = welch ( signal , fs = fs ) all_psd_spectra . append ( psd ) return np . array ( all_psd_spectra ) # Function to calculate the 95th percentile confidence level def calculate_confidence_level_welch ( imfs , fs , num_realizations ): confidence_levels = [] for imf in imfs : all_psd_spectra = calculate_welch_psd_spectra_randomized ([ imf ], fs , num_realizations ) confidence_level = np . percentile ( all_psd_spectra , 95 , axis = 0 ) confidence_levels . append ( confidence_level ) return confidence_levels # ************** Main EMD/EEMD routine ************** def getEMD_HHT ( signal , time , ** kwargs ): \"\"\" Calculate EMD/EEMD and HHT Parameters: signal (array): The input signal (1D). time (array): The time array of the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. EEMD (bool): If True, use Ensemble Empirical Mode Decomposition (EEMD) instead of Empirical Mode Decomposition (EMD). Default: False. Welch_psd (bool): If True, calculate Welch PSD spectra instead of FFT PSD spectra (for the psd_spectra and psd_confidence_levels). Default: False. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: frequencies: Frequencies at which the PSD is estimated. psd: Power Spectral Density values. significance: Significance levels for the PSD. \u2018marginal\u2019 spectrum of Hilbert-Huang Transform (HHT) \"\"\" # Define default values for the optional parameters similar to FFT defaults = { 'siglevel' : 0.95 , 'nperm' : 1000 , # Number of permutations for significance calculation 'apod' : 0.1 , # Tukey window apodization 'silent' : False , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'EEMD' : False , # If True, calculate Ensemble Empirical Mode Decomposition (EEMD) 'nodetrendapod' : False , 'Welch_psd' : False , # If True, calculate Welch PSD spectra 'significant_imfs' : False # If True, return only significant IMFs (and for associated calculations) } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) n = len ( apocube ) dt = cadence fs = 1 / dt # Sampling frequency if params [ 'EEMD' ]: imfs = apply_eemd ( signal , time ) use_eemd = True else : imfs = apply_emd ( signal , time ) use_eemd = False white_noise_imfs = generate_white_noise_imfs ( len ( signal ), time , params [ 'nperm' ], use_eemd = use_eemd ) IMF_significance_levels = test_imf_significance ( imfs , white_noise_imfs ) # Determine significant IMFs significant_imfs_val = [ imf for imf , sig_level in zip ( imfs , IMF_significance_levels ) if sig_level < params [ 'siglevel' ]] if params [ 'significant_imfs' ]: imfs = significant_imfs_val # Compute instantaneous frequencies of IMFs instantaneous_frequencies = compute_instantaneous_frequency ( imfs , time ) if params [ 'Welch_psd' ]: # Calculate and plot Welch PSD spectra of (significant) IMFs psd_spectra = calculate_welch_psd_spectra ( imfs , fs ) # Calculate 95th percentile confidence levels for Welch PSD spectra psd_confidence_levels = calculate_confidence_level_welch ( imfs , fs , params [ 'nperm' ]) else : # Calculate and plot FFT PSD spectra of (significant) IMFs psd_spectra = calculate_fft_psd_spectra ( imfs , time ) # Calculate 95th percentile confidence levels for FFT PSD spectra psd_confidence_levels = calculate_confidence_level ( imfs , time , params [ 'nperm' ]) # Define frequency bins for HHT power spectrum max_freq = max ([ freq . max () for freq in instantaneous_frequencies ]) HHT_freq_bins = np . linspace ( 0 , max_freq , 100 ) # Compute HHT power spectrum of (significant) IMFs HHT_power_spectrum = compute_hht_power_spectrum ( imfs , instantaneous_frequencies , HHT_freq_bins ) # Compute significance level for HHT power spectrum HHT_significance_level = compute_significance_level ( white_noise_imfs , HHT_freq_bins , time ) if not params [ 'silent' ]: if params [ 'EEMD' ]: print ( \"EEMD processed.\" ) else : print ( \"EMD processed.\" ) return HHT_power_spectrum , HHT_significance_level , HHT_freq_bins , psd_spectra , psd_confidence_levels , imfs , IMF_significance_levels , instantaneous_frequencies # ----------------------- Dominant Frequency & Averaged Power ------------------------------- def get_dominant_averaged ( cube , time , ** kwargs ): \"\"\" Analyze a 3D data cube to compute the dominant frequency and averaged power. Parameters: cube (3D array): Input data cube, expected in either 'txy' or 'xyt' format. time (array): Time array of the data cube. method (str): Analysis method ('fft' or 'wavelet'). format (str): Format of the data cube ('txy' or 'xyt'). Default is 'txy'. **kwargs: Additional parameters specific to the analysis method. Returns: dominantfreq (float): Dominant frequency of the data cube. averagedpower (float): Averaged power of the data cube. \"\"\" defaults = { 'method' : 'fft' , 'format' : 'txy' , 'silent' : False , 'GWS' : False , # If True, calculate global wavelet spectrum 'RGWS' : True , # If True, calculate refined global wavelet spectrum } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } # Check and adjust format if necessary if params [ 'format' ] == 'xyt' : cube = np . transpose ( cube , ( 2 , 0 , 1 )) # Convert 'xyt' to 'txy' elif params [ 'format' ] != 'txy' : raise ValueError ( \"Unsupported format. Choose 'txy' or 'xyt'.\" ) # Initialize arrays for storing results across spatial coordinates nt , nx , ny = cube . shape dominantfreq = np . zeros (( nx , ny )) if params [ 'method' ] == 'fft' : method_name = 'FFT' elif params [ 'method' ] == 'lombscargle' : method_name = 'Lomb-Scargle' elif params [ 'method' ] == 'wavelet' : method_name = 'Wavelet' elif params [ 'method' ] == 'welch' : method_name = 'Welch' if not params [ 'silent' ]: print ( f \"Processing { method_name } for a 3D cube with format ' { params [ 'format' ] } ' and shape { cube . shape } .\" ) print ( f \"Calculating Dominant frequencies and/or averaged power spectrum ( { method_name } ) ....\" ) # Iterate over spatial coordinates and apply the chosen analysis method if params [ 'method' ] == 'fft' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] fft_power , fft_freqs , _ , _ = getpowerFFT ( signal , time , silent = True , nosignificance = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( fft_freqs ))) powermap [ x , y , :] = fft_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = fft_freqs [ np . argmax ( fft_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = fft_freqs print ( \" \\n Analysis completed.\" ) elif params [ 'method' ] == 'lombscargle' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] ls_power , ls_freqs , _ = getpowerLS ( signal , time , silent = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( ls_freqs ))) powermap [ x , y , :] = ls_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = ls_freqs [ np . argmax ( ls_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = ls_freqs print ( \" \\n Analysis completed.\" ) elif params [ 'method' ] == 'wavelet' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] if params [ 'GWS' ]: _ , wavelet_periods , _ , _ , wavelet_power , _ , _ = getpowerWavelet ( signal , time , silent = True , ** kwargs ) elif params [ 'RGWS' ]: _ , wavelet_periods , _ , _ , _ , _ , wavelet_power = getpowerWavelet ( signal , time , silent = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( wavelet_periods ))) wavelet_freq = 1. / wavelet_periods powermap [ x , y , :] = wavelet_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = wavelet_freq [ np . argmax ( wavelet_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = wavelet_freq print ( \" \\n Analysis completed.\" ) elif params [ 'method' ] == 'welch' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] welch_power , welch_freqs , _ = welch_psd ( signal , time , silent = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( welch_freqs ))) powermap [ x , y , :] = welch_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = welch_freqs [ np . argmax ( welch_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = welch_freqs print ( \" \\n Analysis completed.\" ) else : raise ValueError ( \"Unsupported method. Choose 'fft', 'lombscargle', 'wavelet', or 'welch'.\" ) return dominantfreq , averagedpower , frequencies , powermap WaLSA_wavelet.py This module implements the Wavelet Transform and related functionalities. WaLSA_wavelet.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools: - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- # The following code is a modified version of the PyCWT package. # The original code and licence: # PyCWT is released under the open source 3-Clause BSD license: # # Copyright (c) 2023 Sebastian Krieger, Nabil Freij, and contributors. All rights # reserved. # # Redistribution and use in source and binary forms, with or without # modification, are permitted provided that the following conditions are met: # # 1. Redistributions of source code must retain the above copyright notice, this # list of conditions and the following disclaimer. # # 2. Redistributions in binary form must reproduce the above copyright notice, # this list of conditions and the following disclaimer in the documentation # and/or other materials provided with the distribution. # # 3. Neither the name of the copyright holder nor the names of its contributors # may be used to endorse or promote products derived from this software # without specific prior written permission. # # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND # ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED # WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE # DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE # FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL # DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR # SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER # CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, # OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. # #---------------------------------------------------------------------------------- # Modifications by Shahin Jafarzadeh, 2024 #---------------------------------------------------------------------------------- from __future__ import ( absolute_import , division , print_function , unicode_literals ) import numpy as np # type: ignore from tqdm import tqdm # type: ignore from scipy.stats import chi2 # type: ignore # Try to import the Python wrapper for FFTW. try : import pyfftw.interfaces.scipy_fftpack as fft # type: ignore from multiprocessing import cpu_count # Fast planning, use all available threads. _FFTW_KWARGS_DEFAULT = { 'planner_effort' : 'FFTW_ESTIMATE' , 'threads' : cpu_count ()} def fft_kwargs ( signal , ** kwargs ): \"\"\"Return optimized keyword arguments for FFTW\"\"\" kwargs . update ( _FFTW_KWARGS_DEFAULT ) kwargs [ 'n' ] = len ( signal ) # do not pad return kwargs # Otherwise, fall back to 2 ** n padded scipy FFTPACK except ImportError : import scipy.fftpack as fft # type: ignore # Can be turned off, e.g. for MKL optimizations _FFT_NEXT_POW2 = True def fft_kwargs ( signal , ** kwargs ): \"\"\"Return next higher power of 2 for given signal to speed up FFT\"\"\" if _FFT_NEXT_POW2 : return { 'n' : int ( 2 ** np . ceil ( np . log2 ( len ( signal ))))} from scipy.signal import lfilter # type: ignore from os import makedirs from os.path import exists , expanduser def find ( condition ): \"\"\"Returns the indices where ravel(condition) is true.\"\"\" res , = np . nonzero ( np . ravel ( condition )) return res def ar1 ( x ): \"\"\" Allen and Smith autoregressive lag-1 autocorrelation coefficient. In an AR(1) model x(t) - <x> = gamma(x(t-1) - <x>) + \\alpha z(t) , where <x> is the process mean, gamma and \\alpha are process parameters and z(t) is a Gaussian unit-variance white noise. Parameters ---------- x : numpy.ndarray, list Univariate time series Returns ------- g : float Estimate of the lag-one autocorrelation. a : float Estimate of the noise variance [var(x) ~= a**2/(1-g**2)] mu2 : float Estimated square on the mean of a finite segment of AR(1) noise, mormalized by the process variance. References ---------- [1] Allen, M. R. and Smith, L. A. Monte Carlo SSA: detecting irregular oscillations in the presence of colored noise. *Journal of Climate*, **1996**, 9(12), 3373-3404. <http://dx.doi.org/10.1175/1520-0442(1996)009<3373:MCSDIO>2.0.CO;2> [2] http://www.madsci.org/posts/archives/may97/864012045.Eg.r.html \"\"\" x = np . asarray ( x ) N = x . size xm = x . mean () x = x - xm # Estimates the lag zero and one covariance c0 = x . transpose () . dot ( x ) / N c1 = x [ 0 : N - 1 ] . transpose () . dot ( x [ 1 : N ]) / ( N - 1 ) # According to A. Grinsteds' substitutions B = - c1 * N - c0 * N ** 2 - 2 * c0 + 2 * c1 - c1 * N ** 2 + c0 * N A = c0 * N ** 2 C = N * ( c0 + c1 * N - c1 ) D = B ** 2 - 4 * A * C if D > 0 : g = ( - B - D ** 0.5 ) / ( 2 * A ) else : raise Warning ( 'Cannot place an upperbound on the unbiased AR(1). ' 'Series is too short or trend is to large.' ) # According to Allen & Smith (1996), footnote 4 mu2 = - 1 / N + ( 2 / N ** 2 ) * (( N - g ** N ) / ( 1 - g ) - g * ( 1 - g ** ( N - 1 )) / ( 1 - g ) ** 2 ) c0t = c0 / ( 1 - mu2 ) a = (( 1 - g ** 2 ) * c0t ) ** 0.5 return g , a , mu2 def ar1_spectrum ( freqs , ar1 = 0. ): \"\"\" Lag-1 autoregressive theoretical power spectrum. Parameters ---------- freqs : numpy.ndarray, list Frequencies at which to calculate the theoretical power spectrum. ar1 : float Autoregressive lag-1 correlation coefficient. Returns ------- Pk : numpy.ndarray Theoretical discrete Fourier power spectrum of noise signal. References ---------- [1] http://www.madsci.org/posts/archives/may97/864012045.Eg.r.html \"\"\" # According to a post from the MadSci Network available at # http://www.madsci.org/posts/archives/may97/864012045.Eg.r.html, # the time-series spectrum for an auto-regressive model can be # represented as # # P_k = \\frac{E}{\\left|1- \\sum\\limits_{k=1}^{K} a_k \\, e^{2 i \\pi # \\frac{k f}{f_s} } \\right|^2} # # which for an AR1 model reduces to # freqs = np . asarray ( freqs ) Pk = ( 1 - ar1 ** 2 ) / np . abs ( 1 - ar1 * np . exp ( - 2 * np . pi * 1 j * freqs )) \\ ** 2 return Pk def rednoise ( N , g , a = 1. ): \"\"\" Red noise generator using filter. Parameters ---------- N : int Length of the desired time series. g : float Lag-1 autocorrelation coefficient. a : float, optional Noise innovation variance parameter. Returns ------- y : numpy.ndarray Red noise time series. \"\"\" if g == 0 : yr = np . randn ( N , 1 ) * a else : # Twice the decorrelation time. tau = int ( np . ceil ( - 2 / np . log ( np . abs ( g )))) yr = lfilter ([ 1 , 0 ], [ 1 , - g ], np . random . randn ( N + tau , 1 ) * a ) yr = yr [ tau :] return yr . flatten () def rect ( x , normalize = False ): \"\"\"TODO: describe what I do.\"\"\" if type ( x ) in [ int , float ]: shape = [ x , ] elif type ( x ) in [ list , dict ]: shape = x elif type ( x ) in [ np . ndarray , np . ma . core . MaskedArray ]: shape = x . shape X = np . zeros ( shape ) X [ 0 ] = X [ - 1 ] = 0.5 X [ 1 : - 1 ] = 1 if normalize : X /= X . sum () return X def boxpdf ( x ): \"\"\" Forces the probability density function of the input data to have a boxed distribution. Parameters ---------- x (array like) : Input data Returns ------- X (array like) : Boxed data varying between zero and one. Bx, By (array like) : Data lookup table. \"\"\" import numpy as np x = np . asarray ( x ) n = x . size # Kind of 'unique' i = np . argsort ( x ) d = ( np . diff ( x [ i ]) != 0 ) j = find ( np . concatenate ([ d , [ True ]])) X = x [ i ][ j ] j = np . concatenate ([[ 0 ], j + 1 ]) Y = 0.5 * ( j [ 0 : - 1 ] + j [ 1 :]) / n bX = np . interp ( x , X , Y ) return bX , X , Y def get_cache_dir (): \"\"\"Returns the location of the cache directory.\"\"\" # Sets cache directory according to user home path. cache_dir = ' {} /.cache/pycwt/' . format ( expanduser ( '~' )) # Creates cache directory if not existant. if not exists ( cache_dir ): makedirs ( cache_dir ) # Returns cache directory. return cache_dir import numpy as np from scipy.special import gamma from scipy.signal import convolve2d from scipy.special.orthogonal import hermitenorm class Morlet ( object ): \"\"\"Implements the Morlet wavelet class. Note that the input parameters f and f0 are angular frequencies. f0 should be more than 0.8 for this function to be correct, its default value is f0 = 6. \"\"\" def __init__ ( self , f0 = 6 ): self . _set_f0 ( f0 ) self . name = 'Morlet' def psi_ft ( self , f ): \"\"\"Fourier transform of the approximate Morlet wavelet.\"\"\" return ( np . pi ** - 0.25 ) * np . exp ( - 0.5 * ( f - self . f0 ) ** 2 ) def psi ( self , t ): \"\"\"Morlet wavelet as described in Torrence and Compo (1998).\"\"\" return ( np . pi ** - 0.25 ) * np . exp ( 1 j * self . f0 * t - t ** 2 / 2 ) def flambda ( self ): \"\"\"Fourier wavelength as of Torrence and Compo (1998).\"\"\" return ( 4 * np . pi ) / ( self . f0 + np . sqrt ( 2 + self . f0 ** 2 )) def coi ( self ): \"\"\"e-Folding Time as of Torrence and Compo (1998).\"\"\" return 1. / np . sqrt ( 2 ) def sup ( self ): \"\"\"Wavelet support defined by the e-Folding time.\"\"\" return 1. / self . coi def _set_f0 ( self , f0 ): # Sets the Morlet wave number, the degrees of freedom and the # empirically derived factors for the wavelet bases C_{\\delta}, # gamma, \\delta j_0 (Torrence and Compo, 1998, Table 2) self . f0 = f0 # Wave number self . dofmin = 2 # Minimum degrees of freedom if self . f0 == 6 : self . cdelta = 0.776 # Reconstruction factor self . gamma = 2.32 # Decorrelation factor for time averaging self . deltaj0 = 0.60 # Factor for scale averaging else : self . cdelta = - 1 self . gamma = - 1 self . deltaj0 = - 1 def smooth ( self , W , dt , dj , scales ): \"\"\"Smoothing function used in coherence analysis. Parameters ---------- W : dt : dj : scales : Returns ------- T : \"\"\" # The smoothing is performed by using a filter given by the absolute # value of the wavelet function at each scale, normalized to have a # total weight of unity, according to suggestions by Torrence & # Webster (1999) and by Grinsted et al. (2004). m , n = W . shape # Filter in time. k = 2 * np . pi * fft . fftfreq ( fft_kwargs ( W [ 0 , :])[ 'n' ]) k2 = k ** 2 snorm = scales / dt # Smoothing by Gaussian window (absolute value of wavelet function) # using the convolution theorem: multiplication by Gaussian curve in # Fourier domain for each scale, outer product of scale and frequency F = np . exp ( - 0.5 * ( snorm [:, np . newaxis ] ** 2 ) * k2 ) # Outer product smooth = fft . ifft ( F * fft . fft ( W , axis = 1 , ** fft_kwargs ( W [ 0 , :])), axis = 1 , # Along Fourier frequencies ** fft_kwargs ( W [ 0 , :], overwrite_x = True )) T = smooth [:, : n ] # Remove possibly padded region due to FFT if np . isreal ( W ) . all (): T = T . real # Filter in scale. For the Morlet wavelet it's simply a boxcar with # 0.6 width. wsize = self . deltaj0 / dj * 2 win = rect ( int ( np . round ( wsize )), normalize = True ) T = convolve2d ( T , win [:, np . newaxis ], 'same' ) # Scales are \"vertical\" return T class Paul ( object ): \"\"\"Implements the Paul wavelet class. Note that the input parameter f is the angular frequency and that the default order for this wavelet is m=4. \"\"\" def __init__ ( self , m = 4 ): self . _set_m ( m ) self . name = 'Paul' # def psi_ft(self, f): # \"\"\"Fourier transform of the Paul wavelet.\"\"\" # return (2 ** self.m / # np.sqrt(self.m * np.prod(range(2, 2 * self.m))) * # f ** self.m * np.exp(-f) * (f > 0)) def psi_ft ( self , f ): # modified by SJ \"\"\"Fourier transform of the Paul wavelet with limits to prevent underflow.\"\"\" expnt = - f expnt [ expnt < - 100 ] = - 100 # Apply the threshold to avoid extreme values return ( 2 ** self . m / np . sqrt ( self . m * np . prod ( range ( 2 , 2 * self . m ))) * f ** self . m * np . exp ( expnt ) * ( f > 0 )) def psi ( self , t ): \"\"\"Paul wavelet as described in Torrence and Compo (1998).\"\"\" return ( 2 ** self . m * 1 j ** self . m * np . prod ( range ( 2 , self . m - 1 )) / np . sqrt ( np . pi * np . prod ( range ( 2 , 2 * self . m + 1 ))) * ( 1 - 1 j * t ) ** ( - ( self . m + 1 ))) def flambda ( self ): \"\"\"Fourier wavelength as of Torrence and Compo (1998).\"\"\" return 4 * np . pi / ( 2 * self . m + 1 ) def coi ( self ): \"\"\"e-Folding Time as of Torrence and Compo (1998).\"\"\" return np . sqrt ( 2 ) def sup ( self ): \"\"\"Wavelet support defined by the e-Folding time.\"\"\" return 1 / self . coi def _set_m ( self , m ): # Sets the m derivative of a Gaussian, the degrees of freedom and the # empirically derived factors for the wavelet bases C_{\\delta}, # gamma, \\delta j_0 (Torrence and Compo, 1998, Table 2) self . m = m # Wavelet order self . dofmin = 2 # Minimum degrees of freedom if self . m == 4 : self . cdelta = 1.132 # Reconstruction factor self . gamma = 1.17 # Decorrelation factor for time averaging self . deltaj0 = 1.50 # Factor for scale averaging else : self . cdelta = - 1 self . gamma = - 1 self . deltaj0 = - 1 class DOG ( object ): \"\"\"Implements the derivative of a Guassian wavelet class. Note that the input parameter f is the angular frequency and that for m=2 the DOG becomes the Mexican hat wavelet, which is then default. \"\"\" def __init__ ( self , m = 2 ): self . _set_m ( m ) self . name = 'DOG' def psi_ft ( self , f ): \"\"\"Fourier transform of the DOG wavelet.\"\"\" return ( - 1 j ** self . m / np . sqrt ( gamma ( self . m + 0.5 )) * f ** self . m * np . exp ( - 0.5 * f ** 2 )) def psi ( self , t ): \"\"\"DOG wavelet as described in Torrence and Compo (1998). The derivative of a Gaussian of order `n` can be determined using the probabilistic Hermite polynomials. They are explicitly written as: Hn(x) = 2 ** (-n / s) * n! * sum ((-1) ** m) * (2 ** 0.5 * x) ** (n - 2 * m) / (m! * (n - 2*m)!) or in the recursive form: Hn(x) = x * Hn(x) - nHn-1(x) Source: http://www.ask.com/wiki/Hermite_polynomials \"\"\" p = hermitenorm ( self . m ) return (( - 1 ) ** ( self . m + 1 ) * np . polyval ( p , t ) * np . exp ( - t ** 2 / 2 ) / np . sqrt ( gamma ( self . m + 0.5 ))) def flambda ( self ): \"\"\"Fourier wavelength as of Torrence and Compo (1998).\"\"\" return ( 2 * np . pi / np . sqrt ( self . m + 0.5 )) def coi ( self ): \"\"\"e-Folding Time as of Torrence and Compo (1998).\"\"\" return 1 / np . sqrt ( 2 ) def sup ( self ): \"\"\"Wavelet support defined by the e-Folding time.\"\"\" return 1 / self . coi def _set_m ( self , m ): # Sets the m derivative of a Gaussian, the degrees of freedom and the # empirically derived factors for the wavelet bases C_{\\delta}, # gamma, \\delta j_0 (Torrence and Compo, 1998, Table 2). self . m = m # m-derivative self . dofmin = 1 # Minimum degrees of freedom if self . m == 2 : self . cdelta = 3.541 # Reconstruction factor self . gamma = 1.43 # Decorrelation factor for time averaging self . deltaj0 = 1.40 # Factor for scale averaging elif self . m == 6 : self . cdelta = 1.966 self . gamma = 1.37 self . deltaj0 = 0.97 else : self . cdelta = - 1 self . gamma = - 1 self . deltaj0 = - 1 class MexicanHat ( DOG ): \"\"\"Implements the Mexican hat wavelet class. This class inherits the DOG class using m=2. \"\"\" def __init__ ( self ): self . name = 'Mexican Hat' self . _set_m ( 2 ) def cwt ( signal , dt , dj = 1 / 12 , s0 =- 1 , J =- 1 , wavelet = 'morlet' , freqs = None , pad = True ): \"\"\"Continuous wavelet transform of the signal at specified scales. Parameters ---------- signal : numpy.ndarray, list Input signal array. dt : float Sampling interval. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N * dt / so)) / dj. wavelet : instance of Wavelet class, or string Mother wavelet class. Default is Morlet wavelet. freqs : numpy.ndarray, optional Custom frequencies to use instead of the ones corresponding to the scales described above. Corresponding scales are calculated using the wavelet Fourier wavelength. pad : optional. Default is True. if set, then pad the time series with enough zeroes to get N up to the next higher power of 2. This prevents wraparound from the end of the time series to the beginning, and also speeds up the FFT's used to do the wavelet transform. This will not eliminate all edge effects. (added by SJ) Returns ------- W : numpy.ndarray Wavelet transform according to the selected mother wavelet. Has (J+1) x N dimensions. sj : numpy.ndarray Vector of scale indices given by sj = s0 * 2**(j * dj), j={0, 1, ..., J}. freqs : array like Vector of Fourier frequencies (in 1 / time units) that corresponds to the wavelet scales. coi : numpy.ndarray Returns the cone of influence, which is a vector of N points containing the maximum Fourier period of useful information at that particular time. Periods greater than those are subject to edge effects. fft : numpy.ndarray Normalized fast Fourier transform of the input signal. fftfreqs : numpy.ndarray Fourier frequencies (in 1/time units) for the calculated FFT spectrum. Example ------- >> mother = wavelet.Morlet(6.) >> wave, scales, freqs, coi, fft, fftfreqs = wavelet.cwt(signal, 0.25, 0.25, 0.5, 28, mother) \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) # Original signal length n0 = len ( signal ) # If no custom frequencies are set, then set default frequencies # according to input parameters `dj`, `s0` and `J`. Otherwise, set wavelet # scales according to Fourier equivalent frequencies. # Zero-padding if enabled (added + the entire code further modified by SJ) if pad : next_power_of_two = int ( 2 ** np . ceil ( np . log2 ( n0 ))) signal_padded = np . zeros ( next_power_of_two ) signal_padded [: n0 ] = signal - np . mean ( signal ) # Remove the mean and pad with zeros else : signal_padded = signal - np . mean ( signal ) # Remove the mean without padding N = len ( signal_padded ) # Length of the padded signal # Calculate scales and frequencies if not provided if freqs is None : # Smallest resolvable scale # if s0 == -1: # s0 = 2 * dt / wavelet.flambda() # # Number of scales # if J == -1: # J = int(np.round(np.log2(N * dt / s0) / dj)) if s0 == - 1 : s0 = 2 * dt if J == - 1 : J = int (( np . log ( float ( N ) * dt / s0 ) / np . log ( 2 )) / dj ) # The scales as of Mallat 1999 sj = s0 * 2 ** ( np . arange ( 0 , J + 1 ) * dj ) # Fourier equivalent frequencies freqs = 1 / ( wavelet . flambda () * sj ) else : # The wavelet scales using custom frequencies. sj = 1 / ( wavelet . flambda () * freqs ) # Fourier transform of the (padded) signal signal_ft = fft . fft ( signal_padded , ** fft_kwargs ( signal_padded )) # Fourier angular frequencies ftfreqs = 2 * np . pi * fft . fftfreq ( N , dt ) # Creates wavelet transform matrix as outer product of scaled transformed # wavelets and transformed signal according to the convolution theorem. # (i) Transform scales to column vector for outer product; # (ii) Calculate 2D matrix [s, f] for each scale s and Fourier angular # frequency f; # (iii) Calculate wavelet transform; sj_col = sj [:, np . newaxis ] psi_ft_bar = (( sj_col * ftfreqs [ 1 ] * N ) ** .5 * np . conjugate ( wavelet . psi_ft ( sj_col * ftfreqs ))) W = fft . ifft ( signal_ft * psi_ft_bar , axis = 1 , ** fft_kwargs ( signal_ft , overwrite_x = True )) # Trim the wavelet transform to original signal length if padded if pad : W = W [:, : n0 ] # Trim to the original signal length # Checks for NaN in transform results and removes them from the scales if # needed, frequencies and wavelet transform. Trims wavelet transform at # length `n0`. sel = np . invert ( np . isnan ( W ) . all ( axis = 1 )) if np . any ( sel ): sj = sj [ sel ] freqs = freqs [ sel ] W = W [ sel , :] # Determines the cone-of-influence. Note that it is returned as a function # of time in Fourier periods. Uses triangualr Bartlett window with # non-zero end-points. coi = ( n0 / 2 - np . abs ( np . arange ( 0 , n0 ) - ( n0 - 1 ) / 2 )) coi = wavelet . flambda () * wavelet . coi () * dt * coi return ( W [:, : n0 ], sj , freqs , coi , signal_ft [ 1 : N // 2 ] / N ** 0.5 , ftfreqs [ 1 : N // 2 ] / ( 2 * np . pi )) def icwt ( W , sj , dt , dj = 1 / 12 , wavelet = 'morlet' ): \"\"\"Inverse continuous wavelet transform. Parameters ---------- W : numpy.ndarray Wavelet transform, the result of the `cwt` function. sj : numpy.ndarray Vector of scale indices as returned by the `cwt` function. dt : float Sample spacing. dj : float, optional Spacing between discrete scales as used in the `cwt` function. Default value is 0.25. wavelet : instance of Wavelet class, or string Mother wavelet class. Default is Morlet Returns ------- iW : numpy.ndarray Inverse wavelet transform. Example ------- >> mother = wavelet.Morlet() >> wave, scales, freqs, coi, fft, fftfreqs = wavelet.cwt(var, 0.25, 0.25, 0.5, 28, mother) >> iwave = wavelet.icwt(wave, scales, 0.25, 0.25, mother) \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) a , b = W . shape c = sj . size if a == c : sj = ( np . ones ([ b , 1 ]) * sj ) . transpose () elif b == c : sj = np . ones ([ a , 1 ]) * sj else : raise Warning ( 'Input array dimensions do not match.' ) # As of Torrence and Compo (1998), eq. (11) iW = ( dj * np . sqrt ( dt ) / ( wavelet . cdelta * wavelet . psi ( 0 )) * ( np . real ( W ) / np . sqrt ( sj )) . sum ( axis = 0 )) return iW def significance ( signal , dt , scales , sigma_test = 0 , alpha = None , significance_level = 0.95 , dof =- 1 , wavelet = 'morlet' ): \"\"\"Significance test for the one dimensional wavelet transform. Parameters ---------- signal : array like, float Input signal array. If a float number is given, then the variance is assumed to have this value. If an array is given, then its variance is automatically computed. dt : float Sample spacing. scales : array like Vector of scale indices given returned by `cwt` function. sigma_test : int, optional Sets the type of significance test to be performed. Accepted values are 0 (default), 1 or 2. See notes below for further details. alpha : float, optional Lag-1 autocorrelation, used for the significance levels. Default is 0.0. significance_level : float, optional Significance level to use. Default is 0.95. dof : variant, optional Degrees of freedom for significance test to be set according to the type set in sigma_test. wavelet : instance of Wavelet class, or string Mother wavelet class. Default is Morlet Returns ------- signif : array like Significance levels as a function of scale. fft_theor (array like): Theoretical red-noise spectrum as a function of period. Notes ----- If sigma_test is set to 0, performs a regular chi-square test, according to Torrence and Compo (1998) equation 18. If set to 1, performs a time-average test (equation 23). In this case, dof should be set to the number of local wavelet spectra that where averaged together. For the global wavelet spectra it would be dof=N, the number of points in the time-series. If set to 2, performs a scale-average test (equations 25 to 28). In this case dof should be set to a two element vector [s1, s2], which gives the scale range that were averaged together. If, for example, the average between scales 2 and 8 was taken, then dof=[2, 8]. \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) try : n0 = len ( signal ) except TypeError : n0 = 1 J = len ( scales ) - 1 dj = np . log2 ( scales [ 1 ] / scales [ 0 ]) if n0 == 1 : variance = signal else : variance = signal . std () ** 2 if alpha is None : alpha , _ , _ = ar1 ( signal ) period = scales * wavelet . flambda () # Fourier equivalent periods freq = dt / period # Normalized frequency dofmin = wavelet . dofmin # Degrees of freedom with no smoothing Cdelta = wavelet . cdelta # Reconstruction factor gamma_fac = wavelet . gamma # Time-decorrelation factor dj0 = wavelet . deltaj0 # Scale-decorrelation factor # Theoretical discrete Fourier power spectrum of the noise signal # following Gilman et al. (1963) and Torrence and Compo (1998), # equation 16. def pk ( k , a , N ): return ( 1 - a ** 2 ) / ( 1 + a ** 2 - 2 * a * np . cos ( 2 * np . pi * k / N )) fft_theor = pk ( freq , alpha , n0 ) fft_theor = variance * fft_theor # Including time-series variance signif = fft_theor try : if dof == - 1 : dof = dofmin except ValueError : pass if sigma_test == 0 : # No smoothing, dof=dofmin, TC98 sec. 4 dof = dofmin # As in Torrence and Compo (1998), equation 18. chisquare = chi2 . ppf ( significance_level , dof ) / dof signif = fft_theor * chisquare elif sigma_test == 1 : # Time-averaged significance if len ( dof ) == 1 : dof = np . zeros ( 1 , J + 1 ) + dof sel = find ( dof < 1 ) dof [ sel ] = 1 # As in Torrence and Compo (1998), equation 23: dof = dofmin * ( 1 + ( dof * dt / gamma_fac / scales ) ** 2 ) ** 0.5 sel = find ( dof < dofmin ) dof [ sel ] = dofmin # Minimum dof is dofmin for n , d in enumerate ( dof ): chisquare = chi2 . ppf ( significance_level , d ) / d signif [ n ] = fft_theor [ n ] * chisquare elif sigma_test == 2 : # Time-averaged significance if len ( dof ) != 2 : raise Exception ( 'DOF must be set to [s1, s2], ' 'the range of scale-averages' ) if Cdelta == - 1 : raise ValueError ( 'Cdelta and dj0 not defined ' 'for {} with f0= {} ' . format ( wavelet . name , wavelet . f0 )) s1 , s2 = dof sel = find (( scales >= s1 ) & ( scales <= s2 )) navg = sel . size if navg == 0 : raise ValueError ( 'No valid scales between {} and {} .' . format ( s1 , s2 )) # As in Torrence and Compo (1998), equation 25. Savg = 1 / sum ( 1. / scales [ sel ]) # Power-of-two mid point: Smid = np . exp (( np . log ( s1 ) + np . log ( s2 )) / 2. ) # As in Torrence and Compo (1998), equation 28. dof = ( dofmin * navg * Savg / Smid ) * \\ (( 1 + ( navg * dj / dj0 ) ** 2 ) ** 0.5 ) # As in Torrence and Compo (1998), equation 27. fft_theor = Savg * sum ( fft_theor [ sel ] / scales [ sel ]) chisquare = chi2 . ppf ( significance_level , dof ) / dof # As in Torrence and Compo (1998), equation 26. signif = ( dj * dt / Cdelta / Savg ) * fft_theor * chisquare else : raise ValueError ( 'sigma_test must be either 0, 1, or 2.' ) return signif , fft_theor def xwt ( y1 , y2 , dt , dj = 1 / 12 , s0 =- 1 , J =- 1 , significance_level = 0.95 , wavelet = 'morlet' , normalize = False , no_default_signif = False ): \"\"\"Cross wavelet transform (XWT) of two signals. The XWT finds regions in time frequency space where the time series show high common power. Parameters ---------- y1, y2 : numpy.ndarray, list Input signal array to calculate cross wavelet transform. dt : float Sample spacing. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N*dt/so))/dj. wavelet : instance of a wavelet class, optional Mother wavelet class. Default is Morlet wavelet. significance_level : float, optional Significance level to use. Default is 0.95. normalize : bool, optional If set to true, normalizes CWT by the standard deviation of the signals. Returns ------- xwt (array like): Cross wavelet transform according to the selected mother wavelet. x (array like): Intersected independent variable. coi (array like): Cone of influence, which is a vector of N points containing the maximum Fourier period of useful information at that particular time. Periods greater than those are subject to edge effects. freqs (array like): Vector of Fourier equivalent frequencies (in 1 / time units) that correspond to the wavelet scales. signif (array like): Significance levels as a function of scale. Notes ----- Torrence and Compo (1998) state that the percent point function (PPF) -- inverse of the cumulative distribution function -- of a chi-square distribution at 95% confidence and two degrees of freedom is Z2(95%)=3.999. However, calculating the PPF using chi2.ppf gives Z2(95%)=5.991. To ensure similar significance intervals as in Grinsted et al. (2004), one has to use confidence of 86.46%. \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) # Makes sure input signal are numpy arrays. y1 = np . asarray ( y1 ) y2 = np . asarray ( y2 ) # Calculates the standard deviation of both input signals. std1 = y1 . std () std2 = y2 . std () # Normalizes both signals, if appropriate. if normalize : y1_normal = ( y1 - y1 . mean ()) / std1 y2_normal = ( y2 - y2 . mean ()) / std2 else : y1_normal = y1 y2_normal = y2 # Calculates the CWT of the time-series making sure the same parameters # are used in both calculations. _kwargs = dict ( dj = dj , s0 = s0 , J = J , wavelet = wavelet ) W1 , sj , freq , coi , _ , _ = cwt ( y1_normal , dt , ** _kwargs ) W2 , sj , freq , coi , _ , _ = cwt ( y2_normal , dt , ** _kwargs ) # Now the wavelet transform coherence # W12ini = W1 * W2.conj() # scales = np.ones([1, y1.size]) * sj[:, None] # # -- Normalization by Scale and Smoothing # W12 = wavelet.smooth(W12ini / scales, dt, dj, sj) # Calculates the cross CWT of y1 and y2. W12 = W1 * W2 . conj () # And the significance tests. Note that the confidence level is calculated # using the percent point function (PPF) of the chi-squared cumulative # distribution function (CDF) instead of using Z1(95%) = 2.182 and # Z2(95%)=3.999 as suggested by Torrence & Compo (1998) and Grinsted et # al. (2004). If the CWT has been normalized, then std1 and std2 should # be reset to unity, otherwise the standard deviation of both series have # to be calculated. if normalize : std1 = std2 = 1. a1 , _ , _ = ar1 ( y1 ) a2 , _ , _ = ar1 ( y2 ) Pk1 = ar1_spectrum ( freq * dt , a1 ) Pk2 = ar1_spectrum ( freq * dt , a2 ) dof = wavelet . dofmin if not no_default_signif : PPF = chi2 . ppf ( significance_level , dof ) signif = ( std1 * std2 * ( Pk1 * Pk2 ) ** 0.5 * PPF / dof ) else : signif = np . asarray ([ 0 ]) # The resuts: return W12 , coi , freq , signif def wct ( y1 , y2 , dt , dj = 1 / 12 , s0 =- 1 , J =- 1 , sig = False , significance_level = 0.95 , wavelet = 'morlet' , normalize = False , ** kwargs ): \"\"\"Wavelet coherence transform (WCT). The WCT finds regions in time frequency space where the two time series co-vary, but do not necessarily have high power. Parameters ---------- y1, y2 : numpy.ndarray, list Input signals. dt : float Sample spacing. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N*dt/so))/dj. sig : bool set to compute signficance, default is True significance_level (float, optional) : Significance level to use. Default is 0.95. normalize (boolean, optional) : If set to true, normalizes CWT by the standard deviation of the signals. Returns ------- WCT : magnitude of coherence aWCT : phase angle of coherence coi (array like): Cone of influence, which is a vector of N points containing the maximum Fourier period of useful information at that particular time. Periods greater than those are subject to edge effects. freq (array like): Vector of Fourier equivalent frequencies (in 1 / time units) coi : sig : Significance levels as a function of scale if sig=True when called, otherwise zero. See also -------- cwt, xwt \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) nt = len ( y1 ) # Checking some input parameters if s0 == - 1 : # s0 = 2 * dt / wavelet.flambda() s0 = 2 * dt if J == - 1 : # Number of scales # J = int(np.round(np.log2(y1.size * dt / s0) / dj)) J = int (( np . log ( float ( nt ) * dt / s0 ) / np . log ( 2 )) / dj ) # Makes sure input signals are numpy arrays. y1 = np . asarray ( y1 ) y2 = np . asarray ( y2 ) # Calculates the standard deviation of both input signals. std1 = y1 . std () std2 = y2 . std () # Normalizes both signals, if appropriate. if normalize : y1_normal = ( y1 - y1 . mean ()) / std1 y2_normal = ( y2 - y2 . mean ()) / std2 else : y1_normal = y1 y2_normal = y2 # Calculates the CWT of the time-series making sure the same parameters # are used in both calculations. _kwargs = dict ( dj = dj , s0 = s0 , J = J , wavelet = wavelet ) W1 , sj , freq , coi , _ , _ = cwt ( y1_normal , dt , ** _kwargs ) W2 , sj , freq , coi , _ , _ = cwt ( y2_normal , dt , ** _kwargs ) scales1 = np . ones ([ 1 , y1 . size ]) * sj [:, None ] scales2 = np . ones ([ 1 , y2 . size ]) * sj [:, None ] # Smooth the wavelet spectra before truncating -- Time Smoothing S1 = wavelet . smooth ( np . abs ( W1 ) ** 2 / scales1 , dt , dj , sj ) S2 = wavelet . smooth ( np . abs ( W2 ) ** 2 / scales2 , dt , dj , sj ) # Now the wavelet transform coherence W12 = W1 * W2 . conj () scales = np . ones ([ 1 , y1 . size ]) * sj [:, None ] # -- Normalization by Scale and Scale Smoothing S12 = wavelet . smooth ( W12 / scales , dt , dj , sj ) WCT = np . abs ( S12 ) ** 2 / ( S1 * S2 ) aWCT = np . angle ( W12 ) # Calculates the significance using Monte Carlo simulations with 95% # confidence as a function of scale. if sig : a1 , b1 , c1 = ar1 ( y1 ) a2 , b2 , c2 = ar1 ( y2 ) sig = wct_significance ( a1 , a2 , dt = dt , dj = dj , s0 = s0 , J = J , significance_level = significance_level , wavelet = wavelet , ** kwargs ) else : sig = np . asarray ([ 0 ]) return WCT , aWCT , coi , freq , sig def wct_significance ( al1 , al2 , dt , dj , s0 , J , significance_level = 0.95 , wavelet = 'morlet' , mc_count = 50 , progress = True , cache = True ): \"\"\"Wavelet coherence transform significance. Calculates WCT significance using Monte Carlo simulations with 95% confidence. Parameters ---------- al1, al2: float Lag-1 autoregressive coeficients of both time series. dt : float Sample spacing. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N*dt/so))/dj. significance_level : float, optional Significance level to use. Default is 0.95. wavelet : instance of a wavelet class, optional Mother wavelet class. Default is Morlet wavelet. mc_count : integer, optional Number of Monte Carlo simulations. Default is 300. progress : bool, optional If `True` (default), shows progress bar on screen. cache : bool, optional If `True` (default) saves cache to file. Returns ------- TODO \"\"\" if cache : # Load cache if previously calculated. It is assumed that wavelet # analysis is performed using the wavelet's default parameters. aa = np . round ( np . arctanh ( np . array ([ al1 , al2 ]) * 4 )) aa = np . abs ( aa ) + 0.5 * ( aa < 0 ) cache_file = 'wct_sig_ {:0.5f} _ {:0.5f} _ {:0.5f} _ {:0.5f} _ {:d} _ {} ' \\ . format ( aa [ 0 ], aa [ 1 ], dj , s0 / dt , J , wavelet . name ) cache_dir = get_cache_dir () try : dat = np . loadtxt ( ' {} / {} .gz' . format ( cache_dir , cache_file ), unpack = True ) print ( 'NOTE: WCT significance loaded from cache. \\n ' ) return dat except IOError : pass # Some output to the screen print ( 'Calculating wavelet coherence significance' ) # Choose N so that largest scale has at least some part outside the COI ms = s0 * ( 2 ** ( J * dj )) / dt N = int ( np . ceil ( ms * 6 )) noise1 = rednoise ( N , al1 , 1 ) nW1 , sj , freq , coi , _ , _ = cwt ( noise1 , dt = dt , dj = dj , s0 = s0 , J = J , wavelet = wavelet ) period = np . ones ([ 1 , N ]) / freq [:, None ] coi = np . ones ([ J + 1 , 1 ]) * coi [ None , :] outsidecoi = ( period <= coi ) scales = np . ones ([ 1 , N ]) * sj [:, None ] sig95 = np . zeros ( J + 1 ) maxscale = find ( outsidecoi . any ( axis = 1 ))[ - 1 ] sig95 [ outsidecoi . any ( axis = 1 )] = np . nan nbins = 1000 wlc = np . ma . zeros ([ J + 1 , nbins ]) # Displays progress bar with tqdm for _ in tqdm ( range ( mc_count ), disable = not progress ): # Generates two red-noise signals with lag-1 autoregressive # coefficients given by al1 and al2 noise1 = rednoise ( N , al1 , 1 ) noise2 = rednoise ( N , al2 , 1 ) # Calculate the cross wavelet transform of both red-noise signals kwargs = dict ( dt = dt , dj = dj , s0 = s0 , J = J , wavelet = wavelet ) nW1 , sj , freq , coi , _ , _ = cwt ( noise1 , ** kwargs ) nW2 , sj , freq , coi , _ , _ = cwt ( noise2 , ** kwargs ) nW12 = nW1 * nW2 . conj () # Smooth wavelet wavelet transforms and calculate wavelet coherence # between both signals. S1 = wavelet . smooth ( np . abs ( nW1 ) ** 2 / scales , dt , dj , sj ) S2 = wavelet . smooth ( np . abs ( nW2 ) ** 2 / scales , dt , dj , sj ) S12 = wavelet . smooth ( nW12 / scales , dt , dj , sj ) R2 = np . ma . array ( np . abs ( S12 ) ** 2 / ( S1 * S2 ), mask =~ outsidecoi ) # Walks through each scale outside the cone of influence and builds a # coherence coefficient counter. for s in range ( maxscale ): cd = np . floor ( R2 [ s , :] * nbins ) for j , t in enumerate ( cd [ ~ cd . mask ]): wlc [ s , int ( t )] += 1 # After many, many, many Monte Carlo simulations, determine the # significance using the coherence coefficient counter percentile. wlc . mask = ( wlc . data == 0. ) R2y = ( np . arange ( nbins ) + 0.5 ) / nbins for s in range ( maxscale ): sel = ~ wlc [ s , :] . mask P = wlc [ s , sel ] . data . cumsum () P = ( P - 0.5 ) / P [ - 1 ] sig95 [ s ] = np . interp ( significance_level , P , R2y [ sel ]) if cache : # Save the results on cache to avoid to many computations in the future np . savetxt ( ' {} / {} .gz' . format ( cache_dir , cache_file ), sig95 ) # And returns the results return sig95 def _check_parameter_wavelet ( wavelet ): mothers = { 'morlet' : Morlet , 'paul' : Paul , 'dog' : DOG , 'mexicanhat' : MexicanHat } # Checks if input parameter is a string. For backwards # compatibility with Python 2 we check if instance is a # `str`. try : if isinstance ( wavelet , str ): return mothers [ wavelet ]() except NameError : if isinstance ( wavelet , str ): return mothers [ wavelet ]() # Otherwise, return itself. return wavelet WaLSA_k_omega.py This module provides functions for performing k-\u03c9 analysis and filtering in spatio-temporal datasets. WaLSA_k_omega.py # -------------------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # -------------------------------------------------------------------------------------------------------------- # The following codes are baed on those originally written by Rob Rutten, David B. Jess, and Samuel D. T. Grant # -------------------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.optimize import curve_fit # type: ignore from scipy.signal import convolve # type: ignore # -------------------------------------------------------------------------------------------- def gaussian_function ( sigma , width = None ): \"\"\" Create a Gaussian kernel that closely matches the IDL implementation. Parameters: sigma (float or list of floats): Standard deviation(s) of the Gaussian. width (int or list of ints, optional): Width of the Gaussian kernel. Returns: np.ndarray: The Gaussian kernel. \"\"\" # sigma = np.array(sigma, dtype=np.float64) sigma = np . atleast_1d ( np . array ( sigma , dtype = np . float64 )) # Ensure sigma is at least 1D if np . any ( sigma <= 0 ): raise ValueError ( \"Sigma must be greater than 0.\" ) # width = np.array(width) width = np . atleast_1d ( np . array ( width )) # Ensure width is always at least 1D width = np . maximum ( width . astype ( np . int64 ), 1 ) # Convert to integers and ensure > 0 if np . any ( width <= 0 ): raise ValueError ( \"Width must be greater than 0.\" ) nSigma = np . size ( sigma ) if nSigma > 8 : raise ValueError ( 'Sigma can have no more than 8 elements' ) nWidth = np . size ( width ) if nWidth > nSigma : raise ValueError ( 'Incorrect width specification' ) if ( nWidth == 1 ) and ( nSigma > 1 ): width = np . full ( nSigma , width [ 0 ]) # kernel = np.zeros(tuple(width.astype(int)), dtype=np.float64) kernel = np . zeros ( tuple ( width [: nSigma ] . astype ( int )), dtype = np . float64 ) # Match kernel size to nSigma temp = np . zeros ( 8 , dtype = np . int64 ) temp [: nSigma ] = width [: nSigma ] width = temp if nSigma == 2 : b = a = 0 if nSigma >= 1 : a = np . linspace ( 0 , width [ 0 ] - 1 , width [ 0 ]) - width [ 0 ] // 2 + ( 0 if width [ 0 ] % 2 else 0.5 ) if nSigma >= 2 : b = np . linspace ( 0 , width [ 1 ] - 1 , width [ 1 ]) - width [ 1 ] // 2 + ( 0 if width [ 1 ] % 2 else 0.5 ) a1 = b1 = 0 # Nested loop for kernel computation (to be completed for larger nSigma ....) for bb in range ( width [ 1 ]): b1 = ( b [ bb ] ** 2 ) / ( 2 * sigma [ 1 ] ** 2 ) if nSigma >= 2 else 0 for aa in range ( width [ 0 ]): a1 = ( a [ aa ] ** 2 ) / ( 2 * sigma [ 0 ] ** 2 ) if nSigma >= 1 else 0 kernel [ aa , bb ] = np . exp ( - np . clip (( a1 + b1 ), - 1e3 , 1e3 ) ) elif nSigma == 1 : a = 0 if nSigma >= 1 : a = np . linspace ( 0 , width [ 0 ] - 1 , width [ 0 ]) - width [ 0 ] // 2 + ( 0 if width [ 0 ] % 2 else 0.5 ) a1 = 0 # Nested loop for kernel computation for aa in range ( width [ 0 ]): a1 = ( a [ aa ] ** 2 ) / ( 2 * sigma [ 0 ] ** 2 ) if nSigma >= 1 else 0 kernel [ aa ] = np . exp ( - np . clip ( a1 , - 1e3 , 1e3 ) ) kernel = np . nan_to_num ( kernel , nan = 0.0 , posinf = 0.0 , neginf = 0.0 ) if np . sum ( kernel ) == 0 : raise ValueError ( \"Generated Gaussian kernel is invalid (all zeros).\" ) return kernel def walsa_radial_distances ( shape ): \"\"\" Compute the radial distance array for a given shape. Parameters: shape (tuple): Shape of the array, typically (ny, nx). Returns: numpy.ndarray: Array of radial distances. \"\"\" if not ( isinstance ( shape , tuple ) and len ( shape ) == 2 ): raise ValueError ( \"Shape must be a tuple with two elements, e.g., (ny, nx).\" ) y , x = np . indices ( shape ) cy , cx = ( np . array ( shape ) - 1 ) / 2 return np . sqrt (( x - cx ) ** 2 + ( y - cy ) ** 2 ) def avgstd ( array ): \"\"\" Calculate the average and standard deviation of an array. \"\"\" avrg = np . sum ( array ) / array . size stdev = np . sqrt ( np . sum (( array - avrg ) ** 2 ) / array . size ) return avrg , stdev def linear ( x , * p ): \"\"\" Compute a linear model y = p[0] + x * p[1]. (used in temporal detrending ) \"\"\" if len ( p ) < 2 : raise ValueError ( \"Parameters p[0] and p[1] must be provided.\" ) ymod = p [ 0 ] + x * p [ 1 ] return ymod def gradient ( xy , * p ): \"\"\" Gradient function for fitting spatial trends. Parameters: xy: Tuple of grid coordinates (x, y). p: Coefficients [offset, slope_x, slope_y]. \"\"\" x , y = xy # Unpack the tuple if len ( p ) < 3 : raise ValueError ( \"Parameters p[0], p[1], and p[2] must be provided.\" ) return p [ 0 ] + x * p [ 1 ] + y * p [ 2 ] def apod3dcube ( cube , apod ): \"\"\" Apodizes a 3D cube in all three coordinates, with detrending. Parameters: cube : Input 3D data cube with dimensions (nx, ny, nt). apod (float): Apodization factor (0 means no apodization). Returns: Apodized 3D cube. \"\"\" # Get cube dimensions nt , nx , ny = cube . shape apocube = np . zeros_like ( cube , dtype = np . float32 ) # Define temporal apodization apodt = np . ones ( nt , dtype = np . float32 ) if apod != 0 : apodrimt = nt * apod apodrimt = int ( apodrimt ) # Ensure apodrimt is an integer apodt [: apodrimt ] = ( np . sin ( np . pi / 2. * np . arange ( apodrimt ) / apodrimt )) ** 2 apodt = apodt * np . roll ( np . flip ( apodt ), 1 ) # Apply symmetrical apodization # Temporal detrending (mean-image trend, not per pixel) ttrend = np . zeros ( nt , dtype = np . float32 ) tf = np . arange ( nt ) + 1.0 for it in range ( nt ): img = cube [ it , :, :] # ttrend[it], _ = avgstd(img) ttrend [ it ] = np . mean ( img ) # Fit the trend with a linear model fitp , _ = curve_fit ( linear , tf , ttrend , p0 = [ 1000.0 , 0.0 ]) # fit = fitp[0] + tf * fitp[1] fit = linear ( tf , * fitp ) # Temporal apodization per (x, y) column for it in range ( nt ): img = cube [ it , :, :] apocube [ it , :, :] = ( img - fit [ it ]) * apodt [ it ] # Define spatial apodization apodx = np . ones ( nx , dtype = np . float32 ) apody = np . ones ( ny , dtype = np . float32 ) if apod != 0 : apodrimx = apod * nx apodrimy = apod * ny apodrimx = int ( apodrimx ) # Ensure apodrimx is an integer apodrimy = int ( apodrimy ) # Ensure apodrimy is an integer apodx [: apodrimx ] = ( np . sin ( np . pi / 2. * np . arange ( int ( apodrimx )) / apodrimx )) ** 2 apody [: apodrimy ] = ( np . sin ( np . pi / 2. * np . arange ( int ( apodrimy )) / apodrimy )) ** 2 apodx = apodx * np . roll ( np . flip ( apodx ), 1 ) apody = apody * np . roll ( np . flip ( apody ), 1 ) apodxy = np . outer ( apodx , apody ) else : apodxy = np . outer ( apodx , apody ) # Spatial gradient removal and apodizing per image # xf, yf = np.meshgrid(np.arange(nx), np.arange(ny), indexing='ij') xf = np . ones (( nx , ny ), dtype = np . float32 ) yf = np . copy ( xf ) for it in range ( nt ): img = apocube [ it , :, :] # avg, _ = avgstd(img) avg = np . mean ( img ) # Ensure xf, yf, and img are properly defined assert xf . shape == yf . shape == img . shape , \"xf, yf, and img must have matching shapes.\" # Flatten the inputs for curve_fit x_flat = xf . ravel () y_flat = yf . ravel () img_flat = img . ravel () # Ensure lengths match assert len ( x_flat ) == len ( y_flat ) == len ( img_flat ), \"Flattened inputs must have the same length.\" # Call curve_fit with initial parameters fitp , _ = curve_fit ( gradient , ( x_flat , y_flat ), img_flat , p0 = [ 1000.0 , 0.0 , 0.0 ]) # Apply the fitted parameters fit = gradient (( xf , yf ), * fitp ) apocube [ it , :, :] = ( img - fit ) * apodxy + avg return apocube def ko_dist ( sx , sy , double = False ): \"\"\" Set up Pythagorean distance array from the origin. \"\"\" # Create distance grids for x and y # (computing dx and dy using floating-point division) dx = np . tile ( np . arange ( sx / 2 + 1 ) / ( sx / 2 ), ( int ( sy / 2 + 1 ), 1 )) . T dy = np . flip ( np . tile ( np . arange ( sy / 2 + 1 ) / ( sy / 2 ), ( int ( sx / 2 + 1 ), 1 )), axis = 0 ) # Compute dxy dxy = np . sqrt ( dx ** 2 + dy ** 2 ) * ( min ( sx , sy ) / 2 + 1 ) # Initialize afstanden afstanden = np . zeros (( sx , sy ), dtype = np . float64 ) # Assign dxy to the first quadrant (upper-left) afstanden [: sx // 2 + 1 , : sy // 2 + 1 ] = dxy # Second quadrant (upper-right) - 90\u00b0 clockwise afstanden [ sx // 2 :, : sy // 2 + 1 ] = np . flip ( np . roll ( dxy [: - 1 , :], shift =- 1 , axis = 1 ), axis = 1 ) # Third quadrant (lower-left) - 270\u00b0 clockwise afstanden [: sx // 2 + 1 , sy // 2 :] = np . flip ( np . roll ( dxy [:, : - 1 ], shift =- 1 , axis = 0 ), axis = 0 ) # Fourth quadrant (lower-right) - 180\u00b0 rotation afstanden [ sx // 2 :, sy // 2 :] = np . flip ( dxy [: - 1 , : - 1 ], axis = ( 0 , 1 )) # Convert to integers if 'double' is False if not double : afstanden = np . round ( afstanden ) . astype ( int ) return afstanden def averpower ( cube ): \"\"\" Compute 2D (k_h, f) power array by circular averaging over k_x, k_y. Parameters: cube : Input 3D data cube of dimensions (nx, ny, nt). Returns: avpow : 2D array of average power over distances, dimensions (maxdist+1, nt/2+1). \"\"\" # Get cube dimensions nt , nx , ny = cube . shape # Perform FFT in all three dimensions (first in time direction) fftcube = np . fft . fft ( np . fft . fft ( np . fft . fft ( cube , axis = 0 )[: nt // 2 + 1 , :, :], axis = 1 ), axis = 2 ) # Set up distances afstanden = ko_dist ( nx , ny ) # Integer-rounded Pythagoras array maxdist = min ( nx , ny ) // 2 + 1 # Largest quarter circle # Initialize average power array avpow = np . zeros (( maxdist + 1 , nt // 2 + 1 ), dtype = np . float64 ) # Compute average power over all k_h distances, building power(k_h, f) for i in range ( maxdist + 1 ): where_indices = np . where ( afstanden == i ) for j in range ( nt // 2 + 1 ): w1 = fftcube [ j , :, :][ where_indices ] avpow [ i , j ] = np . sum ( np . abs ( w1 ) ** 2 ) / len ( where_indices ) return avpow def walsa_kopower_funct ( datacube , ** kwargs ): \"\"\" Calculate k-omega diagram (Fourier power at temporal frequency f against horizontal spatial wavenumber k_h) Origonally written in IDL by Rob Rutten (RR) assembly of Alfred de Wijn's routines (2010) - Translated into Pythn by Shahin Jafarzadeh (2024) Parameters: datacube: Input data cube [t, x, y]. arcsecpx (float): Spatial sampling in arcsec/pixel. cadence (float): Temporal sampling in seconds. apod: fractional extent of apodization edges; default 0.1 kmax: maximum k_h axis as fraction of Nyquist value, default 0.2 fmax: maximum f axis as fraction of Nyquist value, default 0.5 minpower: minimum of power plot range, default maxpower-5 maxpower: maximum of power plot range, default alog10(max(power)) Returns: k-omega power map. \"\"\" # Set default parameter values defaults = { 'apod' : 0.1 , 'kmax' : 1.0 , 'fmax' : 1.0 , 'minpower' : None , 'maxpower' : None } # Update defaults with user-provided values params = { ** defaults , ** kwargs } # Apodize the cube apocube = apod3dcube ( datacube , params [ 'apod' ]) # Compute radially-averaged power avpow = averpower ( apocube ) return avpow # -------------------------------------- Main Function ---------------------------------------- def WaLSA_k_omega ( signal , time = None , ** kwargs ): \"\"\" NAME: WaLSA_k_omega part of -- WaLSAtools -- * Main function to calculate and plot k-omega diagram. ORIGINAL CODE: QUEEns Fourier Filtering (QUEEFF) code WRITTEN, ANNOTATED, TESTED AND UPDATED in IDL BY: (1) Dr. David B. Jess (2) Dr. Samuel D. T. Grant The original code along with its manual can be downloaded at: https://bit.ly/37mx9ic WaLSA_k_omega (in IDL): A lightly modified version of the original code (i.e., a few additional keywords added) by Dr. Shahin Jafarzadeh - Translated into Pythn by Shahin Jafarzadeh (2024) Parameters: signal (array): Input datacube, normally in the form of [x, y, t] or [t, x, y]. Note that the input datacube must have identical x and y dimensions. If not, the datacube will be cropped accordingly. time (array): Time array corresponding to the input datacube. pixelsize (float): Spatial sampling of the input datacube. If not given, it is plotted in units of 'pixel'. filtering (bool): If True, filtering is applied, and the filtered datacube (filtered_cube) is returned. Otherwise, None is returned. Default: False. f1 (float): Optional lower (temporal) frequency to filter, in Hz. f2 (float): Optional upper (temporal) frequency to filter, in Hz. k1 (float): Optional lower (spatial) wavenumber to filter, in units of pixelsize^-1 (k = (2 * \u03c0) / wavelength). k2 (float): Optional upper (spatial) wavenumber to filter, in units of pixelsize^-1. spatial_torus (bool): If True, makes the annulus used for spatial filtering have a Gaussian-shaped profile, useful for preventing aliasing. Default: True. temporal_torus (bool): If True, makes the temporal filter have a Gaussian-shaped profile, useful for preventing aliasing. Default: True. no_spatial_filt (bool): If True, ensures no spatial filtering is performed on the dataset (i.e., only temporal filtering is applied). no_temporal_filt (bool): If True, ensures no temporal filtering is performed on the dataset (i.e., only spatial filtering is applied). silent (bool): If True, suppresses the k-\u03c9 diagram plot. smooth (bool): If True, power is smoothed. Default: True. mode (int): Output power mode: 0 = log10(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude. processing_maps (bool): If True, the function returns the processing maps (spatial_fft_map, torus_map, spatial_fft_filtered_map, temporal_fft, temporal_filter, temporal_frequencies, spatial_frequencies). Otherwise, they are all returned as None. Default: False. OUTPUTS: power : 2D array of power (see mode for the scale). frequencies : 1D array of frequencies (in mHz). wavenumber : 1D array of wavenumber (in pixelsize^-1). filtered_cube : 3D array of filtered datacube (if filtering is set). processing_maps (if set to True) IF YOU USE THIS CODE, THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED: Jess et al. 2017, ApJ, 842, 59 (http://adsabs.harvard.edu/abs/2017ApJ...842...59J) \"\"\" # Set default parameter values defaults = { 'pixelsize' : 1 , 'format' : 'txy' , 'filtering' : False , 'f1' : None , 'f2' : None , 'k1' : None , 'k2' : None , 'spatial_torus' : True , 'temporal_torus' : True , 'no_spatial_filt' : False , 'no_temporal_filt' : False , 'silent' : False , 'xlog' : False , 'ylog' : False , 'xrange' : None , 'yrange' : None , 'nox2' : False , 'noy2' : False , 'smooth' : True , 'mode' : 0 , 'xtitle' : 'Wavenumber' , 'xtitle_units' : '(pixel\u207b\u00b9)' , 'ytitle' : 'Frequency' , 'yttitle_units' : '(Hz)' , 'x2ndaxistitle' : 'Spatial size' , 'y2ndaxistitle' : 'Period' , 'x2ndaxistitle_units' : '(pixel)' , 'y2ndaxistitle_units' : '(s)' , 'processing_maps' : False } # Update defaults with user-provided values params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) pixelsize = params [ 'pixelsize' ] filtered_cube = None spatial_fft_map = None torus_map = None spatial_fft_filtered_map = None temporal_fft = None temporal_frequencies = None spatial_frequencies = None # Check and adjust format if necessary if params [ 'format' ] == 'xyt' : cube = np . transpose ( cube , ( 2 , 0 , 1 )) # Convert 'xyt' to 'txy' elif params [ 'format' ] != 'txy' : raise ValueError ( \"Unsupported format. Choose 'txy' or 'xyt'.\" ) if not params [ 'silent' ]: print ( f \"Processing k-\u03c9 analysis for a 3D cube with format ' { params [ 'format' ] } ' and shape { signal . shape } .\" ) # Input dimensions nt , nx , ny = signal . shape if nx != ny : min_dim = min ( nx , ny ) signal = signal [: min_dim , : min_dim , :] nt , nx , ny = signal . shape # Calculating the Nyquist frequencies spatial_nyquist = ( 2 * np . pi ) / ( pixelsize * 2 ) temporal_nyquist = 1 / ( cadence * 2 ) print ( \"\" ) print ( f \"Input datacube size (t,x,y): { signal . shape } \" ) print ( \"\" ) print ( \"Spatially, the important values are:\" ) print ( f \" 2-pixel size = { pixelsize * 2 : .2f } { params [ 'x2ndaxistitle_units' ] } \" ) print ( f \" Nyquist wavenumber = { spatial_nyquist : .2f } { params [ 'xtitle_units' ] } \" ) if params [ 'no_spatial_filt' ]: print ( \"*** NO SPATIAL FILTERING WILL BE PERFORMED ***\" ) print ( \"\" ) print ( \"Temporally, the important values are:\" ) print ( f \" 2-element duration (Nyquist period) = { cadence * 2 : .2f } { params [ 'y2ndaxistitle_units' ] } \" ) print ( f \" Time series duration = { cadence * signal . shape [ 2 ] : .2f } { params [ 'y2ndaxistitle_units' ] } \" ) temporal_nyquist = 1 / ( cadence * 2 ) print ( f \" Nyquist frequency = { temporal_nyquist : .2f } { params [ 'yttitle_units' ] } \" ) if params [ 'no_temporal_filt' ]: print ( \"***NO TEMPORAL FILTERING WILL BE PERFORMED***\" ) print ( \"\" ) # Generate k-omega power map print ( \"Constructing a k-\u03c9 diagram of the input datacube..........\" ) print ( \"\" ) # Make the k-omega diagram using the proven method of Rob Rutten kopower = walsa_kopower_funct ( signal ) # Scales xsize_kopower = kopower . shape [ 0 ] dxsize_kopower = spatial_nyquist / float ( xsize_kopower - 1 ) kopower_xscale = np . arange ( xsize_kopower ) * dxsize_kopower # in pixel\u207b\u00b9 ysize_kopower = kopower . shape [ 1 ] dysize_kopower = temporal_nyquist / float ( ysize_kopower - 1 ) kopower_yscale = ( np . arange ( ysize_kopower ) * dysize_kopower ) # in Hz # Generate Gaussian Kernel Gaussian_kernel = gaussian_function ( sigma = [ 0.65 , 0.65 ], width = 3 ) Gaussian_kernel_norm = np . nansum ( Gaussian_kernel ) # Normalize kernel sum # Copy kopower to kopower_plot kopower_plot = kopower . copy () # Convolve kopower (ignoring zero-th element, starting from index 1) kopower_plot [:, 1 :] = convolve ( kopower [:, 1 :], Gaussian_kernel , mode = 'same' ) / Gaussian_kernel_norm # Normalize to frequency resolution (in mHz) freq = kopower_yscale [ 1 :] if freq [ 0 ] == 0 : freq0 = freq [ 1 ] else : freq0 = freq [ 0 ] kopower_plot /= freq0 # Apply logarithmic or square root transformation based on mode if params [ 'mode' ] == 0 : # Logarithmic scaling kopower_plot = np . log10 ( kopower_plot ) elif params [ 'mode' ] == 2 : # Square root scaling kopower_plot = np . sqrt ( kopower_plot ) # Normalize the power - preferred for plotting komegamap = np . clip ( kopower_plot [ 1 :, 1 :], np . nanmin ( kopower_plot [ 1 :, 1 :]), np . nanmax ( kopower_plot [ 1 :, 1 :]) ) kopower_zscale = kopower_plot [ 1 :, 1 :] # Rotate kopower counterclockwise by 90 degrees komegamap = np . rot90 ( komegamap , k = 1 ) # Flip vertically (y-axis) komegamap = np . flip ( komegamap , axis = 0 ) # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Filtering implementation if params [ 'filtering' ]: # Extract parameters from the dictionary k1 = params [ 'k1' ] k2 = params [ 'k2' ] f1 = params [ 'f1' ] f2 = params [ 'f2' ] if params [ 'no_spatial_filt' ]: k1 = kopower_xscale [ 1 ] # Default lower wavenumber k2 = np . nanmax ( kopower_xscale ) # Default upper wavenumber # Ensure k1 and k2 are within valid bounds if k1 is None or k1 <= 0.0 : k1 = kopower_xscale [ 1 ] if k2 is None or k2 > np . nanmax ( kopower_xscale ): k2 = np . nanmax ( kopower_xscale ) if params [ 'no_temporal_filt' ]: f1 = kopower_yscale [ 1 ] f2 = np . nanmax ( kopower_yscale ) # Ensure f1 and f2 are within valid bounds if f1 is None or f1 <= 0.0 : f1 = kopower_yscale [ 1 ] if f2 is None or f2 > np . nanmax ( kopower_yscale ): f2 = np . nanmax ( kopower_yscale ) print ( \"Start filtering (in k-\u03c9 space) ......\" ) print ( \"\" ) print ( f \"The preserved wavenumbers are [ { k1 : .3f } , { k2 : .3f } ] { params [ 'xtitle_units' ] } \" ) print ( f \"The preserved spatial sizes are [ { ( 2 * np . pi ) / k2 : .3f } , { ( 2 * np . pi ) / k1 : .3f } ] { params [ 'x2ndaxistitle_units' ] } \" ) print ( \"\" ) print ( f \"The preserved frequencies are [ { f1 : .3f } , { f2 : .3f } ] { params [ 'yttitle_units' ] } \" ) print ( f \"The preserved periods are [ { int ( 1 / ( f2 )) } , { int ( 1 / ( f1 )) } ] { params [ 'y2ndaxistitle_units' ] } \" ) print ( \"\" ) # Perform the 3D Fourier transform print ( \"Making a 3D Fourier transform of the input datacube ..........\" ) threedft = np . fft . fftshift ( np . fft . fftn ( signal )) # Calculate the frequency axes for the 3D FFT temp_x = np . arange (( nx - 1 ) // 2 ) + 1 is_N_even = ( nx % 2 == 0 ) if is_N_even : spatial_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_x , [ nx / 2 ], - nx / 2 + temp_x ]) / ( nx * pixelsize )) * ( 2.0 * np . pi ) else : spatial_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_x , [ - ( nx / 2 + 1 )] + temp_x ]) / ( nx * pixelsize )) * ( 2.0 * np . pi ) temp_t = np . arange (( nt - 1 ) // 2 ) + 1 # Use integer division for clarity is_N_even = ( nt % 2 == 0 ) if is_N_even : temporal_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_t , [ nt / 2 ], - nt / 2 + temp_t ])) / ( nt * cadence ) else : temporal_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_t , [ - ( nt / 2 + 1 )] + temp_t ])) / ( nt * cadence ) # Compensate frequency axes for the use of FFT shift indices = np . where ( spatial_frequencies_orig >= 0 )[ 0 ] spatial_positive_frequencies = len ( indices ) if len ( spatial_frequencies_orig ) % 2 == 0 : spatial_frequencies = np . roll ( spatial_frequencies_orig , spatial_positive_frequencies - 2 ) else : spatial_frequencies = np . roll ( spatial_frequencies_orig , spatial_positive_frequencies - 1 ) tindices = np . where ( temporal_frequencies_orig >= 0 )[ 0 ] temporal_positive_frequencies = len ( tindices ) if len ( temporal_frequencies_orig ) % 2 == 0 : temporal_frequencies = np . roll ( temporal_frequencies_orig , temporal_positive_frequencies - 2 ) else : temporal_frequencies = np . roll ( temporal_frequencies_orig , temporal_positive_frequencies - 1 ) # Ensure the threedft aligns with the new frequency axes if len ( temporal_frequencies_orig ) % 2 == 0 : for x in range ( nx ): for y in range ( ny ): threedft [:, x , y ] = np . roll ( threedft [:, x , y ], - 1 ) if len ( spatial_frequencies_orig ) % 2 == 0 : for z in range ( nt ): threedft [ z , :, :] = np . roll ( threedft [ z , :, :], shift = ( - 1 , - 1 ), axis = ( 0 , 1 )) # Convert frequencies and wavenumbers of interest into FFT datacube pixels pixel_k1_positive = np . argmin ( np . abs ( spatial_frequencies_orig - k1 )) pixel_k2_positive = np . argmin ( np . abs ( spatial_frequencies_orig - k2 )) pixel_f1_positive = np . argmin ( np . abs ( temporal_frequencies - f1 )) pixel_f2_positive = np . argmin ( np . abs ( temporal_frequencies - f2 )) pixel_f1_negative = np . argmin ( np . abs ( temporal_frequencies + f1 )) pixel_f2_negative = np . argmin ( np . abs ( temporal_frequencies + f2 )) torus_depth = int (( pixel_k2_positive - pixel_k1_positive ) / 2 ) * 2 torus_center = int ((( pixel_k2_positive - pixel_k1_positive ) / 2 ) + pixel_k1_positive ) if params [ 'spatial_torus' ] and not params [ 'no_spatial_filt' ]: # Create a filter ring preserving equal wavenumbers for both kx and ky # This forms a torus to preserve an integrated Gaussian shape across the width of the annulus spatial_torus = np . zeros (( torus_depth , nx , ny )) for i in range ( torus_depth // 2 + 1 ): spatial_ring = np . logical_xor ( ( walsa_radial_distances (( nx , ny )) <= ( torus_center - i )), ( walsa_radial_distances (( nx , ny )) <= ( torus_center + i + 1 )) ) spatial_ring = spatial_ring . astype ( int ) # Convert True -> 1 and False -> 0 spatial_ring [ spatial_ring > 0 ] = 1. spatial_ring [ spatial_ring != 1 ] = 0. spatial_torus [ i , :, :] = spatial_ring spatial_torus [ torus_depth - i - 1 , :, :] = spatial_ring # Integrate through the torus to find the spatial filter spatial_ring_filter = np . nansum ( spatial_torus , axis = 0 ) / float ( torus_depth ) spatial_ring_filter = spatial_ring_filter / np . nanmax ( spatial_ring_filter ) # Ensure the peaks are at 1.0 if not params [ 'spatial_torus' ] and not params [ 'no_spatial_filt' ]: spatial_ring_filter = ( ( walsa_radial_distances (( nx , ny )) <= ( torus_center - int ( torus_depth / 2 ))) . astype ( int ) - ( walsa_radial_distances (( nx , ny )) <= ( torus_center + int ( torus_depth / 2 ) + 1 )) . astype ( int ) ) spatial_ring_filter = spatial_ring_filter / np . nanmax ( spatial_ring_filter ) # Ensure the peaks are at 1.0 spatial_ring_filter [ spatial_ring_filter != 1 ] = 0 if params [ 'no_spatial_filt' ]: spatial_ring_filter = np . ones (( nx , ny )) if not params [ 'no_temporal_filt' ] and params [ 'temporal_torus' ]: # CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = np . zeros ( nt , dtype = float ) filter_width = pixel_f2_positive - pixel_f1_positive # Determine sigma based on filter width if filter_width < 25 : sigma = 3 if filter_width >= 25 and filter_width < 30 : sigma = 4 if filter_width >= 30 and filter_width < 40 : sigma = 5 if filter_width >= 40 and filter_width < 45 : sigma = 6 if filter_width >= 45 and filter_width < 50 : sigma = 7 if filter_width >= 50 and filter_width < 55 : sigma = 8 if filter_width >= 55 and filter_width < 60 : sigma = 9 if filter_width >= 60 and filter_width < 65 : sigma = 10 if filter_width >= 65 and filter_width < 70 : sigma = 11 if filter_width >= 70 and filter_width < 80 : sigma = 12 if filter_width >= 80 and filter_width < 90 : sigma = 13 if filter_width >= 90 and filter_width < 100 : sigma = 14 if filter_width >= 100 and filter_width < 110 : sigma = 15 if filter_width >= 110 and filter_width < 130 : sigma = 16 if filter_width >= 130 : sigma = 17 # Generate the Gaussian kernel temporal_gaussian = gaussian_function ( sigma = sigma , width = filter_width ) # Apply the Gaussian to the temporal filter temporal_filter [ pixel_f1_positive : pixel_f2_positive ] = temporal_gaussian temporal_filter [ pixel_f2_negative : pixel_f1_negative ] = temporal_gaussian # Normalize the filter to ensure the peaks are at 1.0 temporal_filter /= np . nanmax ( temporal_filter ) if not params [ 'no_temporal_filt' ] and not params [ 'temporal_torus' ]: temporal_filter = np . zeros ( nt , dtype = float ) temporal_filter [ pixel_f1_positive : pixel_f2_positive + 1 ] = 1.0 temporal_filter [ pixel_f2_negative : pixel_f1_negative + 1 ] = 1.0 if params [ 'no_temporal_filt' ]: temporal_filter = np . ones ( nt , dtype = float ) # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Create useful variables for plotting (if needed), demonstrating the filtering process if params [ 'processing_maps' ]: # Define the spatial frequency step for plotting spatial_dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ] spatial_dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ] # Torus map torus_map = { 'data' : spatial_ring_filter , 'dx' : spatial_dx , 'dy' : spatial_dy , 'xc' : 0 , 'yc' : 0 , 'time' : '' , 'units' : 'pixels' } # Compute the total spatial FFT spatial_fft = np . nansum ( threedft , axis = 0 ) # Spatial FFT map spatial_fft_map = { 'data' : np . log10 ( spatial_fft ), 'dx' : spatial_dx , 'dy' : spatial_dy , 'xc' : 0 , 'yc' : 0 , 'time' : '' , 'units' : 'pixels' } # Spatial FFT filtered and its map spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = { 'data' : np . log10 ( np . maximum ( spatial_fft_filtered , 1e-15 )), 'dx' : spatial_dx , 'dy' : spatial_dy , 'xc' : 0 , 'yc' : 0 , 'time' : '' , 'units' : 'pixels' } # Compute the total temporal FFT temporal_fft = np . nansum ( np . nansum ( threedft , axis = 2 ), axis = 1 ) else : spatial_fft_map = None torus_map = None spatial_fft_filtered_map = None temporal_fft = None temporal_filter , temporal_frequencies , spatial_frequencies = None , None , None # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Apply the Gaussian filters to the data to prevent aliasing for i in range ( nt ): threedft [ i , :, :] *= spatial_ring_filter for x in range ( nx ): for y in range ( ny ): threedft [:, x , y ] *= temporal_filter # ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE /center CALL if len ( temporal_frequencies_orig ) % 2 == 0 : for x in range ( nx ): for y in range ( ny ): threedft [:, x , y ] = np . roll ( threedft [:, x , y ], shift = 1 , axis = 0 ) if len ( spatial_frequencies_orig ) % 2 == 0 : for t in range ( nt ): threedft [ t , :, :] = np . roll ( threedft [ t , :, :], shift = ( 1 , 1 ), axis = ( 0 , 1 )) threedft [ z , :, :] = np . roll ( np . roll ( threedft [ z , :, :], shift = 1 , axis = 0 ), shift = 1 , axis = 1 ) # Inverse FFT to get the filtered cube # filtered_cube = np.real(np.fft.ifftn(threedft, norm='ortho')) filtered_cube = np . real ( np . fft . ifftn ( np . fft . ifftshift ( threedft ))) else : filtered_cube = None print ( \"Filtered datacube generated.\" ) return komegamap , kopower_xscale [ 1 :], kopower_yscale [ 1 :], filtered_cube , spatial_fft_map , torus_map , spatial_fft_filtered_map , temporal_fft , temporal_filter , temporal_frequencies , spatial_frequencies WaLSA_pod.py This module implements Proper Orthogonal Decomposition (POD), as well as Spectral POD (SPOD), for analysing multi-dimensional data and extracting dominant spatial patterns. WaLSA_pod.py # -------------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # -------------------------------------------------------------------------------------------------------- # The following codes are based on those originally written by Jonathan E. Higham & Luiz A. C. A. Schiavo # -------------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.signal import welch , find_peaks # type: ignore from scipy.linalg import svd # type: ignore from scipy.optimize import curve_fit # type: ignore import math def print_pod_results ( results ): \"\"\" Print a summary of the results from WaLSA_pod, including parameter descriptions, types, and shapes. Parameters: ----------- results : dict The dictionary containing all POD results and relevant outputs. \"\"\" descriptions = { 'input_data' : 'Original input data, mean subtracted (Shape: (Nt, Ny, Nx))' , 'spatial_mode' : 'Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx))' , 'temporal_coefficient' : 'Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt))' , 'eigenvalue' : 'Eigenvalues corresponding to singular values squared (Shape: (Nmodes))' , 'eigenvalue_contribution' : 'Eigenvalue contribution of each mode (Shape: (Nmodes))' , 'cumulative_eigenvalues' : 'Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes))' , 'combined_welch_psd' : 'Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf))' , 'frequencies' : 'Frequencies identified in the Welch spectrum (Shape: (Nf))' , 'combined_welch_significance' : 'Significance threshold of the combined Welch spectrum (Shape: (Nf,))' , 'reconstructed' : 'Reconstructed frame at the specified timestep (or for the entire time series) using the top \"num_modes\" modes (Shape: (Ny, Nx))' , 'sorted_frequencies' : 'Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies))' , 'frequency_filtered_modes' : 'Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies))' , 'frequency_filtered_modes_frequencies' : 'Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies))' , 'SPOD_spatial_modes' : 'SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx))' , 'SPOD_temporal_coefficients' : 'SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt))' , 'p' : 'Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes))' , 's' : 'Singular values from SVD (Shape: (Nmodes))' , 'a' : 'Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt))' } print ( \" \\n ---- POD/SPOD Results Summary ---- \\n \" ) for key , value in results . items (): desc = descriptions . get ( key , 'No description available' ) shape = np . shape ( value ) if value is not None else 'None' dtype = type ( value ) . __name__ print ( f \" { key } ( { dtype } , Shape: { shape } ): { desc } \" ) print ( \" \\n ----------------------------------\" ) def spod ( data , ** kwargs ): \"\"\" Perform Spectral Proper Orthogonal Decomposition (SPOD) analysis on input data. Steps: 1. Load the data. 2. Compute a time average. 3. Build the correlation matrix to compute the POD using the snapshot method. 4. Compute eigenvalue decomposition for the correlation matrix for the fluctuation field. The eigenvalues and eigenvectors can be computed by any eigenvalue function or by an SVD procedure, since the correlation matrix is symmetric positive-semidefinite. 5. After obtaining the eigenvalues and eigenvectors, compute the temporal and spatial modes according to the snapshot method. Parameters: ----------- data : np.ndarray 3D data array with shape (time, x, y) or similar. **kwargs : dict, optional Additional keyword arguments to configure the analysis. Returns: -------- SPOD_spatial_modes : np.ndarray SPOD_temporal_coefficients : np.ndarray \"\"\" # Set default parameter values defaults = { 'silent' : False , 'num_modes' : None , 'filter_size' : None , 'periodic_matrix' : True } # Update defaults with user-provided values params = { ** defaults , ** kwargs } if params [ 'num_modes' ] is None : params [ 'num_modes' ] = data . shape [ 0 ] if params [ 'filter_size' ] is None : params [ 'filter_size' ] = params [ 'num_modes' ] if not params [ 'silent' ]: print ( \"Starting SPOD analysis ....\" ) nsnapshots , ny , nx = data . shape # Center the data by subtracting the mean time_average = data . mean ( axis = 0 ) fluctuation_field = data * 0 # Initialize fluctuation field with zeros for n in range ( nsnapshots ): fluctuation_field [ n ,:,:] = data [ n ,:,:] - time_average # Subtract time-average from each snapshot # Build the correlation matrix (snapshot method) correlation_matrix = np . zeros (( nsnapshots , nsnapshots )) for i in range ( nsnapshots ): for j in range ( i , nsnapshots ): correlation_matrix [ i , j ] = ( fluctuation_field [ i , :, :] * fluctuation_field [ j , :, :]) . sum () / ( nsnapshots * nx * ny ) correlation_matrix [ j , i ] = correlation_matrix [ i , j ] # SPOD correlation matrix with periodic boundary conditions nmatrix = np . zeros (( 3 * nsnapshots , 3 * nsnapshots )) nmatrix [ nsnapshots : 2 * nsnapshots , nsnapshots : 2 * nsnapshots ] = correlation_matrix [ 0 : nsnapshots , 0 : nsnapshots ] if params [ 'periodic_matrix' ]: for i in range ( 3 ): for j in range ( 3 ): xs = i * nsnapshots # x-offset for periodic positioning ys = j * nsnapshots # y-offset for periodic positioning nmatrix [ 0 + xs : nsnapshots + xs , 0 + ys : nsnapshots + ys ] = correlation_matrix [ 0 : nsnapshots , 0 : nsnapshots ] # Apply Gaussian filter gk = np . zeros (( 2 * params [ 'filter_size' ] + 1 )) # Create 1D Gaussian kernel esp = 8.0 # Exponential parameter controlling the spread of the filter sumgk = 0.0 # Sum of the Gaussian kernel for normalization for n in range ( 2 * params [ 'filter_size' ] + 1 ): k = - params [ 'filter_size' ] + n # Offset from the center of the kernel gk [ n ] = math . exp ( - esp * k ** 2.0 / ( params [ 'filter_size' ] ** 2.0 )) # Gaussian filter formula sumgk += gk [ n ] # Sum of kernel values for normalization # Filter the extended correlation matrix for j in range ( nsnapshots , 2 * nsnapshots ): for i in range ( nsnapshots , 2 * nsnapshots ): aux = 0.0 # Initialize variable for the weighted sum for n in range ( 2 * params [ 'filter_size' ] + 1 ): k = - params [ 'filter_size' ] + n # Offset from the current index aux += nmatrix [ i + k , j + k ] * gk [ n ] # Apply Gaussian weighting nmatrix [ i , j ] = aux / sumgk # Normalize by the sum of the Gaussian kernel # Extract the SPOD correlation matrix from the central part of the filtered matrix spectral_matrix = nmatrix [ nsnapshots : 2 * nsnapshots , nsnapshots : 2 * nsnapshots ] # Perform SVD to compute SPOD UU , SS , VV = svd ( spectral_matrix , full_matrices = True , compute_uv = True ) # Temporal coefficients SPOD_temporal_coefficients = np . zeros (( nsnapshots , nsnapshots )) for k in range ( nsnapshots ): SPOD_temporal_coefficients [:, k ] = np . sqrt ( SS [ k ] * nsnapshots ) * UU [:, k ] # Extract spatial SPOD modes SPOD_spatial_modes = np . zeros (( params [ 'num_modes' ], ny , nx )) for m in range ( params [ 'num_modes' ]): for t in range ( nsnapshots ): SPOD_spatial_modes [ m , :, :] += fluctuation_field [ t , :, :] * SPOD_temporal_coefficients [ t , m ] / ( SS [ m ] * nsnapshots ) if not params [ 'silent' ]: print ( f \"SPOD analysis completed.\" ) return SPOD_spatial_modes , SPOD_temporal_coefficients # -------------------------------------- Main Function ---------------------------------------- def WaLSA_pod ( signal , time , ** kwargs ): \"\"\" Perform Proper Orthogonal Decomposition (POD) analysis on input data. Parameters: signal (array): 3D data cube with shape (time, x, y) or similar. time (array): 1D array representing the time points for each time step in the data. num_modes (int, optional): Number of top modes to compute. Default is None (all modes). num_top_frequencies (int, optional): Number of top frequencies to consider. Default is None (all frequencies). top_frequencies (list, optional): List of top frequencies to consider. Default is None. num_cumulative_modes (int, optional): Number of cumulative modes to consider. Default is None (all modes). welch_nperseg (int, optional): Number of samples per segment for Welch's method. Default is 150. welch_noverlap (int, optional): Number of overlapping samples for Welch's method. Default is 25. welch_nfft (int, optional): Number of points for the FFT. Default is 2^14. welch_fs (int, optional): Sampling frequency for the data. Default is 2. nperm (int, optional): Number of permutations for significance testing. Default is 1000. siglevel (float, optional): Significance level for the Welch spectrum. Default is 0.95. timestep_to_reconstruct (int, optional): Timestep of the datacube to reconstruct using the top modes. Default is 0. num_modes_reconstruct (int, optional): Number of modes to use for reconstruction. Default is None (all modes). reconstruct_all (bool, optional): If True, reconstruct the entire time series using the top modes. Default is False. spod (bool, optional): If True, perform Spectral Proper Orthogonal Decomposition (SPOD) analysis. Default is False. spod_filter_size (int, optional): Filter size for SPOD analysis. Default is None. spod_num_modes (int, optional): Number of SPOD modes to compute. Default is None. print_results (bool, optional): If True, print a summary of results. Default is True. **kwargs : Additional keyword arguments to configure the analysis. Returns: results : dict A dictionary containing all computed POD results and relevant outputs. See 'descriptions' in the 'print_pod_results' function on top of this page. \"\"\" # Set default parameter values defaults = { 'silent' : False , 'num_modes' : None , 'num_top_frequencies' : None , 'top_frequencies' : None , 'num_cumulative_modes' : None , 'welch_nperseg' : 150 , 'welch_noverlap' : 25 , 'welch_nfft' : 2 ** 14 , 'welch_fs' : 2 , 'nperm' : 1000 , 'siglevel' : 0.95 , 'timestep_to_reconstruct' : 0 , 'reconstruct_all' : False , 'num_modes_reconstruct' : None , 'spod' : False , 'spod_filter_size' : None , 'spod_num_modes' : None , 'print_results' : True # Print summary of results by default } # Update defaults with user-provided values params = { ** defaults , ** kwargs } data = signal if params [ 'num_modes' ] is None : params [ 'num_modes' ] = data . shape [ 0 ] if params [ 'num_top_frequencies' ] is None : params [ 'num_top_frequencies' ] = min ( params [ 'num_modes' ], 10 ) if params [ 'num_cumulative_modes' ] is None : params [ 'num_cumulative_modes' ] = min ( params [ 'num_modes' ], 10 ) if params [ 'num_modes_reconstruct' ] is None : params [ 'num_modes_reconstruct' ] = min ( params [ 'num_modes' ], 10 ) if not params [ 'silent' ]: print ( \"Starting POD analysis ....\" ) print ( f \"Processing a 3D cube with shape { data . shape } .\" ) # The first step is to read in the data and then perform the SVD (or POD). Before we do this, # we need to reshape the matrix such that it is an N x T matrix where N is the column vectorized set of each spatial image and T is the temporal domain. # We also need to ensure that the mean is subtracted from the data; this will ensure we are looking only at the variance of the data, and mode 1 will not be contaminated with the mean image. # Reshape the 3D data into 2D array where each row is a vector from the original 3D data inp = np . reshape ( data , ( data . shape [ 0 ], data . shape [ 1 ] * data . shape [ 2 ])) . astype ( np . float32 ) inp = inp . T # Transpose the matrix to have spatial vectors as columns # Center the data by subtracting the mean mean_per_row = np . nanmean ( inp , axis = 1 , keepdims = True ) mean_replicated = np . tile ( mean_per_row , ( 1 , data . shape [ 0 ])) inp_centered = inp - mean_replicated # Input data, mean subtracted input_dat = np . zeros (( data . shape [ 0 ], data . shape [ 1 ], data . shape [ 2 ])) for im in range ( data . shape [ 0 ]): input_dat [ im , :, :] = np . reshape ( inp_centered [:, im ], ( data . shape [ 1 ], data . shape [ 2 ])) # Perform SVD to compute POD p , s , a = svd ( inp_centered , full_matrices = False ) sorg = s . copy () # Store original singular values eigenvalue = s ** 2 # Convert singular values to eigenvalues # Reshape spatial modes to have the same shape as the input data num_modes = p . shape [ 1 ] spatial_mode = np . zeros (( num_modes , data . shape [ 1 ], data . shape [ 2 ])) for m in range ( num_modes ): spatial_mode [ m , :, :] = np . reshape ( p [:, m ], ( data . shape [ 1 ], data . shape [ 2 ])) # Extract temporal coefficients temporal_coefficient = a [: num_modes , :] # Calculate eigenvalue contributions eigenvalue_contribution = eigenvalue / np . sum ( eigenvalue ) # Calculate cumulative eigenvalues cumulative_eigenvalues = [] for m in range ( params [ 'num_cumulative_modes' ]): contm = 100 * eigenvalue [ 0 : m ] / np . sum ( eigenvalue ) cumulative_eigenvalues . append ( np . sum ( contm )) if params [ 'reconstruct_all' ]: # Reconstruct the entire time series using the top 'num_modes_reconstruct' modes reconstructed = np . zeros (( data . shape [ 0 ], data . shape [ 1 ], data . shape [ 2 ])) for tindex in range ( data . shape [ 0 ]): reconim = np . zeros (( data . shape [ 1 ], data . shape [ 2 ])) for i in range ( params [ 'num_modes_reconstruct' ]): reconim = reconim + np . reshape ( p [:, i ], ( data . shape [ 1 ], data . shape [ 2 ])) * a [ i , tindex ] * sorg [ i ] reconstructed [ tindex , :, :] = reconim else : # Reconstruct the specified timestep using the top 'num_modes_reconstruct' modes reconstructed = np . zeros (( data . shape [ 1 ], data . shape [ 2 ])) for i in range ( params [ 'num_modes_reconstruct' ]): reconstructed = reconstructed + np . reshape ( p [:, i ], ( data . shape [ 1 ], data . shape [ 2 ])) * a [ i , params [ 'timestep_to_reconstruct' ]] * sorg [ i ] #--------------------------------------------------------------------------------- # Combined Welch power spectrum and its significance #--------------------------------------------------------------------------------- # Compute Welch power spectrum for each mode and combine them for 'num_modes' modes combined_welch_psd = [] for m in range ( params [ 'num_modes' ]): frequencies , px = welch ( a [ m , :] - np . mean ( a [ m , :]), nperseg = params [ 'welch_nperseg' ], noverlap = params [ 'welch_noverlap' ], nfft = params [ 'welch_nfft' ], fs = params [ 'welch_fs' ]) if m == 0 : combined_welch_psd = np . zeros (( len ( frequencies ),)) combined_welch_psd += eigenvalue_contribution [ m ] * ( px / np . sum ( px )) # Generate resampled peaks to compute significance threshold resampled_peaks = np . zeros (( params [ 'nperm' ], len ( frequencies ))) for i in range ( params [ 'nperm' ]): resampled_data = np . random . randn ( * a . shape ) resampled_peak = np . zeros (( len ( frequencies ),)) for m in range ( params [ 'num_modes' ]): _ , px = welch ( resampled_data [ m , :] - np . mean ( resampled_data [ m , :]), nperseg = params [ 'welch_nperseg' ], noverlap = params [ 'welch_noverlap' ], nfft = params [ 'welch_nfft' ], fs = params [ 'welch_fs' ]) resampled_peak += eigenvalue_contribution [ m ] * ( px / np . sum ( px )) resampled_peak /= ( np . max ( resampled_peak ) + 1e-30 ) # a small epsilon added to avoid division by zero resampled_peaks [ i , :] = resampled_peak # Calculate significance threshold combined_welch_significance = np . percentile ( resampled_peaks , 100 - ( params [ 'siglevel' ] * 100 ), axis = 0 ) #--------------------------------------------------------------------------------- # Find peaks in the combined spectrum and sort them in descending order normalized_peak = combined_welch_psd / ( np . max ( combined_welch_psd ) + 1e-30 ) peak_indices , _ = find_peaks ( normalized_peak ) sorted_indices = np . argsort ( normalized_peak [ peak_indices ])[:: - 1 ] sorted_frequencies = frequencies [ peak_indices ][ sorted_indices ] # Generate a table of the top N frequencies # Cleaner single-line list comprehension table_data = [ [ float ( np . round ( freq , 2 )), float ( np . round ( pwr , 2 ))] for freq , pwr in zip ( sorted_frequencies [: params [ 'num_top_frequencies' ]], normalized_peak [ peak_indices ][ sorted_indices ][: params [ 'num_top_frequencies' ]]) ] # The frequencies that the POD is able to capture have now been identified (in the top 'num_top_frequencies' modes). # These frequencies can be fitted to the temporal coefficients of the top 'num_top_frequencies' modes, # allowing for a representation of the data described solely by these \"pure\" frequencies. # This approach enables the reconstruction of the original data using the identified dominant frequencies, # resulting in frequency-filtered spatial POD modes. clean_data = np . zeros (( inp . shape [ 0 ], inp . shape [ 1 ], 10 )) if params [ 'top_frequencies' ] is None : top_frequencies = sorted_frequencies [: params [ 'num_top_frequencies' ]] else : top_frequencies = params [ 'top_frequencies' ] params [ 'num_top_frequencies' ] = len ( params [ 'top_frequencies' ]) for i in range ( params [ 'num_top_frequencies' ]): def model_fun ( t , amplitude , phase ): \"\"\" Generate a sinusoidal model function. Parameters: t (array-like): The time variable. amplitude (float): The amplitude of the sinusoidal function. phase (float): The phase shift of the sinusoidal function. Returns: array-like: The computed sinusoidal values at each time point `t`. \"\"\" return amplitude * np . sin ( 2 * np . pi * top_frequencies [ i ] * t + phase ) for j in range ( params [ 'num_modes_reconstruct' ]): csignal = a [ j ,:] # Initial Guesses for Parameters: [Amplitude, Phase] initial_guess = [ 1 , 0 ] # Nonlinear Fit fit_params , _ = curve_fit ( model_fun , time , csignal , p0 = initial_guess ) # Clean Signal from Fit if j == 0 : clean_signal = np . zeros (( params [ 'num_modes_reconstruct' ], len ( csignal ))) clean_signal [ j ,:] = model_fun ( time , * fit_params ) # forming a set of clean data (reconstructed data at the fitted frequencies; frequency filtered reconstructed data) clean_data [:,:, i ] = p [:, 0 : params [ 'num_modes_reconstruct' ]] @np . diag ( sorg [ 0 : params [ 'num_modes_reconstruct' ]]) @clean_signal frequency_filtered_modes = np . zeros (( data . shape [ 0 ], data . shape [ 1 ], data . shape [ 2 ], params [ 'num_top_frequencies' ])) for jj in range ( params [ 'num_top_frequencies' ]): for frame_index in range ( data . shape [ 0 ]): frequency_filtered_modes [ frame_index , :, :, jj ] = np . reshape ( clean_data [:, frame_index , jj ], ( data . shape [ 1 ], data . shape [ 2 ])) if params [ 'spod' ]: SPOD_spatial_modes , SPOD_temporal_coefficients = spod ( data , num_modes = params [ 'spod_num_modes' ], filter_size = params [ 'spod_filter_size' ]) else : SPOD_spatial_modes = None SPOD_temporal_coefficients = None results = { 'input_data' : input_dat , # Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) 'spatial_mode' : spatial_mode , # POD spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) 'temporal_coefficient' : temporal_coefficient , # POD temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) 'eigenvalue' : eigenvalue , # Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) 'eigenvalue_contribution' : eigenvalue_contribution , # Eigenvalue contribution of each mode (Shape: (Nmodes)) 'cumulative_eigenvalues' : cumulative_eigenvalues , # Cumulative percentage of eigenvalues for the first 'num_cumulative_modes' modes (Shape: (Ncumulative_modes)) 'combined_welch_psd' : combined_welch_psd , # Combined Welch power spectral density for the temporal coefficients (Shape: (Nf)) 'frequencies' : frequencies , # Frequencies identified in the Welch spectrum (Shape: (Nf)) 'combined_welch_significance' : combined_welch_significance , # Significance threshold of the combined Welch spectrum (Shape: (Nf)) 'reconstructed' : reconstructed , # Reconstructed frame at the specified timestep (or for the entire time series) using the top modes (Shape: (Ny, Nx)) 'sorted_frequencies' : sorted_frequencies , # Frequencies identified in the Welch spectrum (Shape: (Nfrequencies,)) 'frequency_filtered_modes' : frequency_filtered_modes , # Frequency-filtered spatial POD modes (Shape: (Nt, Ny, Nx, Ntop_frequencies)) 'frequency_filtered_modes_frequencies' : top_frequencies , # Frequencies corresponding to the frequency-filtered modes (Shape: (Ntop_frequencies)) 'SPOD_spatial_modes' : SPOD_spatial_modes , # SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) 'SPOD_temporal_coefficients' : SPOD_temporal_coefficients , # SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) 'p' : p , # Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) 's' : sorg , # Singular values from SVD (Shape: (Nmodes,)) 'a' : a # Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) } if not params [ 'silent' ]: print ( f \"POD analysis completed.\" ) print ( f \"Top { params [ 'num_top_frequencies' ] } frequencies and normalized power values: \\n { table_data } \" ) print ( f \"Total variance contribution of the first { params [ 'num_modes' ] } modes: { np . sum ( 100 * eigenvalue [: params [ 'num_modes' ]] / np . sum ( eigenvalue )) : .2f } %\" ) if params [ 'print_results' ]: print_pod_results ( results ) return results WaLSA_cross_spectra.py This module implements cross-correlation analysis techniques, resulting in cross-spectrum, coherence, and phase relationships, for investigating correlations between two time series. WaLSA_cross_spectra.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.signal import coherence , csd # type: ignore from .WaLSA_speclizer import WaLSA_speclizer # type: ignore from .WaLSA_wavelet import xwt , wct # type: ignore from .WaLSA_detrend_apod import WaLSA_detrend_apod # type: ignore from .WaLSA_wavelet_confidence import WaLSA_wavelet_confidence # type: ignore # -------------------------------------- Main Function ---------------------------------------- def WaLSA_cross_spectra ( signal = None , time = None , method = None , ** kwargs ): \"\"\" Compute the cross-spectra between two time series. Parameters: data1 (array): The first time series (1D). data2 (array): The first time series (1D). time (array): The time array of the signals. method (str): The method to use for the analysis. Options are 'welch' and 'wavelet'. \"\"\" if method == 'welch' : return getcross_spectrum_Welch ( signal , time = time , ** kwargs ) elif method == 'wavelet' : return getcross_spectrum_Wavelet ( signal , time = time , ** kwargs ) elif method == 'fft' : print ( \"Note: FFT method selected. Cross-spectra calculations will use the Welch method instead, \" \"which segments the signal into multiple parts to reduce noise sensitivity. \" \"You can control frequency resolution vs. noise reduction using the 'nperseg' parameter.\" ) return getcross_spectrum_Welch ( signal , time = time , ** kwargs ) else : raise ValueError ( f \"Unknown method: { method } \" ) # -------------------------------------- Welch ---------------------------------------- def getcross_spectrum_Welch ( signal , time , ** kwargs ): \"\"\" Calculate cross-spectral relationships of two time series whose amplitudes and powers are computed using the WaLSA_speclizer routine. The cross-spectrum is complex valued, thus its magnitude is returned as the co-spectrum. The phase lags between the two time series are are estimated from the imaginary and real arguments of the complex cross spectrum. The coherence is calculated from the normalized square of the amplitude of the complex cross-spectrum Parameters: data1 (array): The first 1D time series signal. data2 (array): The second 1D time series signal. time (array): The time array corresponding to the signals. nperseg (int, optional): Length of each segment for analysis. Default: 256. noverlap (int, optional): Number of points to overlap between segments. Default: 128. window (str, optional): Type of window function used in the Welch method. Default: 'hann'. siglevel (float, optional): Significance level for confidence intervals. Default: 0.95. nperm (int, optional): Number of permutations for significance testing. Default: 1000. silent (bool, optional): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: cospectrum, frequencies, phase_angle, coherence, signif_cross, signif_coh, d1_power, d2_power \"\"\" # Define default values for the optional parameters defaults = { 'data1' : None , # First data array 'data1' : None , # Second data array 'nperseg' : 256 , # Number of points per segments to average 'apod' : 0.1 , # Apodization function 'nodetrendapod' : None , # No detrending ot apodization applied 'pxdetrend' : 2 , # Detrend parameter 'meandetrend' : None , # Detrend parameter 'polyfit' : None , # Detrend parameter 'meantemporal' : None , # Detrend parameter 'recon' : None # Detrend parameter } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } data1 = params [ 'data1' ] data2 = params [ 'data2' ] dummy = signal + 2 tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Power spectrum for data1 power_data1 , frequencies , _ = WaLSA_speclizer ( signal = data1 , time = time , method = 'welch' , amplitude = True , nosignificance = True , silent = kwargs . pop ( 'silent' , True ), ** kwargs ) # Power spectrum for data2 power_data2 , _ , _ = WaLSA_speclizer ( signal = data2 , time = time , method = 'welch' , amplitude = True , nosignificance = True , silent = kwargs . pop ( 'silent' , False ), ** kwargs ) # Calculate cross-spectrum _ , crosspower = csd ( data1 , data2 , fs = 1.0 / cadence , window = 'hann' , nperseg = params [ 'nperseg' ],) cospectrum = np . abs ( crosspower ) # Calculate phase lag phase_angle = np . angle ( crosspower , deg = True ) # Calculate coherence freq_coh , coh = coherence ( data1 , data2 , 1.0 / cadence , nperseg = params [ 'nperseg' ]) return frequencies , cospectrum , phase_angle , power_data1 , power_data2 , freq_coh , coh # -------------------------------------- Wavelet ---------------------------------------- def getcross_spectrum_Wavelet ( signal , time , ** kwargs ): \"\"\" Calculate the cross-power spectrum, coherence spectrum, and phase angles between two signals using Wavelet Transform. Parameters: data1 (array): The first 1D time series signal. data2 (array): The second 1D time series signal. time (array): The time array corresponding to the signals. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. mother (str): The mother wavelet function to use. Default: 'morlet'. GWS (bool): If True, calculate the Global Wavelet Spectrum. Default: False. RGWS (bool): If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False. dj (float): Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025. s0 (float): Initial (smallest) scale of the wavelet. Default: 2 * dt. J (int): Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj. lag1 (float): Lag-1 autocorrelation. Default: 0.0. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. Returns: cross_power : np.ndarray Cross power spectrum between `data1` and `data2`. cross_periods : np.ndarray Periods corresponding to the cross-power spectrum. cross_sig : np.ndarray Significance of the cross-power spectrum. cross_coi : np.ndarray Cone of influence for the cross-power spectrum. coherence : np.ndarray Coherence spectrum between `data1` and `data2`. coh_periods : np.ndarray Periods corresponding to the coherence spectrum. coh_sig : np.ndarray Significance of the coherence spectrum. corr_coi : np.ndarray Cone of influence for the coherence spectrum. phase_angle : np.ndarray 2D array containing x- and y-components of the phase direction arrows for each frequency and time point. Notes ----- - Cross-power, coherence, and phase angles are calculated using **cross-wavelet transform (XWT)** and **wavelet coherence transform (WCT)**. - Arrows for phase direction are computed such that: - Arrows pointing downwards indicate anti-phase. - Arrows pointing upwards indicate in-phase. - Arrows pointing right indicate `data1` leading `data2`. - Arrows pointing left indicate `data2` leading `data1`. Examples -------- >>> cross_power, cross_periods, cross_sig, cross_coi, coherence, coh_periods, coh_sig, corr_coi, phase_angle, dt = \\ >>> getcross_spectrum_Wavelet(signal, cadence, data1=signal1, data2=signal2) \"\"\" # Define default values for optional parameters defaults = { 'data1' : None , # First data array 'data2' : None , # Second data array 'mother' : 'morlet' , # Type of mother wavelet 'siglevel' : 0.95 , # Significance level for cross-spectral analysis 'dj' : 0.025 , # Spacing between scales 's0' : - 1 , # Initial scale 'J' : - 1 , # Number of scales 'cache' : False , # Cache results to avoid recomputation 'apod' : 0.1 , 'silent' : False , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'nperm' : 1000 # Number of permutations for significance testing } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } data1 = params [ 'data1' ] data2 = params [ 'data2' ] dummy = signal + 2 tdiff = np . diff ( time ) cadence = np . median ( tdiff ) data1orig = data1 . copy () data2orig = data2 . copy () data1 = WaLSA_detrend_apod ( data1 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) data2 = WaLSA_detrend_apod ( data2 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) # Calculate signal properties nt = len ( params [ 'data1' ]) # Number of time points # Determine the initial scale s0 if not provided if params [ 's0' ] == - 1 : params [ 's0' ] = 2 * cadence # Determine the number of scales J if not provided if params [ 'J' ] == - 1 : params [ 'J' ] = int (( np . log ( float ( nt ) * cadence / params [ 's0' ]) / np . log ( 2 )) / params [ 'dj' ]) # ----------- CROSS-WAVELET TRANSFORM (XWT) ----------- W12 , cross_coi , freq , signif = xwt ( data1 , data2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], no_default_signif = True , wavelet = params [ 'mother' ], normalize = False ) print ( 'Wavelet cross-power spectrum calculated.' ) # Calculate the cross-power spectrum cross_power = np . abs ( W12 ) ** 2 cross_periods = 1 / freq # Periods corresponding to the frequency axis #---------------------------------------------------------------------- # Calculate significance levels using Monte Carlo randomization method #---------------------------------------------------------------------- nxx , nyy = cross_power . shape cross_perm = np . zeros (( nxx , nyy , params [ 'nperm' ])) print ( ' \\n Calculating wavelet cross-power significance:' ) total_iterations = params [ 'nperm' ] # Total number of (x, y) combinations iteration_count = 0 # To keep track of progress for ip in range ( params [ 'nperm' ]): iteration_count += 1 progress = ( iteration_count / total_iterations ) * 100 print ( f \" \\r Progress: { progress : .2f } %\" , end = \"\" ) y_perm1 = np . random . permutation ( data1orig ) # Permuting the original signal apocube1 = WaLSA_detrend_apod ( y_perm1 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) y_perm2 = np . random . permutation ( data2orig ) # Permuting the original signal apocube2 = WaLSA_detrend_apod ( y_perm2 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) W12s , _ , _ , _ = xwt ( apocube1 , apocube2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], no_default_signif = True , wavelet = params [ 'mother' ], normalize = False ) cross_power_sig = np . abs ( W12s ) ** 2 cross_perm [:, :, ip ] = cross_power_sig signifn = WaLSA_wavelet_confidence ( cross_perm , siglevel = params [ 'siglevel' ]) cross_sig = cross_power / signifn # ----------- WAVELET COHERENCE TRANSFORM (WCT) ----------- WCT , aWCT , coh_coi , freq , sig = wct ( data1 , data2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], sig = False , wavelet = params [ 'mother' ], normalize = False , cache = params [ 'cache' ] ) print ( 'Wavelet coherence calculated.' ) # Calculate the coherence spectrum coh_periods = 1 / freq # Periods corresponding to the frequency axis coherence = WCT #---------------------------------------------------------------------- # Calculate significance levels using Monte Carlo randomization method #---------------------------------------------------------------------- nxx , nyy = coherence . shape coh_perm = np . zeros (( nxx , nyy , params [ 'nperm' ])) print ( ' \\n Calculating wavelet coherence significance:' ) total_iterations = params [ 'nperm' ] # Total number of permutations iteration_count = 0 # To keep track of progress for ip in range ( params [ 'nperm' ]): iteration_count += 1 progress = ( iteration_count / total_iterations ) * 100 print ( f \" \\r Progress: { progress : .2f } %\" , end = \"\" ) y_perm1 = np . random . permutation ( data1orig ) # Permuting the original signal apocube1 = WaLSA_detrend_apod ( y_perm1 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) y_perm2 = np . random . permutation ( data2orig ) # Permuting the original signal apocube2 = WaLSA_detrend_apod ( y_perm2 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) WCTs , _ , _ , _ , _ = wct ( apocube1 , apocube2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], sig = False , wavelet = params [ 'mother' ], normalize = False , cache = params [ 'cache' ] ) coh_perm [:, :, ip ] = WCTs sig_coh = WaLSA_wavelet_confidence ( coh_perm , siglevel = params [ 'siglevel' ]) coh_sig = coherence / sig_coh # Ratio > 1 means coherence is significant # --------------- PHASE ANGLES --------------- phase_angle = aWCT return ( cross_power , cross_periods , cross_sig , cross_coi , coherence , coh_periods , coh_sig , coh_coi , phase_angle ) WaLSA_detrend_apod.py This module provides functions for detrending and apodizing time series data to mitigate trends and edge effects. WaLSA_detrend_apod.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.optimize import curve_fit # type: ignore from .WaLSA_wavelet import cwt , significance # type: ignore # -------------------------------------- Wavelet ---------------------------------------- def getWavelet ( signal , time , ** kwargs ): \"\"\" Perform wavelet analysis using the pycwt package. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. mother (str): The mother wavelet function to use. Default: 'morlet'. GWS (bool): If True, calculate the Global Wavelet Spectrum. Default: False. RGWS (bool): If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False. dj (float): Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025. s0 (float): Initial (smallest) scale of the wavelet. Default: 2 * dt. J (int): Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj. lag1 (float): Lag-1 autocorrelation. Default: 0.0. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: power: The wavelet power spectrum. periods: Corresponding periods. sig_slevel: The significance levels. coi: The cone of influence. Optionally, if global_power=True: global_power: Global wavelet power spectrum. global_conf: Confidence levels for the global wavelet spectrum. Optionally, if RGWS=True: rgws_periods: Periods for the refined global wavelet spectrum. rgws_power: Refined global wavelet power spectrum. \"\"\" # Define default values for the optional parameters similar to IDL defaults = { 'siglevel' : 0.95 , 'mother' : 'morlet' , # Morlet wavelet as the mother function 'dj' : 1 / 32. , # Scale spacing 's0' : - 1 , # Initial scale 'J' : - 1 , # Number of scales 'lag1' : 0.0 , # Lag-1 autocorrelation 'silent' : False , 'nperm' : 1000 , # Number of permutations for significance calculation } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) n = len ( signal ) dt = cadence # Standardize the signal before the wavelet transform std_signal = signal . std () norm_signal = signal / std_signal # Determine the initial scale s0 if not provided if params [ 's0' ] == - 1 : params [ 's0' ] = 2 * dt # Determine the number of scales J if not provided if params [ 'J' ] == - 1 : params [ 'J' ] = int (( np . log ( float ( n ) * dt / params [ 's0' ]) / np . log ( 2 )) / params [ 'dj' ]) # Perform wavelet transform W , scales , frequencies , coi , _ , _ = cwt ( norm_signal , dt , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], wavelet = params [ 'mother' ] ) power = np . abs ( W ) ** 2 # Wavelet power spectrum periods = 1 / frequencies # Convert frequencies to periods return power , periods , coi , scales , W # ----------------------------------------------------------------------------------------------------- # Linear detrending function for curve fitting def linear ( x , a , b ): return a + b * x # Custom Tukey window implementation def custom_tukey ( nt , apod = 0.1 ): apodrim = int ( apod * nt ) apodt = np . ones ( nt ) # Initialize with ones # Apply sine-squared taper to the first 'apodrim' points taper = ( np . sin ( np . pi / 2. * np . arange ( apodrim ) / apodrim )) ** 2 # Apply taper symmetrically at both ends apodt [: apodrim ] = taper apodt [ - apodrim :] = taper [:: - 1 ] # Reverse taper for the last points return apodt # Main detrending and apodization function # apod=0: The Tukey window becomes a rectangular window (no tapering). # apod=1: The Tukey window becomes a Hann window (fully tapered with a cosine function). def WaLSA_detrend_apod ( cube , apod = 0.1 , meandetrend = False , pxdetrend = 2 , polyfit = None , meantemporal = False , recon = False , cadence = None , resample_original = False , min_resample = None , max_resample = None , silent = False , dj = 32 , lo_cutoff = None , hi_cutoff = None , upper = False ): nt = len ( cube ) # Assume input is a 1D signal cube = cube - np . mean ( cube ) # Remove the mean of the input signal apocube = np . copy ( cube ) # Create a copy of the input signal t = np . arange ( nt ) # Time array # Apply Tukey window (apodization) if apod > 0 : tukey_window = custom_tukey ( nt , apod ) apocube = apocube * tukey_window # Apodize the signal # Mean detrend (optional) if meandetrend : avg_signal = np . mean ( apocube ) time = np . arange ( nt ) mean_fit_params , _ = curve_fit ( linear , time , avg_signal ) mean_trend = linear ( time , * mean_fit_params ) apocube -= mean_trend # Wavelet-based Fourier reconstruction (optional) if recon and cadence : apocube = WaLSA_wave_recon ( apocube , cadence , dj = dj , lo_cutoff = lo_cutoff , hi_cutoff = hi_cutoff , upper = upper ) # Pixel-based detrending (temporal detrend) if pxdetrend > 0 : mean_val = np . mean ( apocube ) if meantemporal : # Simple temporal detrend by subtracting the mean apocube -= mean_val else : # Advanced detrend (linear or polynomial fit) if polyfit is not None : poly_coeffs = np . polyfit ( t , apocube , polyfit ) trend = np . polyval ( poly_coeffs , t ) else : popt , _ = curve_fit ( linear , t , apocube , p0 = [ mean_val , 0 ]) trend = linear ( t , * popt ) apocube -= trend # Resampling to preserve amplitudes (optional) if resample_original : if min_resample is None : min_resample = np . min ( apocube ) if max_resample is None : max_resample = np . max ( apocube ) apocube = np . interp ( apocube , ( np . min ( apocube ), np . max ( apocube )), ( min_resample , max_resample )) if not silent : print ( \"Detrending and apodization complete.\" ) return apocube # Wavelet-based reconstruction function (optional) def WaLSA_wave_recon ( ts , delt , dj = 32 , lo_cutoff = None , hi_cutoff = None , upper = False ): \"\"\" Reconstructs the wavelet-filtered time series based on given frequency cutoffs. \"\"\" # Define duration based on the time series length dur = ( len ( ts ) - 1 ) * delt # Assign default values if lo_cutoff or hi_cutoff is None if lo_cutoff is None : lo_cutoff = 0.0 # Default to 0 as in IDL if hi_cutoff is None : hi_cutoff = dur / ( 3.0 * np . sqrt ( 2 )) mother = 'morlet' num_points = len ( ts ) time_array = np . linspace ( 0 , ( num_points - 1 ) * delt , num_points ) _ , period , coi , scales , wave = getWavelet ( signal = ts , time = time_array , method = 'wavelet' , siglevel = 0.99 , apod = 0.1 , mother = mother ) # Ensure good_per_idx and bad_per_idx are properly assigned if upper : good_per_idx = np . where ( period > hi_cutoff )[ 0 ][ 0 ] bad_per_idx = len ( period ) else : good_per_idx = np . where ( period > lo_cutoff )[ 0 ][ 0 ] bad_per_idx = np . where ( period > hi_cutoff )[ 0 ][ 0 ] # set the power inside the CoI equal to zero # (i.e., exclude points inside the CoI -- subject to edge effect) iampl = np . zeros (( len ( ts ), len ( period )), dtype = float ) for i in range ( len ( ts )): pcol = np . real ( wave [:, i ]) # Extract real part of wavelet transform for this time index ii = np . where ( period < coi [ i ])[ 0 ] # Find indices where period is less than COI at time i if ii . size > 0 : iampl [ i , ii ] = pcol [ ii ] # Assign values where condition is met # Initialize reconstructed signal array recon_sum = np . zeros ( len ( ts )) # Summation over valid period indices for i in range ( good_per_idx , bad_per_idx ): recon_sum += iampl [:, i ] / np . sqrt ( scales [ i ]) # Apply normalization factor recon_all = dj * np . sqrt ( delt ) * recon_sum / ( 0.766 * ( np . pi ** - 0.25 )) return recon_all WaLSA_confidence.py This module implements statistical significance testing for the spectral analysis results using various methods. WaLSA_confidence.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore def WaLSA_confidence ( ps_perm , siglevel = 0.05 , nf = None ): \"\"\" Find the confidence levels (significance levels) for the given power spectrum permutations. Parameters: ----------- ps_perm : np.ndarray 2D array where each row represents a power spectrum, and each column represents a permutation. siglevel : float Significance level (default 0.05 for 95% confidence). nf : int Number of frequencies (length of the power spectra). If None, inferred from the shape of ps_perm. Returns: -------- signif : np.ndarray Significance levels for each frequency. \"\"\" if nf is None : nf = ps_perm . shape [ 0 ] # Number of frequencies inferred from the shape of ps_perm signif = np . zeros (( nf )) # Loop through each frequency for iv in range ( nf ): # Extract the permutation values for this frequency tmp = np . sort ( ps_perm [ iv , :]) # Sort the power spectrum permutation values # Calculate the number of permutations ntmp = len ( tmp ) # Find the significance threshold nsig = int ( round ( siglevel * ntmp )) # Number of permutations to cut off for the significance level # Set the confidence level for this frequency signif [ iv ] = tmp [ - nsig ] # Select the (ntmp - nsig)-th element (equivalent to IDL's ROUND and indexing) return signif WaLSA_wavelet_confidence.py This module implements statistical significance testing for the wavelet analysis results. WaLSA_wavelet_confidence.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore def WaLSA_wavelet_confidence ( ps_perm , siglevel = None ): \"\"\" Find the confidence levels (significance levels) for the given wavelet power spectrum permutations. Parameters: ----------- ps_perm : np.ndarray 2D array where each row represents a power spectrum, and each column represents a permutation. siglevel : float e.g., 0.95 for 95% confidence level (significance at 5%). Returns: -------- signif : np.ndarray Significance levels for each frequency. \"\"\" nnff , nntt , nnperm = ps_perm . shape signif = np . zeros (( nnff , nntt )) for iv in range ( nnff ): for it in range ( nntt ): signif [ iv , it ] = np . percentile ( ps_perm [ iv , it , :], 100 * siglevel ) # e.g., 95% percentile (for 95% consideence level) return signif WaLSA_io.py This module provides functions for input/output operations, such as saving images as PDF (in both RGB and CMYK formats) and image contrast enhancements. WaLSA_io.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import subprocess import shutil import os import stat import numpy as np # type: ignore from matplotlib.backends.backend_pdf import PdfPages # type: ignore def WaLSA_save_pdf ( fig , pdf_path , color_mode = 'RGB' , dpi = 300 , bbox_inches = None , pad_inches = 0 ): \"\"\" Save a PDF from a Matplotlib figure with an option to convert to CMYK if Ghostscript is available. Parameters: - fig: Matplotlib figure object to save. - pdf_path: Path to save the PDF file. - color_mode: 'RGB' (default) to save in RGB, or 'CMYK' to convert to CMYK. - dpi: Resolution in dots per inch. Default is 300. - bbox_inches: Set to 'tight' to remove extra white space. Default is 'tight'. - pad_inches: Padding around the figure. Default is 0. \"\"\" # Save the initial PDF in RGB format using fig.savefig to apply bbox_inches, pad_inches, and dpi if bbox_inches is None : # Save the initial PDF in RGB format with PdfPages ( pdf_path ) as pdf : pdf . savefig ( fig , transparent = True ) if color_mode . upper () == 'CMYK' : # Check if Ghostscript is installed if shutil . which ( \"gs\" ) is not None : # Set permissions on the initial RGB PDF to ensure access for Ghostscript os . chmod ( pdf_path , stat . S_IRUSR | stat . S_IWUSR | stat . S_IRGRP | stat . S_IROTH ) # Define a temporary path for the CMYK file temp_cmyk_path = pdf_path . replace ( '.pdf' , '_temp_cmyk.pdf' ) # Run Ghostscript to create the CMYK PDF as a temporary file subprocess . run ([ \"gs\" , \"-o\" , temp_cmyk_path , \"-sDEVICE=pdfwrite\" , \"-dProcessColorModel=/DeviceCMYK\" , \"-dColorConversionStrategy=/CMYK\" , \"-dNOPAUSE\" , \"-dBATCH\" , \"-dSAFER\" , \"-dPDFSETTINGS=/prepress\" , pdf_path ], check = True ) # Replace the original RGB PDF with the CMYK version os . remove ( pdf_path ) # Delete the RGB version os . rename ( temp_cmyk_path , pdf_path ) # Rename CMYK as the original file print ( f \"PDF saved in CMYK format as ' { pdf_path } '\" ) else : print ( \"Warning: Ghostscript is not installed, so the PDF remains in RGB format.\" ) print ( \"To enable CMYK saving, please install Ghostscript:\" ) print ( \"- On macOS, use: brew install ghostscript\" ) print ( \"- On Ubuntu, use: sudo apt install ghostscript\" ) print ( \"- On Windows, download from: https://www.ghostscript.com/download.html\" ) else : print ( f \"PDF saved in RGB format as ' { pdf_path } '\" ) else : # Temporary path for the RGB version of the PDF temp_pdf_path = pdf_path . replace ( '.pdf' , '_temp.pdf' ) fig . savefig ( temp_pdf_path , format = 'pdf' , dpi = dpi , bbox_inches = bbox_inches , pad_inches = pad_inches , transparent = True ) if color_mode . upper () == 'CMYK' : # Check if Ghostscript is installed if shutil . which ( \"gs\" ) is not None : # Set permissions on the initial RGB PDF to ensure access for Ghostscript os . chmod ( temp_pdf_path , stat . S_IRUSR | stat . S_IWUSR | stat . S_IRGRP | stat . S_IROTH ) # Run Ghostscript to create the CMYK PDF as a temporary file subprocess . run ([ \"gs\" , \"-o\" , pdf_path , \"-sDEVICE=pdfwrite\" , \"-dProcessColorModel=/DeviceCMYK\" , \"-dColorConversionStrategy=/CMYK\" , \"-dNOPAUSE\" , \"-dBATCH\" , \"-dSAFER\" , \"-dPDFSETTINGS=/prepress\" , temp_pdf_path ], check = True ) # Remove the temporary PDF file os . remove ( temp_pdf_path ) print ( f \"PDF saved in CMYK format as ' { pdf_path } '\" ) else : print ( \"Warning: Ghostscript is not installed, so the PDF remains in RGB format.\" ) print ( \"To enable CMYK saving, please install Ghostscript:\" ) print ( \"- On macOS, use: brew install ghostscript\" ) print ( \"- On Ubuntu, use: sudo apt install ghostscript\" ) print ( \"- On Windows, download from: https://www.ghostscript.com/download.html\" ) else : # Rename the temporary file as the final file if no CMYK conversion is needed os . rename ( temp_pdf_path , pdf_path ) print ( f \"PDF saved in RGB format as ' { pdf_path } '\" ) def WaLSA_histo_opt ( image , cutoff = 1e-3 , top_only = False , bot_only = False ): \"\"\" Clip image values based on the cutoff percentile to enhance contrast. Inspired by IDL's \"iris_histo_opt\" function (Copyright: P.Suetterlin, V.Hansteen, and M. Carlsson) Parameters: - image: 2D array (image data). - cutoff: Fraction of values to clip at the top and bottom (default is 0.001). - top_only: If True, clip only the highest values. - bot_only: If True, clip only the lowest values. Returns: - Clipped image for better contrast. \"\"\" # Ignore NaNs in the image finite_values = image [ np . isfinite ( image )] # Calculate lower and upper bounds based on cutoff percentiles lower_bound = np . percentile ( finite_values , cutoff * 100 ) upper_bound = np . percentile ( finite_values , ( 1 - cutoff ) * 100 ) # Clip image according to bounds and options if top_only : return np . clip ( image , None , upper_bound ) elif bot_only : return np . clip ( image , lower_bound , None ) else : return np . clip ( image , lower_bound , upper_bound ) WaLSA_interactive.py This module implements the interactive interface of WaLSAtools, guiding users through the analysis process. WaLSA_interactive.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import ipywidgets as widgets # type: ignore from IPython.display import display , clear_output , HTML # type: ignore import os # type: ignore # Function to detect if it's running in a notebook or terminal def is_notebook (): try : # Check if IPython is in the environment and if we're using a Jupyter notebook from IPython import get_ipython # type: ignore shell = get_ipython () . __class__ . __name__ if shell == 'ZMQInteractiveShell' : return True # Jupyter notebook or qtconsole elif shell == 'TerminalInteractiveShell' : return False # IPython terminal else : return False # Other types except ( NameError , ImportError ): # NameError: get_ipython is not defined # ImportError: IPython is not installed return False # Standard Python interpreter or shell # Function to print logo and credits for both environments def print_logo_and_credits (): logo_terminal = r \"\"\" __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \"\"\" credits_terminal = \"\"\" \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------- WaLSAtools v1.0.0 - Wave analysis tools Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------- If you use WaLSAtools in your research, please cite: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 Free access to a view-only version: https://WaLSA.tools/nrmp Supplementary Information: https://WaLSA.tools/nrmp-si ----------------------------------------------------------------------- Choose a category, data type, and analysis method from the list below, to get hints on the calling sequence and parameters: \"\"\" credits_notebook = \"\"\" <div style=\"margin-left: 30px; margin-top: 20px; font-size: 1.1em; line-height: 0.8;\"> <p>\u00a9 WaLSA Team (<a href=\"https://www.WaLSA.team\" target=\"_blank\">www.WaLSA.team</a>)</p> <hr style=\"width: 70%; margin: 0; border: 0.98px solid #888; margin-bottom: 10px;\"> <p><strong>WaLSAtools</strong> v1.0.0 - Wave analysis tools</p> <p>Documentation: <a href=\"https://www.WaLSA.tools\" target=\"_blank\">www.WaLSA.tools</a></p> <p>GitHub repository: <a href=\"https://www.github.com/WaLSAteam/WaLSAtools\" target=\"_blank\">www.github.com/WaLSAteam/WaLSAtools</a></p> <hr style=\"width: 70%; margin: 0; border: 0.98px solid #888; margin-bottom: 10px;\"> <p>If you use <strong>WaLSAtools</strong> in your research, please cite:</p> <p>Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, <em>Nature Reviews Methods Primers</em>, 5, 21</p> <p>Free access to a view-only version: <a href=\"https://WaLSA.tools/nrmp\" target=\"_blank\">www.WaLSA.tools</a></p> <p>Supplementary Information: <a href=\"https://WaLSA.tools/nrmp-si\" target=\"_blank\">www.WaLSA.tools</a></p> <hr style=\"width: 70%; margin: 0; border: 0.98px solid #888; margin-bottom: 15px;\"> <p>Choose a category, data type, and analysis method from the list below,</p> <p>to get hints on the calling sequence and parameters:</p> </div> \"\"\" if is_notebook (): try : # For scripts current_dir = os . path . dirname ( os . path . abspath ( __file__ )) except NameError : # For Jupyter notebooks current_dir = os . getcwd () img_path = os . path . join ( current_dir , '..' , 'assets' , 'WaLSAtools_black.png' ) # display(HTML(f'<img src=\"{img_path}\" style=\"margin-left: 40px; margin-top: 20px; width:300px; height: auto;\">')) # not shwon in Jupyter notebook, only in MS Code import base64 # Convert the image to Base64 with open ( img_path , \"rb\" ) as img_file : encoded_img = base64 . b64encode ( img_file . read ()) . decode ( 'utf-8' ) # Embed the Base64 image in the HTML html_code_logo = f \"\"\" <div style=\"margin-left: 30px; margin-top: 20px;\"> <img src=\"data:image/png;base64, { encoded_img } \" style=\"width: 300px; height: auto;\"> </div> \"\"\" display ( HTML ( html_code_logo )) display ( HTML ( credits_notebook )) else : print ( logo_terminal ) print ( credits_terminal ) from .parameter_definitions import display_parameters_text , single_series_parameters , cross_correlation_parameters # Terminal-based interactive function import textwrap import shutil def walsatools_terminal (): \"\"\"Main interactive function for terminal version of WaLSAtools.\"\"\" print_logo_and_credits () # Get terminal width terminal_width = shutil . get_terminal_size () . columns # Calculate 90% of the width (and ensure it's an integer) line_width = int ( terminal_width * 0.90 ) # Step 1: Select Category while True : print ( \" \\n Category:\" ) print ( \" (a) Single time series analysis\" ) print ( \" (b) Cross-correlation between two time series\" ) category = input ( \" --- Select a category (a/b): \" ) . strip () . lower () if category not in [ 'a' , 'b' ]: print ( \" Invalid selection. Please enter either 'a' or 'b'. \\n \" ) continue # Step 2: Data Type if category == 'a' : while True : print ( \" \\n Data Type:\" ) print ( \" (1) 1D signal\" ) print ( \" (2) 3D datacube\" ) method = input ( \" --- Select a data type (1/2): \" ) . strip () if method not in [ '1' , '2' ]: print ( \" Invalid selection. Please enter either '1' or '2'. \\n \" ) continue # Step 3: Analysis Method if method == '1' : # 1D Signal while True : print ( \" \\n Analysis Method:\" ) print ( \" (1) FFT\" ) print ( \" (2) Wavelet\" ) print ( \" (3) Lomb-Scargle\" ) print ( \" (4) Welch\" ) print ( \" (5) EMD\" ) analysis_type = input ( \" --- Select an analysis method (1-5): \" ) . strip () method_map_1d = { '1' : 'fft' , '2' : 'wavelet' , '3' : 'lombscargle' , '4' : 'welch' , '5' : 'emd' } selected_method = method_map_1d . get ( analysis_type , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid analysis method (1-5). \\n \" ) continue # Generate and display the calling sequence for 1D signal print ( \" \\n Calling sequence: \\n \" ) return_values = single_series_parameters [ selected_method ][ 'return_values' ] command = f \">>> { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'a' ) return # Exit the function after successful output elif method == '2' : # 3D Datacube while True : print ( \" \\n Analysis Method:\" ) print ( \" (1) k-omega\" ) print ( \" (2) POD\" ) print ( \" (3) Dominant Freq / Mean Power Spectrum\" ) analysis_type = input ( \" --- Select an analysis method (1-3): \" ) . strip () if analysis_type == '3' : # Sub-method required while True : print ( \" \\n Analysis method for Dominant Freq / Mean Power Spectrum:\" ) print ( \" (1) FFT\" ) print ( \" (2) Wavelet\" ) print ( \" (3) Lomb-Scargle\" ) print ( \" (4) Welch\" ) sub_method = input ( \" --- Select a method (1-4): \" ) . strip () sub_method_map = { '1' : 'fft' , '2' : 'wavelet' , '3' : 'lombscargle' , '4' : 'welch' } selected_method = sub_method_map . get ( sub_method , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid sub-method (1-4). \\n \" ) continue # Generate and display the calling sequence for sub-method print ( \" \\n Calling sequence: \\n \" ) return_values = 'dominant_frequency, mean_power, frequency, power_map' command = f \">>> { return_values } = WaLSAtools(data=INPUT_DATA, time=TIME_ARRAY, averagedpower=True, dominantfreq=True, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'a' ) return # Exit the function after successful output method_map_3d = { '1' : 'k-omega' , '2' : 'pod' } selected_method = method_map_3d . get ( analysis_type , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid analysis method (1-3). \\n \" ) continue # Generate and display the calling sequence for k-omega/POD print ( \" \\n Calling sequence: \\n \" ) return_values = single_series_parameters [ selected_method ][ 'return_values' ] command = f \">>> { return_values } = WaLSAtools(data1=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'a' ) return # Exit the function after successful output elif category == 'b' : # Cross-correlation while True : print ( \" \\n Data Type:\" ) print ( \" (1) 1D signal\" ) method = input ( \" --- Select a data type (1): \" ) . strip () if method != '1' : print ( \" Invalid selection. Please enter '1'. \\n \" ) continue while True : print ( \" \\n Analysis Method:\" ) print ( \" (1) FFT\" ) print ( \" (2) Wavelet\" ) print ( \" (3) Welch\" ) analysis_type = input ( \" --- Select an analysis method (1-2): \" ) . strip () cross_correlation_map = { '1' : 'fft' , '2' : 'wavelet' , '3' : 'welch' } selected_method = cross_correlation_map . get ( analysis_type , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid analysis method (1-2). \\n \" ) continue # Generate and display the calling sequence for cross-correlation print ( \" \\n Calling sequence: \\n \" ) return_values = cross_correlation_parameters [ selected_method ][ 'return_values' ] command = f \">>> { return_values } = WaLSAtools(data1=INPUT_DATA1, data2=INPUT_DATA2, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'b' ) return # Exit the function after successful output # Jupyter-based interactive function import ipywidgets as widgets # type: ignore from IPython.display import display , clear_output , HTML # type: ignore from .parameter_definitions import display_parameters_html , single_series_parameters , cross_correlation_parameters # type: ignore # Global flag to prevent multiple observers is_observer_attached = False def walsatools_jupyter (): \"\"\"Main interactive function for Jupyter Notebook version of WaLSAtools.\"\"\" global is_observer_attached , category , method , analysis_type , sub_method # Declare global variables for reuse # Detach any existing observers and reset the flag try : detach_observers () except NameError : pass # `detach_observers` hasn't been defined yet is_observer_attached = False # Reset observer flag # Clear any previous output clear_output ( wait = True ) print_logo_and_credits () # Recreate widgets to reset state category = widgets . Dropdown ( options = [ 'Select Category' , 'Single time series analysis' , 'Cross-correlation between two time series' ], value = 'Select Category' , description = 'Category:' ) method = widgets . Dropdown ( options = [ 'Select Data Type' ], value = 'Select Data Type' , description = 'Data Type:' ) analysis_type = widgets . Dropdown ( options = [ 'Select Method' ], value = 'Select Method' , description = 'Method:' ) sub_method = widgets . Dropdown ( options = [ 'Select Sub-method' , 'FFT' , 'Wavelet' , 'Lomb-Scargle' , 'Welch' ], value = 'Select Sub-method' , description = 'Sub-method:' , layout = widgets . Layout ( display = 'none' ) # Initially hidden ) # Persistent output widget output = widgets . Output () def clear_output_if_unselected ( change = None ): \"\"\"Clear the output widget if any dropdown menu is unselected.\"\"\" with output : if ( category . value == 'Select Category' or method . value == 'Select Data Type' or analysis_type . value == 'Select Method' or ( analysis_type . value == 'Dominant Freq / Mean Power Spectrum' and sub_method . layout . display == 'block' and sub_method . value == 'Select Sub-method' ) ): clear_output ( wait = True ) warn = '<div style=\"font-size: 1.1em; margin-left: 30px; margin-top:15px; margin-bottom: 15px;\">Please select appropriate options from all dropdown menus.</div>' display ( HTML ( warn )) def update_method_options ( change = None ): \"\"\"Update available Method and Sub-method options.\"\"\" clear_output_if_unselected () # Ensure the output clears if any dropdown is unselected. sub_method . layout . display = 'none' sub_method . value = 'Select Sub-method' sub_method . options = [ 'Select Sub-method' ] if category . value == 'Single time series analysis' : method . options = [ 'Select Data Type' , '1D signal' , '3D datacube' ] if method . value == '1D signal' : analysis_type . options = [ 'Select Method' , 'FFT' , 'Wavelet' , 'Lomb-Scargle' , 'Welch' , 'EMD' ] elif method . value == '3D datacube' : analysis_type . options = [ 'Select Method' , 'k-omega' , 'POD' , 'Dominant Freq / Mean Power Spectrum' ] else : analysis_type . options = [ 'Select Method' ] elif category . value == 'Cross-correlation between two time series' : method . options = [ 'Select Data Type' , '1D signal' ] if method . value == '1D signal' : analysis_type . options = [ 'Select Method' , 'FFT' , 'Wavelet' , 'Welch' ] else : analysis_type . options = [ 'Select Method' ] else : method . options = [ 'Select Data Type' ] analysis_type . options = [ 'Select Method' ] def update_sub_method_visibility ( change = None ): \"\"\"Show or hide the Sub-method dropdown based on conditions.\"\"\" clear_output_if_unselected () # Ensure the output clears if any dropdown is unselected. if ( category . value == 'Single time series analysis' and method . value == '3D datacube' and analysis_type . value == 'Dominant Freq / Mean Power Spectrum' ): sub_method . options = [ 'Select Sub-method' , 'FFT' , 'Wavelet' , 'Lomb-Scargle' , 'Welch' ] sub_method . layout . display = 'block' else : sub_method . options = [ 'Select Sub-method' ] sub_method . value = 'Select Sub-method' sub_method . layout . display = 'none' def update_calling_sequence ( change = None ): \"\"\"Update the function calling sequence based on user's selection.\"\"\" clear_output_if_unselected () # Ensure the output clears if any dropdown is unselected. if ( category . value == 'Select Category' or method . value == 'Select Data Type' or analysis_type . value == 'Select Method' or ( analysis_type . value == 'Dominant Freq / Mean Power Spectrum' and sub_method . layout . display == 'block' and sub_method . value == 'Select Sub-method' ) ): return # Do nothing until all required fields are properly selected with output : clear_output ( wait = True ) # Handle Dominant Frequency / Mean Power Spectrum with Sub-method if ( category . value == 'Single time series analysis' and method . value == '3D datacube' and analysis_type . value == 'Dominant Freq / Mean Power Spectrum' ): if sub_method . value == 'Select Sub-method' : print ( \"Please select a Sub-method.\" ) return sub_method_map = { 'FFT' : 'fft' , 'Wavelet' : 'wavelet' , 'Lomb-Scargle' : 'lombscargle' , 'Welch' : 'welch' } selected_method = sub_method_map . get ( sub_method . value , 'unknown' ) return_values = 'dominant_frequency, mean_power, frequency, power_map' command = f \" { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, averagedpower=True, dominantfreq=True, method=' { selected_method } ', **kwargs)\" # Handle k-omega and POD elif ( category . value == 'Single time series analysis' and method . value == '3D datacube' and analysis_type . value in [ 'k-omega' , 'POD' ] ): method_map = { 'k-omega' : 'k-omega' , 'POD' : 'pod' } selected_method = method_map . get ( analysis_type . value , 'unknown' ) parameter_definitions = single_series_parameters return_values = parameter_definitions . get ( selected_method , {}) . get ( 'return_values' , '' ) command = f \" { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" # Handle Cross-correlation elif category . value == 'Cross-correlation between two time series' : cross_correlation_map = { 'FFT' : 'fft' , 'Wavelet' : 'wavelet' , 'Welch' : 'welch' } selected_method = cross_correlation_map . get ( analysis_type . value , 'unknown' ) parameter_definitions = cross_correlation_parameters return_values = parameter_definitions . get ( selected_method , {}) . get ( 'return_values' , '' ) command = f \" { return_values } = WaLSAtools(data1=INPUT_DATA1, data2=INPUT_DATA2, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" # Handle Single 1D signal analysis elif category . value == 'Single time series analysis' and method . value == '1D signal' : method_map = { 'FFT' : 'fft' , 'Wavelet' : 'wavelet' , 'Lomb-Scargle' : 'lombscargle' , 'Welch' : 'welch' , 'EMD' : 'emd' } selected_method = method_map . get ( analysis_type . value , 'unknown' ) parameter_definitions = single_series_parameters return_values = parameter_definitions . get ( selected_method , {}) . get ( 'return_values' , '' ) command = f \" { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" else : print ( \"Invalid configuration.\" ) return # Generate and display the command in HTML html_code = f \"\"\" <div style=\"font-size: 1.2em; margin-left: 30px; margin-top:15px; margin-bottom: 15px;\">Calling sequence:</div> <div style=\"display: flex; margin-left: 30px; margin-bottom: 3ch;\"> <span style=\"color: #222; min-width: 4ch;\">>>> </span> <pre style=\" white-space: pre-wrap; word-wrap: break-word; color: #01016D; margin: 0; \"> { command } </pre> </div> \"\"\" display ( HTML ( html_code )) display_parameters_html ( selected_method , category = category . value ) def attach_observers (): \"\"\"Attach observers to the dropdown widgets and ensure no duplicates.\"\"\" global is_observer_attached if not is_observer_attached : detach_observers () category . observe ( clear_output_if_unselected , names = 'value' ) method . observe ( clear_output_if_unselected , names = 'value' ) analysis_type . observe ( clear_output_if_unselected , names = 'value' ) category . observe ( update_method_options , names = 'value' ) method . observe ( update_method_options , names = 'value' ) analysis_type . observe ( update_sub_method_visibility , names = 'value' ) sub_method . observe ( update_calling_sequence , names = 'value' ) analysis_type . observe ( update_calling_sequence , names = 'value' ) is_observer_attached = True def detach_observers (): \"\"\"Detach all observers to prevent multiple triggers.\"\"\" try : category . unobserve ( update_method_options , names = 'value' ) method . unobserve ( update_method_options , names = 'value' ) analysis_type . unobserve ( update_sub_method_visibility , names = 'value' ) sub_method . unobserve ( update_calling_sequence , names = 'value' ) analysis_type . unobserve ( update_calling_sequence , names = 'value' ) except ValueError : pass attach_observers () display ( category , method , analysis_type , sub_method , output ) # Unified interactive function for both terminal and Jupyter environments def interactive (): if is_notebook (): walsatools_jupyter () else : walsatools_terminal () WaLSA_plot_k_omega.py This module provides functions for plotting k-\u03c9 diagrams and filtered datacubes. WaLSA_plot_k_omega.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- # The following codes are baed on those originally written by David B. Jess and Samuel D. T. Grant # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from matplotlib.colors import ListedColormap # type: ignore from WaLSAtools import WaLSA_histo_opt # type: ignore from scipy.interpolate import griddata # type: ignore import matplotlib.pyplot as plt # type: ignore from matplotlib.ticker import FixedLocator , FixedFormatter # type: ignore import matplotlib.patches as patches # type: ignore import matplotlib.patheffects as path_effects # type: ignore from matplotlib.colors import Normalize # type: ignore def WaLSA_plot_k_omega ( kopower , kopower_xscale , kopower_yscale , xtitle = 'Wavenumber (pixel\u207b\u00b9)' , ytitle = 'Frequency (mHz)' , xlog = False , ylog = False , xrange = None , yrange = None , xtick_interval = 0.05 , ytick_interval = 200 , xtick_minor_interval = 0.01 , ytick_minor_interval = 50 , colorbar_label = 'Log\u2081\u2080(Power)' , cmap = 'viridis' , cbartab = 0.12 , figsize = ( 9 , 4 ), smooth = True , dypix = 1200 , dxpix = 1600 , ax = None , k1 = None , k2 = None , f1 = None , f2 = None , colorbar_location = 'right' ): \"\"\" Plots the k-omega diagram with corrected orientation and axis alignment. Automatically clips the power array and scales based on x and y ranges. Example usage: WaLSA_plot_k_omega( kopower=power, kopower_xscale=wavenumber, kopower_yscale=frequencies*1000., xlog=False, ylog=False, xrange=(0, 0.3), figsize=(8, 4), cbartab=0.18, xtitle='Wavenumber (pixel\u207b\u00b9)', ytitle='Frequency (mHz)', colorbar_label='Log\u2081\u2080(Oscillation Power)', f1=0.470*1000, f2=0.530*1000, k1=0.047, k2=0.25 ) \"\"\" if xrange is None or len ( xrange ) != 2 : xrange = [ np . min ( kopower_xscale ), np . max ( kopower_xscale )] if yrange is None or len ( yrange ) != 2 : yrange = [ np . min ( kopower_yscale ), np . max ( kopower_yscale )] # Handle xrange and yrange adjustments if xrange is not None and len ( xrange ) == 2 and xrange [ 0 ] == 0 : xrange = [ np . min ( kopower_xscale ), xrange [ 1 ]] if yrange is not None and len ( yrange ) == 2 and yrange [ 0 ] == 0 : yrange = [ np . min ( kopower_yscale ), yrange [ 1 ]] # Clip kopower, kopower_xscale, and kopower_yscale based on xrange and yrange if xrange : x_min , x_max = xrange x_indices = np . where (( kopower_xscale >= x_min ) & ( kopower_xscale <= x_max ))[ 0 ] # Check if the lower bound is not included if kopower_xscale [ x_indices [ 0 ]] > x_min and x_indices [ 0 ] > 0 : x_indices = np . insert ( x_indices , 0 , x_indices [ 0 ] - 1 ) # Check if the upper bound is not included if kopower_xscale [ x_indices [ - 1 ]] < x_max and x_indices [ - 1 ] + 1 < len ( kopower_xscale ): x_indices = np . append ( x_indices , x_indices [ - 1 ] + 1 ) kopower = kopower [:, x_indices ] kopower_xscale = kopower_xscale [ x_indices ] if yrange : y_min , y_max = yrange y_indices = np . where (( kopower_yscale >= y_min ) & ( kopower_yscale <= y_max ))[ 0 ] # Check if the lower bound is not included if kopower_yscale [ y_indices [ 0 ]] > y_min and y_indices [ 0 ] > 0 : y_indices = np . insert ( y_indices , 0 , y_indices [ 0 ] - 1 ) # Check if the upper bound is not included if kopower_yscale [ y_indices [ - 1 ]] < y_max and y_indices [ - 1 ] + 1 < len ( kopower_yscale ): y_indices = np . append ( y_indices , y_indices [ - 1 ] + 1 ) kopower = kopower [ y_indices , :] kopower_yscale = kopower_yscale [ y_indices ] # Pixel coordinates in data space if xlog : nxpix = np . logspace ( np . log10 ( xrange [ 0 ]), np . log10 ( xrange [ 1 ]), dxpix ) else : nxpix = np . linspace ( xrange [ 0 ], xrange [ 1 ], dxpix ) if ylog : nypix = np . logspace ( np . log10 ( yrange [ 0 ]), np . log10 ( yrange [ 1 ]), dypix ) else : nypix = np . linspace ( yrange [ 0 ], yrange [ 1 ], dypix ) # Interpolation over data interpolator = griddata ( points = ( np . repeat ( kopower_yscale , len ( kopower_xscale )), np . tile ( kopower_xscale , len ( kopower_yscale ))), values = kopower . ravel (), xi = ( nypix [:, None ], nxpix [ None , :]), method = 'linear' ) newimage = np . nan_to_num ( interpolator ) # Clip the interpolated image to the exact xrange and yrange x_indices = ( nxpix >= xrange [ 0 ]) & ( nxpix <= xrange [ 1 ]) y_indices = ( nypix >= yrange [ 0 ]) & ( nypix <= yrange [ 1 ]) newimage = newimage [ np . ix_ ( y_indices , x_indices )] nxpix = nxpix [ x_indices ] nypix = nypix [ y_indices ] # Extent for plotting extent = [ nxpix [ 0 ], nxpix [ - 1 ], nypix [ 0 ], nypix [ - 1 ]] # Set up the plot if ax is None : fig , ax = plt . subplots ( figsize = figsize ) # Load custom colormap rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_13.txt' ) / 255.0 idl_colormap_13 = ListedColormap ( rgb_values ) # Compute minimum and maximum values of the data vmin = np . nanmin ( kopower ) vmax = np . nanmax ( kopower ) img = ax . imshow ( WaLSA_histo_opt ( newimage ), extent = extent , origin = 'lower' , aspect = 'auto' , cmap = idl_colormap_13 , norm = Normalize ( vmin = vmin , vmax = vmax ) ) # Configure axis labels and scales ax . set_xlabel ( xtitle ) ax . set_ylabel ( ytitle ) if xlog : ax . set_xscale ( 'log' ) if ylog : ax . set_yscale ( 'log' ) # Configure ticks ax . xaxis . set_major_locator ( plt . MultipleLocator ( xtick_interval )) ax . xaxis . set_minor_locator ( plt . MultipleLocator ( xtick_minor_interval )) ax . yaxis . set_major_locator ( plt . MultipleLocator ( ytick_interval )) ax . yaxis . set_minor_locator ( plt . MultipleLocator ( ytick_minor_interval )) # # Add a secondary x and y axes for perido and spatial size ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) # Minor ticks major_xticks = ax . get_xticks () major_yticks = ax . get_yticks () # Define a function to calculate the period (1000 / frequency) def frequency_to_period ( frequency ): return 1000. / frequency if frequency > 0 else np . inf # Generate labels for the secondary y-axis based on the primary y-axis ticks period_labels = [ f \" { frequency_to_period ( tick ) : .1f } \" if tick > 0 else \"\" for tick in major_yticks ] # Set custom labels for the secondary y-axis ax_right = ax . secondary_yaxis ( 'right' ) ax_right . set_yticks ( major_yticks ) ax_right . set_yticklabels ( period_labels ) ax_right . set_ylabel ( 'Period (s)' , labelpad = 12 ) # Define a function to calculate spatial size (2\u03c0 / wavenumber) def wavenumber_to_spatial_size ( wavenumber ): return 2 * np . pi / wavenumber if wavenumber > 0 else np . inf # Generate labels for the secondary x-axis based on the primary x-axis ticks spatial_size_labels = [ f \" { wavenumber_to_spatial_size ( tick ) : .1f } \" if tick > 0 else \"\" for tick in major_xticks ] # Set custom labels for the secondary x-axis ax_top = ax . secondary_xaxis ( 'top' ) ax_top . set_xticks ( major_xticks ) ax_top . set_xticklabels ( spatial_size_labels ) ax_top . set_xlabel ( 'Spatial Size (pixel)' , labelpad = 12 ) if k1 is not None and k2 is not None and f1 is not None and f2 is not None : width = k2 - k1 height = f2 - f1 rectangle = patches . Rectangle ( ( k1 , f1 ), width , height , zorder = 10 , linewidth = 1.5 , edgecolor = 'white' , facecolor = 'none' , linestyle = '--' ) rectangle . set_path_effects ([ path_effects . Stroke ( linewidth = 2.5 , foreground = 'black' ), path_effects . Normal () ]) # Mark the filtered area ax . add_patch ( rectangle ) # Add colorbar tick_values = [ vmin , vmin + ( vmax - vmin ) * 0.33 , vmin + ( vmax - vmin ) * 0.67 , vmax ] # Format the tick labels tick_labels = [ f \" { v : .1f } \" for v in tick_values ] if colorbar_location == 'top' : cbar = plt . colorbar ( img , ax = ax , orientation = 'horizontal' , pad = cbartab , location = 'top' , aspect = 30 ) cbar . set_label ( colorbar_label ) # Override the ticks and tick labels cbar . set_ticks ( tick_values ) # Set custom tick locations cbar . set_ticklabels ( tick_labels ) # Set custom tick labels cbar . ax . xaxis . set_major_locator ( FixedLocator ( tick_values )) # Fix tick locations cbar . ax . xaxis . set_major_formatter ( FixedFormatter ( tick_labels )) # Fix tick labels # Suppress auto ticks completely cbar . ax . xaxis . set_minor_locator ( FixedLocator ([])) # Ensure no minor ticks appear else : cbar = plt . colorbar ( img , ax = ax , orientation = 'vertical' , pad = cbartab , aspect = 22 ) cbar . set_label ( colorbar_label ) # Override the ticks and tick labels cbar . set_ticks ( tick_values ) # Set custom tick locations cbar . set_ticklabels ( tick_labels ) # Set custom tick labels cbar . ax . yaxis . set_major_locator ( FixedLocator ( tick_values )) # Fix tick locations cbar . ax . yaxis . set_major_formatter ( FixedFormatter ( tick_labels )) # Fix tick labels # Suppress auto ticks completely cbar . ax . yaxis . set_minor_locator ( FixedLocator ([])) # Ensure no minor ticks appear return ax WaLSA_plot_wavelet_spectrum.py This module provides functions for plotting wavelet power spectra and related visualizations. WaLSA_plot_wavelet_spectrum.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import matplotlib.pyplot as plt import matplotlib.ticker as ticker import numpy as np from matplotlib.colors import LinearSegmentedColormap from mpl_toolkits.axes_grid1 import make_axes_locatable def WaLSA_plot_wavelet_spectrum ( t , power , periods , sig_slevel , coi , dt , normalize_power = False , title = 'Wavelet Power Spectrum' , ylabel = 'Period [s]' , xlabel = 'Time [s]' , colorbar_label = 'Power (%)' , ax = None , colormap = 'custom' , removespace = False ): \"\"\"Plots the wavelet power spectrum of a given signal. Parameters: - t (array-like): Time values for the signal. - power (2D array-like): Wavelet power spectrum. - periods (array-like): Period values corresponding to the power. - sig_slevel (2D array-like): Significance levels of the power spectrum. - coi (array-like): Cone of influence, showing where edge effects might be present. - dt (float): Time interval between successive time values. - normalize_power (bool): If True, normalize power to 0-100%. Default is False. - title (str): Title of the plot. Default is 'Wavelet Power Spectrum'. - ylabel (str): Y-axis label. Default is 'Period [s]'. - xlabel (str): X-axis label. Default is 'Time [s]'. - colorbar_label (str): Label for the color bar. Default is 'Power (%)'. - ax (matplotlib axis, optional): Axis to plot on. Default is None, which creates a new figure and axis. - colormap (str or colormap, optional): Colormap to be used. Default is 'custom'. - removespace (bool, optional): If True, limits the maximum y-range to the peak of the cone of influence. \"\"\" if ax is None : fig , ax = plt . subplots ( figsize = ( 12 , 6 )) # Custom colormap with white at the lower end if colormap == 'custom' : cmap = LinearSegmentedColormap . from_list ( 'custom_white' , [ 'white' , 'blue' , 'green' , 'yellow' , 'red' ], N = 256 ) else : cmap = plt . get_cmap ( colormap ) # Normalize power if requested if normalize_power : power = 100 * power / np . nanmax ( power ) # Define a larger number of levels to create a continuous color bar levels = np . linspace ( np . nanmin ( power ), np . nanmax ( power ), 100 ) # Plot the wavelet power spectrum CS = ax . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # Removed 'extend' mode for straight ends # 95% significance contour ax . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) if removespace : max_period = np . max ( coi ) else : max_period = np . max ( periods ) # Cone-of-influence ax . plot ( t , coi , '-k' , lw = 2 ) ax . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ max_period ], [ max_period ], [ 1e-9 ]]), 'k' , alpha = 0.3 , hatch = 'x' ) # Log scale for periods ax . set_ylim ([ np . min ( periods ), max_period ]) ax . set_yscale ( 'log' , base = 10 ) ax . yaxis . set_major_formatter ( ticker . ScalarFormatter ()) ax . ticklabel_format ( axis = 'y' , style = 'plain' ) ax . invert_yaxis () # Set axis limits and labels ax . set_xlim ([ t . min (), t . max ()]) ax . set_ylabel ( ylabel , fontsize = 14 ) ax . set_xlabel ( xlabel , fontsize = 14 ) ax . tick_params ( axis = 'both' , which = 'major' , labelsize = 12 ) ax . set_title ( title , fontsize = 16 ) # Add a secondary y-axis for frequency in Hz ax_freq = ax . twinx () # Set limits for the frequency axis based on the `max_period` used for the period axis min_frequency = 1 / max_period max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( ticker . ScalarFormatter ()) ax_freq . ticklabel_format ( axis = 'y' , style = 'plain' ) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' , fontsize = 14 ) ax_freq . tick_params ( axis = 'both' , which = 'major' , labelsize = 12 ) # Add color bar on top with minimal distance divider = make_axes_locatable ( ax ) cax = divider . append_axes ( 'top' , size = '5%' , pad = 0.01 ) # Use 'pad=0.01' for a small fixed distance cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , fontsize = 12 , labelpad = 5 ) cbar . ax . tick_params ( labelsize = 10 , direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust layout if a new figure was created if ax is None : plt . tight_layout () plt . show ()", "title": "Main Routines"}, {"location": "python/routines/#under-the-hood", "text": "We strongly recommend everyone to follow the procedure as instructed here when using WaLSAtools \u2014 a user-friendly tool \u2014 which gives you all information you need to do your analysis. However, for experts who want to make themselves familiar with the techniques and codes under the hood, inspect them and modify/develop/improve them, some of the main codes are also provided below. Please note that all codes and their dependencies are available in the GitHub repository .", "title": "Under the Hood"}, {"location": "python/routines/#analysis-modules", "text": "WaLSAtools is built upon a collection of analysis modules, each designed for a specific aspect of wave analysis. These modules are combined and accessed through the main WaLSAtools interface, providing a streamlined and user-friendly experience. Here's a brief overview of the core analysis modules: WaLSA_speclizer.py This module provides a collection of spectral analysis techniques, including FFT, Lomb-Scargle, Wavelet, Welch, and EMD/HHT. WaLSA_speclizer.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from astropy.timeseries import LombScargle # type: ignore from tqdm import tqdm # type: ignore from .WaLSA_detrend_apod import WaLSA_detrend_apod # type: ignore from .WaLSA_confidence import WaLSA_confidence # type: ignore from .WaLSA_wavelet import cwt , significance # type: ignore from scipy.signal import welch # type: ignore # -------------------------------------- Main Function ---------------------------------------- def WaLSA_speclizer ( signal = None , time = None , method = None , dominantfreq = False , averagedpower = False , ** kwargs ): \"\"\" Main function to prepare data and call the specific spectral analysis method. Parameters: signal (array): The input signal (1D or 3D). time (array): The time array of the signal. method (str): The method to use for spectral analysis ('fft', 'lombscargle', etc.) **kwargs: Additional parameters for data preparation and analysis methods. Returns: Power spectrum, frequencies, and significance (if applicable). \"\"\" if not dominantfreq or not averagedpower : if method == 'fft' : return getpowerFFT ( signal , time = time , ** kwargs ) elif method == 'lombscargle' : return getpowerLS ( signal , time = time , ** kwargs ) elif method == 'wavelet' : return getpowerWavelet ( signal , time = time , ** kwargs ) elif method == 'welch' : return welch_psd ( signal , time = time , ** kwargs ) elif method == 'emd' : return getEMD_HHT ( signal , time = time , ** kwargs ) else : raise ValueError ( f \"Unknown method: { method } \" ) else : return get_dominant_averaged ( signal , time = time , method = method , ** kwargs ) # -------------------------------------- FFT ---------------------------------------- def getpowerFFT ( signal , time , ** kwargs ): \"\"\" Perform FFT analysis on the given signal. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. nosignificance (bool): If True, skip significance calculation. Default: False. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. amplitude (bool): If True, return the amplitudes of the Fourier transform. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: Power spectrum, frequencies, significance, amplitudes \"\"\" # Define default values for the optional parameters defaults = { 'siglevel' : 0.95 , 'significance' : None , 'nperm' : 1000 , 'nosignificance' : False , 'apod' : 0.1 , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'nodetrendapod' : False , 'amplitude' : False , 'silent' : False } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } params [ 'siglevel' ] = 1 - params [ 'siglevel' ] # different convention tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) else : apocube = signal nt = len ( apocube ) # Length of the time series (1D) # Calculate the frequencies frequencies = 1. / ( cadence * 2 ) * np . arange ( nt // 2 + 1 ) / ( nt // 2 ) frequencies = frequencies [ 1 :] powermap = np . zeros ( len ( frequencies )) signal = apocube spec = np . fft . fft ( signal ) power = 2 * np . abs ( spec [ 1 : len ( frequencies ) + 1 ]) ** 2 powermap [:] = power / frequencies [ 0 ] if params [ 'amplitude' ]: amplitudes = np . zeros (( len ( signal ), len ( frequencies )), dtype = np . complex_ ) amplitudes = spec [ 1 : len ( frequencies ) + 1 ] else : amplitudes = None # Calculate significance if requested if not params [ 'nosignificance' ]: ps_perm = np . zeros (( len ( frequencies ), params [ 'nperm' ])) for ip in range ( params [ 'nperm' ]): perm_signal = np . random . permutation ( signal ) # Permuting the original signal apocube = WaLSA_detrend_apod ( perm_signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) perm_spec = np . fft . fft ( perm_signal ) perm_power = 2 * np . abs ( perm_spec [ 1 : len ( frequencies ) + 1 ]) ** 2 ps_perm [:, ip ] = perm_power # Correct call to WaLSA_confidence significance = WaLSA_confidence ( ps_perm , siglevel = params [ 'siglevel' ], nf = len ( frequencies )) significance = significance / frequencies [ 0 ] else : significance = None if not params [ 'silent' ]: print ( \"FFT processed.\" ) return powermap , frequencies , significance , amplitudes # -------------------------------------- Lomb-Scargle ---------------------------------------- def getpowerLS ( signal , time , ** kwargs ): \"\"\" Perform Lomb-Scargle analysis on the given signal. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. dy (array): Errors or observational uncertainties associated with the time series. fit_mean (bool): If True, include a constant offset as part of the model at each frequency. This improves accuracy, especially for incomplete phase coverage. center_data (bool): If True, pre-center the data by subtracting the weighted mean of the input data. This is especially important if fit_mean=False. nterms (int): Number of terms to use in the Fourier fit. Default: 1. normalization (str): The normalization method for the periodogram. Options: 'standard', 'model', 'log', 'psd'. Default: 'standard'. nosignificance (bool): If True, skip significance calculation. Default: False. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False.. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: Power spectrum, frequencies, and significance (if applicable). \"\"\" # Define default values for the optional parameters defaults = { 'siglevel' : 0.05 , 'nperm' : 1000 , 'nosignificance' : False , 'apod' : 0.1 , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'silent' : False , # Ensure 'silent' is included in defaults 'nodetrendapod' : False , 'dy' : None , # Error or sequence of observational errors associated with times t 'fit_mean' : False , # If True include a constant offset as part of the model at each frequency. This can lead to more accurate results, especially in the case of incomplete phase coverage 'center_data' : True , # If True pre-center the data by subtracting the weighted mean of the input data. This is especially important if fit_mean = False 'nterms' : 1 , # Number of terms to use in the Fourier fit 'normalization' : 'standard' # The normalization to use for the periodogram. Options are 'standard', 'model', 'log', 'psd' } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } params [ 'siglevel' ] = 1 - params [ 'siglevel' ] # different convention tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) else : apocube = signal frequencies , power = LombScargle ( time , apocube , dy = params [ 'dy' ], fit_mean = params [ 'fit_mean' ], center_data = params [ 'center_data' ], nterms = params [ 'nterms' ], normalization = params [ 'normalization' ]) . autopower () # Calculate significance if needed if not params [ 'nosignificance' ]: ps_perm = np . zeros (( len ( frequencies ), params [ 'nperm' ])) for ip in range ( params [ 'nperm' ]): perm_signal = np . random . permutation ( signal ) # Permuting the original signal apocubep = WaLSA_detrend_apod ( perm_signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) frequencies , perm_power = LombScargle ( time , apocubep , dy = params [ 'dy' ], fit_mean = params [ 'fit_mean' ], center_data = params [ 'center_data' ], nterms = params [ 'nterms' ], normalization = params [ 'normalization' ]) . autopower () ps_perm [:, ip ] = perm_power significance = WaLSA_confidence ( ps_perm , siglevel = params [ 'siglevel' ], nf = len ( frequencies )) else : significance = None if not params [ 'silent' ]: print ( \"Lomb-Scargle processed.\" ) return power , frequencies , significance # -------------------------------------- Wavelet ---------------------------------------- def getpowerWavelet ( signal , time , ** kwargs ): \"\"\" Perform wavelet analysis using the pycwt package. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. mother (str): The mother wavelet function to use. Default: 'morlet'. GWS (bool): If True, calculate the Global Wavelet Spectrum. Default: False. RGWS (bool): If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False. dj (float): Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025. s0 (float): Initial (smallest) scale of the wavelet. Default: 2 * dt. J (int): Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj. lag1 (float): Lag-1 autocorrelation. Default: 0.0. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: power: The wavelet power spectrum. periods: Corresponding periods. sig_slevel: The significance levels. coi: The cone of influence. Optionally, if global_power=True: global_power: Global wavelet power spectrum. global_conf: Confidence levels for the global wavelet spectrum. Optionally, if RGWS=True: rgws_periods: Periods for the refined global wavelet spectrum. rgws_power: Refined global wavelet power spectrum. \"\"\" # Define default values for the optional parameters similar to IDL defaults = { 'siglevel' : 0.95 , 'mother' : 'morlet' , # Morlet wavelet as the mother function 'dj' : 0.025 , # Scale spacing 's0' : - 1 , # Initial scale 'J' : - 1 , # Number of scales 'lag1' : 0.0 , # Lag-1 autocorrelation 'apod' : 0.1 , # Tukey window apodization 'silent' : False , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'GWS' : False , # If True, calculate global wavelet spectrum 'RGWS' : False , # If True, calculate refined global wavelet spectrum (excluding COI) 'nperm' : 1000 , # Number of permutations for significance calculation 'nodetrendapod' : False } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) else : apocube = signal n = len ( apocube ) dt = cadence # Standardize the signal before the wavelet transform std_signal = apocube . std () norm_signal = apocube / std_signal # Determine the initial scale s0 if not provided if params [ 's0' ] == - 1 : params [ 's0' ] = 2 * dt # Determine the number of scales J if not provided if params [ 'J' ] == - 1 : params [ 'J' ] = int (( np . log ( float ( n ) * dt / params [ 's0' ]) / np . log ( 2 )) / params [ 'dj' ]) # Perform wavelet transform W , scales , frequencies , coi , _ , _ = cwt ( norm_signal , dt , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], wavelet = params [ 'mother' ] ) power = np . abs ( W ) ** 2 # Wavelet power spectrum periods = 1 / frequencies # Convert frequencies to periods # Calculate the significance levels signif , _ = significance ( 1.0 , # Normalized variance dt , scales , 0 , # Ignored for now, used for background noise (e.g., red noise) params [ 'lag1' ], significance_level = params [ 'siglevel' ], wavelet = params [ 'mother' ] ) # Calculate the significance level for each power value sig_matrix = np . ones ([ len ( scales ), n ]) * signif [:, None ] sig_slevel = power / sig_matrix # Calculate global power if requested if params [ 'GWS' ]: global_power = np . mean ( power , axis = 1 ) # Average along the time axis dof = n - scales # the -scale corrects for padding at edges global_conf , _ = significance ( norm_signal , # time series data dt , # time step between values scales , # scale vector 1 , # sigtest = 1 for \"time-average\" test 0.0 , significance_level = params [ 'siglevel' ], dof = dof , wavelet = params [ 'mother' ] ) else : global_power = None global_conf = None # Calculate refined global wavelet spectrum (RGWS) if requested if params [ 'RGWS' ]: isig = sig_slevel < 1.0 power [ isig ] = np . nan ipower = np . full_like ( power , np . nan ) for i in range ( len ( coi )): pcol = power [:, i ] valid_idx = periods < coi [ i ] ipower [ valid_idx , i ] = pcol [ valid_idx ] rgws_power = np . nansum ( ipower , axis = 1 ) else : rgws_power = None if not params [ 'silent' ]: print ( \"Wavelet (\" + params [ 'mother' ] + \") processed.\" ) return power , periods , sig_slevel , coi , global_power , global_conf , rgws_power # -------------------------------------- Welch ---------------------------------------- def welch_psd ( signal , time , ** kwargs ): \"\"\" Calculate Welch Power Spectral Density (PSD) and significance levels. Parameters: signal (array): The 1D time series signal. time (array): The time array corresponding to the signal. nperseg (int, optional): Length of each segment for analysis. Default: 256. noverlap (int, optional): Number of points to overlap between segments. Default: 128. window (str, optional): Type of window function used in the Welch method. Default: 'hann'. siglevel (float, optional): Significance level for confidence intervals. Default: 0.95. nperm (int, optional): Number of permutations for significance testing. Default: 1000. silent (bool, optional): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: frequencies: Frequencies at which the PSD is estimated. psd: Power Spectral Density values. significance: Significance levels for the PSD. \"\"\" # Define default values for the optional parameters similar to FFT defaults = { 'siglevel' : 0.95 , 'nperm' : 1000 , # Number of permutations for significance calculation 'window' : 'hann' , # Window type for Welch method 'nperseg' : 256 , # Length of each segment 'silent' : False , 'noverlap' : 128 # Number of points to overlap between segments } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Calculate Welch PSD frequencies , psd = welch ( signal , fs = 1.0 / cadence , window = params [ 'window' ], nperseg = params [ 'nperseg' ], noverlap = params [ 'noverlap' ]) # Calculate significance levels using permutation ps_perm = np . zeros (( len ( frequencies ), params [ 'nperm' ])) for ip in range ( params [ 'nperm' ]): perm_signal = np . random . permutation ( signal ) # Permuting the original signal _ , perm_psd = welch ( perm_signal , fs = 1.0 / cadence , window = params [ 'window' ], nperseg = params [ 'nperseg' ], noverlap = params [ 'noverlap' ]) ps_perm [:, ip ] = perm_psd # Calculate significance level for Welch PSD significance = np . percentile ( ps_perm , params [ 'siglevel' ] * 100 , axis = 1 ) if not params [ 'silent' ]: print ( \"Welch processed.\" ) return psd , frequencies , significance # -------------------------------------- EMD / EEMD ---------------------------------------- import numpy as np # type: ignore from .PyEMD import EMD , EEMD # type: ignore from scipy.stats import norm # type: ignore from scipy.signal import hilbert , welch # type: ignore from scipy.signal import find_peaks # type: ignore from scipy.fft import fft , fftfreq # type: ignore # Function to apply EMD and return Intrinsic Mode Functions (IMFs) def apply_emd ( signal , time ): emd = EMD () emd . FIXE_H = 5 imfs = emd . emd ( signal , time ) # max_imfs=7, emd.FIXE_H = 10 return imfs # Function to apply EEMD and return Intrinsic Mode Functions (IMFs) def apply_eemd ( signal , time , noise_std = 0.2 , num_realizations = 1000 ): eemd = EEMD () eemd . FIXE_H = 5 eemd . noise_seed ( 12345 ) eemd . noise_width = noise_std eemd . ensemble_size = num_realizations imfs = eemd . eemd ( signal , time ) return imfs # Function to generate white noise IMFs for significance testing def generate_white_noise_imfs ( signal_length , time , num_realizations , use_eemd = None , noise_std = 0.2 ): white_noise_imfs = [] if use_eemd : eemd = EEMD () eemd . FIXE_H = 5 eemd . noise_seed ( 12345 ) eemd . noise_width = noise_std eemd . ensemble_size = num_realizations for _ in range ( num_realizations ): white_noise = np . random . normal ( size = signal_length ) imfs = eemd . eemd ( white_noise , time ) white_noise_imfs . append ( imfs ) else : emd = EMD () emd . FIXE_H = 5 for _ in range ( num_realizations ): white_noise = np . random . normal ( size = signal_length ) imfs = emd . emd ( white_noise , time ) white_noise_imfs . append ( imfs ) return white_noise_imfs # Function to calculate the energy of each IMF def calculate_imf_energy ( imfs ): return [ np . sum ( imf ** 2 ) for imf in imfs ] # Function to determine the significance of the IMFs def test_imf_significance ( imfs , white_noise_imfs ): imf_energies = calculate_imf_energy ( imfs ) num_imfs = len ( imfs ) white_noise_energies = [ calculate_imf_energy ( imf_set ) for imf_set in white_noise_imfs ] significance_levels = [] for i in range ( num_imfs ): # Collect the i-th IMF energy from each white noise realization white_noise_energy_dist = [ imf_energies [ i ] for imf_energies in white_noise_energies if i < len ( imf_energies )] mean_energy = np . mean ( white_noise_energy_dist ) std_energy = np . std ( white_noise_energy_dist ) z_score = ( imf_energies [ i ] - mean_energy ) / std_energy significance_level = 1 - norm . cdf ( z_score ) significance_levels . append ( significance_level ) return significance_levels # Function to compute instantaneous frequency of IMFs using Hilbert transform def compute_instantaneous_frequency ( imfs , time ): instantaneous_frequencies = [] for imf in imfs : analytic_signal = hilbert ( imf ) instantaneous_phase = np . unwrap ( np . angle ( analytic_signal )) instantaneous_frequency = np . diff ( instantaneous_phase ) / ( 2.0 * np . pi * np . diff ( time )) instantaneous_frequency = np . abs ( instantaneous_frequency ) # Ensure frequencies are positive instantaneous_frequencies . append ( instantaneous_frequency ) return instantaneous_frequencies # Function to compute HHT power spectrum def compute_hht_power_spectrum ( imfs , instantaneous_frequencies , freq_bins ): power_spectrum = np . zeros_like ( freq_bins ) for i in range ( len ( imfs )): amplitude = np . abs ( hilbert ( imfs [ i ])) power = amplitude ** 2 for j in range ( len ( instantaneous_frequencies [ i ])): freq_idx = np . searchsorted ( freq_bins , instantaneous_frequencies [ i ][ j ]) if freq_idx < len ( freq_bins ): power_spectrum [ freq_idx ] += power [ j ] return power_spectrum # Function to compute significance level for HHT power spectrum def compute_significance_level ( white_noise_imfs , freq_bins , time ): all_power_spectra = [] for imfs in white_noise_imfs : instantaneous_frequencies = compute_instantaneous_frequency ( imfs , time ) power_spectrum = compute_hht_power_spectrum ( imfs , instantaneous_frequencies , freq_bins ) all_power_spectra . append ( power_spectrum ) # Compute the 95th percentile power spectrum as the significance level significance_level = np . percentile ( all_power_spectra , 95 , axis = 0 ) return significance_level ## Custom rounding function def custom_round ( freq ): if freq < 1 : return round ( freq , 1 ) else : return round ( freq ) def smooth_power_spectrum ( power_spectrum , window_size = 5 ): return np . convolve ( power_spectrum , np . ones ( window_size ) / window_size , mode = 'same' ) # Function to identify and print significant peaks def identify_significant_peaks ( freq_bins , power_spectrum , significance_level ): peaks , _ = find_peaks ( power_spectrum , height = significance_level ) significant_frequencies = freq_bins [ peaks ] rounded_frequencies = [ custom_round ( freq ) for freq in significant_frequencies ] rounded_frequencies_two = [ round ( freq , 1 ) for freq in significant_frequencies ] print ( \"Significant Frequencies (Hz):\" , rounded_frequencies_two ) print ( \"Significant Frequencies (Hz):\" , rounded_frequencies ) return significant_frequencies # Function to generate randomized signals def generate_randomized_signals ( signal , num_realizations ): randomized_signals = [] for _ in range ( num_realizations ): randomized_signal = np . random . permutation ( signal ) randomized_signals . append ( randomized_signal ) return randomized_signals # Function to calculate the FFT power spectrum for each IMF def calculate_fft_psd_spectra ( imfs , time ): psd_spectra = [] for imf in imfs : N = len ( imf ) T = time [ 1 ] - time [ 0 ] # Assuming uniform sampling yf = fft ( imf ) xf = fftfreq ( N , T )[: N // 2 ] psd = ( 2.0 / N ) * ( np . abs ( yf [: N // 2 ]) ** 2 ) / ( N * T ) psd_spectra . append (( xf , psd )) return psd_spectra # Function to calculate the FFT power spectrum for randomized signals def calculate_fft_psd_spectra_randomized ( imfs , time , num_realizations ): all_psd_spectra = [] for imf in imfs : randomized_signals = generate_randomized_signals ( imf , num_realizations ) for signal in randomized_signals : N = len ( signal ) T = time [ 1 ] - time [ 0 ] # Assuming uniform sampling yf = fft ( signal ) psd = ( 2.0 / N ) * ( np . abs ( yf [: N // 2 ]) ** 2 ) / ( N * T ) all_psd_spectra . append ( psd ) return np . array ( all_psd_spectra ) # Function to calculate the 95th percentile confidence level def calculate_confidence_level ( imfs , time , num_realizations ): confidence_levels = [] for imf in imfs : all_psd_spectra = calculate_fft_psd_spectra_randomized ([ imf ], time , num_realizations ) confidence_level = np . percentile ( all_psd_spectra , 95 , axis = 0 ) confidence_levels . append ( confidence_level ) return confidence_levels # Function to calculate the Welch PSD for each IMF def calculate_welch_psd_spectra ( imfs , fs ): psd_spectra = [] for imf in imfs : f , psd = welch ( imf , fs = fs ) psd_spectra . append (( f , psd )) return psd_spectra # Function to calculate the Welch PSD for randomized signals def calculate_welch_psd_spectra_randomized ( imfs , fs , num_realizations ): all_psd_spectra = [] for imf in imfs : randomized_signals = generate_randomized_signals ( imf , num_realizations ) for signal in randomized_signals : f , psd = welch ( signal , fs = fs ) all_psd_spectra . append ( psd ) return np . array ( all_psd_spectra ) # Function to calculate the 95th percentile confidence level def calculate_confidence_level_welch ( imfs , fs , num_realizations ): confidence_levels = [] for imf in imfs : all_psd_spectra = calculate_welch_psd_spectra_randomized ([ imf ], fs , num_realizations ) confidence_level = np . percentile ( all_psd_spectra , 95 , axis = 0 ) confidence_levels . append ( confidence_level ) return confidence_levels # ************** Main EMD/EEMD routine ************** def getEMD_HHT ( signal , time , ** kwargs ): \"\"\" Calculate EMD/EEMD and HHT Parameters: signal (array): The input signal (1D). time (array): The time array of the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. EEMD (bool): If True, use Ensemble Empirical Mode Decomposition (EEMD) instead of Empirical Mode Decomposition (EMD). Default: False. Welch_psd (bool): If True, calculate Welch PSD spectra instead of FFT PSD spectra (for the psd_spectra and psd_confidence_levels). Default: False. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon is set to True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: frequencies: Frequencies at which the PSD is estimated. psd: Power Spectral Density values. significance: Significance levels for the PSD. \u2018marginal\u2019 spectrum of Hilbert-Huang Transform (HHT) \"\"\" # Define default values for the optional parameters similar to FFT defaults = { 'siglevel' : 0.95 , 'nperm' : 1000 , # Number of permutations for significance calculation 'apod' : 0.1 , # Tukey window apodization 'silent' : False , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'EEMD' : False , # If True, calculate Ensemble Empirical Mode Decomposition (EEMD) 'nodetrendapod' : False , 'Welch_psd' : False , # If True, calculate Welch PSD spectra 'significant_imfs' : False # If True, return only significant IMFs (and for associated calculations) } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Perform detrending and apodization if not params [ 'nodetrendapod' ]: apocube = WaLSA_detrend_apod ( signal , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = params [ 'silent' ] ) n = len ( apocube ) dt = cadence fs = 1 / dt # Sampling frequency if params [ 'EEMD' ]: imfs = apply_eemd ( signal , time ) use_eemd = True else : imfs = apply_emd ( signal , time ) use_eemd = False white_noise_imfs = generate_white_noise_imfs ( len ( signal ), time , params [ 'nperm' ], use_eemd = use_eemd ) IMF_significance_levels = test_imf_significance ( imfs , white_noise_imfs ) # Determine significant IMFs significant_imfs_val = [ imf for imf , sig_level in zip ( imfs , IMF_significance_levels ) if sig_level < params [ 'siglevel' ]] if params [ 'significant_imfs' ]: imfs = significant_imfs_val # Compute instantaneous frequencies of IMFs instantaneous_frequencies = compute_instantaneous_frequency ( imfs , time ) if params [ 'Welch_psd' ]: # Calculate and plot Welch PSD spectra of (significant) IMFs psd_spectra = calculate_welch_psd_spectra ( imfs , fs ) # Calculate 95th percentile confidence levels for Welch PSD spectra psd_confidence_levels = calculate_confidence_level_welch ( imfs , fs , params [ 'nperm' ]) else : # Calculate and plot FFT PSD spectra of (significant) IMFs psd_spectra = calculate_fft_psd_spectra ( imfs , time ) # Calculate 95th percentile confidence levels for FFT PSD spectra psd_confidence_levels = calculate_confidence_level ( imfs , time , params [ 'nperm' ]) # Define frequency bins for HHT power spectrum max_freq = max ([ freq . max () for freq in instantaneous_frequencies ]) HHT_freq_bins = np . linspace ( 0 , max_freq , 100 ) # Compute HHT power spectrum of (significant) IMFs HHT_power_spectrum = compute_hht_power_spectrum ( imfs , instantaneous_frequencies , HHT_freq_bins ) # Compute significance level for HHT power spectrum HHT_significance_level = compute_significance_level ( white_noise_imfs , HHT_freq_bins , time ) if not params [ 'silent' ]: if params [ 'EEMD' ]: print ( \"EEMD processed.\" ) else : print ( \"EMD processed.\" ) return HHT_power_spectrum , HHT_significance_level , HHT_freq_bins , psd_spectra , psd_confidence_levels , imfs , IMF_significance_levels , instantaneous_frequencies # ----------------------- Dominant Frequency & Averaged Power ------------------------------- def get_dominant_averaged ( cube , time , ** kwargs ): \"\"\" Analyze a 3D data cube to compute the dominant frequency and averaged power. Parameters: cube (3D array): Input data cube, expected in either 'txy' or 'xyt' format. time (array): Time array of the data cube. method (str): Analysis method ('fft' or 'wavelet'). format (str): Format of the data cube ('txy' or 'xyt'). Default is 'txy'. **kwargs: Additional parameters specific to the analysis method. Returns: dominantfreq (float): Dominant frequency of the data cube. averagedpower (float): Averaged power of the data cube. \"\"\" defaults = { 'method' : 'fft' , 'format' : 'txy' , 'silent' : False , 'GWS' : False , # If True, calculate global wavelet spectrum 'RGWS' : True , # If True, calculate refined global wavelet spectrum } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } # Check and adjust format if necessary if params [ 'format' ] == 'xyt' : cube = np . transpose ( cube , ( 2 , 0 , 1 )) # Convert 'xyt' to 'txy' elif params [ 'format' ] != 'txy' : raise ValueError ( \"Unsupported format. Choose 'txy' or 'xyt'.\" ) # Initialize arrays for storing results across spatial coordinates nt , nx , ny = cube . shape dominantfreq = np . zeros (( nx , ny )) if params [ 'method' ] == 'fft' : method_name = 'FFT' elif params [ 'method' ] == 'lombscargle' : method_name = 'Lomb-Scargle' elif params [ 'method' ] == 'wavelet' : method_name = 'Wavelet' elif params [ 'method' ] == 'welch' : method_name = 'Welch' if not params [ 'silent' ]: print ( f \"Processing { method_name } for a 3D cube with format ' { params [ 'format' ] } ' and shape { cube . shape } .\" ) print ( f \"Calculating Dominant frequencies and/or averaged power spectrum ( { method_name } ) ....\" ) # Iterate over spatial coordinates and apply the chosen analysis method if params [ 'method' ] == 'fft' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] fft_power , fft_freqs , _ , _ = getpowerFFT ( signal , time , silent = True , nosignificance = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( fft_freqs ))) powermap [ x , y , :] = fft_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = fft_freqs [ np . argmax ( fft_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = fft_freqs print ( \" \\n Analysis completed.\" ) elif params [ 'method' ] == 'lombscargle' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] ls_power , ls_freqs , _ = getpowerLS ( signal , time , silent = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( ls_freqs ))) powermap [ x , y , :] = ls_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = ls_freqs [ np . argmax ( ls_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = ls_freqs print ( \" \\n Analysis completed.\" ) elif params [ 'method' ] == 'wavelet' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] if params [ 'GWS' ]: _ , wavelet_periods , _ , _ , wavelet_power , _ , _ = getpowerWavelet ( signal , time , silent = True , ** kwargs ) elif params [ 'RGWS' ]: _ , wavelet_periods , _ , _ , _ , _ , wavelet_power = getpowerWavelet ( signal , time , silent = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( wavelet_periods ))) wavelet_freq = 1. / wavelet_periods powermap [ x , y , :] = wavelet_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = wavelet_freq [ np . argmax ( wavelet_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = wavelet_freq print ( \" \\n Analysis completed.\" ) elif params [ 'method' ] == 'welch' : for x in tqdm ( range ( nx ), desc = \"Processing x\" , leave = True ): for y in range ( ny ): signal = cube [:, x , y ] welch_power , welch_freqs , _ = welch_psd ( signal , time , silent = True , ** kwargs ) if x == 0 and y == 0 : powermap = np . zeros (( nx , ny , len ( welch_freqs ))) powermap [ x , y , :] = welch_power # Determine the dominant frequency for this pixel dominantfreq [ x , y ] = welch_freqs [ np . argmax ( welch_power )] # Calculate the averaged power over all pixels averagedpower = np . mean ( powermap , axis = ( 0 , 1 )) frequencies = welch_freqs print ( \" \\n Analysis completed.\" ) else : raise ValueError ( \"Unsupported method. Choose 'fft', 'lombscargle', 'wavelet', or 'welch'.\" ) return dominantfreq , averagedpower , frequencies , powermap WaLSA_wavelet.py This module implements the Wavelet Transform and related functionalities. WaLSA_wavelet.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools: - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- # The following code is a modified version of the PyCWT package. # The original code and licence: # PyCWT is released under the open source 3-Clause BSD license: # # Copyright (c) 2023 Sebastian Krieger, Nabil Freij, and contributors. All rights # reserved. # # Redistribution and use in source and binary forms, with or without # modification, are permitted provided that the following conditions are met: # # 1. Redistributions of source code must retain the above copyright notice, this # list of conditions and the following disclaimer. # # 2. Redistributions in binary form must reproduce the above copyright notice, # this list of conditions and the following disclaimer in the documentation # and/or other materials provided with the distribution. # # 3. Neither the name of the copyright holder nor the names of its contributors # may be used to endorse or promote products derived from this software # without specific prior written permission. # # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u201cAS IS\u201d AND # ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED # WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE # DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE # FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL # DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR # SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER # CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, # OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. # #---------------------------------------------------------------------------------- # Modifications by Shahin Jafarzadeh, 2024 #---------------------------------------------------------------------------------- from __future__ import ( absolute_import , division , print_function , unicode_literals ) import numpy as np # type: ignore from tqdm import tqdm # type: ignore from scipy.stats import chi2 # type: ignore # Try to import the Python wrapper for FFTW. try : import pyfftw.interfaces.scipy_fftpack as fft # type: ignore from multiprocessing import cpu_count # Fast planning, use all available threads. _FFTW_KWARGS_DEFAULT = { 'planner_effort' : 'FFTW_ESTIMATE' , 'threads' : cpu_count ()} def fft_kwargs ( signal , ** kwargs ): \"\"\"Return optimized keyword arguments for FFTW\"\"\" kwargs . update ( _FFTW_KWARGS_DEFAULT ) kwargs [ 'n' ] = len ( signal ) # do not pad return kwargs # Otherwise, fall back to 2 ** n padded scipy FFTPACK except ImportError : import scipy.fftpack as fft # type: ignore # Can be turned off, e.g. for MKL optimizations _FFT_NEXT_POW2 = True def fft_kwargs ( signal , ** kwargs ): \"\"\"Return next higher power of 2 for given signal to speed up FFT\"\"\" if _FFT_NEXT_POW2 : return { 'n' : int ( 2 ** np . ceil ( np . log2 ( len ( signal ))))} from scipy.signal import lfilter # type: ignore from os import makedirs from os.path import exists , expanduser def find ( condition ): \"\"\"Returns the indices where ravel(condition) is true.\"\"\" res , = np . nonzero ( np . ravel ( condition )) return res def ar1 ( x ): \"\"\" Allen and Smith autoregressive lag-1 autocorrelation coefficient. In an AR(1) model x(t) - <x> = gamma(x(t-1) - <x>) + \\alpha z(t) , where <x> is the process mean, gamma and \\alpha are process parameters and z(t) is a Gaussian unit-variance white noise. Parameters ---------- x : numpy.ndarray, list Univariate time series Returns ------- g : float Estimate of the lag-one autocorrelation. a : float Estimate of the noise variance [var(x) ~= a**2/(1-g**2)] mu2 : float Estimated square on the mean of a finite segment of AR(1) noise, mormalized by the process variance. References ---------- [1] Allen, M. R. and Smith, L. A. Monte Carlo SSA: detecting irregular oscillations in the presence of colored noise. *Journal of Climate*, **1996**, 9(12), 3373-3404. <http://dx.doi.org/10.1175/1520-0442(1996)009<3373:MCSDIO>2.0.CO;2> [2] http://www.madsci.org/posts/archives/may97/864012045.Eg.r.html \"\"\" x = np . asarray ( x ) N = x . size xm = x . mean () x = x - xm # Estimates the lag zero and one covariance c0 = x . transpose () . dot ( x ) / N c1 = x [ 0 : N - 1 ] . transpose () . dot ( x [ 1 : N ]) / ( N - 1 ) # According to A. Grinsteds' substitutions B = - c1 * N - c0 * N ** 2 - 2 * c0 + 2 * c1 - c1 * N ** 2 + c0 * N A = c0 * N ** 2 C = N * ( c0 + c1 * N - c1 ) D = B ** 2 - 4 * A * C if D > 0 : g = ( - B - D ** 0.5 ) / ( 2 * A ) else : raise Warning ( 'Cannot place an upperbound on the unbiased AR(1). ' 'Series is too short or trend is to large.' ) # According to Allen & Smith (1996), footnote 4 mu2 = - 1 / N + ( 2 / N ** 2 ) * (( N - g ** N ) / ( 1 - g ) - g * ( 1 - g ** ( N - 1 )) / ( 1 - g ) ** 2 ) c0t = c0 / ( 1 - mu2 ) a = (( 1 - g ** 2 ) * c0t ) ** 0.5 return g , a , mu2 def ar1_spectrum ( freqs , ar1 = 0. ): \"\"\" Lag-1 autoregressive theoretical power spectrum. Parameters ---------- freqs : numpy.ndarray, list Frequencies at which to calculate the theoretical power spectrum. ar1 : float Autoregressive lag-1 correlation coefficient. Returns ------- Pk : numpy.ndarray Theoretical discrete Fourier power spectrum of noise signal. References ---------- [1] http://www.madsci.org/posts/archives/may97/864012045.Eg.r.html \"\"\" # According to a post from the MadSci Network available at # http://www.madsci.org/posts/archives/may97/864012045.Eg.r.html, # the time-series spectrum for an auto-regressive model can be # represented as # # P_k = \\frac{E}{\\left|1- \\sum\\limits_{k=1}^{K} a_k \\, e^{2 i \\pi # \\frac{k f}{f_s} } \\right|^2} # # which for an AR1 model reduces to # freqs = np . asarray ( freqs ) Pk = ( 1 - ar1 ** 2 ) / np . abs ( 1 - ar1 * np . exp ( - 2 * np . pi * 1 j * freqs )) \\ ** 2 return Pk def rednoise ( N , g , a = 1. ): \"\"\" Red noise generator using filter. Parameters ---------- N : int Length of the desired time series. g : float Lag-1 autocorrelation coefficient. a : float, optional Noise innovation variance parameter. Returns ------- y : numpy.ndarray Red noise time series. \"\"\" if g == 0 : yr = np . randn ( N , 1 ) * a else : # Twice the decorrelation time. tau = int ( np . ceil ( - 2 / np . log ( np . abs ( g )))) yr = lfilter ([ 1 , 0 ], [ 1 , - g ], np . random . randn ( N + tau , 1 ) * a ) yr = yr [ tau :] return yr . flatten () def rect ( x , normalize = False ): \"\"\"TODO: describe what I do.\"\"\" if type ( x ) in [ int , float ]: shape = [ x , ] elif type ( x ) in [ list , dict ]: shape = x elif type ( x ) in [ np . ndarray , np . ma . core . MaskedArray ]: shape = x . shape X = np . zeros ( shape ) X [ 0 ] = X [ - 1 ] = 0.5 X [ 1 : - 1 ] = 1 if normalize : X /= X . sum () return X def boxpdf ( x ): \"\"\" Forces the probability density function of the input data to have a boxed distribution. Parameters ---------- x (array like) : Input data Returns ------- X (array like) : Boxed data varying between zero and one. Bx, By (array like) : Data lookup table. \"\"\" import numpy as np x = np . asarray ( x ) n = x . size # Kind of 'unique' i = np . argsort ( x ) d = ( np . diff ( x [ i ]) != 0 ) j = find ( np . concatenate ([ d , [ True ]])) X = x [ i ][ j ] j = np . concatenate ([[ 0 ], j + 1 ]) Y = 0.5 * ( j [ 0 : - 1 ] + j [ 1 :]) / n bX = np . interp ( x , X , Y ) return bX , X , Y def get_cache_dir (): \"\"\"Returns the location of the cache directory.\"\"\" # Sets cache directory according to user home path. cache_dir = ' {} /.cache/pycwt/' . format ( expanduser ( '~' )) # Creates cache directory if not existant. if not exists ( cache_dir ): makedirs ( cache_dir ) # Returns cache directory. return cache_dir import numpy as np from scipy.special import gamma from scipy.signal import convolve2d from scipy.special.orthogonal import hermitenorm class Morlet ( object ): \"\"\"Implements the Morlet wavelet class. Note that the input parameters f and f0 are angular frequencies. f0 should be more than 0.8 for this function to be correct, its default value is f0 = 6. \"\"\" def __init__ ( self , f0 = 6 ): self . _set_f0 ( f0 ) self . name = 'Morlet' def psi_ft ( self , f ): \"\"\"Fourier transform of the approximate Morlet wavelet.\"\"\" return ( np . pi ** - 0.25 ) * np . exp ( - 0.5 * ( f - self . f0 ) ** 2 ) def psi ( self , t ): \"\"\"Morlet wavelet as described in Torrence and Compo (1998).\"\"\" return ( np . pi ** - 0.25 ) * np . exp ( 1 j * self . f0 * t - t ** 2 / 2 ) def flambda ( self ): \"\"\"Fourier wavelength as of Torrence and Compo (1998).\"\"\" return ( 4 * np . pi ) / ( self . f0 + np . sqrt ( 2 + self . f0 ** 2 )) def coi ( self ): \"\"\"e-Folding Time as of Torrence and Compo (1998).\"\"\" return 1. / np . sqrt ( 2 ) def sup ( self ): \"\"\"Wavelet support defined by the e-Folding time.\"\"\" return 1. / self . coi def _set_f0 ( self , f0 ): # Sets the Morlet wave number, the degrees of freedom and the # empirically derived factors for the wavelet bases C_{\\delta}, # gamma, \\delta j_0 (Torrence and Compo, 1998, Table 2) self . f0 = f0 # Wave number self . dofmin = 2 # Minimum degrees of freedom if self . f0 == 6 : self . cdelta = 0.776 # Reconstruction factor self . gamma = 2.32 # Decorrelation factor for time averaging self . deltaj0 = 0.60 # Factor for scale averaging else : self . cdelta = - 1 self . gamma = - 1 self . deltaj0 = - 1 def smooth ( self , W , dt , dj , scales ): \"\"\"Smoothing function used in coherence analysis. Parameters ---------- W : dt : dj : scales : Returns ------- T : \"\"\" # The smoothing is performed by using a filter given by the absolute # value of the wavelet function at each scale, normalized to have a # total weight of unity, according to suggestions by Torrence & # Webster (1999) and by Grinsted et al. (2004). m , n = W . shape # Filter in time. k = 2 * np . pi * fft . fftfreq ( fft_kwargs ( W [ 0 , :])[ 'n' ]) k2 = k ** 2 snorm = scales / dt # Smoothing by Gaussian window (absolute value of wavelet function) # using the convolution theorem: multiplication by Gaussian curve in # Fourier domain for each scale, outer product of scale and frequency F = np . exp ( - 0.5 * ( snorm [:, np . newaxis ] ** 2 ) * k2 ) # Outer product smooth = fft . ifft ( F * fft . fft ( W , axis = 1 , ** fft_kwargs ( W [ 0 , :])), axis = 1 , # Along Fourier frequencies ** fft_kwargs ( W [ 0 , :], overwrite_x = True )) T = smooth [:, : n ] # Remove possibly padded region due to FFT if np . isreal ( W ) . all (): T = T . real # Filter in scale. For the Morlet wavelet it's simply a boxcar with # 0.6 width. wsize = self . deltaj0 / dj * 2 win = rect ( int ( np . round ( wsize )), normalize = True ) T = convolve2d ( T , win [:, np . newaxis ], 'same' ) # Scales are \"vertical\" return T class Paul ( object ): \"\"\"Implements the Paul wavelet class. Note that the input parameter f is the angular frequency and that the default order for this wavelet is m=4. \"\"\" def __init__ ( self , m = 4 ): self . _set_m ( m ) self . name = 'Paul' # def psi_ft(self, f): # \"\"\"Fourier transform of the Paul wavelet.\"\"\" # return (2 ** self.m / # np.sqrt(self.m * np.prod(range(2, 2 * self.m))) * # f ** self.m * np.exp(-f) * (f > 0)) def psi_ft ( self , f ): # modified by SJ \"\"\"Fourier transform of the Paul wavelet with limits to prevent underflow.\"\"\" expnt = - f expnt [ expnt < - 100 ] = - 100 # Apply the threshold to avoid extreme values return ( 2 ** self . m / np . sqrt ( self . m * np . prod ( range ( 2 , 2 * self . m ))) * f ** self . m * np . exp ( expnt ) * ( f > 0 )) def psi ( self , t ): \"\"\"Paul wavelet as described in Torrence and Compo (1998).\"\"\" return ( 2 ** self . m * 1 j ** self . m * np . prod ( range ( 2 , self . m - 1 )) / np . sqrt ( np . pi * np . prod ( range ( 2 , 2 * self . m + 1 ))) * ( 1 - 1 j * t ) ** ( - ( self . m + 1 ))) def flambda ( self ): \"\"\"Fourier wavelength as of Torrence and Compo (1998).\"\"\" return 4 * np . pi / ( 2 * self . m + 1 ) def coi ( self ): \"\"\"e-Folding Time as of Torrence and Compo (1998).\"\"\" return np . sqrt ( 2 ) def sup ( self ): \"\"\"Wavelet support defined by the e-Folding time.\"\"\" return 1 / self . coi def _set_m ( self , m ): # Sets the m derivative of a Gaussian, the degrees of freedom and the # empirically derived factors for the wavelet bases C_{\\delta}, # gamma, \\delta j_0 (Torrence and Compo, 1998, Table 2) self . m = m # Wavelet order self . dofmin = 2 # Minimum degrees of freedom if self . m == 4 : self . cdelta = 1.132 # Reconstruction factor self . gamma = 1.17 # Decorrelation factor for time averaging self . deltaj0 = 1.50 # Factor for scale averaging else : self . cdelta = - 1 self . gamma = - 1 self . deltaj0 = - 1 class DOG ( object ): \"\"\"Implements the derivative of a Guassian wavelet class. Note that the input parameter f is the angular frequency and that for m=2 the DOG becomes the Mexican hat wavelet, which is then default. \"\"\" def __init__ ( self , m = 2 ): self . _set_m ( m ) self . name = 'DOG' def psi_ft ( self , f ): \"\"\"Fourier transform of the DOG wavelet.\"\"\" return ( - 1 j ** self . m / np . sqrt ( gamma ( self . m + 0.5 )) * f ** self . m * np . exp ( - 0.5 * f ** 2 )) def psi ( self , t ): \"\"\"DOG wavelet as described in Torrence and Compo (1998). The derivative of a Gaussian of order `n` can be determined using the probabilistic Hermite polynomials. They are explicitly written as: Hn(x) = 2 ** (-n / s) * n! * sum ((-1) ** m) * (2 ** 0.5 * x) ** (n - 2 * m) / (m! * (n - 2*m)!) or in the recursive form: Hn(x) = x * Hn(x) - nHn-1(x) Source: http://www.ask.com/wiki/Hermite_polynomials \"\"\" p = hermitenorm ( self . m ) return (( - 1 ) ** ( self . m + 1 ) * np . polyval ( p , t ) * np . exp ( - t ** 2 / 2 ) / np . sqrt ( gamma ( self . m + 0.5 ))) def flambda ( self ): \"\"\"Fourier wavelength as of Torrence and Compo (1998).\"\"\" return ( 2 * np . pi / np . sqrt ( self . m + 0.5 )) def coi ( self ): \"\"\"e-Folding Time as of Torrence and Compo (1998).\"\"\" return 1 / np . sqrt ( 2 ) def sup ( self ): \"\"\"Wavelet support defined by the e-Folding time.\"\"\" return 1 / self . coi def _set_m ( self , m ): # Sets the m derivative of a Gaussian, the degrees of freedom and the # empirically derived factors for the wavelet bases C_{\\delta}, # gamma, \\delta j_0 (Torrence and Compo, 1998, Table 2). self . m = m # m-derivative self . dofmin = 1 # Minimum degrees of freedom if self . m == 2 : self . cdelta = 3.541 # Reconstruction factor self . gamma = 1.43 # Decorrelation factor for time averaging self . deltaj0 = 1.40 # Factor for scale averaging elif self . m == 6 : self . cdelta = 1.966 self . gamma = 1.37 self . deltaj0 = 0.97 else : self . cdelta = - 1 self . gamma = - 1 self . deltaj0 = - 1 class MexicanHat ( DOG ): \"\"\"Implements the Mexican hat wavelet class. This class inherits the DOG class using m=2. \"\"\" def __init__ ( self ): self . name = 'Mexican Hat' self . _set_m ( 2 ) def cwt ( signal , dt , dj = 1 / 12 , s0 =- 1 , J =- 1 , wavelet = 'morlet' , freqs = None , pad = True ): \"\"\"Continuous wavelet transform of the signal at specified scales. Parameters ---------- signal : numpy.ndarray, list Input signal array. dt : float Sampling interval. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N * dt / so)) / dj. wavelet : instance of Wavelet class, or string Mother wavelet class. Default is Morlet wavelet. freqs : numpy.ndarray, optional Custom frequencies to use instead of the ones corresponding to the scales described above. Corresponding scales are calculated using the wavelet Fourier wavelength. pad : optional. Default is True. if set, then pad the time series with enough zeroes to get N up to the next higher power of 2. This prevents wraparound from the end of the time series to the beginning, and also speeds up the FFT's used to do the wavelet transform. This will not eliminate all edge effects. (added by SJ) Returns ------- W : numpy.ndarray Wavelet transform according to the selected mother wavelet. Has (J+1) x N dimensions. sj : numpy.ndarray Vector of scale indices given by sj = s0 * 2**(j * dj), j={0, 1, ..., J}. freqs : array like Vector of Fourier frequencies (in 1 / time units) that corresponds to the wavelet scales. coi : numpy.ndarray Returns the cone of influence, which is a vector of N points containing the maximum Fourier period of useful information at that particular time. Periods greater than those are subject to edge effects. fft : numpy.ndarray Normalized fast Fourier transform of the input signal. fftfreqs : numpy.ndarray Fourier frequencies (in 1/time units) for the calculated FFT spectrum. Example ------- >> mother = wavelet.Morlet(6.) >> wave, scales, freqs, coi, fft, fftfreqs = wavelet.cwt(signal, 0.25, 0.25, 0.5, 28, mother) \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) # Original signal length n0 = len ( signal ) # If no custom frequencies are set, then set default frequencies # according to input parameters `dj`, `s0` and `J`. Otherwise, set wavelet # scales according to Fourier equivalent frequencies. # Zero-padding if enabled (added + the entire code further modified by SJ) if pad : next_power_of_two = int ( 2 ** np . ceil ( np . log2 ( n0 ))) signal_padded = np . zeros ( next_power_of_two ) signal_padded [: n0 ] = signal - np . mean ( signal ) # Remove the mean and pad with zeros else : signal_padded = signal - np . mean ( signal ) # Remove the mean without padding N = len ( signal_padded ) # Length of the padded signal # Calculate scales and frequencies if not provided if freqs is None : # Smallest resolvable scale # if s0 == -1: # s0 = 2 * dt / wavelet.flambda() # # Number of scales # if J == -1: # J = int(np.round(np.log2(N * dt / s0) / dj)) if s0 == - 1 : s0 = 2 * dt if J == - 1 : J = int (( np . log ( float ( N ) * dt / s0 ) / np . log ( 2 )) / dj ) # The scales as of Mallat 1999 sj = s0 * 2 ** ( np . arange ( 0 , J + 1 ) * dj ) # Fourier equivalent frequencies freqs = 1 / ( wavelet . flambda () * sj ) else : # The wavelet scales using custom frequencies. sj = 1 / ( wavelet . flambda () * freqs ) # Fourier transform of the (padded) signal signal_ft = fft . fft ( signal_padded , ** fft_kwargs ( signal_padded )) # Fourier angular frequencies ftfreqs = 2 * np . pi * fft . fftfreq ( N , dt ) # Creates wavelet transform matrix as outer product of scaled transformed # wavelets and transformed signal according to the convolution theorem. # (i) Transform scales to column vector for outer product; # (ii) Calculate 2D matrix [s, f] for each scale s and Fourier angular # frequency f; # (iii) Calculate wavelet transform; sj_col = sj [:, np . newaxis ] psi_ft_bar = (( sj_col * ftfreqs [ 1 ] * N ) ** .5 * np . conjugate ( wavelet . psi_ft ( sj_col * ftfreqs ))) W = fft . ifft ( signal_ft * psi_ft_bar , axis = 1 , ** fft_kwargs ( signal_ft , overwrite_x = True )) # Trim the wavelet transform to original signal length if padded if pad : W = W [:, : n0 ] # Trim to the original signal length # Checks for NaN in transform results and removes them from the scales if # needed, frequencies and wavelet transform. Trims wavelet transform at # length `n0`. sel = np . invert ( np . isnan ( W ) . all ( axis = 1 )) if np . any ( sel ): sj = sj [ sel ] freqs = freqs [ sel ] W = W [ sel , :] # Determines the cone-of-influence. Note that it is returned as a function # of time in Fourier periods. Uses triangualr Bartlett window with # non-zero end-points. coi = ( n0 / 2 - np . abs ( np . arange ( 0 , n0 ) - ( n0 - 1 ) / 2 )) coi = wavelet . flambda () * wavelet . coi () * dt * coi return ( W [:, : n0 ], sj , freqs , coi , signal_ft [ 1 : N // 2 ] / N ** 0.5 , ftfreqs [ 1 : N // 2 ] / ( 2 * np . pi )) def icwt ( W , sj , dt , dj = 1 / 12 , wavelet = 'morlet' ): \"\"\"Inverse continuous wavelet transform. Parameters ---------- W : numpy.ndarray Wavelet transform, the result of the `cwt` function. sj : numpy.ndarray Vector of scale indices as returned by the `cwt` function. dt : float Sample spacing. dj : float, optional Spacing between discrete scales as used in the `cwt` function. Default value is 0.25. wavelet : instance of Wavelet class, or string Mother wavelet class. Default is Morlet Returns ------- iW : numpy.ndarray Inverse wavelet transform. Example ------- >> mother = wavelet.Morlet() >> wave, scales, freqs, coi, fft, fftfreqs = wavelet.cwt(var, 0.25, 0.25, 0.5, 28, mother) >> iwave = wavelet.icwt(wave, scales, 0.25, 0.25, mother) \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) a , b = W . shape c = sj . size if a == c : sj = ( np . ones ([ b , 1 ]) * sj ) . transpose () elif b == c : sj = np . ones ([ a , 1 ]) * sj else : raise Warning ( 'Input array dimensions do not match.' ) # As of Torrence and Compo (1998), eq. (11) iW = ( dj * np . sqrt ( dt ) / ( wavelet . cdelta * wavelet . psi ( 0 )) * ( np . real ( W ) / np . sqrt ( sj )) . sum ( axis = 0 )) return iW def significance ( signal , dt , scales , sigma_test = 0 , alpha = None , significance_level = 0.95 , dof =- 1 , wavelet = 'morlet' ): \"\"\"Significance test for the one dimensional wavelet transform. Parameters ---------- signal : array like, float Input signal array. If a float number is given, then the variance is assumed to have this value. If an array is given, then its variance is automatically computed. dt : float Sample spacing. scales : array like Vector of scale indices given returned by `cwt` function. sigma_test : int, optional Sets the type of significance test to be performed. Accepted values are 0 (default), 1 or 2. See notes below for further details. alpha : float, optional Lag-1 autocorrelation, used for the significance levels. Default is 0.0. significance_level : float, optional Significance level to use. Default is 0.95. dof : variant, optional Degrees of freedom for significance test to be set according to the type set in sigma_test. wavelet : instance of Wavelet class, or string Mother wavelet class. Default is Morlet Returns ------- signif : array like Significance levels as a function of scale. fft_theor (array like): Theoretical red-noise spectrum as a function of period. Notes ----- If sigma_test is set to 0, performs a regular chi-square test, according to Torrence and Compo (1998) equation 18. If set to 1, performs a time-average test (equation 23). In this case, dof should be set to the number of local wavelet spectra that where averaged together. For the global wavelet spectra it would be dof=N, the number of points in the time-series. If set to 2, performs a scale-average test (equations 25 to 28). In this case dof should be set to a two element vector [s1, s2], which gives the scale range that were averaged together. If, for example, the average between scales 2 and 8 was taken, then dof=[2, 8]. \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) try : n0 = len ( signal ) except TypeError : n0 = 1 J = len ( scales ) - 1 dj = np . log2 ( scales [ 1 ] / scales [ 0 ]) if n0 == 1 : variance = signal else : variance = signal . std () ** 2 if alpha is None : alpha , _ , _ = ar1 ( signal ) period = scales * wavelet . flambda () # Fourier equivalent periods freq = dt / period # Normalized frequency dofmin = wavelet . dofmin # Degrees of freedom with no smoothing Cdelta = wavelet . cdelta # Reconstruction factor gamma_fac = wavelet . gamma # Time-decorrelation factor dj0 = wavelet . deltaj0 # Scale-decorrelation factor # Theoretical discrete Fourier power spectrum of the noise signal # following Gilman et al. (1963) and Torrence and Compo (1998), # equation 16. def pk ( k , a , N ): return ( 1 - a ** 2 ) / ( 1 + a ** 2 - 2 * a * np . cos ( 2 * np . pi * k / N )) fft_theor = pk ( freq , alpha , n0 ) fft_theor = variance * fft_theor # Including time-series variance signif = fft_theor try : if dof == - 1 : dof = dofmin except ValueError : pass if sigma_test == 0 : # No smoothing, dof=dofmin, TC98 sec. 4 dof = dofmin # As in Torrence and Compo (1998), equation 18. chisquare = chi2 . ppf ( significance_level , dof ) / dof signif = fft_theor * chisquare elif sigma_test == 1 : # Time-averaged significance if len ( dof ) == 1 : dof = np . zeros ( 1 , J + 1 ) + dof sel = find ( dof < 1 ) dof [ sel ] = 1 # As in Torrence and Compo (1998), equation 23: dof = dofmin * ( 1 + ( dof * dt / gamma_fac / scales ) ** 2 ) ** 0.5 sel = find ( dof < dofmin ) dof [ sel ] = dofmin # Minimum dof is dofmin for n , d in enumerate ( dof ): chisquare = chi2 . ppf ( significance_level , d ) / d signif [ n ] = fft_theor [ n ] * chisquare elif sigma_test == 2 : # Time-averaged significance if len ( dof ) != 2 : raise Exception ( 'DOF must be set to [s1, s2], ' 'the range of scale-averages' ) if Cdelta == - 1 : raise ValueError ( 'Cdelta and dj0 not defined ' 'for {} with f0= {} ' . format ( wavelet . name , wavelet . f0 )) s1 , s2 = dof sel = find (( scales >= s1 ) & ( scales <= s2 )) navg = sel . size if navg == 0 : raise ValueError ( 'No valid scales between {} and {} .' . format ( s1 , s2 )) # As in Torrence and Compo (1998), equation 25. Savg = 1 / sum ( 1. / scales [ sel ]) # Power-of-two mid point: Smid = np . exp (( np . log ( s1 ) + np . log ( s2 )) / 2. ) # As in Torrence and Compo (1998), equation 28. dof = ( dofmin * navg * Savg / Smid ) * \\ (( 1 + ( navg * dj / dj0 ) ** 2 ) ** 0.5 ) # As in Torrence and Compo (1998), equation 27. fft_theor = Savg * sum ( fft_theor [ sel ] / scales [ sel ]) chisquare = chi2 . ppf ( significance_level , dof ) / dof # As in Torrence and Compo (1998), equation 26. signif = ( dj * dt / Cdelta / Savg ) * fft_theor * chisquare else : raise ValueError ( 'sigma_test must be either 0, 1, or 2.' ) return signif , fft_theor def xwt ( y1 , y2 , dt , dj = 1 / 12 , s0 =- 1 , J =- 1 , significance_level = 0.95 , wavelet = 'morlet' , normalize = False , no_default_signif = False ): \"\"\"Cross wavelet transform (XWT) of two signals. The XWT finds regions in time frequency space where the time series show high common power. Parameters ---------- y1, y2 : numpy.ndarray, list Input signal array to calculate cross wavelet transform. dt : float Sample spacing. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N*dt/so))/dj. wavelet : instance of a wavelet class, optional Mother wavelet class. Default is Morlet wavelet. significance_level : float, optional Significance level to use. Default is 0.95. normalize : bool, optional If set to true, normalizes CWT by the standard deviation of the signals. Returns ------- xwt (array like): Cross wavelet transform according to the selected mother wavelet. x (array like): Intersected independent variable. coi (array like): Cone of influence, which is a vector of N points containing the maximum Fourier period of useful information at that particular time. Periods greater than those are subject to edge effects. freqs (array like): Vector of Fourier equivalent frequencies (in 1 / time units) that correspond to the wavelet scales. signif (array like): Significance levels as a function of scale. Notes ----- Torrence and Compo (1998) state that the percent point function (PPF) -- inverse of the cumulative distribution function -- of a chi-square distribution at 95% confidence and two degrees of freedom is Z2(95%)=3.999. However, calculating the PPF using chi2.ppf gives Z2(95%)=5.991. To ensure similar significance intervals as in Grinsted et al. (2004), one has to use confidence of 86.46%. \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) # Makes sure input signal are numpy arrays. y1 = np . asarray ( y1 ) y2 = np . asarray ( y2 ) # Calculates the standard deviation of both input signals. std1 = y1 . std () std2 = y2 . std () # Normalizes both signals, if appropriate. if normalize : y1_normal = ( y1 - y1 . mean ()) / std1 y2_normal = ( y2 - y2 . mean ()) / std2 else : y1_normal = y1 y2_normal = y2 # Calculates the CWT of the time-series making sure the same parameters # are used in both calculations. _kwargs = dict ( dj = dj , s0 = s0 , J = J , wavelet = wavelet ) W1 , sj , freq , coi , _ , _ = cwt ( y1_normal , dt , ** _kwargs ) W2 , sj , freq , coi , _ , _ = cwt ( y2_normal , dt , ** _kwargs ) # Now the wavelet transform coherence # W12ini = W1 * W2.conj() # scales = np.ones([1, y1.size]) * sj[:, None] # # -- Normalization by Scale and Smoothing # W12 = wavelet.smooth(W12ini / scales, dt, dj, sj) # Calculates the cross CWT of y1 and y2. W12 = W1 * W2 . conj () # And the significance tests. Note that the confidence level is calculated # using the percent point function (PPF) of the chi-squared cumulative # distribution function (CDF) instead of using Z1(95%) = 2.182 and # Z2(95%)=3.999 as suggested by Torrence & Compo (1998) and Grinsted et # al. (2004). If the CWT has been normalized, then std1 and std2 should # be reset to unity, otherwise the standard deviation of both series have # to be calculated. if normalize : std1 = std2 = 1. a1 , _ , _ = ar1 ( y1 ) a2 , _ , _ = ar1 ( y2 ) Pk1 = ar1_spectrum ( freq * dt , a1 ) Pk2 = ar1_spectrum ( freq * dt , a2 ) dof = wavelet . dofmin if not no_default_signif : PPF = chi2 . ppf ( significance_level , dof ) signif = ( std1 * std2 * ( Pk1 * Pk2 ) ** 0.5 * PPF / dof ) else : signif = np . asarray ([ 0 ]) # The resuts: return W12 , coi , freq , signif def wct ( y1 , y2 , dt , dj = 1 / 12 , s0 =- 1 , J =- 1 , sig = False , significance_level = 0.95 , wavelet = 'morlet' , normalize = False , ** kwargs ): \"\"\"Wavelet coherence transform (WCT). The WCT finds regions in time frequency space where the two time series co-vary, but do not necessarily have high power. Parameters ---------- y1, y2 : numpy.ndarray, list Input signals. dt : float Sample spacing. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N*dt/so))/dj. sig : bool set to compute signficance, default is True significance_level (float, optional) : Significance level to use. Default is 0.95. normalize (boolean, optional) : If set to true, normalizes CWT by the standard deviation of the signals. Returns ------- WCT : magnitude of coherence aWCT : phase angle of coherence coi (array like): Cone of influence, which is a vector of N points containing the maximum Fourier period of useful information at that particular time. Periods greater than those are subject to edge effects. freq (array like): Vector of Fourier equivalent frequencies (in 1 / time units) coi : sig : Significance levels as a function of scale if sig=True when called, otherwise zero. See also -------- cwt, xwt \"\"\" wavelet = _check_parameter_wavelet ( wavelet ) nt = len ( y1 ) # Checking some input parameters if s0 == - 1 : # s0 = 2 * dt / wavelet.flambda() s0 = 2 * dt if J == - 1 : # Number of scales # J = int(np.round(np.log2(y1.size * dt / s0) / dj)) J = int (( np . log ( float ( nt ) * dt / s0 ) / np . log ( 2 )) / dj ) # Makes sure input signals are numpy arrays. y1 = np . asarray ( y1 ) y2 = np . asarray ( y2 ) # Calculates the standard deviation of both input signals. std1 = y1 . std () std2 = y2 . std () # Normalizes both signals, if appropriate. if normalize : y1_normal = ( y1 - y1 . mean ()) / std1 y2_normal = ( y2 - y2 . mean ()) / std2 else : y1_normal = y1 y2_normal = y2 # Calculates the CWT of the time-series making sure the same parameters # are used in both calculations. _kwargs = dict ( dj = dj , s0 = s0 , J = J , wavelet = wavelet ) W1 , sj , freq , coi , _ , _ = cwt ( y1_normal , dt , ** _kwargs ) W2 , sj , freq , coi , _ , _ = cwt ( y2_normal , dt , ** _kwargs ) scales1 = np . ones ([ 1 , y1 . size ]) * sj [:, None ] scales2 = np . ones ([ 1 , y2 . size ]) * sj [:, None ] # Smooth the wavelet spectra before truncating -- Time Smoothing S1 = wavelet . smooth ( np . abs ( W1 ) ** 2 / scales1 , dt , dj , sj ) S2 = wavelet . smooth ( np . abs ( W2 ) ** 2 / scales2 , dt , dj , sj ) # Now the wavelet transform coherence W12 = W1 * W2 . conj () scales = np . ones ([ 1 , y1 . size ]) * sj [:, None ] # -- Normalization by Scale and Scale Smoothing S12 = wavelet . smooth ( W12 / scales , dt , dj , sj ) WCT = np . abs ( S12 ) ** 2 / ( S1 * S2 ) aWCT = np . angle ( W12 ) # Calculates the significance using Monte Carlo simulations with 95% # confidence as a function of scale. if sig : a1 , b1 , c1 = ar1 ( y1 ) a2 , b2 , c2 = ar1 ( y2 ) sig = wct_significance ( a1 , a2 , dt = dt , dj = dj , s0 = s0 , J = J , significance_level = significance_level , wavelet = wavelet , ** kwargs ) else : sig = np . asarray ([ 0 ]) return WCT , aWCT , coi , freq , sig def wct_significance ( al1 , al2 , dt , dj , s0 , J , significance_level = 0.95 , wavelet = 'morlet' , mc_count = 50 , progress = True , cache = True ): \"\"\"Wavelet coherence transform significance. Calculates WCT significance using Monte Carlo simulations with 95% confidence. Parameters ---------- al1, al2: float Lag-1 autoregressive coeficients of both time series. dt : float Sample spacing. dj : float, optional Spacing between discrete scales. Default value is 1/12. Smaller values will result in better scale resolution, but slower calculation and plot. s0 : float, optional Smallest scale of the wavelet. Default value is 2*dt. J : float, optional Number of scales less one. Scales range from s0 up to s0 * 2**(J * dj), which gives a total of (J + 1) scales. Default is J = (log2(N*dt/so))/dj. significance_level : float, optional Significance level to use. Default is 0.95. wavelet : instance of a wavelet class, optional Mother wavelet class. Default is Morlet wavelet. mc_count : integer, optional Number of Monte Carlo simulations. Default is 300. progress : bool, optional If `True` (default), shows progress bar on screen. cache : bool, optional If `True` (default) saves cache to file. Returns ------- TODO \"\"\" if cache : # Load cache if previously calculated. It is assumed that wavelet # analysis is performed using the wavelet's default parameters. aa = np . round ( np . arctanh ( np . array ([ al1 , al2 ]) * 4 )) aa = np . abs ( aa ) + 0.5 * ( aa < 0 ) cache_file = 'wct_sig_ {:0.5f} _ {:0.5f} _ {:0.5f} _ {:0.5f} _ {:d} _ {} ' \\ . format ( aa [ 0 ], aa [ 1 ], dj , s0 / dt , J , wavelet . name ) cache_dir = get_cache_dir () try : dat = np . loadtxt ( ' {} / {} .gz' . format ( cache_dir , cache_file ), unpack = True ) print ( 'NOTE: WCT significance loaded from cache. \\n ' ) return dat except IOError : pass # Some output to the screen print ( 'Calculating wavelet coherence significance' ) # Choose N so that largest scale has at least some part outside the COI ms = s0 * ( 2 ** ( J * dj )) / dt N = int ( np . ceil ( ms * 6 )) noise1 = rednoise ( N , al1 , 1 ) nW1 , sj , freq , coi , _ , _ = cwt ( noise1 , dt = dt , dj = dj , s0 = s0 , J = J , wavelet = wavelet ) period = np . ones ([ 1 , N ]) / freq [:, None ] coi = np . ones ([ J + 1 , 1 ]) * coi [ None , :] outsidecoi = ( period <= coi ) scales = np . ones ([ 1 , N ]) * sj [:, None ] sig95 = np . zeros ( J + 1 ) maxscale = find ( outsidecoi . any ( axis = 1 ))[ - 1 ] sig95 [ outsidecoi . any ( axis = 1 )] = np . nan nbins = 1000 wlc = np . ma . zeros ([ J + 1 , nbins ]) # Displays progress bar with tqdm for _ in tqdm ( range ( mc_count ), disable = not progress ): # Generates two red-noise signals with lag-1 autoregressive # coefficients given by al1 and al2 noise1 = rednoise ( N , al1 , 1 ) noise2 = rednoise ( N , al2 , 1 ) # Calculate the cross wavelet transform of both red-noise signals kwargs = dict ( dt = dt , dj = dj , s0 = s0 , J = J , wavelet = wavelet ) nW1 , sj , freq , coi , _ , _ = cwt ( noise1 , ** kwargs ) nW2 , sj , freq , coi , _ , _ = cwt ( noise2 , ** kwargs ) nW12 = nW1 * nW2 . conj () # Smooth wavelet wavelet transforms and calculate wavelet coherence # between both signals. S1 = wavelet . smooth ( np . abs ( nW1 ) ** 2 / scales , dt , dj , sj ) S2 = wavelet . smooth ( np . abs ( nW2 ) ** 2 / scales , dt , dj , sj ) S12 = wavelet . smooth ( nW12 / scales , dt , dj , sj ) R2 = np . ma . array ( np . abs ( S12 ) ** 2 / ( S1 * S2 ), mask =~ outsidecoi ) # Walks through each scale outside the cone of influence and builds a # coherence coefficient counter. for s in range ( maxscale ): cd = np . floor ( R2 [ s , :] * nbins ) for j , t in enumerate ( cd [ ~ cd . mask ]): wlc [ s , int ( t )] += 1 # After many, many, many Monte Carlo simulations, determine the # significance using the coherence coefficient counter percentile. wlc . mask = ( wlc . data == 0. ) R2y = ( np . arange ( nbins ) + 0.5 ) / nbins for s in range ( maxscale ): sel = ~ wlc [ s , :] . mask P = wlc [ s , sel ] . data . cumsum () P = ( P - 0.5 ) / P [ - 1 ] sig95 [ s ] = np . interp ( significance_level , P , R2y [ sel ]) if cache : # Save the results on cache to avoid to many computations in the future np . savetxt ( ' {} / {} .gz' . format ( cache_dir , cache_file ), sig95 ) # And returns the results return sig95 def _check_parameter_wavelet ( wavelet ): mothers = { 'morlet' : Morlet , 'paul' : Paul , 'dog' : DOG , 'mexicanhat' : MexicanHat } # Checks if input parameter is a string. For backwards # compatibility with Python 2 we check if instance is a # `str`. try : if isinstance ( wavelet , str ): return mothers [ wavelet ]() except NameError : if isinstance ( wavelet , str ): return mothers [ wavelet ]() # Otherwise, return itself. return wavelet WaLSA_k_omega.py This module provides functions for performing k-\u03c9 analysis and filtering in spatio-temporal datasets. WaLSA_k_omega.py # -------------------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # -------------------------------------------------------------------------------------------------------------- # The following codes are baed on those originally written by Rob Rutten, David B. Jess, and Samuel D. T. Grant # -------------------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.optimize import curve_fit # type: ignore from scipy.signal import convolve # type: ignore # -------------------------------------------------------------------------------------------- def gaussian_function ( sigma , width = None ): \"\"\" Create a Gaussian kernel that closely matches the IDL implementation. Parameters: sigma (float or list of floats): Standard deviation(s) of the Gaussian. width (int or list of ints, optional): Width of the Gaussian kernel. Returns: np.ndarray: The Gaussian kernel. \"\"\" # sigma = np.array(sigma, dtype=np.float64) sigma = np . atleast_1d ( np . array ( sigma , dtype = np . float64 )) # Ensure sigma is at least 1D if np . any ( sigma <= 0 ): raise ValueError ( \"Sigma must be greater than 0.\" ) # width = np.array(width) width = np . atleast_1d ( np . array ( width )) # Ensure width is always at least 1D width = np . maximum ( width . astype ( np . int64 ), 1 ) # Convert to integers and ensure > 0 if np . any ( width <= 0 ): raise ValueError ( \"Width must be greater than 0.\" ) nSigma = np . size ( sigma ) if nSigma > 8 : raise ValueError ( 'Sigma can have no more than 8 elements' ) nWidth = np . size ( width ) if nWidth > nSigma : raise ValueError ( 'Incorrect width specification' ) if ( nWidth == 1 ) and ( nSigma > 1 ): width = np . full ( nSigma , width [ 0 ]) # kernel = np.zeros(tuple(width.astype(int)), dtype=np.float64) kernel = np . zeros ( tuple ( width [: nSigma ] . astype ( int )), dtype = np . float64 ) # Match kernel size to nSigma temp = np . zeros ( 8 , dtype = np . int64 ) temp [: nSigma ] = width [: nSigma ] width = temp if nSigma == 2 : b = a = 0 if nSigma >= 1 : a = np . linspace ( 0 , width [ 0 ] - 1 , width [ 0 ]) - width [ 0 ] // 2 + ( 0 if width [ 0 ] % 2 else 0.5 ) if nSigma >= 2 : b = np . linspace ( 0 , width [ 1 ] - 1 , width [ 1 ]) - width [ 1 ] // 2 + ( 0 if width [ 1 ] % 2 else 0.5 ) a1 = b1 = 0 # Nested loop for kernel computation (to be completed for larger nSigma ....) for bb in range ( width [ 1 ]): b1 = ( b [ bb ] ** 2 ) / ( 2 * sigma [ 1 ] ** 2 ) if nSigma >= 2 else 0 for aa in range ( width [ 0 ]): a1 = ( a [ aa ] ** 2 ) / ( 2 * sigma [ 0 ] ** 2 ) if nSigma >= 1 else 0 kernel [ aa , bb ] = np . exp ( - np . clip (( a1 + b1 ), - 1e3 , 1e3 ) ) elif nSigma == 1 : a = 0 if nSigma >= 1 : a = np . linspace ( 0 , width [ 0 ] - 1 , width [ 0 ]) - width [ 0 ] // 2 + ( 0 if width [ 0 ] % 2 else 0.5 ) a1 = 0 # Nested loop for kernel computation for aa in range ( width [ 0 ]): a1 = ( a [ aa ] ** 2 ) / ( 2 * sigma [ 0 ] ** 2 ) if nSigma >= 1 else 0 kernel [ aa ] = np . exp ( - np . clip ( a1 , - 1e3 , 1e3 ) ) kernel = np . nan_to_num ( kernel , nan = 0.0 , posinf = 0.0 , neginf = 0.0 ) if np . sum ( kernel ) == 0 : raise ValueError ( \"Generated Gaussian kernel is invalid (all zeros).\" ) return kernel def walsa_radial_distances ( shape ): \"\"\" Compute the radial distance array for a given shape. Parameters: shape (tuple): Shape of the array, typically (ny, nx). Returns: numpy.ndarray: Array of radial distances. \"\"\" if not ( isinstance ( shape , tuple ) and len ( shape ) == 2 ): raise ValueError ( \"Shape must be a tuple with two elements, e.g., (ny, nx).\" ) y , x = np . indices ( shape ) cy , cx = ( np . array ( shape ) - 1 ) / 2 return np . sqrt (( x - cx ) ** 2 + ( y - cy ) ** 2 ) def avgstd ( array ): \"\"\" Calculate the average and standard deviation of an array. \"\"\" avrg = np . sum ( array ) / array . size stdev = np . sqrt ( np . sum (( array - avrg ) ** 2 ) / array . size ) return avrg , stdev def linear ( x , * p ): \"\"\" Compute a linear model y = p[0] + x * p[1]. (used in temporal detrending ) \"\"\" if len ( p ) < 2 : raise ValueError ( \"Parameters p[0] and p[1] must be provided.\" ) ymod = p [ 0 ] + x * p [ 1 ] return ymod def gradient ( xy , * p ): \"\"\" Gradient function for fitting spatial trends. Parameters: xy: Tuple of grid coordinates (x, y). p: Coefficients [offset, slope_x, slope_y]. \"\"\" x , y = xy # Unpack the tuple if len ( p ) < 3 : raise ValueError ( \"Parameters p[0], p[1], and p[2] must be provided.\" ) return p [ 0 ] + x * p [ 1 ] + y * p [ 2 ] def apod3dcube ( cube , apod ): \"\"\" Apodizes a 3D cube in all three coordinates, with detrending. Parameters: cube : Input 3D data cube with dimensions (nx, ny, nt). apod (float): Apodization factor (0 means no apodization). Returns: Apodized 3D cube. \"\"\" # Get cube dimensions nt , nx , ny = cube . shape apocube = np . zeros_like ( cube , dtype = np . float32 ) # Define temporal apodization apodt = np . ones ( nt , dtype = np . float32 ) if apod != 0 : apodrimt = nt * apod apodrimt = int ( apodrimt ) # Ensure apodrimt is an integer apodt [: apodrimt ] = ( np . sin ( np . pi / 2. * np . arange ( apodrimt ) / apodrimt )) ** 2 apodt = apodt * np . roll ( np . flip ( apodt ), 1 ) # Apply symmetrical apodization # Temporal detrending (mean-image trend, not per pixel) ttrend = np . zeros ( nt , dtype = np . float32 ) tf = np . arange ( nt ) + 1.0 for it in range ( nt ): img = cube [ it , :, :] # ttrend[it], _ = avgstd(img) ttrend [ it ] = np . mean ( img ) # Fit the trend with a linear model fitp , _ = curve_fit ( linear , tf , ttrend , p0 = [ 1000.0 , 0.0 ]) # fit = fitp[0] + tf * fitp[1] fit = linear ( tf , * fitp ) # Temporal apodization per (x, y) column for it in range ( nt ): img = cube [ it , :, :] apocube [ it , :, :] = ( img - fit [ it ]) * apodt [ it ] # Define spatial apodization apodx = np . ones ( nx , dtype = np . float32 ) apody = np . ones ( ny , dtype = np . float32 ) if apod != 0 : apodrimx = apod * nx apodrimy = apod * ny apodrimx = int ( apodrimx ) # Ensure apodrimx is an integer apodrimy = int ( apodrimy ) # Ensure apodrimy is an integer apodx [: apodrimx ] = ( np . sin ( np . pi / 2. * np . arange ( int ( apodrimx )) / apodrimx )) ** 2 apody [: apodrimy ] = ( np . sin ( np . pi / 2. * np . arange ( int ( apodrimy )) / apodrimy )) ** 2 apodx = apodx * np . roll ( np . flip ( apodx ), 1 ) apody = apody * np . roll ( np . flip ( apody ), 1 ) apodxy = np . outer ( apodx , apody ) else : apodxy = np . outer ( apodx , apody ) # Spatial gradient removal and apodizing per image # xf, yf = np.meshgrid(np.arange(nx), np.arange(ny), indexing='ij') xf = np . ones (( nx , ny ), dtype = np . float32 ) yf = np . copy ( xf ) for it in range ( nt ): img = apocube [ it , :, :] # avg, _ = avgstd(img) avg = np . mean ( img ) # Ensure xf, yf, and img are properly defined assert xf . shape == yf . shape == img . shape , \"xf, yf, and img must have matching shapes.\" # Flatten the inputs for curve_fit x_flat = xf . ravel () y_flat = yf . ravel () img_flat = img . ravel () # Ensure lengths match assert len ( x_flat ) == len ( y_flat ) == len ( img_flat ), \"Flattened inputs must have the same length.\" # Call curve_fit with initial parameters fitp , _ = curve_fit ( gradient , ( x_flat , y_flat ), img_flat , p0 = [ 1000.0 , 0.0 , 0.0 ]) # Apply the fitted parameters fit = gradient (( xf , yf ), * fitp ) apocube [ it , :, :] = ( img - fit ) * apodxy + avg return apocube def ko_dist ( sx , sy , double = False ): \"\"\" Set up Pythagorean distance array from the origin. \"\"\" # Create distance grids for x and y # (computing dx and dy using floating-point division) dx = np . tile ( np . arange ( sx / 2 + 1 ) / ( sx / 2 ), ( int ( sy / 2 + 1 ), 1 )) . T dy = np . flip ( np . tile ( np . arange ( sy / 2 + 1 ) / ( sy / 2 ), ( int ( sx / 2 + 1 ), 1 )), axis = 0 ) # Compute dxy dxy = np . sqrt ( dx ** 2 + dy ** 2 ) * ( min ( sx , sy ) / 2 + 1 ) # Initialize afstanden afstanden = np . zeros (( sx , sy ), dtype = np . float64 ) # Assign dxy to the first quadrant (upper-left) afstanden [: sx // 2 + 1 , : sy // 2 + 1 ] = dxy # Second quadrant (upper-right) - 90\u00b0 clockwise afstanden [ sx // 2 :, : sy // 2 + 1 ] = np . flip ( np . roll ( dxy [: - 1 , :], shift =- 1 , axis = 1 ), axis = 1 ) # Third quadrant (lower-left) - 270\u00b0 clockwise afstanden [: sx // 2 + 1 , sy // 2 :] = np . flip ( np . roll ( dxy [:, : - 1 ], shift =- 1 , axis = 0 ), axis = 0 ) # Fourth quadrant (lower-right) - 180\u00b0 rotation afstanden [ sx // 2 :, sy // 2 :] = np . flip ( dxy [: - 1 , : - 1 ], axis = ( 0 , 1 )) # Convert to integers if 'double' is False if not double : afstanden = np . round ( afstanden ) . astype ( int ) return afstanden def averpower ( cube ): \"\"\" Compute 2D (k_h, f) power array by circular averaging over k_x, k_y. Parameters: cube : Input 3D data cube of dimensions (nx, ny, nt). Returns: avpow : 2D array of average power over distances, dimensions (maxdist+1, nt/2+1). \"\"\" # Get cube dimensions nt , nx , ny = cube . shape # Perform FFT in all three dimensions (first in time direction) fftcube = np . fft . fft ( np . fft . fft ( np . fft . fft ( cube , axis = 0 )[: nt // 2 + 1 , :, :], axis = 1 ), axis = 2 ) # Set up distances afstanden = ko_dist ( nx , ny ) # Integer-rounded Pythagoras array maxdist = min ( nx , ny ) // 2 + 1 # Largest quarter circle # Initialize average power array avpow = np . zeros (( maxdist + 1 , nt // 2 + 1 ), dtype = np . float64 ) # Compute average power over all k_h distances, building power(k_h, f) for i in range ( maxdist + 1 ): where_indices = np . where ( afstanden == i ) for j in range ( nt // 2 + 1 ): w1 = fftcube [ j , :, :][ where_indices ] avpow [ i , j ] = np . sum ( np . abs ( w1 ) ** 2 ) / len ( where_indices ) return avpow def walsa_kopower_funct ( datacube , ** kwargs ): \"\"\" Calculate k-omega diagram (Fourier power at temporal frequency f against horizontal spatial wavenumber k_h) Origonally written in IDL by Rob Rutten (RR) assembly of Alfred de Wijn's routines (2010) - Translated into Pythn by Shahin Jafarzadeh (2024) Parameters: datacube: Input data cube [t, x, y]. arcsecpx (float): Spatial sampling in arcsec/pixel. cadence (float): Temporal sampling in seconds. apod: fractional extent of apodization edges; default 0.1 kmax: maximum k_h axis as fraction of Nyquist value, default 0.2 fmax: maximum f axis as fraction of Nyquist value, default 0.5 minpower: minimum of power plot range, default maxpower-5 maxpower: maximum of power plot range, default alog10(max(power)) Returns: k-omega power map. \"\"\" # Set default parameter values defaults = { 'apod' : 0.1 , 'kmax' : 1.0 , 'fmax' : 1.0 , 'minpower' : None , 'maxpower' : None } # Update defaults with user-provided values params = { ** defaults , ** kwargs } # Apodize the cube apocube = apod3dcube ( datacube , params [ 'apod' ]) # Compute radially-averaged power avpow = averpower ( apocube ) return avpow # -------------------------------------- Main Function ---------------------------------------- def WaLSA_k_omega ( signal , time = None , ** kwargs ): \"\"\" NAME: WaLSA_k_omega part of -- WaLSAtools -- * Main function to calculate and plot k-omega diagram. ORIGINAL CODE: QUEEns Fourier Filtering (QUEEFF) code WRITTEN, ANNOTATED, TESTED AND UPDATED in IDL BY: (1) Dr. David B. Jess (2) Dr. Samuel D. T. Grant The original code along with its manual can be downloaded at: https://bit.ly/37mx9ic WaLSA_k_omega (in IDL): A lightly modified version of the original code (i.e., a few additional keywords added) by Dr. Shahin Jafarzadeh - Translated into Pythn by Shahin Jafarzadeh (2024) Parameters: signal (array): Input datacube, normally in the form of [x, y, t] or [t, x, y]. Note that the input datacube must have identical x and y dimensions. If not, the datacube will be cropped accordingly. time (array): Time array corresponding to the input datacube. pixelsize (float): Spatial sampling of the input datacube. If not given, it is plotted in units of 'pixel'. filtering (bool): If True, filtering is applied, and the filtered datacube (filtered_cube) is returned. Otherwise, None is returned. Default: False. f1 (float): Optional lower (temporal) frequency to filter, in Hz. f2 (float): Optional upper (temporal) frequency to filter, in Hz. k1 (float): Optional lower (spatial) wavenumber to filter, in units of pixelsize^-1 (k = (2 * \u03c0) / wavelength). k2 (float): Optional upper (spatial) wavenumber to filter, in units of pixelsize^-1. spatial_torus (bool): If True, makes the annulus used for spatial filtering have a Gaussian-shaped profile, useful for preventing aliasing. Default: True. temporal_torus (bool): If True, makes the temporal filter have a Gaussian-shaped profile, useful for preventing aliasing. Default: True. no_spatial_filt (bool): If True, ensures no spatial filtering is performed on the dataset (i.e., only temporal filtering is applied). no_temporal_filt (bool): If True, ensures no temporal filtering is performed on the dataset (i.e., only spatial filtering is applied). silent (bool): If True, suppresses the k-\u03c9 diagram plot. smooth (bool): If True, power is smoothed. Default: True. mode (int): Output power mode: 0 = log10(power) (default), 1 = linear power, 2 = sqrt(power) = amplitude. processing_maps (bool): If True, the function returns the processing maps (spatial_fft_map, torus_map, spatial_fft_filtered_map, temporal_fft, temporal_filter, temporal_frequencies, spatial_frequencies). Otherwise, they are all returned as None. Default: False. OUTPUTS: power : 2D array of power (see mode for the scale). frequencies : 1D array of frequencies (in mHz). wavenumber : 1D array of wavenumber (in pixelsize^-1). filtered_cube : 3D array of filtered datacube (if filtering is set). processing_maps (if set to True) IF YOU USE THIS CODE, THEN PLEASE CITE THE ORIGINAL PUBLICATION WHERE IT WAS USED: Jess et al. 2017, ApJ, 842, 59 (http://adsabs.harvard.edu/abs/2017ApJ...842...59J) \"\"\" # Set default parameter values defaults = { 'pixelsize' : 1 , 'format' : 'txy' , 'filtering' : False , 'f1' : None , 'f2' : None , 'k1' : None , 'k2' : None , 'spatial_torus' : True , 'temporal_torus' : True , 'no_spatial_filt' : False , 'no_temporal_filt' : False , 'silent' : False , 'xlog' : False , 'ylog' : False , 'xrange' : None , 'yrange' : None , 'nox2' : False , 'noy2' : False , 'smooth' : True , 'mode' : 0 , 'xtitle' : 'Wavenumber' , 'xtitle_units' : '(pixel\u207b\u00b9)' , 'ytitle' : 'Frequency' , 'yttitle_units' : '(Hz)' , 'x2ndaxistitle' : 'Spatial size' , 'y2ndaxistitle' : 'Period' , 'x2ndaxistitle_units' : '(pixel)' , 'y2ndaxistitle_units' : '(s)' , 'processing_maps' : False } # Update defaults with user-provided values params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) pixelsize = params [ 'pixelsize' ] filtered_cube = None spatial_fft_map = None torus_map = None spatial_fft_filtered_map = None temporal_fft = None temporal_frequencies = None spatial_frequencies = None # Check and adjust format if necessary if params [ 'format' ] == 'xyt' : cube = np . transpose ( cube , ( 2 , 0 , 1 )) # Convert 'xyt' to 'txy' elif params [ 'format' ] != 'txy' : raise ValueError ( \"Unsupported format. Choose 'txy' or 'xyt'.\" ) if not params [ 'silent' ]: print ( f \"Processing k-\u03c9 analysis for a 3D cube with format ' { params [ 'format' ] } ' and shape { signal . shape } .\" ) # Input dimensions nt , nx , ny = signal . shape if nx != ny : min_dim = min ( nx , ny ) signal = signal [: min_dim , : min_dim , :] nt , nx , ny = signal . shape # Calculating the Nyquist frequencies spatial_nyquist = ( 2 * np . pi ) / ( pixelsize * 2 ) temporal_nyquist = 1 / ( cadence * 2 ) print ( \"\" ) print ( f \"Input datacube size (t,x,y): { signal . shape } \" ) print ( \"\" ) print ( \"Spatially, the important values are:\" ) print ( f \" 2-pixel size = { pixelsize * 2 : .2f } { params [ 'x2ndaxistitle_units' ] } \" ) print ( f \" Nyquist wavenumber = { spatial_nyquist : .2f } { params [ 'xtitle_units' ] } \" ) if params [ 'no_spatial_filt' ]: print ( \"*** NO SPATIAL FILTERING WILL BE PERFORMED ***\" ) print ( \"\" ) print ( \"Temporally, the important values are:\" ) print ( f \" 2-element duration (Nyquist period) = { cadence * 2 : .2f } { params [ 'y2ndaxistitle_units' ] } \" ) print ( f \" Time series duration = { cadence * signal . shape [ 2 ] : .2f } { params [ 'y2ndaxistitle_units' ] } \" ) temporal_nyquist = 1 / ( cadence * 2 ) print ( f \" Nyquist frequency = { temporal_nyquist : .2f } { params [ 'yttitle_units' ] } \" ) if params [ 'no_temporal_filt' ]: print ( \"***NO TEMPORAL FILTERING WILL BE PERFORMED***\" ) print ( \"\" ) # Generate k-omega power map print ( \"Constructing a k-\u03c9 diagram of the input datacube..........\" ) print ( \"\" ) # Make the k-omega diagram using the proven method of Rob Rutten kopower = walsa_kopower_funct ( signal ) # Scales xsize_kopower = kopower . shape [ 0 ] dxsize_kopower = spatial_nyquist / float ( xsize_kopower - 1 ) kopower_xscale = np . arange ( xsize_kopower ) * dxsize_kopower # in pixel\u207b\u00b9 ysize_kopower = kopower . shape [ 1 ] dysize_kopower = temporal_nyquist / float ( ysize_kopower - 1 ) kopower_yscale = ( np . arange ( ysize_kopower ) * dysize_kopower ) # in Hz # Generate Gaussian Kernel Gaussian_kernel = gaussian_function ( sigma = [ 0.65 , 0.65 ], width = 3 ) Gaussian_kernel_norm = np . nansum ( Gaussian_kernel ) # Normalize kernel sum # Copy kopower to kopower_plot kopower_plot = kopower . copy () # Convolve kopower (ignoring zero-th element, starting from index 1) kopower_plot [:, 1 :] = convolve ( kopower [:, 1 :], Gaussian_kernel , mode = 'same' ) / Gaussian_kernel_norm # Normalize to frequency resolution (in mHz) freq = kopower_yscale [ 1 :] if freq [ 0 ] == 0 : freq0 = freq [ 1 ] else : freq0 = freq [ 0 ] kopower_plot /= freq0 # Apply logarithmic or square root transformation based on mode if params [ 'mode' ] == 0 : # Logarithmic scaling kopower_plot = np . log10 ( kopower_plot ) elif params [ 'mode' ] == 2 : # Square root scaling kopower_plot = np . sqrt ( kopower_plot ) # Normalize the power - preferred for plotting komegamap = np . clip ( kopower_plot [ 1 :, 1 :], np . nanmin ( kopower_plot [ 1 :, 1 :]), np . nanmax ( kopower_plot [ 1 :, 1 :]) ) kopower_zscale = kopower_plot [ 1 :, 1 :] # Rotate kopower counterclockwise by 90 degrees komegamap = np . rot90 ( komegamap , k = 1 ) # Flip vertically (y-axis) komegamap = np . flip ( komegamap , axis = 0 ) # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Filtering implementation if params [ 'filtering' ]: # Extract parameters from the dictionary k1 = params [ 'k1' ] k2 = params [ 'k2' ] f1 = params [ 'f1' ] f2 = params [ 'f2' ] if params [ 'no_spatial_filt' ]: k1 = kopower_xscale [ 1 ] # Default lower wavenumber k2 = np . nanmax ( kopower_xscale ) # Default upper wavenumber # Ensure k1 and k2 are within valid bounds if k1 is None or k1 <= 0.0 : k1 = kopower_xscale [ 1 ] if k2 is None or k2 > np . nanmax ( kopower_xscale ): k2 = np . nanmax ( kopower_xscale ) if params [ 'no_temporal_filt' ]: f1 = kopower_yscale [ 1 ] f2 = np . nanmax ( kopower_yscale ) # Ensure f1 and f2 are within valid bounds if f1 is None or f1 <= 0.0 : f1 = kopower_yscale [ 1 ] if f2 is None or f2 > np . nanmax ( kopower_yscale ): f2 = np . nanmax ( kopower_yscale ) print ( \"Start filtering (in k-\u03c9 space) ......\" ) print ( \"\" ) print ( f \"The preserved wavenumbers are [ { k1 : .3f } , { k2 : .3f } ] { params [ 'xtitle_units' ] } \" ) print ( f \"The preserved spatial sizes are [ { ( 2 * np . pi ) / k2 : .3f } , { ( 2 * np . pi ) / k1 : .3f } ] { params [ 'x2ndaxistitle_units' ] } \" ) print ( \"\" ) print ( f \"The preserved frequencies are [ { f1 : .3f } , { f2 : .3f } ] { params [ 'yttitle_units' ] } \" ) print ( f \"The preserved periods are [ { int ( 1 / ( f2 )) } , { int ( 1 / ( f1 )) } ] { params [ 'y2ndaxistitle_units' ] } \" ) print ( \"\" ) # Perform the 3D Fourier transform print ( \"Making a 3D Fourier transform of the input datacube ..........\" ) threedft = np . fft . fftshift ( np . fft . fftn ( signal )) # Calculate the frequency axes for the 3D FFT temp_x = np . arange (( nx - 1 ) // 2 ) + 1 is_N_even = ( nx % 2 == 0 ) if is_N_even : spatial_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_x , [ nx / 2 ], - nx / 2 + temp_x ]) / ( nx * pixelsize )) * ( 2.0 * np . pi ) else : spatial_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_x , [ - ( nx / 2 + 1 )] + temp_x ]) / ( nx * pixelsize )) * ( 2.0 * np . pi ) temp_t = np . arange (( nt - 1 ) // 2 ) + 1 # Use integer division for clarity is_N_even = ( nt % 2 == 0 ) if is_N_even : temporal_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_t , [ nt / 2 ], - nt / 2 + temp_t ])) / ( nt * cadence ) else : temporal_frequencies_orig = ( np . concatenate ([[ 0.0 ], temp_t , [ - ( nt / 2 + 1 )] + temp_t ])) / ( nt * cadence ) # Compensate frequency axes for the use of FFT shift indices = np . where ( spatial_frequencies_orig >= 0 )[ 0 ] spatial_positive_frequencies = len ( indices ) if len ( spatial_frequencies_orig ) % 2 == 0 : spatial_frequencies = np . roll ( spatial_frequencies_orig , spatial_positive_frequencies - 2 ) else : spatial_frequencies = np . roll ( spatial_frequencies_orig , spatial_positive_frequencies - 1 ) tindices = np . where ( temporal_frequencies_orig >= 0 )[ 0 ] temporal_positive_frequencies = len ( tindices ) if len ( temporal_frequencies_orig ) % 2 == 0 : temporal_frequencies = np . roll ( temporal_frequencies_orig , temporal_positive_frequencies - 2 ) else : temporal_frequencies = np . roll ( temporal_frequencies_orig , temporal_positive_frequencies - 1 ) # Ensure the threedft aligns with the new frequency axes if len ( temporal_frequencies_orig ) % 2 == 0 : for x in range ( nx ): for y in range ( ny ): threedft [:, x , y ] = np . roll ( threedft [:, x , y ], - 1 ) if len ( spatial_frequencies_orig ) % 2 == 0 : for z in range ( nt ): threedft [ z , :, :] = np . roll ( threedft [ z , :, :], shift = ( - 1 , - 1 ), axis = ( 0 , 1 )) # Convert frequencies and wavenumbers of interest into FFT datacube pixels pixel_k1_positive = np . argmin ( np . abs ( spatial_frequencies_orig - k1 )) pixel_k2_positive = np . argmin ( np . abs ( spatial_frequencies_orig - k2 )) pixel_f1_positive = np . argmin ( np . abs ( temporal_frequencies - f1 )) pixel_f2_positive = np . argmin ( np . abs ( temporal_frequencies - f2 )) pixel_f1_negative = np . argmin ( np . abs ( temporal_frequencies + f1 )) pixel_f2_negative = np . argmin ( np . abs ( temporal_frequencies + f2 )) torus_depth = int (( pixel_k2_positive - pixel_k1_positive ) / 2 ) * 2 torus_center = int ((( pixel_k2_positive - pixel_k1_positive ) / 2 ) + pixel_k1_positive ) if params [ 'spatial_torus' ] and not params [ 'no_spatial_filt' ]: # Create a filter ring preserving equal wavenumbers for both kx and ky # This forms a torus to preserve an integrated Gaussian shape across the width of the annulus spatial_torus = np . zeros (( torus_depth , nx , ny )) for i in range ( torus_depth // 2 + 1 ): spatial_ring = np . logical_xor ( ( walsa_radial_distances (( nx , ny )) <= ( torus_center - i )), ( walsa_radial_distances (( nx , ny )) <= ( torus_center + i + 1 )) ) spatial_ring = spatial_ring . astype ( int ) # Convert True -> 1 and False -> 0 spatial_ring [ spatial_ring > 0 ] = 1. spatial_ring [ spatial_ring != 1 ] = 0. spatial_torus [ i , :, :] = spatial_ring spatial_torus [ torus_depth - i - 1 , :, :] = spatial_ring # Integrate through the torus to find the spatial filter spatial_ring_filter = np . nansum ( spatial_torus , axis = 0 ) / float ( torus_depth ) spatial_ring_filter = spatial_ring_filter / np . nanmax ( spatial_ring_filter ) # Ensure the peaks are at 1.0 if not params [ 'spatial_torus' ] and not params [ 'no_spatial_filt' ]: spatial_ring_filter = ( ( walsa_radial_distances (( nx , ny )) <= ( torus_center - int ( torus_depth / 2 ))) . astype ( int ) - ( walsa_radial_distances (( nx , ny )) <= ( torus_center + int ( torus_depth / 2 ) + 1 )) . astype ( int ) ) spatial_ring_filter = spatial_ring_filter / np . nanmax ( spatial_ring_filter ) # Ensure the peaks are at 1.0 spatial_ring_filter [ spatial_ring_filter != 1 ] = 0 if params [ 'no_spatial_filt' ]: spatial_ring_filter = np . ones (( nx , ny )) if not params [ 'no_temporal_filt' ] and params [ 'temporal_torus' ]: # CREATE A GAUSSIAN TEMPORAL FILTER TO PREVENT ALIASING temporal_filter = np . zeros ( nt , dtype = float ) filter_width = pixel_f2_positive - pixel_f1_positive # Determine sigma based on filter width if filter_width < 25 : sigma = 3 if filter_width >= 25 and filter_width < 30 : sigma = 4 if filter_width >= 30 and filter_width < 40 : sigma = 5 if filter_width >= 40 and filter_width < 45 : sigma = 6 if filter_width >= 45 and filter_width < 50 : sigma = 7 if filter_width >= 50 and filter_width < 55 : sigma = 8 if filter_width >= 55 and filter_width < 60 : sigma = 9 if filter_width >= 60 and filter_width < 65 : sigma = 10 if filter_width >= 65 and filter_width < 70 : sigma = 11 if filter_width >= 70 and filter_width < 80 : sigma = 12 if filter_width >= 80 and filter_width < 90 : sigma = 13 if filter_width >= 90 and filter_width < 100 : sigma = 14 if filter_width >= 100 and filter_width < 110 : sigma = 15 if filter_width >= 110 and filter_width < 130 : sigma = 16 if filter_width >= 130 : sigma = 17 # Generate the Gaussian kernel temporal_gaussian = gaussian_function ( sigma = sigma , width = filter_width ) # Apply the Gaussian to the temporal filter temporal_filter [ pixel_f1_positive : pixel_f2_positive ] = temporal_gaussian temporal_filter [ pixel_f2_negative : pixel_f1_negative ] = temporal_gaussian # Normalize the filter to ensure the peaks are at 1.0 temporal_filter /= np . nanmax ( temporal_filter ) if not params [ 'no_temporal_filt' ] and not params [ 'temporal_torus' ]: temporal_filter = np . zeros ( nt , dtype = float ) temporal_filter [ pixel_f1_positive : pixel_f2_positive + 1 ] = 1.0 temporal_filter [ pixel_f2_negative : pixel_f1_negative + 1 ] = 1.0 if params [ 'no_temporal_filt' ]: temporal_filter = np . ones ( nt , dtype = float ) # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Create useful variables for plotting (if needed), demonstrating the filtering process if params [ 'processing_maps' ]: # Define the spatial frequency step for plotting spatial_dx = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ] spatial_dy = spatial_frequencies [ 1 ] - spatial_frequencies [ 0 ] # Torus map torus_map = { 'data' : spatial_ring_filter , 'dx' : spatial_dx , 'dy' : spatial_dy , 'xc' : 0 , 'yc' : 0 , 'time' : '' , 'units' : 'pixels' } # Compute the total spatial FFT spatial_fft = np . nansum ( threedft , axis = 0 ) # Spatial FFT map spatial_fft_map = { 'data' : np . log10 ( spatial_fft ), 'dx' : spatial_dx , 'dy' : spatial_dy , 'xc' : 0 , 'yc' : 0 , 'time' : '' , 'units' : 'pixels' } # Spatial FFT filtered and its map spatial_fft_filtered = spatial_fft * spatial_ring_filter spatial_fft_filtered_map = { 'data' : np . log10 ( np . maximum ( spatial_fft_filtered , 1e-15 )), 'dx' : spatial_dx , 'dy' : spatial_dy , 'xc' : 0 , 'yc' : 0 , 'time' : '' , 'units' : 'pixels' } # Compute the total temporal FFT temporal_fft = np . nansum ( np . nansum ( threedft , axis = 2 ), axis = 1 ) else : spatial_fft_map = None torus_map = None spatial_fft_filtered_map = None temporal_fft = None temporal_filter , temporal_frequencies , spatial_frequencies = None , None , None # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Apply the Gaussian filters to the data to prevent aliasing for i in range ( nt ): threedft [ i , :, :] *= spatial_ring_filter for x in range ( nx ): for y in range ( ny ): threedft [:, x , y ] *= temporal_filter # ALSO NEED TO ENSURE THE threedft ALIGNS WITH THE OLD FREQUENCY AXES USED BY THE /center CALL if len ( temporal_frequencies_orig ) % 2 == 0 : for x in range ( nx ): for y in range ( ny ): threedft [:, x , y ] = np . roll ( threedft [:, x , y ], shift = 1 , axis = 0 ) if len ( spatial_frequencies_orig ) % 2 == 0 : for t in range ( nt ): threedft [ t , :, :] = np . roll ( threedft [ t , :, :], shift = ( 1 , 1 ), axis = ( 0 , 1 )) threedft [ z , :, :] = np . roll ( np . roll ( threedft [ z , :, :], shift = 1 , axis = 0 ), shift = 1 , axis = 1 ) # Inverse FFT to get the filtered cube # filtered_cube = np.real(np.fft.ifftn(threedft, norm='ortho')) filtered_cube = np . real ( np . fft . ifftn ( np . fft . ifftshift ( threedft ))) else : filtered_cube = None print ( \"Filtered datacube generated.\" ) return komegamap , kopower_xscale [ 1 :], kopower_yscale [ 1 :], filtered_cube , spatial_fft_map , torus_map , spatial_fft_filtered_map , temporal_fft , temporal_filter , temporal_frequencies , spatial_frequencies WaLSA_pod.py This module implements Proper Orthogonal Decomposition (POD), as well as Spectral POD (SPOD), for analysing multi-dimensional data and extracting dominant spatial patterns. WaLSA_pod.py # -------------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # -------------------------------------------------------------------------------------------------------- # The following codes are based on those originally written by Jonathan E. Higham & Luiz A. C. A. Schiavo # -------------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.signal import welch , find_peaks # type: ignore from scipy.linalg import svd # type: ignore from scipy.optimize import curve_fit # type: ignore import math def print_pod_results ( results ): \"\"\" Print a summary of the results from WaLSA_pod, including parameter descriptions, types, and shapes. Parameters: ----------- results : dict The dictionary containing all POD results and relevant outputs. \"\"\" descriptions = { 'input_data' : 'Original input data, mean subtracted (Shape: (Nt, Ny, Nx))' , 'spatial_mode' : 'Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx))' , 'temporal_coefficient' : 'Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt))' , 'eigenvalue' : 'Eigenvalues corresponding to singular values squared (Shape: (Nmodes))' , 'eigenvalue_contribution' : 'Eigenvalue contribution of each mode (Shape: (Nmodes))' , 'cumulative_eigenvalues' : 'Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes))' , 'combined_welch_psd' : 'Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf))' , 'frequencies' : 'Frequencies identified in the Welch spectrum (Shape: (Nf))' , 'combined_welch_significance' : 'Significance threshold of the combined Welch spectrum (Shape: (Nf,))' , 'reconstructed' : 'Reconstructed frame at the specified timestep (or for the entire time series) using the top \"num_modes\" modes (Shape: (Ny, Nx))' , 'sorted_frequencies' : 'Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies))' , 'frequency_filtered_modes' : 'Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies))' , 'frequency_filtered_modes_frequencies' : 'Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies))' , 'SPOD_spatial_modes' : 'SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx))' , 'SPOD_temporal_coefficients' : 'SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt))' , 'p' : 'Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes))' , 's' : 'Singular values from SVD (Shape: (Nmodes))' , 'a' : 'Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt))' } print ( \" \\n ---- POD/SPOD Results Summary ---- \\n \" ) for key , value in results . items (): desc = descriptions . get ( key , 'No description available' ) shape = np . shape ( value ) if value is not None else 'None' dtype = type ( value ) . __name__ print ( f \" { key } ( { dtype } , Shape: { shape } ): { desc } \" ) print ( \" \\n ----------------------------------\" ) def spod ( data , ** kwargs ): \"\"\" Perform Spectral Proper Orthogonal Decomposition (SPOD) analysis on input data. Steps: 1. Load the data. 2. Compute a time average. 3. Build the correlation matrix to compute the POD using the snapshot method. 4. Compute eigenvalue decomposition for the correlation matrix for the fluctuation field. The eigenvalues and eigenvectors can be computed by any eigenvalue function or by an SVD procedure, since the correlation matrix is symmetric positive-semidefinite. 5. After obtaining the eigenvalues and eigenvectors, compute the temporal and spatial modes according to the snapshot method. Parameters: ----------- data : np.ndarray 3D data array with shape (time, x, y) or similar. **kwargs : dict, optional Additional keyword arguments to configure the analysis. Returns: -------- SPOD_spatial_modes : np.ndarray SPOD_temporal_coefficients : np.ndarray \"\"\" # Set default parameter values defaults = { 'silent' : False , 'num_modes' : None , 'filter_size' : None , 'periodic_matrix' : True } # Update defaults with user-provided values params = { ** defaults , ** kwargs } if params [ 'num_modes' ] is None : params [ 'num_modes' ] = data . shape [ 0 ] if params [ 'filter_size' ] is None : params [ 'filter_size' ] = params [ 'num_modes' ] if not params [ 'silent' ]: print ( \"Starting SPOD analysis ....\" ) nsnapshots , ny , nx = data . shape # Center the data by subtracting the mean time_average = data . mean ( axis = 0 ) fluctuation_field = data * 0 # Initialize fluctuation field with zeros for n in range ( nsnapshots ): fluctuation_field [ n ,:,:] = data [ n ,:,:] - time_average # Subtract time-average from each snapshot # Build the correlation matrix (snapshot method) correlation_matrix = np . zeros (( nsnapshots , nsnapshots )) for i in range ( nsnapshots ): for j in range ( i , nsnapshots ): correlation_matrix [ i , j ] = ( fluctuation_field [ i , :, :] * fluctuation_field [ j , :, :]) . sum () / ( nsnapshots * nx * ny ) correlation_matrix [ j , i ] = correlation_matrix [ i , j ] # SPOD correlation matrix with periodic boundary conditions nmatrix = np . zeros (( 3 * nsnapshots , 3 * nsnapshots )) nmatrix [ nsnapshots : 2 * nsnapshots , nsnapshots : 2 * nsnapshots ] = correlation_matrix [ 0 : nsnapshots , 0 : nsnapshots ] if params [ 'periodic_matrix' ]: for i in range ( 3 ): for j in range ( 3 ): xs = i * nsnapshots # x-offset for periodic positioning ys = j * nsnapshots # y-offset for periodic positioning nmatrix [ 0 + xs : nsnapshots + xs , 0 + ys : nsnapshots + ys ] = correlation_matrix [ 0 : nsnapshots , 0 : nsnapshots ] # Apply Gaussian filter gk = np . zeros (( 2 * params [ 'filter_size' ] + 1 )) # Create 1D Gaussian kernel esp = 8.0 # Exponential parameter controlling the spread of the filter sumgk = 0.0 # Sum of the Gaussian kernel for normalization for n in range ( 2 * params [ 'filter_size' ] + 1 ): k = - params [ 'filter_size' ] + n # Offset from the center of the kernel gk [ n ] = math . exp ( - esp * k ** 2.0 / ( params [ 'filter_size' ] ** 2.0 )) # Gaussian filter formula sumgk += gk [ n ] # Sum of kernel values for normalization # Filter the extended correlation matrix for j in range ( nsnapshots , 2 * nsnapshots ): for i in range ( nsnapshots , 2 * nsnapshots ): aux = 0.0 # Initialize variable for the weighted sum for n in range ( 2 * params [ 'filter_size' ] + 1 ): k = - params [ 'filter_size' ] + n # Offset from the current index aux += nmatrix [ i + k , j + k ] * gk [ n ] # Apply Gaussian weighting nmatrix [ i , j ] = aux / sumgk # Normalize by the sum of the Gaussian kernel # Extract the SPOD correlation matrix from the central part of the filtered matrix spectral_matrix = nmatrix [ nsnapshots : 2 * nsnapshots , nsnapshots : 2 * nsnapshots ] # Perform SVD to compute SPOD UU , SS , VV = svd ( spectral_matrix , full_matrices = True , compute_uv = True ) # Temporal coefficients SPOD_temporal_coefficients = np . zeros (( nsnapshots , nsnapshots )) for k in range ( nsnapshots ): SPOD_temporal_coefficients [:, k ] = np . sqrt ( SS [ k ] * nsnapshots ) * UU [:, k ] # Extract spatial SPOD modes SPOD_spatial_modes = np . zeros (( params [ 'num_modes' ], ny , nx )) for m in range ( params [ 'num_modes' ]): for t in range ( nsnapshots ): SPOD_spatial_modes [ m , :, :] += fluctuation_field [ t , :, :] * SPOD_temporal_coefficients [ t , m ] / ( SS [ m ] * nsnapshots ) if not params [ 'silent' ]: print ( f \"SPOD analysis completed.\" ) return SPOD_spatial_modes , SPOD_temporal_coefficients # -------------------------------------- Main Function ---------------------------------------- def WaLSA_pod ( signal , time , ** kwargs ): \"\"\" Perform Proper Orthogonal Decomposition (POD) analysis on input data. Parameters: signal (array): 3D data cube with shape (time, x, y) or similar. time (array): 1D array representing the time points for each time step in the data. num_modes (int, optional): Number of top modes to compute. Default is None (all modes). num_top_frequencies (int, optional): Number of top frequencies to consider. Default is None (all frequencies). top_frequencies (list, optional): List of top frequencies to consider. Default is None. num_cumulative_modes (int, optional): Number of cumulative modes to consider. Default is None (all modes). welch_nperseg (int, optional): Number of samples per segment for Welch's method. Default is 150. welch_noverlap (int, optional): Number of overlapping samples for Welch's method. Default is 25. welch_nfft (int, optional): Number of points for the FFT. Default is 2^14. welch_fs (int, optional): Sampling frequency for the data. Default is 2. nperm (int, optional): Number of permutations for significance testing. Default is 1000. siglevel (float, optional): Significance level for the Welch spectrum. Default is 0.95. timestep_to_reconstruct (int, optional): Timestep of the datacube to reconstruct using the top modes. Default is 0. num_modes_reconstruct (int, optional): Number of modes to use for reconstruction. Default is None (all modes). reconstruct_all (bool, optional): If True, reconstruct the entire time series using the top modes. Default is False. spod (bool, optional): If True, perform Spectral Proper Orthogonal Decomposition (SPOD) analysis. Default is False. spod_filter_size (int, optional): Filter size for SPOD analysis. Default is None. spod_num_modes (int, optional): Number of SPOD modes to compute. Default is None. print_results (bool, optional): If True, print a summary of results. Default is True. **kwargs : Additional keyword arguments to configure the analysis. Returns: results : dict A dictionary containing all computed POD results and relevant outputs. See 'descriptions' in the 'print_pod_results' function on top of this page. \"\"\" # Set default parameter values defaults = { 'silent' : False , 'num_modes' : None , 'num_top_frequencies' : None , 'top_frequencies' : None , 'num_cumulative_modes' : None , 'welch_nperseg' : 150 , 'welch_noverlap' : 25 , 'welch_nfft' : 2 ** 14 , 'welch_fs' : 2 , 'nperm' : 1000 , 'siglevel' : 0.95 , 'timestep_to_reconstruct' : 0 , 'reconstruct_all' : False , 'num_modes_reconstruct' : None , 'spod' : False , 'spod_filter_size' : None , 'spod_num_modes' : None , 'print_results' : True # Print summary of results by default } # Update defaults with user-provided values params = { ** defaults , ** kwargs } data = signal if params [ 'num_modes' ] is None : params [ 'num_modes' ] = data . shape [ 0 ] if params [ 'num_top_frequencies' ] is None : params [ 'num_top_frequencies' ] = min ( params [ 'num_modes' ], 10 ) if params [ 'num_cumulative_modes' ] is None : params [ 'num_cumulative_modes' ] = min ( params [ 'num_modes' ], 10 ) if params [ 'num_modes_reconstruct' ] is None : params [ 'num_modes_reconstruct' ] = min ( params [ 'num_modes' ], 10 ) if not params [ 'silent' ]: print ( \"Starting POD analysis ....\" ) print ( f \"Processing a 3D cube with shape { data . shape } .\" ) # The first step is to read in the data and then perform the SVD (or POD). Before we do this, # we need to reshape the matrix such that it is an N x T matrix where N is the column vectorized set of each spatial image and T is the temporal domain. # We also need to ensure that the mean is subtracted from the data; this will ensure we are looking only at the variance of the data, and mode 1 will not be contaminated with the mean image. # Reshape the 3D data into 2D array where each row is a vector from the original 3D data inp = np . reshape ( data , ( data . shape [ 0 ], data . shape [ 1 ] * data . shape [ 2 ])) . astype ( np . float32 ) inp = inp . T # Transpose the matrix to have spatial vectors as columns # Center the data by subtracting the mean mean_per_row = np . nanmean ( inp , axis = 1 , keepdims = True ) mean_replicated = np . tile ( mean_per_row , ( 1 , data . shape [ 0 ])) inp_centered = inp - mean_replicated # Input data, mean subtracted input_dat = np . zeros (( data . shape [ 0 ], data . shape [ 1 ], data . shape [ 2 ])) for im in range ( data . shape [ 0 ]): input_dat [ im , :, :] = np . reshape ( inp_centered [:, im ], ( data . shape [ 1 ], data . shape [ 2 ])) # Perform SVD to compute POD p , s , a = svd ( inp_centered , full_matrices = False ) sorg = s . copy () # Store original singular values eigenvalue = s ** 2 # Convert singular values to eigenvalues # Reshape spatial modes to have the same shape as the input data num_modes = p . shape [ 1 ] spatial_mode = np . zeros (( num_modes , data . shape [ 1 ], data . shape [ 2 ])) for m in range ( num_modes ): spatial_mode [ m , :, :] = np . reshape ( p [:, m ], ( data . shape [ 1 ], data . shape [ 2 ])) # Extract temporal coefficients temporal_coefficient = a [: num_modes , :] # Calculate eigenvalue contributions eigenvalue_contribution = eigenvalue / np . sum ( eigenvalue ) # Calculate cumulative eigenvalues cumulative_eigenvalues = [] for m in range ( params [ 'num_cumulative_modes' ]): contm = 100 * eigenvalue [ 0 : m ] / np . sum ( eigenvalue ) cumulative_eigenvalues . append ( np . sum ( contm )) if params [ 'reconstruct_all' ]: # Reconstruct the entire time series using the top 'num_modes_reconstruct' modes reconstructed = np . zeros (( data . shape [ 0 ], data . shape [ 1 ], data . shape [ 2 ])) for tindex in range ( data . shape [ 0 ]): reconim = np . zeros (( data . shape [ 1 ], data . shape [ 2 ])) for i in range ( params [ 'num_modes_reconstruct' ]): reconim = reconim + np . reshape ( p [:, i ], ( data . shape [ 1 ], data . shape [ 2 ])) * a [ i , tindex ] * sorg [ i ] reconstructed [ tindex , :, :] = reconim else : # Reconstruct the specified timestep using the top 'num_modes_reconstruct' modes reconstructed = np . zeros (( data . shape [ 1 ], data . shape [ 2 ])) for i in range ( params [ 'num_modes_reconstruct' ]): reconstructed = reconstructed + np . reshape ( p [:, i ], ( data . shape [ 1 ], data . shape [ 2 ])) * a [ i , params [ 'timestep_to_reconstruct' ]] * sorg [ i ] #--------------------------------------------------------------------------------- # Combined Welch power spectrum and its significance #--------------------------------------------------------------------------------- # Compute Welch power spectrum for each mode and combine them for 'num_modes' modes combined_welch_psd = [] for m in range ( params [ 'num_modes' ]): frequencies , px = welch ( a [ m , :] - np . mean ( a [ m , :]), nperseg = params [ 'welch_nperseg' ], noverlap = params [ 'welch_noverlap' ], nfft = params [ 'welch_nfft' ], fs = params [ 'welch_fs' ]) if m == 0 : combined_welch_psd = np . zeros (( len ( frequencies ),)) combined_welch_psd += eigenvalue_contribution [ m ] * ( px / np . sum ( px )) # Generate resampled peaks to compute significance threshold resampled_peaks = np . zeros (( params [ 'nperm' ], len ( frequencies ))) for i in range ( params [ 'nperm' ]): resampled_data = np . random . randn ( * a . shape ) resampled_peak = np . zeros (( len ( frequencies ),)) for m in range ( params [ 'num_modes' ]): _ , px = welch ( resampled_data [ m , :] - np . mean ( resampled_data [ m , :]), nperseg = params [ 'welch_nperseg' ], noverlap = params [ 'welch_noverlap' ], nfft = params [ 'welch_nfft' ], fs = params [ 'welch_fs' ]) resampled_peak += eigenvalue_contribution [ m ] * ( px / np . sum ( px )) resampled_peak /= ( np . max ( resampled_peak ) + 1e-30 ) # a small epsilon added to avoid division by zero resampled_peaks [ i , :] = resampled_peak # Calculate significance threshold combined_welch_significance = np . percentile ( resampled_peaks , 100 - ( params [ 'siglevel' ] * 100 ), axis = 0 ) #--------------------------------------------------------------------------------- # Find peaks in the combined spectrum and sort them in descending order normalized_peak = combined_welch_psd / ( np . max ( combined_welch_psd ) + 1e-30 ) peak_indices , _ = find_peaks ( normalized_peak ) sorted_indices = np . argsort ( normalized_peak [ peak_indices ])[:: - 1 ] sorted_frequencies = frequencies [ peak_indices ][ sorted_indices ] # Generate a table of the top N frequencies # Cleaner single-line list comprehension table_data = [ [ float ( np . round ( freq , 2 )), float ( np . round ( pwr , 2 ))] for freq , pwr in zip ( sorted_frequencies [: params [ 'num_top_frequencies' ]], normalized_peak [ peak_indices ][ sorted_indices ][: params [ 'num_top_frequencies' ]]) ] # The frequencies that the POD is able to capture have now been identified (in the top 'num_top_frequencies' modes). # These frequencies can be fitted to the temporal coefficients of the top 'num_top_frequencies' modes, # allowing for a representation of the data described solely by these \"pure\" frequencies. # This approach enables the reconstruction of the original data using the identified dominant frequencies, # resulting in frequency-filtered spatial POD modes. clean_data = np . zeros (( inp . shape [ 0 ], inp . shape [ 1 ], 10 )) if params [ 'top_frequencies' ] is None : top_frequencies = sorted_frequencies [: params [ 'num_top_frequencies' ]] else : top_frequencies = params [ 'top_frequencies' ] params [ 'num_top_frequencies' ] = len ( params [ 'top_frequencies' ]) for i in range ( params [ 'num_top_frequencies' ]): def model_fun ( t , amplitude , phase ): \"\"\" Generate a sinusoidal model function. Parameters: t (array-like): The time variable. amplitude (float): The amplitude of the sinusoidal function. phase (float): The phase shift of the sinusoidal function. Returns: array-like: The computed sinusoidal values at each time point `t`. \"\"\" return amplitude * np . sin ( 2 * np . pi * top_frequencies [ i ] * t + phase ) for j in range ( params [ 'num_modes_reconstruct' ]): csignal = a [ j ,:] # Initial Guesses for Parameters: [Amplitude, Phase] initial_guess = [ 1 , 0 ] # Nonlinear Fit fit_params , _ = curve_fit ( model_fun , time , csignal , p0 = initial_guess ) # Clean Signal from Fit if j == 0 : clean_signal = np . zeros (( params [ 'num_modes_reconstruct' ], len ( csignal ))) clean_signal [ j ,:] = model_fun ( time , * fit_params ) # forming a set of clean data (reconstructed data at the fitted frequencies; frequency filtered reconstructed data) clean_data [:,:, i ] = p [:, 0 : params [ 'num_modes_reconstruct' ]] @np . diag ( sorg [ 0 : params [ 'num_modes_reconstruct' ]]) @clean_signal frequency_filtered_modes = np . zeros (( data . shape [ 0 ], data . shape [ 1 ], data . shape [ 2 ], params [ 'num_top_frequencies' ])) for jj in range ( params [ 'num_top_frequencies' ]): for frame_index in range ( data . shape [ 0 ]): frequency_filtered_modes [ frame_index , :, :, jj ] = np . reshape ( clean_data [:, frame_index , jj ], ( data . shape [ 1 ], data . shape [ 2 ])) if params [ 'spod' ]: SPOD_spatial_modes , SPOD_temporal_coefficients = spod ( data , num_modes = params [ 'spod_num_modes' ], filter_size = params [ 'spod_filter_size' ]) else : SPOD_spatial_modes = None SPOD_temporal_coefficients = None results = { 'input_data' : input_dat , # Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) 'spatial_mode' : spatial_mode , # POD spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) 'temporal_coefficient' : temporal_coefficient , # POD temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) 'eigenvalue' : eigenvalue , # Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) 'eigenvalue_contribution' : eigenvalue_contribution , # Eigenvalue contribution of each mode (Shape: (Nmodes)) 'cumulative_eigenvalues' : cumulative_eigenvalues , # Cumulative percentage of eigenvalues for the first 'num_cumulative_modes' modes (Shape: (Ncumulative_modes)) 'combined_welch_psd' : combined_welch_psd , # Combined Welch power spectral density for the temporal coefficients (Shape: (Nf)) 'frequencies' : frequencies , # Frequencies identified in the Welch spectrum (Shape: (Nf)) 'combined_welch_significance' : combined_welch_significance , # Significance threshold of the combined Welch spectrum (Shape: (Nf)) 'reconstructed' : reconstructed , # Reconstructed frame at the specified timestep (or for the entire time series) using the top modes (Shape: (Ny, Nx)) 'sorted_frequencies' : sorted_frequencies , # Frequencies identified in the Welch spectrum (Shape: (Nfrequencies,)) 'frequency_filtered_modes' : frequency_filtered_modes , # Frequency-filtered spatial POD modes (Shape: (Nt, Ny, Nx, Ntop_frequencies)) 'frequency_filtered_modes_frequencies' : top_frequencies , # Frequencies corresponding to the frequency-filtered modes (Shape: (Ntop_frequencies)) 'SPOD_spatial_modes' : SPOD_spatial_modes , # SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) 'SPOD_temporal_coefficients' : SPOD_temporal_coefficients , # SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) 'p' : p , # Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) 's' : sorg , # Singular values from SVD (Shape: (Nmodes,)) 'a' : a # Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) } if not params [ 'silent' ]: print ( f \"POD analysis completed.\" ) print ( f \"Top { params [ 'num_top_frequencies' ] } frequencies and normalized power values: \\n { table_data } \" ) print ( f \"Total variance contribution of the first { params [ 'num_modes' ] } modes: { np . sum ( 100 * eigenvalue [: params [ 'num_modes' ]] / np . sum ( eigenvalue )) : .2f } %\" ) if params [ 'print_results' ]: print_pod_results ( results ) return results WaLSA_cross_spectra.py This module implements cross-correlation analysis techniques, resulting in cross-spectrum, coherence, and phase relationships, for investigating correlations between two time series. WaLSA_cross_spectra.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.signal import coherence , csd # type: ignore from .WaLSA_speclizer import WaLSA_speclizer # type: ignore from .WaLSA_wavelet import xwt , wct # type: ignore from .WaLSA_detrend_apod import WaLSA_detrend_apod # type: ignore from .WaLSA_wavelet_confidence import WaLSA_wavelet_confidence # type: ignore # -------------------------------------- Main Function ---------------------------------------- def WaLSA_cross_spectra ( signal = None , time = None , method = None , ** kwargs ): \"\"\" Compute the cross-spectra between two time series. Parameters: data1 (array): The first time series (1D). data2 (array): The first time series (1D). time (array): The time array of the signals. method (str): The method to use for the analysis. Options are 'welch' and 'wavelet'. \"\"\" if method == 'welch' : return getcross_spectrum_Welch ( signal , time = time , ** kwargs ) elif method == 'wavelet' : return getcross_spectrum_Wavelet ( signal , time = time , ** kwargs ) elif method == 'fft' : print ( \"Note: FFT method selected. Cross-spectra calculations will use the Welch method instead, \" \"which segments the signal into multiple parts to reduce noise sensitivity. \" \"You can control frequency resolution vs. noise reduction using the 'nperseg' parameter.\" ) return getcross_spectrum_Welch ( signal , time = time , ** kwargs ) else : raise ValueError ( f \"Unknown method: { method } \" ) # -------------------------------------- Welch ---------------------------------------- def getcross_spectrum_Welch ( signal , time , ** kwargs ): \"\"\" Calculate cross-spectral relationships of two time series whose amplitudes and powers are computed using the WaLSA_speclizer routine. The cross-spectrum is complex valued, thus its magnitude is returned as the co-spectrum. The phase lags between the two time series are are estimated from the imaginary and real arguments of the complex cross spectrum. The coherence is calculated from the normalized square of the amplitude of the complex cross-spectrum Parameters: data1 (array): The first 1D time series signal. data2 (array): The second 1D time series signal. time (array): The time array corresponding to the signals. nperseg (int, optional): Length of each segment for analysis. Default: 256. noverlap (int, optional): Number of points to overlap between segments. Default: 128. window (str, optional): Type of window function used in the Welch method. Default: 'hann'. siglevel (float, optional): Significance level for confidence intervals. Default: 0.95. nperm (int, optional): Number of permutations for significance testing. Default: 1000. silent (bool, optional): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: cospectrum, frequencies, phase_angle, coherence, signif_cross, signif_coh, d1_power, d2_power \"\"\" # Define default values for the optional parameters defaults = { 'data1' : None , # First data array 'data1' : None , # Second data array 'nperseg' : 256 , # Number of points per segments to average 'apod' : 0.1 , # Apodization function 'nodetrendapod' : None , # No detrending ot apodization applied 'pxdetrend' : 2 , # Detrend parameter 'meandetrend' : None , # Detrend parameter 'polyfit' : None , # Detrend parameter 'meantemporal' : None , # Detrend parameter 'recon' : None # Detrend parameter } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } data1 = params [ 'data1' ] data2 = params [ 'data2' ] dummy = signal + 2 tdiff = np . diff ( time ) cadence = np . median ( tdiff ) # Power spectrum for data1 power_data1 , frequencies , _ = WaLSA_speclizer ( signal = data1 , time = time , method = 'welch' , amplitude = True , nosignificance = True , silent = kwargs . pop ( 'silent' , True ), ** kwargs ) # Power spectrum for data2 power_data2 , _ , _ = WaLSA_speclizer ( signal = data2 , time = time , method = 'welch' , amplitude = True , nosignificance = True , silent = kwargs . pop ( 'silent' , False ), ** kwargs ) # Calculate cross-spectrum _ , crosspower = csd ( data1 , data2 , fs = 1.0 / cadence , window = 'hann' , nperseg = params [ 'nperseg' ],) cospectrum = np . abs ( crosspower ) # Calculate phase lag phase_angle = np . angle ( crosspower , deg = True ) # Calculate coherence freq_coh , coh = coherence ( data1 , data2 , 1.0 / cadence , nperseg = params [ 'nperseg' ]) return frequencies , cospectrum , phase_angle , power_data1 , power_data2 , freq_coh , coh # -------------------------------------- Wavelet ---------------------------------------- def getcross_spectrum_Wavelet ( signal , time , ** kwargs ): \"\"\" Calculate the cross-power spectrum, coherence spectrum, and phase angles between two signals using Wavelet Transform. Parameters: data1 (array): The first 1D time series signal. data2 (array): The second 1D time series signal. time (array): The time array corresponding to the signals. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. mother (str): The mother wavelet function to use. Default: 'morlet'. GWS (bool): If True, calculate the Global Wavelet Spectrum. Default: False. RGWS (bool): If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False. dj (float): Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025. s0 (float): Initial (smallest) scale of the wavelet. Default: 2 * dt. J (int): Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj. lag1 (float): Lag-1 autocorrelation. Default: 0.0. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. Returns: cross_power : np.ndarray Cross power spectrum between `data1` and `data2`. cross_periods : np.ndarray Periods corresponding to the cross-power spectrum. cross_sig : np.ndarray Significance of the cross-power spectrum. cross_coi : np.ndarray Cone of influence for the cross-power spectrum. coherence : np.ndarray Coherence spectrum between `data1` and `data2`. coh_periods : np.ndarray Periods corresponding to the coherence spectrum. coh_sig : np.ndarray Significance of the coherence spectrum. corr_coi : np.ndarray Cone of influence for the coherence spectrum. phase_angle : np.ndarray 2D array containing x- and y-components of the phase direction arrows for each frequency and time point. Notes ----- - Cross-power, coherence, and phase angles are calculated using **cross-wavelet transform (XWT)** and **wavelet coherence transform (WCT)**. - Arrows for phase direction are computed such that: - Arrows pointing downwards indicate anti-phase. - Arrows pointing upwards indicate in-phase. - Arrows pointing right indicate `data1` leading `data2`. - Arrows pointing left indicate `data2` leading `data1`. Examples -------- >>> cross_power, cross_periods, cross_sig, cross_coi, coherence, coh_periods, coh_sig, corr_coi, phase_angle, dt = \\ >>> getcross_spectrum_Wavelet(signal, cadence, data1=signal1, data2=signal2) \"\"\" # Define default values for optional parameters defaults = { 'data1' : None , # First data array 'data2' : None , # Second data array 'mother' : 'morlet' , # Type of mother wavelet 'siglevel' : 0.95 , # Significance level for cross-spectral analysis 'dj' : 0.025 , # Spacing between scales 's0' : - 1 , # Initial scale 'J' : - 1 , # Number of scales 'cache' : False , # Cache results to avoid recomputation 'apod' : 0.1 , 'silent' : False , 'pxdetrend' : 2 , 'meandetrend' : False , 'polyfit' : None , 'meantemporal' : False , 'recon' : False , 'resample_original' : False , 'nperm' : 1000 # Number of permutations for significance testing } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } data1 = params [ 'data1' ] data2 = params [ 'data2' ] dummy = signal + 2 tdiff = np . diff ( time ) cadence = np . median ( tdiff ) data1orig = data1 . copy () data2orig = data2 . copy () data1 = WaLSA_detrend_apod ( data1 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) data2 = WaLSA_detrend_apod ( data2 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) # Calculate signal properties nt = len ( params [ 'data1' ]) # Number of time points # Determine the initial scale s0 if not provided if params [ 's0' ] == - 1 : params [ 's0' ] = 2 * cadence # Determine the number of scales J if not provided if params [ 'J' ] == - 1 : params [ 'J' ] = int (( np . log ( float ( nt ) * cadence / params [ 's0' ]) / np . log ( 2 )) / params [ 'dj' ]) # ----------- CROSS-WAVELET TRANSFORM (XWT) ----------- W12 , cross_coi , freq , signif = xwt ( data1 , data2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], no_default_signif = True , wavelet = params [ 'mother' ], normalize = False ) print ( 'Wavelet cross-power spectrum calculated.' ) # Calculate the cross-power spectrum cross_power = np . abs ( W12 ) ** 2 cross_periods = 1 / freq # Periods corresponding to the frequency axis #---------------------------------------------------------------------- # Calculate significance levels using Monte Carlo randomization method #---------------------------------------------------------------------- nxx , nyy = cross_power . shape cross_perm = np . zeros (( nxx , nyy , params [ 'nperm' ])) print ( ' \\n Calculating wavelet cross-power significance:' ) total_iterations = params [ 'nperm' ] # Total number of (x, y) combinations iteration_count = 0 # To keep track of progress for ip in range ( params [ 'nperm' ]): iteration_count += 1 progress = ( iteration_count / total_iterations ) * 100 print ( f \" \\r Progress: { progress : .2f } %\" , end = \"\" ) y_perm1 = np . random . permutation ( data1orig ) # Permuting the original signal apocube1 = WaLSA_detrend_apod ( y_perm1 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) y_perm2 = np . random . permutation ( data2orig ) # Permuting the original signal apocube2 = WaLSA_detrend_apod ( y_perm2 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) W12s , _ , _ , _ = xwt ( apocube1 , apocube2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], no_default_signif = True , wavelet = params [ 'mother' ], normalize = False ) cross_power_sig = np . abs ( W12s ) ** 2 cross_perm [:, :, ip ] = cross_power_sig signifn = WaLSA_wavelet_confidence ( cross_perm , siglevel = params [ 'siglevel' ]) cross_sig = cross_power / signifn # ----------- WAVELET COHERENCE TRANSFORM (WCT) ----------- WCT , aWCT , coh_coi , freq , sig = wct ( data1 , data2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], sig = False , wavelet = params [ 'mother' ], normalize = False , cache = params [ 'cache' ] ) print ( 'Wavelet coherence calculated.' ) # Calculate the coherence spectrum coh_periods = 1 / freq # Periods corresponding to the frequency axis coherence = WCT #---------------------------------------------------------------------- # Calculate significance levels using Monte Carlo randomization method #---------------------------------------------------------------------- nxx , nyy = coherence . shape coh_perm = np . zeros (( nxx , nyy , params [ 'nperm' ])) print ( ' \\n Calculating wavelet coherence significance:' ) total_iterations = params [ 'nperm' ] # Total number of permutations iteration_count = 0 # To keep track of progress for ip in range ( params [ 'nperm' ]): iteration_count += 1 progress = ( iteration_count / total_iterations ) * 100 print ( f \" \\r Progress: { progress : .2f } %\" , end = \"\" ) y_perm1 = np . random . permutation ( data1orig ) # Permuting the original signal apocube1 = WaLSA_detrend_apod ( y_perm1 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) y_perm2 = np . random . permutation ( data2orig ) # Permuting the original signal apocube2 = WaLSA_detrend_apod ( y_perm2 , apod = params [ 'apod' ], meandetrend = params [ 'meandetrend' ], pxdetrend = params [ 'pxdetrend' ], polyfit = params [ 'polyfit' ], meantemporal = params [ 'meantemporal' ], recon = params [ 'recon' ], cadence = cadence , resample_original = params [ 'resample_original' ], silent = True ) WCTs , _ , _ , _ , _ = wct ( apocube1 , apocube2 , cadence , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], sig = False , wavelet = params [ 'mother' ], normalize = False , cache = params [ 'cache' ] ) coh_perm [:, :, ip ] = WCTs sig_coh = WaLSA_wavelet_confidence ( coh_perm , siglevel = params [ 'siglevel' ]) coh_sig = coherence / sig_coh # Ratio > 1 means coherence is significant # --------------- PHASE ANGLES --------------- phase_angle = aWCT return ( cross_power , cross_periods , cross_sig , cross_coi , coherence , coh_periods , coh_sig , coh_coi , phase_angle ) WaLSA_detrend_apod.py This module provides functions for detrending and apodizing time series data to mitigate trends and edge effects. WaLSA_detrend_apod.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from scipy.optimize import curve_fit # type: ignore from .WaLSA_wavelet import cwt , significance # type: ignore # -------------------------------------- Wavelet ---------------------------------------- def getWavelet ( signal , time , ** kwargs ): \"\"\" Perform wavelet analysis using the pycwt package. Parameters: signal (array): The input signal (1D). time (array): The time array corresponding to the signal. siglevel (float): Significance level for the confidence intervals. Default: 0.95. nperm (int): Number of permutations for significance testing. Default: 1000. mother (str): The mother wavelet function to use. Default: 'morlet'. GWS (bool): If True, calculate the Global Wavelet Spectrum. Default: False. RGWS (bool): If True, calculate the Refined Global Wavelet Spectrum (time-integrated power, excluding COI and insignificant areas). Default: False. dj (float): Scale spacing. Smaller values result in better scale resolution but slower calculations. Default: 0.025. s0 (float): Initial (smallest) scale of the wavelet. Default: 2 * dt. J (int): Number of scales minus one. Scales range from s0 up to s0 * 2**(J * dj), giving a total of (J + 1) scales. Default: (log2(N * dt / s0)) / dj. lag1 (float): Lag-1 autocorrelation. Default: 0.0. apod (float): Extent of apodization edges (of a Tukey window). Default: 0.1. pxdetrend (int): Subtract linear trend with time per pixel. Options: 1 (simple) or 2 (advanced). Default: 2. polyfit (int): Degree of polynomial fit for detrending the data. If set, a polynomial fit (instead of linear) is applied. Default: None. meantemporal (bool): If True, apply simple temporal detrending by subtracting the mean signal from the data, skipping fitting procedures. Default: False. meandetrend (bool): If True, subtract the linear trend with time for the image means (spatial detrending). Default: False. recon (bool): If True, perform Fourier reconstruction of the input time series. This does not preserve amplitudes but is useful for examining frequencies far from the low-frequency range. Default: False. resample_original (bool): If True, and if recon set True, approximate values close to the original are returned for comparison. Default: False. nodetrendapod (bool): If True, neither detrending nor apodization is performed. Default: False. silent (bool): If True, suppress print statements. Default: False. **kwargs: Additional parameters for the analysis method. Returns: power: The wavelet power spectrum. periods: Corresponding periods. sig_slevel: The significance levels. coi: The cone of influence. Optionally, if global_power=True: global_power: Global wavelet power spectrum. global_conf: Confidence levels for the global wavelet spectrum. Optionally, if RGWS=True: rgws_periods: Periods for the refined global wavelet spectrum. rgws_power: Refined global wavelet power spectrum. \"\"\" # Define default values for the optional parameters similar to IDL defaults = { 'siglevel' : 0.95 , 'mother' : 'morlet' , # Morlet wavelet as the mother function 'dj' : 1 / 32. , # Scale spacing 's0' : - 1 , # Initial scale 'J' : - 1 , # Number of scales 'lag1' : 0.0 , # Lag-1 autocorrelation 'silent' : False , 'nperm' : 1000 , # Number of permutations for significance calculation } # Update defaults with any user-provided keyword arguments params = { ** defaults , ** kwargs } tdiff = np . diff ( time ) cadence = np . median ( tdiff ) n = len ( signal ) dt = cadence # Standardize the signal before the wavelet transform std_signal = signal . std () norm_signal = signal / std_signal # Determine the initial scale s0 if not provided if params [ 's0' ] == - 1 : params [ 's0' ] = 2 * dt # Determine the number of scales J if not provided if params [ 'J' ] == - 1 : params [ 'J' ] = int (( np . log ( float ( n ) * dt / params [ 's0' ]) / np . log ( 2 )) / params [ 'dj' ]) # Perform wavelet transform W , scales , frequencies , coi , _ , _ = cwt ( norm_signal , dt , dj = params [ 'dj' ], s0 = params [ 's0' ], J = params [ 'J' ], wavelet = params [ 'mother' ] ) power = np . abs ( W ) ** 2 # Wavelet power spectrum periods = 1 / frequencies # Convert frequencies to periods return power , periods , coi , scales , W # ----------------------------------------------------------------------------------------------------- # Linear detrending function for curve fitting def linear ( x , a , b ): return a + b * x # Custom Tukey window implementation def custom_tukey ( nt , apod = 0.1 ): apodrim = int ( apod * nt ) apodt = np . ones ( nt ) # Initialize with ones # Apply sine-squared taper to the first 'apodrim' points taper = ( np . sin ( np . pi / 2. * np . arange ( apodrim ) / apodrim )) ** 2 # Apply taper symmetrically at both ends apodt [: apodrim ] = taper apodt [ - apodrim :] = taper [:: - 1 ] # Reverse taper for the last points return apodt # Main detrending and apodization function # apod=0: The Tukey window becomes a rectangular window (no tapering). # apod=1: The Tukey window becomes a Hann window (fully tapered with a cosine function). def WaLSA_detrend_apod ( cube , apod = 0.1 , meandetrend = False , pxdetrend = 2 , polyfit = None , meantemporal = False , recon = False , cadence = None , resample_original = False , min_resample = None , max_resample = None , silent = False , dj = 32 , lo_cutoff = None , hi_cutoff = None , upper = False ): nt = len ( cube ) # Assume input is a 1D signal cube = cube - np . mean ( cube ) # Remove the mean of the input signal apocube = np . copy ( cube ) # Create a copy of the input signal t = np . arange ( nt ) # Time array # Apply Tukey window (apodization) if apod > 0 : tukey_window = custom_tukey ( nt , apod ) apocube = apocube * tukey_window # Apodize the signal # Mean detrend (optional) if meandetrend : avg_signal = np . mean ( apocube ) time = np . arange ( nt ) mean_fit_params , _ = curve_fit ( linear , time , avg_signal ) mean_trend = linear ( time , * mean_fit_params ) apocube -= mean_trend # Wavelet-based Fourier reconstruction (optional) if recon and cadence : apocube = WaLSA_wave_recon ( apocube , cadence , dj = dj , lo_cutoff = lo_cutoff , hi_cutoff = hi_cutoff , upper = upper ) # Pixel-based detrending (temporal detrend) if pxdetrend > 0 : mean_val = np . mean ( apocube ) if meantemporal : # Simple temporal detrend by subtracting the mean apocube -= mean_val else : # Advanced detrend (linear or polynomial fit) if polyfit is not None : poly_coeffs = np . polyfit ( t , apocube , polyfit ) trend = np . polyval ( poly_coeffs , t ) else : popt , _ = curve_fit ( linear , t , apocube , p0 = [ mean_val , 0 ]) trend = linear ( t , * popt ) apocube -= trend # Resampling to preserve amplitudes (optional) if resample_original : if min_resample is None : min_resample = np . min ( apocube ) if max_resample is None : max_resample = np . max ( apocube ) apocube = np . interp ( apocube , ( np . min ( apocube ), np . max ( apocube )), ( min_resample , max_resample )) if not silent : print ( \"Detrending and apodization complete.\" ) return apocube # Wavelet-based reconstruction function (optional) def WaLSA_wave_recon ( ts , delt , dj = 32 , lo_cutoff = None , hi_cutoff = None , upper = False ): \"\"\" Reconstructs the wavelet-filtered time series based on given frequency cutoffs. \"\"\" # Define duration based on the time series length dur = ( len ( ts ) - 1 ) * delt # Assign default values if lo_cutoff or hi_cutoff is None if lo_cutoff is None : lo_cutoff = 0.0 # Default to 0 as in IDL if hi_cutoff is None : hi_cutoff = dur / ( 3.0 * np . sqrt ( 2 )) mother = 'morlet' num_points = len ( ts ) time_array = np . linspace ( 0 , ( num_points - 1 ) * delt , num_points ) _ , period , coi , scales , wave = getWavelet ( signal = ts , time = time_array , method = 'wavelet' , siglevel = 0.99 , apod = 0.1 , mother = mother ) # Ensure good_per_idx and bad_per_idx are properly assigned if upper : good_per_idx = np . where ( period > hi_cutoff )[ 0 ][ 0 ] bad_per_idx = len ( period ) else : good_per_idx = np . where ( period > lo_cutoff )[ 0 ][ 0 ] bad_per_idx = np . where ( period > hi_cutoff )[ 0 ][ 0 ] # set the power inside the CoI equal to zero # (i.e., exclude points inside the CoI -- subject to edge effect) iampl = np . zeros (( len ( ts ), len ( period )), dtype = float ) for i in range ( len ( ts )): pcol = np . real ( wave [:, i ]) # Extract real part of wavelet transform for this time index ii = np . where ( period < coi [ i ])[ 0 ] # Find indices where period is less than COI at time i if ii . size > 0 : iampl [ i , ii ] = pcol [ ii ] # Assign values where condition is met # Initialize reconstructed signal array recon_sum = np . zeros ( len ( ts )) # Summation over valid period indices for i in range ( good_per_idx , bad_per_idx ): recon_sum += iampl [:, i ] / np . sqrt ( scales [ i ]) # Apply normalization factor recon_all = dj * np . sqrt ( delt ) * recon_sum / ( 0.766 * ( np . pi ** - 0.25 )) return recon_all WaLSA_confidence.py This module implements statistical significance testing for the spectral analysis results using various methods. WaLSA_confidence.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore def WaLSA_confidence ( ps_perm , siglevel = 0.05 , nf = None ): \"\"\" Find the confidence levels (significance levels) for the given power spectrum permutations. Parameters: ----------- ps_perm : np.ndarray 2D array where each row represents a power spectrum, and each column represents a permutation. siglevel : float Significance level (default 0.05 for 95% confidence). nf : int Number of frequencies (length of the power spectra). If None, inferred from the shape of ps_perm. Returns: -------- signif : np.ndarray Significance levels for each frequency. \"\"\" if nf is None : nf = ps_perm . shape [ 0 ] # Number of frequencies inferred from the shape of ps_perm signif = np . zeros (( nf )) # Loop through each frequency for iv in range ( nf ): # Extract the permutation values for this frequency tmp = np . sort ( ps_perm [ iv , :]) # Sort the power spectrum permutation values # Calculate the number of permutations ntmp = len ( tmp ) # Find the significance threshold nsig = int ( round ( siglevel * ntmp )) # Number of permutations to cut off for the significance level # Set the confidence level for this frequency signif [ iv ] = tmp [ - nsig ] # Select the (ntmp - nsig)-th element (equivalent to IDL's ROUND and indexing) return signif WaLSA_wavelet_confidence.py This module implements statistical significance testing for the wavelet analysis results. WaLSA_wavelet_confidence.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore def WaLSA_wavelet_confidence ( ps_perm , siglevel = None ): \"\"\" Find the confidence levels (significance levels) for the given wavelet power spectrum permutations. Parameters: ----------- ps_perm : np.ndarray 2D array where each row represents a power spectrum, and each column represents a permutation. siglevel : float e.g., 0.95 for 95% confidence level (significance at 5%). Returns: -------- signif : np.ndarray Significance levels for each frequency. \"\"\" nnff , nntt , nnperm = ps_perm . shape signif = np . zeros (( nnff , nntt )) for iv in range ( nnff ): for it in range ( nntt ): signif [ iv , it ] = np . percentile ( ps_perm [ iv , it , :], 100 * siglevel ) # e.g., 95% percentile (for 95% consideence level) return signif WaLSA_io.py This module provides functions for input/output operations, such as saving images as PDF (in both RGB and CMYK formats) and image contrast enhancements. WaLSA_io.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import subprocess import shutil import os import stat import numpy as np # type: ignore from matplotlib.backends.backend_pdf import PdfPages # type: ignore def WaLSA_save_pdf ( fig , pdf_path , color_mode = 'RGB' , dpi = 300 , bbox_inches = None , pad_inches = 0 ): \"\"\" Save a PDF from a Matplotlib figure with an option to convert to CMYK if Ghostscript is available. Parameters: - fig: Matplotlib figure object to save. - pdf_path: Path to save the PDF file. - color_mode: 'RGB' (default) to save in RGB, or 'CMYK' to convert to CMYK. - dpi: Resolution in dots per inch. Default is 300. - bbox_inches: Set to 'tight' to remove extra white space. Default is 'tight'. - pad_inches: Padding around the figure. Default is 0. \"\"\" # Save the initial PDF in RGB format using fig.savefig to apply bbox_inches, pad_inches, and dpi if bbox_inches is None : # Save the initial PDF in RGB format with PdfPages ( pdf_path ) as pdf : pdf . savefig ( fig , transparent = True ) if color_mode . upper () == 'CMYK' : # Check if Ghostscript is installed if shutil . which ( \"gs\" ) is not None : # Set permissions on the initial RGB PDF to ensure access for Ghostscript os . chmod ( pdf_path , stat . S_IRUSR | stat . S_IWUSR | stat . S_IRGRP | stat . S_IROTH ) # Define a temporary path for the CMYK file temp_cmyk_path = pdf_path . replace ( '.pdf' , '_temp_cmyk.pdf' ) # Run Ghostscript to create the CMYK PDF as a temporary file subprocess . run ([ \"gs\" , \"-o\" , temp_cmyk_path , \"-sDEVICE=pdfwrite\" , \"-dProcessColorModel=/DeviceCMYK\" , \"-dColorConversionStrategy=/CMYK\" , \"-dNOPAUSE\" , \"-dBATCH\" , \"-dSAFER\" , \"-dPDFSETTINGS=/prepress\" , pdf_path ], check = True ) # Replace the original RGB PDF with the CMYK version os . remove ( pdf_path ) # Delete the RGB version os . rename ( temp_cmyk_path , pdf_path ) # Rename CMYK as the original file print ( f \"PDF saved in CMYK format as ' { pdf_path } '\" ) else : print ( \"Warning: Ghostscript is not installed, so the PDF remains in RGB format.\" ) print ( \"To enable CMYK saving, please install Ghostscript:\" ) print ( \"- On macOS, use: brew install ghostscript\" ) print ( \"- On Ubuntu, use: sudo apt install ghostscript\" ) print ( \"- On Windows, download from: https://www.ghostscript.com/download.html\" ) else : print ( f \"PDF saved in RGB format as ' { pdf_path } '\" ) else : # Temporary path for the RGB version of the PDF temp_pdf_path = pdf_path . replace ( '.pdf' , '_temp.pdf' ) fig . savefig ( temp_pdf_path , format = 'pdf' , dpi = dpi , bbox_inches = bbox_inches , pad_inches = pad_inches , transparent = True ) if color_mode . upper () == 'CMYK' : # Check if Ghostscript is installed if shutil . which ( \"gs\" ) is not None : # Set permissions on the initial RGB PDF to ensure access for Ghostscript os . chmod ( temp_pdf_path , stat . S_IRUSR | stat . S_IWUSR | stat . S_IRGRP | stat . S_IROTH ) # Run Ghostscript to create the CMYK PDF as a temporary file subprocess . run ([ \"gs\" , \"-o\" , pdf_path , \"-sDEVICE=pdfwrite\" , \"-dProcessColorModel=/DeviceCMYK\" , \"-dColorConversionStrategy=/CMYK\" , \"-dNOPAUSE\" , \"-dBATCH\" , \"-dSAFER\" , \"-dPDFSETTINGS=/prepress\" , temp_pdf_path ], check = True ) # Remove the temporary PDF file os . remove ( temp_pdf_path ) print ( f \"PDF saved in CMYK format as ' { pdf_path } '\" ) else : print ( \"Warning: Ghostscript is not installed, so the PDF remains in RGB format.\" ) print ( \"To enable CMYK saving, please install Ghostscript:\" ) print ( \"- On macOS, use: brew install ghostscript\" ) print ( \"- On Ubuntu, use: sudo apt install ghostscript\" ) print ( \"- On Windows, download from: https://www.ghostscript.com/download.html\" ) else : # Rename the temporary file as the final file if no CMYK conversion is needed os . rename ( temp_pdf_path , pdf_path ) print ( f \"PDF saved in RGB format as ' { pdf_path } '\" ) def WaLSA_histo_opt ( image , cutoff = 1e-3 , top_only = False , bot_only = False ): \"\"\" Clip image values based on the cutoff percentile to enhance contrast. Inspired by IDL's \"iris_histo_opt\" function (Copyright: P.Suetterlin, V.Hansteen, and M. Carlsson) Parameters: - image: 2D array (image data). - cutoff: Fraction of values to clip at the top and bottom (default is 0.001). - top_only: If True, clip only the highest values. - bot_only: If True, clip only the lowest values. Returns: - Clipped image for better contrast. \"\"\" # Ignore NaNs in the image finite_values = image [ np . isfinite ( image )] # Calculate lower and upper bounds based on cutoff percentiles lower_bound = np . percentile ( finite_values , cutoff * 100 ) upper_bound = np . percentile ( finite_values , ( 1 - cutoff ) * 100 ) # Clip image according to bounds and options if top_only : return np . clip ( image , None , upper_bound ) elif bot_only : return np . clip ( image , lower_bound , None ) else : return np . clip ( image , lower_bound , upper_bound ) WaLSA_interactive.py This module implements the interactive interface of WaLSAtools, guiding users through the analysis process. WaLSA_interactive.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import ipywidgets as widgets # type: ignore from IPython.display import display , clear_output , HTML # type: ignore import os # type: ignore # Function to detect if it's running in a notebook or terminal def is_notebook (): try : # Check if IPython is in the environment and if we're using a Jupyter notebook from IPython import get_ipython # type: ignore shell = get_ipython () . __class__ . __name__ if shell == 'ZMQInteractiveShell' : return True # Jupyter notebook or qtconsole elif shell == 'TerminalInteractiveShell' : return False # IPython terminal else : return False # Other types except ( NameError , ImportError ): # NameError: get_ipython is not defined # ImportError: IPython is not installed return False # Standard Python interpreter or shell # Function to print logo and credits for both environments def print_logo_and_credits (): logo_terminal = r \"\"\" __ __ _ _____ \\ \\ / / | | / ____| /\\ \\ \\ /\\ / / \u2584\u2584\u2584\u2584\u2584 | | | (___ / \\ \\ \\/ \\/ / \u2580\u2580\u2580\u2580\u2588\u2588 | | \\___ \\ / /\\ \\ \\ /\\ / \u2584\u2588\u2588\u2580\u2580\u2588\u2588 | |____ ____) | / ____ \\ \\/ \\/ \u2580\u2588\u2588\u2584\u2584\u2588\u2588 |______| |_____/ /_/ \\_\\ \"\"\" credits_terminal = \"\"\" \u00a9 WaLSA Team (www.WaLSA.team) ----------------------------------------------------------------------- WaLSAtools v1.0.0 - Wave analysis tools Documentation: www.WaLSA.tools GitHub repository: www.github.com/WaLSAteam/WaLSAtools ----------------------------------------------------------------------- If you use WaLSAtools in your research, please cite: Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 Free access to a view-only version: https://WaLSA.tools/nrmp Supplementary Information: https://WaLSA.tools/nrmp-si ----------------------------------------------------------------------- Choose a category, data type, and analysis method from the list below, to get hints on the calling sequence and parameters: \"\"\" credits_notebook = \"\"\" <div style=\"margin-left: 30px; margin-top: 20px; font-size: 1.1em; line-height: 0.8;\"> <p>\u00a9 WaLSA Team (<a href=\"https://www.WaLSA.team\" target=\"_blank\">www.WaLSA.team</a>)</p> <hr style=\"width: 70%; margin: 0; border: 0.98px solid #888; margin-bottom: 10px;\"> <p><strong>WaLSAtools</strong> v1.0.0 - Wave analysis tools</p> <p>Documentation: <a href=\"https://www.WaLSA.tools\" target=\"_blank\">www.WaLSA.tools</a></p> <p>GitHub repository: <a href=\"https://www.github.com/WaLSAteam/WaLSAtools\" target=\"_blank\">www.github.com/WaLSAteam/WaLSAtools</a></p> <hr style=\"width: 70%; margin: 0; border: 0.98px solid #888; margin-bottom: 10px;\"> <p>If you use <strong>WaLSAtools</strong> in your research, please cite:</p> <p>Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, <em>Nature Reviews Methods Primers</em>, 5, 21</p> <p>Free access to a view-only version: <a href=\"https://WaLSA.tools/nrmp\" target=\"_blank\">www.WaLSA.tools</a></p> <p>Supplementary Information: <a href=\"https://WaLSA.tools/nrmp-si\" target=\"_blank\">www.WaLSA.tools</a></p> <hr style=\"width: 70%; margin: 0; border: 0.98px solid #888; margin-bottom: 15px;\"> <p>Choose a category, data type, and analysis method from the list below,</p> <p>to get hints on the calling sequence and parameters:</p> </div> \"\"\" if is_notebook (): try : # For scripts current_dir = os . path . dirname ( os . path . abspath ( __file__ )) except NameError : # For Jupyter notebooks current_dir = os . getcwd () img_path = os . path . join ( current_dir , '..' , 'assets' , 'WaLSAtools_black.png' ) # display(HTML(f'<img src=\"{img_path}\" style=\"margin-left: 40px; margin-top: 20px; width:300px; height: auto;\">')) # not shwon in Jupyter notebook, only in MS Code import base64 # Convert the image to Base64 with open ( img_path , \"rb\" ) as img_file : encoded_img = base64 . b64encode ( img_file . read ()) . decode ( 'utf-8' ) # Embed the Base64 image in the HTML html_code_logo = f \"\"\" <div style=\"margin-left: 30px; margin-top: 20px;\"> <img src=\"data:image/png;base64, { encoded_img } \" style=\"width: 300px; height: auto;\"> </div> \"\"\" display ( HTML ( html_code_logo )) display ( HTML ( credits_notebook )) else : print ( logo_terminal ) print ( credits_terminal ) from .parameter_definitions import display_parameters_text , single_series_parameters , cross_correlation_parameters # Terminal-based interactive function import textwrap import shutil def walsatools_terminal (): \"\"\"Main interactive function for terminal version of WaLSAtools.\"\"\" print_logo_and_credits () # Get terminal width terminal_width = shutil . get_terminal_size () . columns # Calculate 90% of the width (and ensure it's an integer) line_width = int ( terminal_width * 0.90 ) # Step 1: Select Category while True : print ( \" \\n Category:\" ) print ( \" (a) Single time series analysis\" ) print ( \" (b) Cross-correlation between two time series\" ) category = input ( \" --- Select a category (a/b): \" ) . strip () . lower () if category not in [ 'a' , 'b' ]: print ( \" Invalid selection. Please enter either 'a' or 'b'. \\n \" ) continue # Step 2: Data Type if category == 'a' : while True : print ( \" \\n Data Type:\" ) print ( \" (1) 1D signal\" ) print ( \" (2) 3D datacube\" ) method = input ( \" --- Select a data type (1/2): \" ) . strip () if method not in [ '1' , '2' ]: print ( \" Invalid selection. Please enter either '1' or '2'. \\n \" ) continue # Step 3: Analysis Method if method == '1' : # 1D Signal while True : print ( \" \\n Analysis Method:\" ) print ( \" (1) FFT\" ) print ( \" (2) Wavelet\" ) print ( \" (3) Lomb-Scargle\" ) print ( \" (4) Welch\" ) print ( \" (5) EMD\" ) analysis_type = input ( \" --- Select an analysis method (1-5): \" ) . strip () method_map_1d = { '1' : 'fft' , '2' : 'wavelet' , '3' : 'lombscargle' , '4' : 'welch' , '5' : 'emd' } selected_method = method_map_1d . get ( analysis_type , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid analysis method (1-5). \\n \" ) continue # Generate and display the calling sequence for 1D signal print ( \" \\n Calling sequence: \\n \" ) return_values = single_series_parameters [ selected_method ][ 'return_values' ] command = f \">>> { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'a' ) return # Exit the function after successful output elif method == '2' : # 3D Datacube while True : print ( \" \\n Analysis Method:\" ) print ( \" (1) k-omega\" ) print ( \" (2) POD\" ) print ( \" (3) Dominant Freq / Mean Power Spectrum\" ) analysis_type = input ( \" --- Select an analysis method (1-3): \" ) . strip () if analysis_type == '3' : # Sub-method required while True : print ( \" \\n Analysis method for Dominant Freq / Mean Power Spectrum:\" ) print ( \" (1) FFT\" ) print ( \" (2) Wavelet\" ) print ( \" (3) Lomb-Scargle\" ) print ( \" (4) Welch\" ) sub_method = input ( \" --- Select a method (1-4): \" ) . strip () sub_method_map = { '1' : 'fft' , '2' : 'wavelet' , '3' : 'lombscargle' , '4' : 'welch' } selected_method = sub_method_map . get ( sub_method , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid sub-method (1-4). \\n \" ) continue # Generate and display the calling sequence for sub-method print ( \" \\n Calling sequence: \\n \" ) return_values = 'dominant_frequency, mean_power, frequency, power_map' command = f \">>> { return_values } = WaLSAtools(data=INPUT_DATA, time=TIME_ARRAY, averagedpower=True, dominantfreq=True, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'a' ) return # Exit the function after successful output method_map_3d = { '1' : 'k-omega' , '2' : 'pod' } selected_method = method_map_3d . get ( analysis_type , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid analysis method (1-3). \\n \" ) continue # Generate and display the calling sequence for k-omega/POD print ( \" \\n Calling sequence: \\n \" ) return_values = single_series_parameters [ selected_method ][ 'return_values' ] command = f \">>> { return_values } = WaLSAtools(data1=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'a' ) return # Exit the function after successful output elif category == 'b' : # Cross-correlation while True : print ( \" \\n Data Type:\" ) print ( \" (1) 1D signal\" ) method = input ( \" --- Select a data type (1): \" ) . strip () if method != '1' : print ( \" Invalid selection. Please enter '1'. \\n \" ) continue while True : print ( \" \\n Analysis Method:\" ) print ( \" (1) FFT\" ) print ( \" (2) Wavelet\" ) print ( \" (3) Welch\" ) analysis_type = input ( \" --- Select an analysis method (1-2): \" ) . strip () cross_correlation_map = { '1' : 'fft' , '2' : 'wavelet' , '3' : 'welch' } selected_method = cross_correlation_map . get ( analysis_type , 'unknown' ) if selected_method == 'unknown' : print ( \" Invalid selection. Please select a valid analysis method (1-2). \\n \" ) continue # Generate and display the calling sequence for cross-correlation print ( \" \\n Calling sequence: \\n \" ) return_values = cross_correlation_parameters [ selected_method ][ 'return_values' ] command = f \">>> { return_values } = WaLSAtools(data1=INPUT_DATA1, data2=INPUT_DATA2, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" wrapper = textwrap . TextWrapper ( width = line_width - 4 , initial_indent = ' ' , subsequent_indent = ' ' ) wrapped_command = wrapper . fill ( command ) print ( wrapped_command ) # Display parameter hints display_parameters_text ( selected_method , category = 'b' ) return # Exit the function after successful output # Jupyter-based interactive function import ipywidgets as widgets # type: ignore from IPython.display import display , clear_output , HTML # type: ignore from .parameter_definitions import display_parameters_html , single_series_parameters , cross_correlation_parameters # type: ignore # Global flag to prevent multiple observers is_observer_attached = False def walsatools_jupyter (): \"\"\"Main interactive function for Jupyter Notebook version of WaLSAtools.\"\"\" global is_observer_attached , category , method , analysis_type , sub_method # Declare global variables for reuse # Detach any existing observers and reset the flag try : detach_observers () except NameError : pass # `detach_observers` hasn't been defined yet is_observer_attached = False # Reset observer flag # Clear any previous output clear_output ( wait = True ) print_logo_and_credits () # Recreate widgets to reset state category = widgets . Dropdown ( options = [ 'Select Category' , 'Single time series analysis' , 'Cross-correlation between two time series' ], value = 'Select Category' , description = 'Category:' ) method = widgets . Dropdown ( options = [ 'Select Data Type' ], value = 'Select Data Type' , description = 'Data Type:' ) analysis_type = widgets . Dropdown ( options = [ 'Select Method' ], value = 'Select Method' , description = 'Method:' ) sub_method = widgets . Dropdown ( options = [ 'Select Sub-method' , 'FFT' , 'Wavelet' , 'Lomb-Scargle' , 'Welch' ], value = 'Select Sub-method' , description = 'Sub-method:' , layout = widgets . Layout ( display = 'none' ) # Initially hidden ) # Persistent output widget output = widgets . Output () def clear_output_if_unselected ( change = None ): \"\"\"Clear the output widget if any dropdown menu is unselected.\"\"\" with output : if ( category . value == 'Select Category' or method . value == 'Select Data Type' or analysis_type . value == 'Select Method' or ( analysis_type . value == 'Dominant Freq / Mean Power Spectrum' and sub_method . layout . display == 'block' and sub_method . value == 'Select Sub-method' ) ): clear_output ( wait = True ) warn = '<div style=\"font-size: 1.1em; margin-left: 30px; margin-top:15px; margin-bottom: 15px;\">Please select appropriate options from all dropdown menus.</div>' display ( HTML ( warn )) def update_method_options ( change = None ): \"\"\"Update available Method and Sub-method options.\"\"\" clear_output_if_unselected () # Ensure the output clears if any dropdown is unselected. sub_method . layout . display = 'none' sub_method . value = 'Select Sub-method' sub_method . options = [ 'Select Sub-method' ] if category . value == 'Single time series analysis' : method . options = [ 'Select Data Type' , '1D signal' , '3D datacube' ] if method . value == '1D signal' : analysis_type . options = [ 'Select Method' , 'FFT' , 'Wavelet' , 'Lomb-Scargle' , 'Welch' , 'EMD' ] elif method . value == '3D datacube' : analysis_type . options = [ 'Select Method' , 'k-omega' , 'POD' , 'Dominant Freq / Mean Power Spectrum' ] else : analysis_type . options = [ 'Select Method' ] elif category . value == 'Cross-correlation between two time series' : method . options = [ 'Select Data Type' , '1D signal' ] if method . value == '1D signal' : analysis_type . options = [ 'Select Method' , 'FFT' , 'Wavelet' , 'Welch' ] else : analysis_type . options = [ 'Select Method' ] else : method . options = [ 'Select Data Type' ] analysis_type . options = [ 'Select Method' ] def update_sub_method_visibility ( change = None ): \"\"\"Show or hide the Sub-method dropdown based on conditions.\"\"\" clear_output_if_unselected () # Ensure the output clears if any dropdown is unselected. if ( category . value == 'Single time series analysis' and method . value == '3D datacube' and analysis_type . value == 'Dominant Freq / Mean Power Spectrum' ): sub_method . options = [ 'Select Sub-method' , 'FFT' , 'Wavelet' , 'Lomb-Scargle' , 'Welch' ] sub_method . layout . display = 'block' else : sub_method . options = [ 'Select Sub-method' ] sub_method . value = 'Select Sub-method' sub_method . layout . display = 'none' def update_calling_sequence ( change = None ): \"\"\"Update the function calling sequence based on user's selection.\"\"\" clear_output_if_unselected () # Ensure the output clears if any dropdown is unselected. if ( category . value == 'Select Category' or method . value == 'Select Data Type' or analysis_type . value == 'Select Method' or ( analysis_type . value == 'Dominant Freq / Mean Power Spectrum' and sub_method . layout . display == 'block' and sub_method . value == 'Select Sub-method' ) ): return # Do nothing until all required fields are properly selected with output : clear_output ( wait = True ) # Handle Dominant Frequency / Mean Power Spectrum with Sub-method if ( category . value == 'Single time series analysis' and method . value == '3D datacube' and analysis_type . value == 'Dominant Freq / Mean Power Spectrum' ): if sub_method . value == 'Select Sub-method' : print ( \"Please select a Sub-method.\" ) return sub_method_map = { 'FFT' : 'fft' , 'Wavelet' : 'wavelet' , 'Lomb-Scargle' : 'lombscargle' , 'Welch' : 'welch' } selected_method = sub_method_map . get ( sub_method . value , 'unknown' ) return_values = 'dominant_frequency, mean_power, frequency, power_map' command = f \" { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, averagedpower=True, dominantfreq=True, method=' { selected_method } ', **kwargs)\" # Handle k-omega and POD elif ( category . value == 'Single time series analysis' and method . value == '3D datacube' and analysis_type . value in [ 'k-omega' , 'POD' ] ): method_map = { 'k-omega' : 'k-omega' , 'POD' : 'pod' } selected_method = method_map . get ( analysis_type . value , 'unknown' ) parameter_definitions = single_series_parameters return_values = parameter_definitions . get ( selected_method , {}) . get ( 'return_values' , '' ) command = f \" { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" # Handle Cross-correlation elif category . value == 'Cross-correlation between two time series' : cross_correlation_map = { 'FFT' : 'fft' , 'Wavelet' : 'wavelet' , 'Welch' : 'welch' } selected_method = cross_correlation_map . get ( analysis_type . value , 'unknown' ) parameter_definitions = cross_correlation_parameters return_values = parameter_definitions . get ( selected_method , {}) . get ( 'return_values' , '' ) command = f \" { return_values } = WaLSAtools(data1=INPUT_DATA1, data2=INPUT_DATA2, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" # Handle Single 1D signal analysis elif category . value == 'Single time series analysis' and method . value == '1D signal' : method_map = { 'FFT' : 'fft' , 'Wavelet' : 'wavelet' , 'Lomb-Scargle' : 'lombscargle' , 'Welch' : 'welch' , 'EMD' : 'emd' } selected_method = method_map . get ( analysis_type . value , 'unknown' ) parameter_definitions = single_series_parameters return_values = parameter_definitions . get ( selected_method , {}) . get ( 'return_values' , '' ) command = f \" { return_values } = WaLSAtools(signal=INPUT_DATA, time=TIME_ARRAY, method=' { selected_method } ', **kwargs)\" else : print ( \"Invalid configuration.\" ) return # Generate and display the command in HTML html_code = f \"\"\" <div style=\"font-size: 1.2em; margin-left: 30px; margin-top:15px; margin-bottom: 15px;\">Calling sequence:</div> <div style=\"display: flex; margin-left: 30px; margin-bottom: 3ch;\"> <span style=\"color: #222; min-width: 4ch;\">>>> </span> <pre style=\" white-space: pre-wrap; word-wrap: break-word; color: #01016D; margin: 0; \"> { command } </pre> </div> \"\"\" display ( HTML ( html_code )) display_parameters_html ( selected_method , category = category . value ) def attach_observers (): \"\"\"Attach observers to the dropdown widgets and ensure no duplicates.\"\"\" global is_observer_attached if not is_observer_attached : detach_observers () category . observe ( clear_output_if_unselected , names = 'value' ) method . observe ( clear_output_if_unselected , names = 'value' ) analysis_type . observe ( clear_output_if_unselected , names = 'value' ) category . observe ( update_method_options , names = 'value' ) method . observe ( update_method_options , names = 'value' ) analysis_type . observe ( update_sub_method_visibility , names = 'value' ) sub_method . observe ( update_calling_sequence , names = 'value' ) analysis_type . observe ( update_calling_sequence , names = 'value' ) is_observer_attached = True def detach_observers (): \"\"\"Detach all observers to prevent multiple triggers.\"\"\" try : category . unobserve ( update_method_options , names = 'value' ) method . unobserve ( update_method_options , names = 'value' ) analysis_type . unobserve ( update_sub_method_visibility , names = 'value' ) sub_method . unobserve ( update_calling_sequence , names = 'value' ) analysis_type . unobserve ( update_calling_sequence , names = 'value' ) except ValueError : pass attach_observers () display ( category , method , analysis_type , sub_method , output ) # Unified interactive function for both terminal and Jupyter environments def interactive (): if is_notebook (): walsatools_jupyter () else : walsatools_terminal () WaLSA_plot_k_omega.py This module provides functions for plotting k-\u03c9 diagrams and filtered datacubes. WaLSA_plot_k_omega.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- # The following codes are baed on those originally written by David B. Jess and Samuel D. T. Grant # ----------------------------------------------------------------------------------------------------- import numpy as np # type: ignore from matplotlib.colors import ListedColormap # type: ignore from WaLSAtools import WaLSA_histo_opt # type: ignore from scipy.interpolate import griddata # type: ignore import matplotlib.pyplot as plt # type: ignore from matplotlib.ticker import FixedLocator , FixedFormatter # type: ignore import matplotlib.patches as patches # type: ignore import matplotlib.patheffects as path_effects # type: ignore from matplotlib.colors import Normalize # type: ignore def WaLSA_plot_k_omega ( kopower , kopower_xscale , kopower_yscale , xtitle = 'Wavenumber (pixel\u207b\u00b9)' , ytitle = 'Frequency (mHz)' , xlog = False , ylog = False , xrange = None , yrange = None , xtick_interval = 0.05 , ytick_interval = 200 , xtick_minor_interval = 0.01 , ytick_minor_interval = 50 , colorbar_label = 'Log\u2081\u2080(Power)' , cmap = 'viridis' , cbartab = 0.12 , figsize = ( 9 , 4 ), smooth = True , dypix = 1200 , dxpix = 1600 , ax = None , k1 = None , k2 = None , f1 = None , f2 = None , colorbar_location = 'right' ): \"\"\" Plots the k-omega diagram with corrected orientation and axis alignment. Automatically clips the power array and scales based on x and y ranges. Example usage: WaLSA_plot_k_omega( kopower=power, kopower_xscale=wavenumber, kopower_yscale=frequencies*1000., xlog=False, ylog=False, xrange=(0, 0.3), figsize=(8, 4), cbartab=0.18, xtitle='Wavenumber (pixel\u207b\u00b9)', ytitle='Frequency (mHz)', colorbar_label='Log\u2081\u2080(Oscillation Power)', f1=0.470*1000, f2=0.530*1000, k1=0.047, k2=0.25 ) \"\"\" if xrange is None or len ( xrange ) != 2 : xrange = [ np . min ( kopower_xscale ), np . max ( kopower_xscale )] if yrange is None or len ( yrange ) != 2 : yrange = [ np . min ( kopower_yscale ), np . max ( kopower_yscale )] # Handle xrange and yrange adjustments if xrange is not None and len ( xrange ) == 2 and xrange [ 0 ] == 0 : xrange = [ np . min ( kopower_xscale ), xrange [ 1 ]] if yrange is not None and len ( yrange ) == 2 and yrange [ 0 ] == 0 : yrange = [ np . min ( kopower_yscale ), yrange [ 1 ]] # Clip kopower, kopower_xscale, and kopower_yscale based on xrange and yrange if xrange : x_min , x_max = xrange x_indices = np . where (( kopower_xscale >= x_min ) & ( kopower_xscale <= x_max ))[ 0 ] # Check if the lower bound is not included if kopower_xscale [ x_indices [ 0 ]] > x_min and x_indices [ 0 ] > 0 : x_indices = np . insert ( x_indices , 0 , x_indices [ 0 ] - 1 ) # Check if the upper bound is not included if kopower_xscale [ x_indices [ - 1 ]] < x_max and x_indices [ - 1 ] + 1 < len ( kopower_xscale ): x_indices = np . append ( x_indices , x_indices [ - 1 ] + 1 ) kopower = kopower [:, x_indices ] kopower_xscale = kopower_xscale [ x_indices ] if yrange : y_min , y_max = yrange y_indices = np . where (( kopower_yscale >= y_min ) & ( kopower_yscale <= y_max ))[ 0 ] # Check if the lower bound is not included if kopower_yscale [ y_indices [ 0 ]] > y_min and y_indices [ 0 ] > 0 : y_indices = np . insert ( y_indices , 0 , y_indices [ 0 ] - 1 ) # Check if the upper bound is not included if kopower_yscale [ y_indices [ - 1 ]] < y_max and y_indices [ - 1 ] + 1 < len ( kopower_yscale ): y_indices = np . append ( y_indices , y_indices [ - 1 ] + 1 ) kopower = kopower [ y_indices , :] kopower_yscale = kopower_yscale [ y_indices ] # Pixel coordinates in data space if xlog : nxpix = np . logspace ( np . log10 ( xrange [ 0 ]), np . log10 ( xrange [ 1 ]), dxpix ) else : nxpix = np . linspace ( xrange [ 0 ], xrange [ 1 ], dxpix ) if ylog : nypix = np . logspace ( np . log10 ( yrange [ 0 ]), np . log10 ( yrange [ 1 ]), dypix ) else : nypix = np . linspace ( yrange [ 0 ], yrange [ 1 ], dypix ) # Interpolation over data interpolator = griddata ( points = ( np . repeat ( kopower_yscale , len ( kopower_xscale )), np . tile ( kopower_xscale , len ( kopower_yscale ))), values = kopower . ravel (), xi = ( nypix [:, None ], nxpix [ None , :]), method = 'linear' ) newimage = np . nan_to_num ( interpolator ) # Clip the interpolated image to the exact xrange and yrange x_indices = ( nxpix >= xrange [ 0 ]) & ( nxpix <= xrange [ 1 ]) y_indices = ( nypix >= yrange [ 0 ]) & ( nypix <= yrange [ 1 ]) newimage = newimage [ np . ix_ ( y_indices , x_indices )] nxpix = nxpix [ x_indices ] nypix = nypix [ y_indices ] # Extent for plotting extent = [ nxpix [ 0 ], nxpix [ - 1 ], nypix [ 0 ], nypix [ - 1 ]] # Set up the plot if ax is None : fig , ax = plt . subplots ( figsize = figsize ) # Load custom colormap rgb_values = np . loadtxt ( 'Color_Tables/idl_colormap_13.txt' ) / 255.0 idl_colormap_13 = ListedColormap ( rgb_values ) # Compute minimum and maximum values of the data vmin = np . nanmin ( kopower ) vmax = np . nanmax ( kopower ) img = ax . imshow ( WaLSA_histo_opt ( newimage ), extent = extent , origin = 'lower' , aspect = 'auto' , cmap = idl_colormap_13 , norm = Normalize ( vmin = vmin , vmax = vmax ) ) # Configure axis labels and scales ax . set_xlabel ( xtitle ) ax . set_ylabel ( ytitle ) if xlog : ax . set_xscale ( 'log' ) if ylog : ax . set_yscale ( 'log' ) # Configure ticks ax . xaxis . set_major_locator ( plt . MultipleLocator ( xtick_interval )) ax . xaxis . set_minor_locator ( plt . MultipleLocator ( xtick_minor_interval )) ax . yaxis . set_major_locator ( plt . MultipleLocator ( ytick_interval )) ax . yaxis . set_minor_locator ( plt . MultipleLocator ( ytick_minor_interval )) # # Add a secondary x and y axes for perido and spatial size ax . tick_params ( axis = 'both' , which = 'both' , direction = 'out' , top = True , right = True ) ax . tick_params ( axis = 'both' , which = 'major' , length = 7 , width = 1.1 ) # Major ticks ax . tick_params ( axis = 'both' , which = 'minor' , length = 4 , width = 1.1 ) # Minor ticks major_xticks = ax . get_xticks () major_yticks = ax . get_yticks () # Define a function to calculate the period (1000 / frequency) def frequency_to_period ( frequency ): return 1000. / frequency if frequency > 0 else np . inf # Generate labels for the secondary y-axis based on the primary y-axis ticks period_labels = [ f \" { frequency_to_period ( tick ) : .1f } \" if tick > 0 else \"\" for tick in major_yticks ] # Set custom labels for the secondary y-axis ax_right = ax . secondary_yaxis ( 'right' ) ax_right . set_yticks ( major_yticks ) ax_right . set_yticklabels ( period_labels ) ax_right . set_ylabel ( 'Period (s)' , labelpad = 12 ) # Define a function to calculate spatial size (2\u03c0 / wavenumber) def wavenumber_to_spatial_size ( wavenumber ): return 2 * np . pi / wavenumber if wavenumber > 0 else np . inf # Generate labels for the secondary x-axis based on the primary x-axis ticks spatial_size_labels = [ f \" { wavenumber_to_spatial_size ( tick ) : .1f } \" if tick > 0 else \"\" for tick in major_xticks ] # Set custom labels for the secondary x-axis ax_top = ax . secondary_xaxis ( 'top' ) ax_top . set_xticks ( major_xticks ) ax_top . set_xticklabels ( spatial_size_labels ) ax_top . set_xlabel ( 'Spatial Size (pixel)' , labelpad = 12 ) if k1 is not None and k2 is not None and f1 is not None and f2 is not None : width = k2 - k1 height = f2 - f1 rectangle = patches . Rectangle ( ( k1 , f1 ), width , height , zorder = 10 , linewidth = 1.5 , edgecolor = 'white' , facecolor = 'none' , linestyle = '--' ) rectangle . set_path_effects ([ path_effects . Stroke ( linewidth = 2.5 , foreground = 'black' ), path_effects . Normal () ]) # Mark the filtered area ax . add_patch ( rectangle ) # Add colorbar tick_values = [ vmin , vmin + ( vmax - vmin ) * 0.33 , vmin + ( vmax - vmin ) * 0.67 , vmax ] # Format the tick labels tick_labels = [ f \" { v : .1f } \" for v in tick_values ] if colorbar_location == 'top' : cbar = plt . colorbar ( img , ax = ax , orientation = 'horizontal' , pad = cbartab , location = 'top' , aspect = 30 ) cbar . set_label ( colorbar_label ) # Override the ticks and tick labels cbar . set_ticks ( tick_values ) # Set custom tick locations cbar . set_ticklabels ( tick_labels ) # Set custom tick labels cbar . ax . xaxis . set_major_locator ( FixedLocator ( tick_values )) # Fix tick locations cbar . ax . xaxis . set_major_formatter ( FixedFormatter ( tick_labels )) # Fix tick labels # Suppress auto ticks completely cbar . ax . xaxis . set_minor_locator ( FixedLocator ([])) # Ensure no minor ticks appear else : cbar = plt . colorbar ( img , ax = ax , orientation = 'vertical' , pad = cbartab , aspect = 22 ) cbar . set_label ( colorbar_label ) # Override the ticks and tick labels cbar . set_ticks ( tick_values ) # Set custom tick locations cbar . set_ticklabels ( tick_labels ) # Set custom tick labels cbar . ax . yaxis . set_major_locator ( FixedLocator ( tick_values )) # Fix tick locations cbar . ax . yaxis . set_major_formatter ( FixedFormatter ( tick_labels )) # Fix tick labels # Suppress auto ticks completely cbar . ax . yaxis . set_minor_locator ( FixedLocator ([])) # Ensure no minor ticks appear return ax WaLSA_plot_wavelet_spectrum.py This module provides functions for plotting wavelet power spectra and related visualizations. WaLSA_plot_wavelet_spectrum.py # ----------------------------------------------------------------------------------------------------- # WaLSAtools - Wave analysis tools # Copyright (C) 2025 WaLSA Team - Shahin Jafarzadeh et al. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # # Note: If you use WaLSAtools for research, please consider citing: # Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, 5, 21 # ----------------------------------------------------------------------------------------------------- import matplotlib.pyplot as plt import matplotlib.ticker as ticker import numpy as np from matplotlib.colors import LinearSegmentedColormap from mpl_toolkits.axes_grid1 import make_axes_locatable def WaLSA_plot_wavelet_spectrum ( t , power , periods , sig_slevel , coi , dt , normalize_power = False , title = 'Wavelet Power Spectrum' , ylabel = 'Period [s]' , xlabel = 'Time [s]' , colorbar_label = 'Power (%)' , ax = None , colormap = 'custom' , removespace = False ): \"\"\"Plots the wavelet power spectrum of a given signal. Parameters: - t (array-like): Time values for the signal. - power (2D array-like): Wavelet power spectrum. - periods (array-like): Period values corresponding to the power. - sig_slevel (2D array-like): Significance levels of the power spectrum. - coi (array-like): Cone of influence, showing where edge effects might be present. - dt (float): Time interval between successive time values. - normalize_power (bool): If True, normalize power to 0-100%. Default is False. - title (str): Title of the plot. Default is 'Wavelet Power Spectrum'. - ylabel (str): Y-axis label. Default is 'Period [s]'. - xlabel (str): X-axis label. Default is 'Time [s]'. - colorbar_label (str): Label for the color bar. Default is 'Power (%)'. - ax (matplotlib axis, optional): Axis to plot on. Default is None, which creates a new figure and axis. - colormap (str or colormap, optional): Colormap to be used. Default is 'custom'. - removespace (bool, optional): If True, limits the maximum y-range to the peak of the cone of influence. \"\"\" if ax is None : fig , ax = plt . subplots ( figsize = ( 12 , 6 )) # Custom colormap with white at the lower end if colormap == 'custom' : cmap = LinearSegmentedColormap . from_list ( 'custom_white' , [ 'white' , 'blue' , 'green' , 'yellow' , 'red' ], N = 256 ) else : cmap = plt . get_cmap ( colormap ) # Normalize power if requested if normalize_power : power = 100 * power / np . nanmax ( power ) # Define a larger number of levels to create a continuous color bar levels = np . linspace ( np . nanmin ( power ), np . nanmax ( power ), 100 ) # Plot the wavelet power spectrum CS = ax . contourf ( t , periods , power , levels = levels , cmap = cmap , extend = 'neither' ) # Removed 'extend' mode for straight ends # 95% significance contour ax . contour ( t , periods , sig_slevel , levels = [ 1 ], colors = 'k' , linewidths = [ 1.0 ]) if removespace : max_period = np . max ( coi ) else : max_period = np . max ( periods ) # Cone-of-influence ax . plot ( t , coi , '-k' , lw = 2 ) ax . fill ( np . concatenate ([ t , t [ - 1 :] + dt , t [ - 1 :] + dt , t [: 1 ] - dt , t [: 1 ] - dt ]), np . concatenate ([ coi , [ 1e-9 ], [ max_period ], [ max_period ], [ 1e-9 ]]), 'k' , alpha = 0.3 , hatch = 'x' ) # Log scale for periods ax . set_ylim ([ np . min ( periods ), max_period ]) ax . set_yscale ( 'log' , base = 10 ) ax . yaxis . set_major_formatter ( ticker . ScalarFormatter ()) ax . ticklabel_format ( axis = 'y' , style = 'plain' ) ax . invert_yaxis () # Set axis limits and labels ax . set_xlim ([ t . min (), t . max ()]) ax . set_ylabel ( ylabel , fontsize = 14 ) ax . set_xlabel ( xlabel , fontsize = 14 ) ax . tick_params ( axis = 'both' , which = 'major' , labelsize = 12 ) ax . set_title ( title , fontsize = 16 ) # Add a secondary y-axis for frequency in Hz ax_freq = ax . twinx () # Set limits for the frequency axis based on the `max_period` used for the period axis min_frequency = 1 / max_period max_frequency = 1 / np . min ( periods ) ax_freq . set_yscale ( 'log' , base = 10 ) ax_freq . set_ylim ([ max_frequency , min_frequency ]) # Adjust frequency range properly ax_freq . yaxis . set_major_formatter ( ticker . ScalarFormatter ()) ax_freq . ticklabel_format ( axis = 'y' , style = 'plain' ) ax_freq . invert_yaxis () ax_freq . set_ylabel ( 'Frequency (Hz)' , fontsize = 14 ) ax_freq . tick_params ( axis = 'both' , which = 'major' , labelsize = 12 ) # Add color bar on top with minimal distance divider = make_axes_locatable ( ax ) cax = divider . append_axes ( 'top' , size = '5%' , pad = 0.01 ) # Use 'pad=0.01' for a small fixed distance cbar = plt . colorbar ( CS , cax = cax , orientation = 'horizontal' ) # Move color bar label to the top of the bar cbar . set_label ( colorbar_label , fontsize = 12 , labelpad = 5 ) cbar . ax . tick_params ( labelsize = 10 , direction = 'out' , top = True , labeltop = True , bottom = False , labelbottom = False ) cbar . ax . xaxis . set_label_position ( 'top' ) # Adjust layout if a new figure was created if ax is None : plt . tight_layout () plt . show ()", "title": "Analysis Modules"}, {"location": "python/spod-example/", "text": "Worked Example - NRMP: Spectral Proper Orthogonal Decomposition (SPOD) Analysis \u00b6 This example demonstrates the application of Spectral Proper Orthogonal Decomposition (SPOD) to a synthetic spatio-temporal dataset. SPOD is an extension of the traditional Proper Orthogonal Decomposition (POD) method that incorporates frequency filtering to isolate specific modes associated with particular frequencies. This allows for a more refined analysis of the dominant spatial patterns and their temporal evolution, particularly in complex datasets with multiple superimposed oscillations. Analysis and Figure The figure below shows the results of applying SPOD to the synthetic spatio-temporal dataset. Methods used: Spectral Proper Orthogonal Decomposition (SPOD) Welch's method (to analyze the frequency content of the temporal coefficients) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S8 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: SPOD analysis. Spatial modes (130\u00d7130 pixels 2 each), temporal coefficients, and Welch power spectra of the first six SPOD modes. The SPOD analysis was performed with a Gaussian filter kernel, illustrating the frequency pairing phenomenon, where each frequency is associated with two distinct spatial modes with corresponding temporal coefficients. The shared frequency content is evident in the Welch power spectra. The ten base frequencies are marked with vertical dashed lines. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , spod = True ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). Starting SPOD analysis .... SPOD analysis completed. POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.71], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.4], [0.35, 0.33], [0.4, 0.26], [0.45, 0.25], [0.55, 0.19]] Total variance contribution of the first 200 modes: 100.00% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (10,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (ndarray, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (ndarray, Shape: (200, 130, 130)): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (ndarray, Shape: (200, 200)): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 SPOD_spatial_modes = pod_results [ 'SPOD_spatial_modes' ] SPOD_temporal_coefficients = pod_results [ 'SPOD_temporal_coefficients' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import AutoMinorLocator from scipy.signal import welch # Setting global parameters for plot appearance plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 18 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 20 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) mode_shift = 0 # Offset for mode indices # Create a figure with specific dimensions fig = plt . figure ( figsize = ( 15 , 19 )) # Create a grid layout for subplots gs1 = gridspec . GridSpec ( 9 , 3 , height_ratios = [ 1 , 0.5 , - 0.04 , 0.5 , 0.2 , 1 , 0.5 , - 0.04 , 0.5 ], figure = fig , hspace = 0.5 , wspace = 0.3 ) # Loop to plot the first set of 3 modes for m in range ( 3 ): # Plot SPOD spatial mode as an image ax_img = plt . subplot ( gs1 [ 0 , m ]) ax_img . set_title ( f 'SPOD Mode ($P_ { m + 1 + mode_shift } $)' ) vmax = ( np . abs ( SPOD_spatial_modes [ m + mode_shift ,:,:]) . max ()) img = ax_img . imshow ( np . flipud ( SPOD_spatial_modes [ m + mode_shift ,:,:]), cmap = 'jet' , vmax = vmax , vmin =- vmax ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) # Plot temporal coefficients ax_line = plt . subplot ( gs1 [ 1 , m ]) ax_line . plot ( time , SPOD_temporal_coefficients [:, m + mode_shift ], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 + mode_shift } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 0 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . grid ( False ) # Add grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) # Plot power spectrum of the temporal coefficients - using Welch's method ax_welch = plt . subplot ( gs1 [ 3 , m ]) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ] for freq in pre_defined_freq : rounded_freq = freq ax_welch . axvline ( x = freq , color = 'r' , linestyle = '--' , linewidth = 1.1 ) f , px = welch ( SPOD_temporal_coefficients [:, m + mode_shift ] - np . mean ( SPOD_temporal_coefficients [:, m + mode_shift ]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 + mode_shift } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 0 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . grid ( False ) # Add grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) # Set major ticks every 50 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 50 ), minor = True ) # Set tick labels every 100 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 200 ), minor = False ) ax_welch . set_xticklabels ( np . arange ( 0 , 1001 , 200 )) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Create space between two sets of 3 modes gs_space = gridspec . GridSpec ( 1 , 1 , top = 0.98 , bottom = 0.95 , hspace = 0.5 , wspace = 0.5 , figure = fig ) # Loop to plot the second set of 3 modes for m in range ( 3 , 6 ): # Plot SPOD spatial mode as an image row = m - 3 col = m % 3 ax_img = plt . subplot ( gs1 [ 5 , col ]) ax_img . set_title ( f 'SPOD Mode ($P_ { m + 1 + mode_shift } $)' ) img = ax_img . imshow ( np . flipud ( SPOD_spatial_modes [ m + mode_shift ,:,:]), cmap = 'jet' , vmax = vmax , vmin =- vmax ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) # Plot temporal coefficients ax_line = plt . subplot ( gs1 [ 6 , col ]) ax_line . plot ( time , SPOD_temporal_coefficients [:, m + mode_shift ], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 + mode_shift } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 3 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . grid ( False ) # Add grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) # Plot power spectrum of the temporal coefficients - using Welch's method ax_welch = plt . subplot ( gs1 [ 8 , col ]) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ] for freq in pre_defined_freq : rounded_freq = freq ax_welch . axvline ( x = freq , color = 'r' , linestyle = '--' , linewidth = 1.1 ) f , px = welch ( SPOD_temporal_coefficients [:, m + mode_shift ] - np . mean ( SPOD_temporal_coefficients [:, m + mode_shift ]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 + mode_shift } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 3 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . grid ( False ) # Add grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) # Set major ticks every 50 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 50 ), minor = True ) # Set tick labels every 100 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 200 ), minor = False ) ax_welch . set_xticklabels ( np . arange ( 0 , 1001 , 200 )) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Save the figure as a PDF pdf_path = 'Figures/FIGS8_SPOD.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FIGS8_SPOD.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 # Create a set of images for the frequency-filtered POD reconstruction at all time steps # To be used in the Supplementary Video 4 from matplotlib.ticker import FuncFormatter from matplotlib.transforms import Bbox from mpl_toolkits.axes_grid1 import make_axes_locatable t = np . arange ( 0 , 100 , 0.5 ) # Time array for temporal coefficient plots for mode_shift in range ( 200 ): # Loop through each mode shift (0 to 199) # Setting global plot parameters plt . rcParams . update ({ 'font.size' : 14 , # Default font size for all text 'axes.titlesize' : 15 , # Font size for axis titles 'axes.labelsize' : 15 , # Font size for axis labels 'xtick.labelsize' : 12 , # Font size for x-axis tick labels 'ytick.labelsize' : 12 , # Font size for y-axis tick labels 'legend.fontsize' : 14 , # Font size for legend text 'figure.titlesize' : 16 , # Font size for the overall figure title 'axes.grid' : False , # Disable gridlines on plots 'grid.alpha' : 0.5 , # Set transparency of gridlines 'grid.linestyle' : '--' , # Dashed style for gridlines }) fig = plt . figure ( figsize = ( 8 , 10 )) # Create a figure with dimensions (width=8, height=10) inches # Create a 4-row, 1-column grid layout using GridSpec gs1 = gridspec . GridSpec ( 4 , 1 , height_ratios = [ 1 , 0.5 , - 0.04 , 0.5 ], figure = fig , hspace = 0.5 , wspace = 0.3 ) # Plot SPOD spatial mode as an image m = 0 # First mode to plot ax_img = plt . subplot ( gs1 [ 0 ]) # Create the first subplot ax_img . set_title ( f 'SPOD Mode ($P_ {{ { m + 1 + mode_shift } }} $)' ) # Title for the spatial mode vmax = np . abs ( SPOD_spatial_modes [ m + mode_shift , :, :]) . max () # Get maximum value for color normalization img = ax_img . imshow ( np . flipud ( SPOD_spatial_modes [ m + mode_shift , :, :]), cmap = 'jet' , vmax = vmax , vmin =- vmax ) # Display the image divider = make_axes_locatable ( ax_img ) cax = divider . append_axes ( \"left\" , size = \"5%\" , pad = 0.1 ) # Create space for the colorbar colorbar = plt . colorbar ( img , cax = cax ) # Add colorbar colorbar . outline . set_linewidth ( 1.5 ) # Set colorbar border width cax . yaxis . set_ticks_position ( 'left' ) # Set colorbar ticks on the left cax . yaxis . set_label_position ( 'left' ) # Set colorbar label on the left ax_img . set_xticks ([]) # Remove x-axis ticks ax_img . set_yticks ([]) # Remove y-axis ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) # Set the border thickness of the plot # Adjust position of the temporal coefficient plot ax_img_position = ax_img . get_position () ax_line_position = Bbox . from_bounds ( ax_img_position . x0 , gs1 [ 1 ] . get_position ( fig ) . y0 , ax_img_position . width , gs1 [ 1 ] . get_position ( fig ) . height ) ax_line = fig . add_axes ( ax_line_position ) # Create a new axis at the desired position ax_line . plot ( time , SPOD_temporal_coefficients [:, m + mode_shift ], 'k' ) # Plot temporal coefficient ax_line . set_title ( f 'Temporal Coefficient ($A_ {{ { m + 1 + mode_shift } }} $)' ) # Title for temporal coefficient ax_line . set_xlabel ( 'Time (s)' ) # X-axis label if m == 0 : ax_line . set_ylabel ( 'Amplitude' ) # Y-axis label for first mode ax_line . yaxis . set_label_coords ( - 0.15 , 0.5 ) # Position y-axis label ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Minor ticks for x-axis ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Minor ticks for y-axis ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) # Major tick formatting ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) # Minor tick formatting ax_line . set_xlim ( 0 , 100 ) # Set x-axis range for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) # Set the border thickness of the plot # Adjust position of the power spectrum plot ax_welch_position = Bbox . from_bounds ( ax_img_position . x0 , gs1 [ 3 ] . get_position ( fig ) . y0 , ax_img_position . width , gs1 [ 3 ] . get_position ( fig ) . height ) ax_welch = fig . add_axes ( ax_welch_position ) # Create a new axis at the desired position for freq in [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ]: # Pre-defined frequencies ax_welch . axvline ( x = freq , color = 'r' , linestyle = '--' , linewidth = 1.1 ) # Add vertical frequency lines f , px = welch ( SPOD_temporal_coefficients [:, m + mode_shift ] - np . mean ( SPOD_temporal_coefficients [:, m + mode_shift ]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) # Compute Welch power spectrum ax_welch . plot ( f * 1000 , px , color = 'navy' , linewidth = 2 ) # Plot power spectrum ax_welch . set_title ( f 'Power Spectrum ($A_ {{ { m + 1 + mode_shift } }} $)' ) # Title for power spectrum ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X-axis label if m == 0 : ax_welch . set_ylabel ( 'Power' ) # Y-axis label for first mode ax_welch . yaxis . set_label_coords ( - 0.15 , 0.5 ) # Position y-axis label # Dynamically format y-axis to display simplified numbers and scientific notation def format_func ( value , tick_number ): exponent = np . floor ( np . log10 ( np . max ( px ))) # Calculate exponent return f ' { value / 10 ** exponent : .1f } ' ax_welch . yaxis . set_major_formatter ( FuncFormatter ( format_func )) # Format y-axis labels ax_welch . yaxis . offsetText . set_visible ( False ) # Hide the default exponent text # Add the exponent value as a label exponent = np . floor ( np . log10 ( np . max ( px ))) fig . text ( ax_welch_position . x0 - 0.04 , ax_welch_position . y1 + 0.013 , f 'x1e { int ( exponent ) } ' , ha = 'center' , va = 'bottom' , fontsize = 14 ) # Set major and minor ticks on x-axis ax_welch . set_xticks ( np . arange ( 0 , 1001 , 50 ), minor = True ) # Minor ticks every 50 ax_welch . set_xticks ( np . arange ( 0 , 1001 , 100 )) # Major ticks every 100 ax_welch . set_xticklabels ( np . arange ( 0 , 1001 , 100 )) # Set tick labels for major ticks ax_welch . set_xlim ( 0 , 1000 ) # Set x-axis range ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) # Set the border thickness of the plot # Save the plot as an image file plt . savefig ( f 'Video_Snapshots/SPOD_images__video_S4/im_ { mode_shift : 03d } .jpg' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0.2 ) plt . close () # Close the figure to free up memory print ( \"Images saved successfully.\" ) # Print message when all images are saved Images saved successfully.", "title": "SPOD analysis"}, {"location": "python/spod-example/#worked-example-nrmp-spectral-proper-orthogonal-decomposition-spod-analysis", "text": "This example demonstrates the application of Spectral Proper Orthogonal Decomposition (SPOD) to a synthetic spatio-temporal dataset. SPOD is an extension of the traditional Proper Orthogonal Decomposition (POD) method that incorporates frequency filtering to isolate specific modes associated with particular frequencies. This allows for a more refined analysis of the dominant spatial patterns and their temporal evolution, particularly in complex datasets with multiple superimposed oscillations. Analysis and Figure The figure below shows the results of applying SPOD to the synthetic spatio-temporal dataset. Methods used: Spectral Proper Orthogonal Decomposition (SPOD) Welch's method (to analyze the frequency content of the temporal coefficients) WaLSAtools version: 1.0 These particular analyses generate the figure below (Supplementary Figure S8 in Nature Reviews Methods Primers ; copyrighted). For a full description of the datasets and the analyses performed, see the associated article. See the source code at the bottom of this page (or here on Github) for a complete analyses and the plotting routines used to generate this figure. Figure Caption: SPOD analysis. Spatial modes (130\u00d7130 pixels 2 each), temporal coefficients, and Welch power spectra of the first six SPOD modes. The SPOD analysis was performed with a Gaussian filter kernel, illustrating the frequency pairing phenomenon, where each frequency is associated with two distinct spatial modes with corresponding temporal coefficients. The shared frequency content is evident in the Welch power spectra. The ten base frequencies are marked with vertical dashed lines. Source code \u00a9 2025 WaLSA Team - Shahin Jafarzadeh et al. This notebook is part of the WaLSAtools package (v1.0), provided under the Apache License, Version 2.0 . You may use, modify, and distribute this notebook and its contents under the terms of the license. Important Note on Figures : Figures generated using this notebook that are identical to or derivative of those published in : Jafarzadeh, S., Jess, D. B., Stangalini, M. et al. 2025, Nature Reviews Methods Primers, in press , are copyrighted by Nature Reviews Methods Primers . Any reuse of such figures requires explicit permission from the journal. Figures that are newly created, modified, or unrelated to the published article may be used under the terms of the Apache License. Disclaimer : This notebook and its code are provided \"as is\", without warranty of any kind, express or implied. Refer to the license for more details. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import numpy as np from astropy.io import fits from WaLSAtools import WaLSAtools , WaLSA_save_pdf # Load FITS data data_dir = 'Synthetic_Data/' hdul = fits . open ( data_dir + 'NRMP_signal_3D.fits' ) signal_3d = hdul [ 0 ] . data # 3D synthetic data time = hdul [ 1 ] . data # Time array, saved in the second HDU (Extension HDU 1) hdul . close () # Computed POD modes using WaLSAtools pod_results = WaLSAtools ( signal = signal_3d , time = time , method = 'pod' , spod = True ) Starting POD analysis .... Processing a 3D cube with shape (200, 130, 130). Starting SPOD analysis .... SPOD analysis completed. POD analysis completed. Top 10 frequencies and normalized power values: [[0.1, 1.0], [0.15, 0.71], [0.25, 0.61], [0.2, 0.54], [0.3, 0.47], [0.5, 0.4], [0.35, 0.33], [0.4, 0.26], [0.45, 0.25], [0.55, 0.19]] Total variance contribution of the first 200 modes: 100.00% ---- POD/SPOD Results Summary ---- input_data (ndarray, Shape: (200, 130, 130)): Original input data, mean subtracted (Shape: (Nt, Ny, Nx)) spatial_mode (ndarray, Shape: (200, 130, 130)): Reshaped spatial modes matching the dimensions of the input data (Shape: (Nmodes, Ny, Nx)) temporal_coefficient (ndarray, Shape: (200, 200)): Temporal coefficients associated with each spatial mode (Shape: (Nmodes, Nt)) eigenvalue (ndarray, Shape: (200,)): Eigenvalues corresponding to singular values squared (Shape: (Nmodes)) eigenvalue_contribution (ndarray, Shape: (200,)): Eigenvalue contribution of each mode (Shape: (Nmodes)) cumulative_eigenvalues (list, Shape: (10,)): Cumulative percentage of eigenvalues for the first \"num_cumulative_modes\" modes (Shape: (num_cumulative_modes)) combined_welch_psd (ndarray, Shape: (8193,)): Combined Welch power spectral density for the temporal coefficients of the firts \"num_modes\" modes (Shape: (Nf)) frequencies (ndarray, Shape: (8193,)): Frequencies identified in the Welch spectrum (Shape: (Nf)) combined_welch_significance (ndarray, Shape: (8193,)): Significance threshold of the combined Welch spectrum (Shape: (Nf,)) reconstructed (ndarray, Shape: (130, 130)): Reconstructed frame at the specified timestep using the top \"num_modes\" modes (Shape: (Ny, Nx)) sorted_frequencies (ndarray, Shape: (21,)): Frequencies identified in the Welch combined power spectrum (Shape: (Nfrequencies)) frequency_filtered_modes (ndarray, Shape: (200, 130, 130, 10)): Frequency-filtered spatial POD modes for the first \"num_top_frequencies\" frequencies (Shape: (Nt, Ny, Nx, num_top_frequencies)) frequency_filtered_modes_frequencies (ndarray, Shape: (10,)): Frequencies corresponding to the frequency-filtered modes (Shape: (num_top_frequencies)) SPOD_spatial_modes (ndarray, Shape: (200, 130, 130)): SPOD spatial modes if SPOD is used (Shape: (Nspod_modes, Ny, Nx)) SPOD_temporal_coefficients (ndarray, Shape: (200, 200)): SPOD temporal coefficients if SPOD is used (Shape: (Nspod_modes, Nt)) p (ndarray, Shape: (16900, 200)): Left singular vectors (spatial modes) from SVD (Shape: (Nx, Nmodes)) s (ndarray, Shape: (200,)): Singular values from SVD (Shape: (Nmodes)) a (ndarray, Shape: (200, 200)): Right singular vectors (temporal coefficients) from SVD (Shape: (Nmodes, Nt)) 1 2 SPOD_spatial_modes = pod_results [ 'SPOD_spatial_modes' ] SPOD_temporal_coefficients = pod_results [ 'SPOD_temporal_coefficients' ] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 import numpy as np import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from matplotlib.ticker import AutoMinorLocator from scipy.signal import welch # Setting global parameters for plot appearance plt . rcParams . update ({ 'font.size' : 14 , # Global font size 'axes.titlesize' : 18 , # Title font size 'axes.labelsize' : 16 , # Axis label font size 'xtick.labelsize' : 12 , # X-axis tick label font size 'ytick.labelsize' : 12 , # Y-axis tick label font size 'legend.fontsize' : 14 , # Legend font size 'figure.titlesize' : 20 , # Figure title font size 'axes.grid' : False , # Turn on grid by default 'grid.alpha' : 0.5 , # Grid transparency 'grid.linestyle' : '--' , # Grid line style }) mode_shift = 0 # Offset for mode indices # Create a figure with specific dimensions fig = plt . figure ( figsize = ( 15 , 19 )) # Create a grid layout for subplots gs1 = gridspec . GridSpec ( 9 , 3 , height_ratios = [ 1 , 0.5 , - 0.04 , 0.5 , 0.2 , 1 , 0.5 , - 0.04 , 0.5 ], figure = fig , hspace = 0.5 , wspace = 0.3 ) # Loop to plot the first set of 3 modes for m in range ( 3 ): # Plot SPOD spatial mode as an image ax_img = plt . subplot ( gs1 [ 0 , m ]) ax_img . set_title ( f 'SPOD Mode ($P_ { m + 1 + mode_shift } $)' ) vmax = ( np . abs ( SPOD_spatial_modes [ m + mode_shift ,:,:]) . max ()) img = ax_img . imshow ( np . flipud ( SPOD_spatial_modes [ m + mode_shift ,:,:]), cmap = 'jet' , vmax = vmax , vmin =- vmax ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) # Plot temporal coefficients ax_line = plt . subplot ( gs1 [ 1 , m ]) ax_line . plot ( time , SPOD_temporal_coefficients [:, m + mode_shift ], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 + mode_shift } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 0 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . grid ( False ) # Add grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) # Plot power spectrum of the temporal coefficients - using Welch's method ax_welch = plt . subplot ( gs1 [ 3 , m ]) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ] for freq in pre_defined_freq : rounded_freq = freq ax_welch . axvline ( x = freq , color = 'r' , linestyle = '--' , linewidth = 1.1 ) f , px = welch ( SPOD_temporal_coefficients [:, m + mode_shift ] - np . mean ( SPOD_temporal_coefficients [:, m + mode_shift ]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 + mode_shift } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 0 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . grid ( False ) # Add grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) # Set major ticks every 50 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 50 ), minor = True ) # Set tick labels every 100 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 200 ), minor = False ) ax_welch . set_xticklabels ( np . arange ( 0 , 1001 , 200 )) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Create space between two sets of 3 modes gs_space = gridspec . GridSpec ( 1 , 1 , top = 0.98 , bottom = 0.95 , hspace = 0.5 , wspace = 0.5 , figure = fig ) # Loop to plot the second set of 3 modes for m in range ( 3 , 6 ): # Plot SPOD spatial mode as an image row = m - 3 col = m % 3 ax_img = plt . subplot ( gs1 [ 5 , col ]) ax_img . set_title ( f 'SPOD Mode ($P_ { m + 1 + mode_shift } $)' ) img = ax_img . imshow ( np . flipud ( SPOD_spatial_modes [ m + mode_shift ,:,:]), cmap = 'jet' , vmax = vmax , vmin =- vmax ) colorbar = plt . colorbar ( img , ax = ax_img , orientation = 'vertical' , shrink = 1.0 ) colorbar . outline . set_linewidth ( 1.5 ) ax_img . set_xticks ([]) # Remove x ticks ax_img . set_yticks ([]) # Remove y ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) # Plot temporal coefficients ax_line = plt . subplot ( gs1 [ 6 , col ]) ax_line . plot ( time , SPOD_temporal_coefficients [:, m + mode_shift ], 'k' ) ax_line . set_title ( f 'Temporal Coefficient ($A_ { m + 1 + mode_shift } $)' ) ax_line . set_xlabel ( 'Time (s)' ) # X label if m == 3 : ax_line . set_ylabel ( 'Amplitude' ) # Y label ax_line . grid ( False ) # Add grid ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_line . tick_params ( axis = 'both' , labelsize = 14 ) for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) ax_line . set_xlim ( 0 , 100 ) # Plot power spectrum of the temporal coefficients - using Welch's method ax_welch = plt . subplot ( gs1 [ 8 , col ]) # Mark pre-defined frequencies with vertical lines pre_defined_freq = [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ] for freq in pre_defined_freq : rounded_freq = freq ax_welch . axvline ( x = freq , color = 'r' , linestyle = '--' , linewidth = 1.1 ) f , px = welch ( SPOD_temporal_coefficients [:, m + mode_shift ] - np . mean ( SPOD_temporal_coefficients [:, m + mode_shift ]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) ax_welch . plot ( f * 1000. , px , 'k' ) ax_welch . set_title ( f 'Power Spectrum ($A_ { m + 1 + mode_shift } $)' ) ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X label if m == 3 : ax_welch . set_ylabel ( 'Power' ) # Y label ax_welch . grid ( False ) # Add grid ax_welch . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , labelsize = 14 ) # Set major ticks every 50 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 50 ), minor = True ) # Set tick labels every 100 units ax_welch . set_xticks ( np . arange ( 0 , 1001 , 200 ), minor = False ) ax_welch . set_xticklabels ( np . arange ( 0 , 1001 , 200 )) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) ax_welch . set_xlim ( 0 , 1000 ) # Save the figure as a PDF pdf_path = 'Figures/FIGS8_SPOD.pdf' WaLSA_save_pdf ( fig , pdf_path , color_mode = 'CMYK' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0 ) plt . show () GPL Ghostscript 10.04.0 (2024-09-18) Copyright (C) 2024 Artifex Software, Inc. All rights reserved. This software is supplied under the GNU AGPLv3 and comes with NO WARRANTY: see the file COPYING for details. Processing pages 1 through 1. Page 1 PDF saved in CMYK format as 'Figures/FIGS8_SPOD.pdf' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 # Create a set of images for the frequency-filtered POD reconstruction at all time steps # To be used in the Supplementary Video 4 from matplotlib.ticker import FuncFormatter from matplotlib.transforms import Bbox from mpl_toolkits.axes_grid1 import make_axes_locatable t = np . arange ( 0 , 100 , 0.5 ) # Time array for temporal coefficient plots for mode_shift in range ( 200 ): # Loop through each mode shift (0 to 199) # Setting global plot parameters plt . rcParams . update ({ 'font.size' : 14 , # Default font size for all text 'axes.titlesize' : 15 , # Font size for axis titles 'axes.labelsize' : 15 , # Font size for axis labels 'xtick.labelsize' : 12 , # Font size for x-axis tick labels 'ytick.labelsize' : 12 , # Font size for y-axis tick labels 'legend.fontsize' : 14 , # Font size for legend text 'figure.titlesize' : 16 , # Font size for the overall figure title 'axes.grid' : False , # Disable gridlines on plots 'grid.alpha' : 0.5 , # Set transparency of gridlines 'grid.linestyle' : '--' , # Dashed style for gridlines }) fig = plt . figure ( figsize = ( 8 , 10 )) # Create a figure with dimensions (width=8, height=10) inches # Create a 4-row, 1-column grid layout using GridSpec gs1 = gridspec . GridSpec ( 4 , 1 , height_ratios = [ 1 , 0.5 , - 0.04 , 0.5 ], figure = fig , hspace = 0.5 , wspace = 0.3 ) # Plot SPOD spatial mode as an image m = 0 # First mode to plot ax_img = plt . subplot ( gs1 [ 0 ]) # Create the first subplot ax_img . set_title ( f 'SPOD Mode ($P_ {{ { m + 1 + mode_shift } }} $)' ) # Title for the spatial mode vmax = np . abs ( SPOD_spatial_modes [ m + mode_shift , :, :]) . max () # Get maximum value for color normalization img = ax_img . imshow ( np . flipud ( SPOD_spatial_modes [ m + mode_shift , :, :]), cmap = 'jet' , vmax = vmax , vmin =- vmax ) # Display the image divider = make_axes_locatable ( ax_img ) cax = divider . append_axes ( \"left\" , size = \"5%\" , pad = 0.1 ) # Create space for the colorbar colorbar = plt . colorbar ( img , cax = cax ) # Add colorbar colorbar . outline . set_linewidth ( 1.5 ) # Set colorbar border width cax . yaxis . set_ticks_position ( 'left' ) # Set colorbar ticks on the left cax . yaxis . set_label_position ( 'left' ) # Set colorbar label on the left ax_img . set_xticks ([]) # Remove x-axis ticks ax_img . set_yticks ([]) # Remove y-axis ticks for spine in ax_img . spines . values (): spine . set_linewidth ( 1.5 ) # Set the border thickness of the plot # Adjust position of the temporal coefficient plot ax_img_position = ax_img . get_position () ax_line_position = Bbox . from_bounds ( ax_img_position . x0 , gs1 [ 1 ] . get_position ( fig ) . y0 , ax_img_position . width , gs1 [ 1 ] . get_position ( fig ) . height ) ax_line = fig . add_axes ( ax_line_position ) # Create a new axis at the desired position ax_line . plot ( time , SPOD_temporal_coefficients [:, m + mode_shift ], 'k' ) # Plot temporal coefficient ax_line . set_title ( f 'Temporal Coefficient ($A_ {{ { m + 1 + mode_shift } }} $)' ) # Title for temporal coefficient ax_line . set_xlabel ( 'Time (s)' ) # X-axis label if m == 0 : ax_line . set_ylabel ( 'Amplitude' ) # Y-axis label for first mode ax_line . yaxis . set_label_coords ( - 0.15 , 0.5 ) # Position y-axis label ax_line . xaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Minor ticks for x-axis ax_line . yaxis . set_minor_locator ( AutoMinorLocator ( 5 )) # Minor ticks for y-axis ax_line . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) # Major tick formatting ax_line . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) # Minor tick formatting ax_line . set_xlim ( 0 , 100 ) # Set x-axis range for spine in ax_line . spines . values (): spine . set_linewidth ( 1.5 ) # Set the border thickness of the plot # Adjust position of the power spectrum plot ax_welch_position = Bbox . from_bounds ( ax_img_position . x0 , gs1 [ 3 ] . get_position ( fig ) . y0 , ax_img_position . width , gs1 [ 3 ] . get_position ( fig ) . height ) ax_welch = fig . add_axes ( ax_welch_position ) # Create a new axis at the desired position for freq in [ 100 , 150 , 200 , 250 , 300 , 350 , 400 , 450 , 500 , 550 ]: # Pre-defined frequencies ax_welch . axvline ( x = freq , color = 'r' , linestyle = '--' , linewidth = 1.1 ) # Add vertical frequency lines f , px = welch ( SPOD_temporal_coefficients [:, m + mode_shift ] - np . mean ( SPOD_temporal_coefficients [:, m + mode_shift ]), nperseg = 150 , noverlap = 25 , nfft = 2 ** 14 , fs = 2 ) # Compute Welch power spectrum ax_welch . plot ( f * 1000 , px , color = 'navy' , linewidth = 2 ) # Plot power spectrum ax_welch . set_title ( f 'Power Spectrum ($A_ {{ { m + 1 + mode_shift } }} $)' ) # Title for power spectrum ax_welch . set_xlabel ( 'Frequency (mHz)' ) # X-axis label if m == 0 : ax_welch . set_ylabel ( 'Power' ) # Y-axis label for first mode ax_welch . yaxis . set_label_coords ( - 0.15 , 0.5 ) # Position y-axis label # Dynamically format y-axis to display simplified numbers and scientific notation def format_func ( value , tick_number ): exponent = np . floor ( np . log10 ( np . max ( px ))) # Calculate exponent return f ' { value / 10 ** exponent : .1f } ' ax_welch . yaxis . set_major_formatter ( FuncFormatter ( format_func )) # Format y-axis labels ax_welch . yaxis . offsetText . set_visible ( False ) # Hide the default exponent text # Add the exponent value as a label exponent = np . floor ( np . log10 ( np . max ( px ))) fig . text ( ax_welch_position . x0 - 0.04 , ax_welch_position . y1 + 0.013 , f 'x1e { int ( exponent ) } ' , ha = 'center' , va = 'bottom' , fontsize = 14 ) # Set major and minor ticks on x-axis ax_welch . set_xticks ( np . arange ( 0 , 1001 , 50 ), minor = True ) # Minor ticks every 50 ax_welch . set_xticks ( np . arange ( 0 , 1001 , 100 )) # Major ticks every 100 ax_welch . set_xticklabels ( np . arange ( 0 , 1001 , 100 )) # Set tick labels for major ticks ax_welch . set_xlim ( 0 , 1000 ) # Set x-axis range ax_welch . tick_params ( axis = 'both' , which = 'major' , direction = 'out' , length = 8 , width = 1.5 ) ax_welch . tick_params ( axis = 'both' , which = 'minor' , direction = 'out' , length = 4 , width = 1.5 ) for spine in ax_welch . spines . values (): spine . set_linewidth ( 1.5 ) # Set the border thickness of the plot # Save the plot as an image file plt . savefig ( f 'Video_Snapshots/SPOD_images__video_S4/im_ { mode_shift : 03d } .jpg' , dpi = 300 , bbox_inches = 'tight' , pad_inches = 0.2 ) plt . close () # Close the figure to free up memory print ( \"Images saved successfully.\" ) # Print message when all images are saved Images saved successfully.", "title": "Worked Example - NRMP: Spectral Proper Orthogonal Decomposition (SPOD) Analysis"}, {"location": "python/troubleshooting/", "text": "Troubleshooting \u00b6 This page provides detailed solutions to common issues encountered during the installation and usage of WaLSAtools . If you experience a problem not listed here, we recommend: First, carefully reviewing the Beginner-Friendly Guide and this Troubleshooting page. If the issue remains unresolved, posting your question in our GitHub Discussions area. If the problem appears to be a confirmed bug, submitting a GitHub Issue (see the Contribution guideline for details). New here? Many installation and setup problems are already covered step-by-step in the Beginner-Friendly Guide . We highly recommend checking it if you haven't already. Installation Issues \u00b6 1. pip install WaLSAtools fails \u00b6 Possible reasons and solutions: Outdated pip : Upgrade pip to the latest version: pip install --upgrade pip Python version mismatch : Ensure you are using Python 3.8 or later (preferably 3.12.8 as recommended). Some dependencies require newer Python versions. Virtual environment not used : To avoid conflicts (especially with libraries like NumPy 2.0+ ), we strongly recommend creating a clean virtual environment . Conda Users If you are using Anaconda or Miniconda , be aware that some pre-installed packages (like numpy, scipy, matplotlib) may not match the latest stable versions or may be compiled differently, leading to compatibility problems. Solution: Create a fresh Conda environment without preinstalled packages, or Prefer a clean virtual environment created with pyenv or venv when working with WaLSAtools . Always manually upgrade critical packages like pip , setuptools , and wheel after creating a new environment. Firewall or proxy blocking installation : If you are behind a firewall or corporate proxy, configure pip accordingly: pip install WaLSAtools --proxy = \"your_proxy_address\" Temporary server issue : If installation fails from PyPI, wait a few minutes and try again. 2. Problems related to NumPy or compiled dependencies \u00b6 Specific Issue: Some users reported installation failures due to NumPy ABI (Application Binary Interface) conflicts, especially when using NumPy 2.0.0+ . See the GitHub Discussion here for more details. Solution: If you encounter NumPy-related errors: Ensure you are installing inside a fresh virtual environment . Manually install a compatible NumPy version: pip install \"numpy<2.0\" Then reinstall WaLSAtools: pip install WaLSAtools Important Avoid using pre-installed system Python or OS-level packages (e.g., /usr/bin/python3 ) for WaLSAtools. Always prefer user-managed virtual environments. 3. Installation from source fails \u00b6 Checklist: Clone the repository properly : git clone https://github.com/WaLSAteam/WaLSAtools.git cd WaLSAtools/codes/python Install using pip inside the directory : pip install . Ensure build tools are installed : macOS: Install Xcode and command-line tools: xcode-select --install Linux: Install build essentials: sudo apt install build-essential Windows: Use pre-built binaries and ensure pip is up to date. Permission errors : Never use sudo pip install . Always use virtual environments to avoid permission problems. Usage Issues \u00b6 1. WaLSAtools interactive interface does not launch \u00b6 Solutions: Confirm environment activation : Ensure you are working inside the environment where WaLSAtools was installed. Correct import syntax : Start a Python session and enter: from WaLSAtools import WaLSAtools WaLSAtools Notebook environment issue : Inside a Jupyter notebook, make sure you select the correct Python kernel linked to your WaLSAtools environment. Conflicting libraries : Conflicts with old versions of packages like matplotlib , scipy , or numpy can prevent proper functioning. Use a clean environment. 2. Problems related to data input or unit handling \u00b6 Specific Issue: One user reported crashes when passing data arrays with attached units (e.g., astropy Quantity arrays for time or signal). See the specific issue and solution here for more details. Solution: WaLSAtools expects raw numpy.ndarray inputs without units. Remove units before passing: data = data_with_units . value If using astropy.Time objects for time axes, convert them to seconds manually. Future Improvements Support for native Quantity and Time inputs is planned for a future WaLSAtools release. 3. WaLSAtools behaves differently across environments \u00b6 Different behavior (e.g., function outputs, warnings) can occur due to: Different dependency versions (e.g., numpy , scipy , matplotlib ). Mixed installations (system vs. virtual environment). Solution: Check installed versions and compare them with those listed in requirements.txt under WaLSAtools/codes/python : import astropy import IPython import ipywidgets import matplotlib import numba import numpy import pyfftw import scipy import setuptools import skimage import tqdm modules = { 'astropy' : astropy , 'ipython' : IPython , 'ipywidgets' : ipywidgets , 'matplotlib' : matplotlib , 'numba' : numba , 'numpy' : numpy , 'pyFFTW' : pyfftw , 'scipy' : scipy , 'setuptools' : setuptools , 'scikit-image' : skimage , 'tqdm' : tqdm } for name , module in modules . items (): print ( f \" { name } : { module . __version__ } \" ) Always install WaLSAtools inside a fresh environment with the recommended package versions (that is done automatically when installing WaLSAtools). Additional Resources \u00b6 Beginner-Friendly Guide Installation Guide Contribution Guidelines GitHub Discussions Still stuck? If the solutions above don't work, search GitHub Issues or Discussions. If your issue is not already reported, feel free to post a new discussion or bug report! Final Notes \u00b6 Always read error messages carefully \u2014 they usually point directly to the problem. Keep your pip , setuptools , and wheel packages updated. Prefer working inside clean virtual environments. If you fix an issue not yet listed here, please consider contributing to this page!", "title": "Troubleshooting"}, {"location": "python/troubleshooting/#troubleshooting", "text": "This page provides detailed solutions to common issues encountered during the installation and usage of WaLSAtools . If you experience a problem not listed here, we recommend: First, carefully reviewing the Beginner-Friendly Guide and this Troubleshooting page. If the issue remains unresolved, posting your question in our GitHub Discussions area. If the problem appears to be a confirmed bug, submitting a GitHub Issue (see the Contribution guideline for details). New here? Many installation and setup problems are already covered step-by-step in the Beginner-Friendly Guide . We highly recommend checking it if you haven't already.", "title": "Troubleshooting"}, {"location": "python/troubleshooting/#installation-issues", "text": "", "title": "Installation Issues"}, {"location": "python/troubleshooting/#1-pip-install-walsatools-fails", "text": "Possible reasons and solutions: Outdated pip : Upgrade pip to the latest version: pip install --upgrade pip Python version mismatch : Ensure you are using Python 3.8 or later (preferably 3.12.8 as recommended). Some dependencies require newer Python versions. Virtual environment not used : To avoid conflicts (especially with libraries like NumPy 2.0+ ), we strongly recommend creating a clean virtual environment . Conda Users If you are using Anaconda or Miniconda , be aware that some pre-installed packages (like numpy, scipy, matplotlib) may not match the latest stable versions or may be compiled differently, leading to compatibility problems. Solution: Create a fresh Conda environment without preinstalled packages, or Prefer a clean virtual environment created with pyenv or venv when working with WaLSAtools . Always manually upgrade critical packages like pip , setuptools , and wheel after creating a new environment. Firewall or proxy blocking installation : If you are behind a firewall or corporate proxy, configure pip accordingly: pip install WaLSAtools --proxy = \"your_proxy_address\" Temporary server issue : If installation fails from PyPI, wait a few minutes and try again.", "title": "1. pip install WaLSAtools fails"}, {"location": "python/troubleshooting/#2-problems-related-to-numpy-or-compiled-dependencies", "text": "Specific Issue: Some users reported installation failures due to NumPy ABI (Application Binary Interface) conflicts, especially when using NumPy 2.0.0+ . See the GitHub Discussion here for more details. Solution: If you encounter NumPy-related errors: Ensure you are installing inside a fresh virtual environment . Manually install a compatible NumPy version: pip install \"numpy<2.0\" Then reinstall WaLSAtools: pip install WaLSAtools Important Avoid using pre-installed system Python or OS-level packages (e.g., /usr/bin/python3 ) for WaLSAtools. Always prefer user-managed virtual environments.", "title": "2. Problems related to NumPy or compiled dependencies"}, {"location": "python/troubleshooting/#3-installation-from-source-fails", "text": "Checklist: Clone the repository properly : git clone https://github.com/WaLSAteam/WaLSAtools.git cd WaLSAtools/codes/python Install using pip inside the directory : pip install . Ensure build tools are installed : macOS: Install Xcode and command-line tools: xcode-select --install Linux: Install build essentials: sudo apt install build-essential Windows: Use pre-built binaries and ensure pip is up to date. Permission errors : Never use sudo pip install . Always use virtual environments to avoid permission problems.", "title": "3. Installation from source fails"}, {"location": "python/troubleshooting/#usage-issues", "text": "", "title": "Usage Issues"}, {"location": "python/troubleshooting/#1-walsatools-interactive-interface-does-not-launch", "text": "Solutions: Confirm environment activation : Ensure you are working inside the environment where WaLSAtools was installed. Correct import syntax : Start a Python session and enter: from WaLSAtools import WaLSAtools WaLSAtools Notebook environment issue : Inside a Jupyter notebook, make sure you select the correct Python kernel linked to your WaLSAtools environment. Conflicting libraries : Conflicts with old versions of packages like matplotlib , scipy , or numpy can prevent proper functioning. Use a clean environment.", "title": "1. WaLSAtools interactive interface does not launch"}, {"location": "python/troubleshooting/#2-problems-related-to-data-input-or-unit-handling", "text": "Specific Issue: One user reported crashes when passing data arrays with attached units (e.g., astropy Quantity arrays for time or signal). See the specific issue and solution here for more details. Solution: WaLSAtools expects raw numpy.ndarray inputs without units. Remove units before passing: data = data_with_units . value If using astropy.Time objects for time axes, convert them to seconds manually. Future Improvements Support for native Quantity and Time inputs is planned for a future WaLSAtools release.", "title": "2. Problems related to data input or unit handling"}, {"location": "python/troubleshooting/#3-walsatools-behaves-differently-across-environments", "text": "Different behavior (e.g., function outputs, warnings) can occur due to: Different dependency versions (e.g., numpy , scipy , matplotlib ). Mixed installations (system vs. virtual environment). Solution: Check installed versions and compare them with those listed in requirements.txt under WaLSAtools/codes/python : import astropy import IPython import ipywidgets import matplotlib import numba import numpy import pyfftw import scipy import setuptools import skimage import tqdm modules = { 'astropy' : astropy , 'ipython' : IPython , 'ipywidgets' : ipywidgets , 'matplotlib' : matplotlib , 'numba' : numba , 'numpy' : numpy , 'pyFFTW' : pyfftw , 'scipy' : scipy , 'setuptools' : setuptools , 'scikit-image' : skimage , 'tqdm' : tqdm } for name , module in modules . items (): print ( f \" { name } : { module . __version__ } \" ) Always install WaLSAtools inside a fresh environment with the recommended package versions (that is done automatically when installing WaLSAtools).", "title": "3. WaLSAtools behaves differently across environments"}, {"location": "python/troubleshooting/#additional-resources", "text": "Beginner-Friendly Guide Installation Guide Contribution Guidelines GitHub Discussions Still stuck? If the solutions above don't work, search GitHub Issues or Discussions. If your issue is not already reported, feel free to post a new discussion or bug report!", "title": "Additional Resources"}, {"location": "python/troubleshooting/#final-notes", "text": "Always read error messages carefully \u2014 they usually point directly to the problem. Keep your pip , setuptools , and wheel packages updated. Prefer working inside clean virtual environments. If you fix an issue not yet listed here, please consider contributing to this page!", "title": "Final Notes"}, {"location": "releases/v1.0.0/", "text": "WaLSAtools v1.0.0 \u2013 Initial Release \u00b6 Release Notes \u00b6 We are excited to introduce WaLSAtools , an evolving open-source library for wave analysis that provides a solid foundation for comprehensive time-series exploration. This initial release equips users with essential tools for analysing a wide range of wave phenomena in time-series data, including: Core Analysis Modules: Fast Fourier Transform (FFT) Lomb-Scargle Approach Wavelet Transform Empirical Mode Decomposition (EMD) Hilbert-Huang Transform (HHT) Welch's Method k-\u03c9 Analysis Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis Interactive Interface: User-friendly interface for easy access to analysis tools and parameters. Worked Examples: Reproducible examples demonstrating the application of WaLSAtools to synthetic datasets, as featured in the associated Nature Reviews Methods Primers article. Documentation: Comprehensive documentation covering installation, usage, and analysis methods ( https://WaLSA.tools ) Multi-Language Support: Available in Python and IDL, with plans to expand to other languages. Python serves as the primary development language, while IDL support is partially implemented in this release, with ongoing development to achieve full feature parity. Known Issues \u00b6 Feature Parity Between Languages: While we aim for full consistency between the Python and IDL versions, some functions have not yet been fully translated into IDL. Efforts are ongoing to bridge these gaps in future updates. Future Developments \u00b6 We are committed to continuously enhancing WaLSAtools . Upcoming plans include: Expanded Functionality: New analysis methods, improved algorithms, and an enriched interactive experience. Broader Language Support: Further development in IDL, with potential expansion to MATLAB and other programming languages. Contributions and feedback are welcome to ensure WaLSAtools remains a valuable tool for wave analysis.", "title": "v1.0.0"}, {"location": "releases/v1.0.0/#walsatools-v100-initial-release", "text": "", "title": "WaLSAtools v1.0.0 \u2013 Initial Release"}, {"location": "releases/v1.0.0/#release-notes", "text": "We are excited to introduce WaLSAtools , an evolving open-source library for wave analysis that provides a solid foundation for comprehensive time-series exploration. This initial release equips users with essential tools for analysing a wide range of wave phenomena in time-series data, including: Core Analysis Modules: Fast Fourier Transform (FFT) Lomb-Scargle Approach Wavelet Transform Empirical Mode Decomposition (EMD) Hilbert-Huang Transform (HHT) Welch's Method k-\u03c9 Analysis Proper Orthogonal Decomposition (POD) Cross-Correlation Analysis Interactive Interface: User-friendly interface for easy access to analysis tools and parameters. Worked Examples: Reproducible examples demonstrating the application of WaLSAtools to synthetic datasets, as featured in the associated Nature Reviews Methods Primers article. Documentation: Comprehensive documentation covering installation, usage, and analysis methods ( https://WaLSA.tools ) Multi-Language Support: Available in Python and IDL, with plans to expand to other languages. Python serves as the primary development language, while IDL support is partially implemented in this release, with ongoing development to achieve full feature parity.", "title": "Release Notes"}, {"location": "releases/v1.0.0/#known-issues", "text": "Feature Parity Between Languages: While we aim for full consistency between the Python and IDL versions, some functions have not yet been fully translated into IDL. Efforts are ongoing to bridge these gaps in future updates.", "title": "Known Issues"}, {"location": "releases/v1.0.0/#future-developments", "text": "We are committed to continuously enhancing WaLSAtools . Upcoming plans include: Expanded Functionality: New analysis methods, improved algorithms, and an enriched interactive experience. Broader Language Support: Further development in IDL, with potential expansion to MATLAB and other programming languages. Contributions and feedback are welcome to ensure WaLSAtools remains a valuable tool for wave analysis.", "title": "Future Developments"}]}